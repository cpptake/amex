{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70f58d85-14e4-4371-ad96-458843ea228c",
   "metadata": {},
   "source": [
    "# exp37\n",
    "\n",
    "lag_diff„ÅÆXGB\n",
    "\n",
    "\n",
    "https://www.kaggle.com/code/ragnar123/amex-lgbm-dart-cv-0-7977"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "325051a6-7ea3-4398-b022-6a81c18b14eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Library\n",
    "# ====================================================\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "from tqdm.auto import tqdm\n",
    "import itertools\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "979ad950-7ef8-4116-97b7-0081786d9e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.0\n"
     ]
    }
   ],
   "source": [
    "print(xgb.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce478709-32b7-4d68-bda7-4928785a13b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/data/train.parquet'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15952\\217815574.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;31m# Read & Preprocess Data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m \u001b[0mread_preprocess_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15952\\217815574.py\u001b[0m in \u001b[0;36mread_preprocess_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;31m# ====================================================\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mread_preprocess_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/data/train.parquet'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m     \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'customer_ID'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'S_2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     cat_features = [\n",
      "\u001b[1;32m~\\anaconda3\\envs\\amex\\lib\\site-packages\\pandas\\io\\parquet.py\u001b[0m in \u001b[0;36mread_parquet\u001b[1;34m(path, engine, columns, storage_options, use_nullable_dtypes, **kwargs)\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    499\u001b[0m         \u001b[0muse_nullable_dtypes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_nullable_dtypes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 500\u001b[1;33m         \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    501\u001b[0m     )\n",
      "\u001b[1;32m~\\anaconda3\\envs\\amex\\lib\\site-packages\\pandas\\io\\parquet.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, path, columns, use_nullable_dtypes, storage_options, **kwargs)\u001b[0m\n\u001b[0;32m    234\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"filesystem\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 236\u001b[1;33m             \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    237\u001b[0m         )\n\u001b[0;32m    238\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\amex\\lib\\site-packages\\pandas\\io\\parquet.py\u001b[0m in \u001b[0;36m_get_path_or_handle\u001b[1;34m(path, fs, storage_options, mode, is_dir)\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[1;31m# this branch is used for example when reading from non-fsspec URLs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         handles = get_handle(\n\u001b[1;32m--> 102\u001b[1;33m             \u001b[0mpath_or_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m         )\n\u001b[0;32m    104\u001b[0m         \u001b[0mfs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\amex\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    709\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m             \u001b[1;31m# Binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 711\u001b[1;33m             \u001b[0mhandle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    712\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    713\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/data/train.parquet'"
     ]
    }
   ],
   "source": [
    "\n",
    "# ====================================================\n",
    "# Get the difference\n",
    "# ====================================================\n",
    "def get_difference(data, num_features):\n",
    "    df1 = []\n",
    "    customer_ids = []\n",
    "    for customer_id, df in tqdm(data.groupby(['customer_ID'])):\n",
    "        # Get the differences\n",
    "        diff_df1 = df[num_features].diff(1).iloc[[-1]].values.astype(np.float32)\n",
    "        # Append to lists\n",
    "        df1.append(diff_df1)\n",
    "        customer_ids.append(customer_id)\n",
    "    # Concatenate\n",
    "    df1 = np.concatenate(df1, axis = 0)\n",
    "    # Transform to dataframe\n",
    "    df1 = pd.DataFrame(df1, columns = [col + '_diff1' for col in df[num_features].columns])\n",
    "    # Add customer id\n",
    "    df1['customer_ID'] = customer_ids\n",
    "    return df1\n",
    "\n",
    "# ====================================================\n",
    "# Read & preprocess data and save it to disk\n",
    "# ====================================================\n",
    "def read_preprocess_data():\n",
    "    train = pd.read_parquet('/content/data/train.parquet')\n",
    "    features = train.drop(['customer_ID', 'S_2'], axis = 1).columns.to_list()\n",
    "    cat_features = [\n",
    "        \"B_30\",\n",
    "        \"B_38\",\n",
    "        \"D_114\",\n",
    "        \"D_116\",\n",
    "        \"D_117\",\n",
    "        \"D_120\",\n",
    "        \"D_126\",\n",
    "        \"D_63\",\n",
    "        \"D_64\",\n",
    "        \"D_66\",\n",
    "        \"D_68\",\n",
    "    ]\n",
    "    num_features = [col for col in features if col not in cat_features]\n",
    "    print('Starting training feature engineer...')\n",
    "    train_num_agg = train.groupby(\"customer_ID\")[num_features].agg(['mean', 'std', 'min', 'max', 'last'])\n",
    "    train_num_agg.columns = ['_'.join(x) for x in train_num_agg.columns]\n",
    "    train_num_agg.reset_index(inplace = True)\n",
    "    train_cat_agg = train.groupby(\"customer_ID\")[cat_features].agg(['count', 'last', 'nunique'])\n",
    "    train_cat_agg.columns = ['_'.join(x) for x in train_cat_agg.columns]\n",
    "    train_cat_agg.reset_index(inplace = True)\n",
    "    train_labels = pd.read_csv('../input/amex-default-prediction/train_labels.csv')\n",
    "    # Transform float64 columns to float32\n",
    "    cols = list(train_num_agg.dtypes[train_num_agg.dtypes == 'float64'].index)\n",
    "    for col in tqdm(cols):\n",
    "        train_num_agg[col] = train_num_agg[col].astype(np.float32)\n",
    "    # Transform int64 columns to int32\n",
    "    cols = list(train_cat_agg.dtypes[train_cat_agg.dtypes == 'int64'].index)\n",
    "    for col in tqdm(cols):\n",
    "        train_cat_agg[col] = train_cat_agg[col].astype(np.int32)\n",
    "    # Get the difference\n",
    "    train_diff = get_difference(train, num_features)\n",
    "    train = train_num_agg.merge(train_cat_agg, how = 'inner', on = 'customer_ID').merge(train_diff, how = 'inner', on = 'customer_ID').merge(train_labels, how = 'inner', on = 'customer_ID')\n",
    "    del train_num_agg, train_cat_agg, train_diff\n",
    "    gc.collect()\n",
    "    test = pd.read_parquet('../input/amex-fe/test_fe.parquet')\n",
    "    print('Starting test feature engineer...')\n",
    "    test_num_agg = test.groupby(\"customer_ID\")[num_features].agg(['mean', 'std', 'min', 'max', 'last'])\n",
    "    test_num_agg.columns = ['_'.join(x) for x in test_num_agg.columns]\n",
    "    test_num_agg.reset_index(inplace = True)\n",
    "    test_cat_agg = test.groupby(\"customer_ID\")[cat_features].agg(['count', 'last', 'nunique'])\n",
    "    test_cat_agg.columns = ['_'.join(x) for x in test_cat_agg.columns]\n",
    "    test_cat_agg.reset_index(inplace = True)\n",
    "    # Transform float64 columns to float32\n",
    "    cols = list(test_num_agg.dtypes[test_num_agg.dtypes == 'float64'].index)\n",
    "    for col in tqdm(cols):\n",
    "        test_num_agg[col] = test_num_agg[col].astype(np.float32)\n",
    "    # Transform int64 columns to int32\n",
    "    cols = list(test_cat_agg.dtypes[test_cat_agg.dtypes == 'int64'].index)\n",
    "    for col in tqdm(cols):\n",
    "        test_cat_agg[col] = test_cat_agg[col].astype(np.int32)\n",
    "    # Get the difference\n",
    "    test_diff = get_difference(test, num_features)\n",
    "    test = test_num_agg.merge(test_cat_agg, how = 'inner', on = 'customer_ID').merge(test_diff, how = 'inner', on = 'customer_ID')\n",
    "    del test_num_agg, test_cat_agg, test_diff\n",
    "    gc.collect()\n",
    "    # Save files to disk\n",
    "    train.to_parquet('../input/amex-fe/train_fe.parquet')\n",
    "    test.to_parquet('../input/amex-fe/test_fe.parquet')\n",
    "\n",
    "# Read & Preprocess Data\n",
    "read_preprocess_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e80847-25f2-4784-97c5-b8012eae1a3e",
   "metadata": {},
   "source": [
    "# Training & Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c68ef141-3c78-4cd6-988b-db0421753882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Library\n",
    "# ====================================================\n",
    "import os\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import random\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import itertools\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import lightgbm as lgb\n",
    "from itertools import combinations\n",
    "\n",
    "import pickle\n",
    "\n",
    "# ====================================================\n",
    "# Configurations\n",
    "# ====================================================\n",
    "class CFG:\n",
    "    \n",
    "    \n",
    "    # input_dir = '../feature/exp35_lagdiff/'\n",
    "    input_dir = '../feature/exp03_amex-fe/'\n",
    "    output_dir = '../output/exp50_cat_lagdiff_c3_statedate/'\n",
    "    seed = 42\n",
    "    n_folds = 5\n",
    "    target = 'target'\n",
    "    boosting_type = 'dart'\n",
    "    metric = 'binary_logloss'\n",
    "    model = \"cat\"\n",
    "    ver = \"exp50\"\n",
    "\n",
    "# ====================================================\n",
    "# Seed everything\n",
    "# ====================================================\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "# ====================================================\n",
    "# Read data\n",
    "# ====================================================\n",
    "# def read_data():\n",
    "#     train = pd.read_parquet(CFG.input_dir + 'train_diff.parquet')\n",
    "#     test = pd.read_parquet(CFG.input_dir + 'test_diff.parquet')\n",
    "#     return train, test\n",
    "\n",
    "def read_data():\n",
    "    train = pd.read_parquet(CFG.input_dir + 'train_fe_plus_plus.parquet')\n",
    "    test = pd.read_parquet(CFG.input_dir + 'test_fe_plus_plus.parquet')\n",
    "    return train, test\n",
    "\n",
    "# ====================================================\n",
    "# Amex metric\n",
    "# ====================================================\n",
    "def amex_metric(y_true, y_pred):\n",
    "    labels = np.transpose(np.array([y_true, y_pred]))\n",
    "    labels = labels[labels[:, 1].argsort()[::-1]]\n",
    "    weights = np.where(labels[:,0]==0, 20, 1)\n",
    "    cut_vals = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n",
    "    top_four = np.sum(cut_vals[:,0]) / np.sum(labels[:,0])\n",
    "    gini = [0,0]\n",
    "    for i in [1,0]:\n",
    "        labels = np.transpose(np.array([y_true, y_pred]))\n",
    "        labels = labels[labels[:, i].argsort()[::-1]]\n",
    "        weight = np.where(labels[:,0]==0, 20, 1)\n",
    "        weight_random = np.cumsum(weight / np.sum(weight))\n",
    "        total_pos = np.sum(labels[:, 0] *  weight)\n",
    "        cum_pos_found = np.cumsum(labels[:, 0] * weight)\n",
    "        lorentz = cum_pos_found / total_pos\n",
    "        gini[i] = np.sum((lorentz - weight_random) * weight)\n",
    "    return 0.5 * (gini[1]/gini[0] + top_four)\n",
    "\n",
    "# ====================================================\n",
    "# LGBM amex metric\n",
    "# ====================================================\n",
    "def lgb_amex_metric(y_pred, y_true):\n",
    "    y_true = y_true.get_label()\n",
    "    return 'amex_metric', amex_metric(y_true, y_pred), True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5df5be5-8119-4c74-965b-89abb98ff5a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(458913, 2025)\n",
      "(924621, 2024)\n"
     ]
    }
   ],
   "source": [
    "seed_everything(CFG.seed)\n",
    "\n",
    "train = pd.read_pickle('../feature/exp50_lagdiff_c3_statedate/train_lagdiff_c3_statedate.pkl')\n",
    "test = pd.read_pickle('../feature/exp50_lagdiff_c3_statedate/test_lagdiff_c3_statedate.pkl')\n",
    "\n",
    "# train_sd = pd.read_pickle(\"../feature/Statement Dates/train_SDist.pkl\")\n",
    "# test_sd = pd.read_pickle(\"../feature/Statement Dates/test_SDist.pkl\")\n",
    "\n",
    "\n",
    "# train = pd.read_parquet('../feature/exp35_lagdiff/train_lagdiff.parquet')\n",
    "# test = pd.read_parquet('../feature/exp35_lagdiff/test_lagdiff.parquet')\n",
    "\n",
    "# # train, test = read_data()\n",
    "\n",
    "# train_c3 = pd.read_pickle('../feature/exp18_4_tsfresh/train_c3.pkl')\n",
    "# test_c3 = pd.read_pickle('../feature/exp18_4_tsfresh/test_c3.pkl')\n",
    "\n",
    "# train = train.merge(train_sd,on = \"customer_ID\",how = \"left\")\n",
    "# test = test.merge(test_sd,on = \"customer_ID\",how = \"left\")\n",
    "\n",
    "# del train_sd,test_sd\n",
    "# gc.collect\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30007ce2-4854-4fd8-8c1b-477936511e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def xgb_amex(y_pred, y_true):\n",
    "    return 'amex', amex_metric_np(y_pred,y_true.get_label())\n",
    "\n",
    "\n",
    "def amex_metric_np(preds: np.ndarray, target: np.ndarray) -> float:\n",
    "    indices = np.argsort(preds)[::-1]\n",
    "    preds, target = preds[indices], target[indices]\n",
    "\n",
    "    weight = 20.0 - target * 19.0\n",
    "    cum_norm_weight = (weight / weight.sum()).cumsum()\n",
    "    four_pct_mask = cum_norm_weight <= 0.04\n",
    "    d = np.sum(target[four_pct_mask]) / np.sum(target)\n",
    "\n",
    "    weighted_target = target * weight\n",
    "    lorentz = (weighted_target / weighted_target.sum()).cumsum()\n",
    "    gini = ((lorentz - cum_norm_weight) * weight).sum()\n",
    "\n",
    "    n_pos = np.sum(target)\n",
    "    n_neg = target.shape[0] - n_pos\n",
    "    gini_max = 10 * n_neg * (n_pos + 20 * n_neg - 19) / (n_pos + 20 * n_neg)\n",
    "\n",
    "    g = gini / gini_max\n",
    "    return 0.5 * (g + d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f413ef2-75eb-4b37-8254-4c24be59662f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da1aef6c-6e01-413f-b9a0-46be991ca78e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "--------------------------------------------------\n",
      "Training fold 0 with 2023 features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6666713\ttest: 0.6665801\tbest: 0.6665801 (0)\ttotal: 840ms\tremaining: 2h 19m 58s\n",
      "100:\tlearn: 0.2440632\ttest: 0.2436376\tbest: 0.2436376 (100)\ttotal: 1m 9s\tremaining: 1h 53m 30s\n",
      "200:\tlearn: 0.2291157\ttest: 0.2296980\tbest: 0.2296980 (200)\ttotal: 2m 16s\tremaining: 1h 51m 9s\n",
      "300:\tlearn: 0.2234676\ttest: 0.2252200\tbest: 0.2252200 (300)\ttotal: 3m 23s\tremaining: 1h 49m 32s\n",
      "400:\tlearn: 0.2196969\ttest: 0.2227170\tbest: 0.2227170 (400)\ttotal: 4m 30s\tremaining: 1h 47m 57s\n",
      "500:\tlearn: 0.2169216\ttest: 0.2211465\tbest: 0.2211465 (500)\ttotal: 5m 37s\tremaining: 1h 46m 44s\n",
      "600:\tlearn: 0.2144739\ttest: 0.2199916\tbest: 0.2199916 (600)\ttotal: 6m 43s\tremaining: 1h 45m 9s\n",
      "700:\tlearn: 0.2120083\ttest: 0.2190870\tbest: 0.2190870 (700)\ttotal: 7m 52s\tremaining: 1h 44m 23s\n",
      "800:\tlearn: 0.2096348\ttest: 0.2183694\tbest: 0.2183694 (800)\ttotal: 8m 57s\tremaining: 1h 42m 46s\n",
      "900:\tlearn: 0.2074275\ttest: 0.2178640\tbest: 0.2178640 (900)\ttotal: 10m 4s\tremaining: 1h 41m 45s\n",
      "1000:\tlearn: 0.2054126\ttest: 0.2174640\tbest: 0.2174640 (1000)\ttotal: 11m 8s\tremaining: 1h 40m 11s\n",
      "1100:\tlearn: 0.2034647\ttest: 0.2171200\tbest: 0.2171200 (1100)\ttotal: 12m 13s\tremaining: 1h 38m 49s\n",
      "1200:\tlearn: 0.2016028\ttest: 0.2168263\tbest: 0.2168263 (1200)\ttotal: 13m 15s\tremaining: 1h 37m 8s\n",
      "1300:\tlearn: 0.1999235\ttest: 0.2165854\tbest: 0.2165854 (1300)\ttotal: 14m 17s\tremaining: 1h 35m 30s\n",
      "1400:\tlearn: 0.1983095\ttest: 0.2163759\tbest: 0.2163759 (1400)\ttotal: 15m 17s\tremaining: 1h 33m 48s\n",
      "1500:\tlearn: 0.1967349\ttest: 0.2161710\tbest: 0.2161710 (1500)\ttotal: 16m 20s\tremaining: 1h 32m 33s\n",
      "1600:\tlearn: 0.1952025\ttest: 0.2159916\tbest: 0.2159916 (1600)\ttotal: 17m 20s\tremaining: 1h 30m 59s\n",
      "1700:\tlearn: 0.1936139\ttest: 0.2158122\tbest: 0.2158122 (1700)\ttotal: 18m 22s\tremaining: 1h 29m 39s\n",
      "1800:\tlearn: 0.1921369\ttest: 0.2157052\tbest: 0.2157052 (1800)\ttotal: 19m 22s\tremaining: 1h 28m 10s\n",
      "1900:\tlearn: 0.1906402\ttest: 0.2155941\tbest: 0.2155917 (1899)\ttotal: 20m 23s\tremaining: 1h 26m 52s\n",
      "2000:\tlearn: 0.1891924\ttest: 0.2154682\tbest: 0.2154675 (1992)\ttotal: 21m 25s\tremaining: 1h 25m 37s\n",
      "2100:\tlearn: 0.1877482\ttest: 0.2153470\tbest: 0.2153470 (2100)\ttotal: 22m 30s\tremaining: 1h 24m 35s\n",
      "2200:\tlearn: 0.1862955\ttest: 0.2152401\tbest: 0.2152401 (2200)\ttotal: 23m 35s\tremaining: 1h 23m 36s\n",
      "2300:\tlearn: 0.1848874\ttest: 0.2151376\tbest: 0.2151376 (2300)\ttotal: 24m 40s\tremaining: 1h 22m 33s\n",
      "2400:\tlearn: 0.1834887\ttest: 0.2150546\tbest: 0.2150519 (2392)\ttotal: 25m 43s\tremaining: 1h 21m 24s\n",
      "2500:\tlearn: 0.1820814\ttest: 0.2149926\tbest: 0.2149887 (2490)\ttotal: 26m 47s\tremaining: 1h 20m 18s\n",
      "2600:\tlearn: 0.1807400\ttest: 0.2149209\tbest: 0.2149209 (2600)\ttotal: 27m 52s\tremaining: 1h 19m 17s\n",
      "2700:\tlearn: 0.1794247\ttest: 0.2148280\tbest: 0.2148280 (2700)\ttotal: 28m 56s\tremaining: 1h 18m 12s\n",
      "2800:\tlearn: 0.1781177\ttest: 0.2147734\tbest: 0.2147726 (2786)\ttotal: 30m 2s\tremaining: 1h 17m 11s\n",
      "2900:\tlearn: 0.1767729\ttest: 0.2146929\tbest: 0.2146929 (2900)\ttotal: 31m 6s\tremaining: 1h 16m 7s\n",
      "3000:\tlearn: 0.1755195\ttest: 0.2146177\tbest: 0.2146153 (2991)\ttotal: 32m 10s\tremaining: 1h 15m 2s\n",
      "3100:\tlearn: 0.1742954\ttest: 0.2145389\tbest: 0.2145385 (3099)\ttotal: 33m 13s\tremaining: 1h 13m 55s\n",
      "3200:\tlearn: 0.1730155\ttest: 0.2145152\tbest: 0.2145152 (3200)\ttotal: 34m 19s\tremaining: 1h 12m 53s\n",
      "3300:\tlearn: 0.1717541\ttest: 0.2144865\tbest: 0.2144865 (3300)\ttotal: 35m 23s\tremaining: 1h 11m 49s\n",
      "3400:\tlearn: 0.1705528\ttest: 0.2144282\tbest: 0.2144229 (3397)\ttotal: 36m 29s\tremaining: 1h 10m 47s\n",
      "3500:\tlearn: 0.1693172\ttest: 0.2143679\tbest: 0.2143672 (3498)\ttotal: 37m 32s\tremaining: 1h 9m 41s\n",
      "3600:\tlearn: 0.1681238\ttest: 0.2143327\tbest: 0.2143309 (3586)\ttotal: 38m 35s\tremaining: 1h 8m 33s\n",
      "3700:\tlearn: 0.1669749\ttest: 0.2142879\tbest: 0.2142855 (3691)\ttotal: 39m 38s\tremaining: 1h 7m 27s\n",
      "3800:\tlearn: 0.1657561\ttest: 0.2142382\tbest: 0.2142372 (3799)\ttotal: 40m 44s\tremaining: 1h 6m 26s\n",
      "3900:\tlearn: 0.1645984\ttest: 0.2142213\tbest: 0.2142210 (3894)\ttotal: 41m 48s\tremaining: 1h 5m 21s\n",
      "4000:\tlearn: 0.1634391\ttest: 0.2141895\tbest: 0.2141871 (3992)\ttotal: 42m 52s\tremaining: 1h 4m 16s\n",
      "4100:\tlearn: 0.1623139\ttest: 0.2141417\tbest: 0.2141408 (4099)\ttotal: 43m 54s\tremaining: 1h 3m 8s\n",
      "4200:\tlearn: 0.1612075\ttest: 0.2140834\tbest: 0.2140834 (4200)\ttotal: 44m 56s\tremaining: 1h 2m 1s\n",
      "4300:\tlearn: 0.1600746\ttest: 0.2140576\tbest: 0.2140573 (4296)\ttotal: 46m 2s\tremaining: 1h 59s\n",
      "4400:\tlearn: 0.1589983\ttest: 0.2140246\tbest: 0.2140202 (4381)\ttotal: 47m 6s\tremaining: 59m 55s\n",
      "4500:\tlearn: 0.1579820\ttest: 0.2140226\tbest: 0.2140202 (4381)\ttotal: 48m 10s\tremaining: 58m 51s\n",
      "4600:\tlearn: 0.1568817\ttest: 0.2140063\tbest: 0.2139944 (4580)\ttotal: 49m 15s\tremaining: 57m 47s\n",
      "4700:\tlearn: 0.1558241\ttest: 0.2139890\tbest: 0.2139838 (4696)\ttotal: 50m 20s\tremaining: 56m 44s\n",
      "4800:\tlearn: 0.1547420\ttest: 0.2139874\tbest: 0.2139673 (4753)\ttotal: 51m 25s\tremaining: 55m 40s\n",
      "4900:\tlearn: 0.1536604\ttest: 0.2139852\tbest: 0.2139673 (4753)\ttotal: 52m 32s\tremaining: 54m 39s\n",
      "5000:\tlearn: 0.1525454\ttest: 0.2139917\tbest: 0.2139673 (4753)\ttotal: 53m 38s\tremaining: 53m 36s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 0.2139673126\n",
      "bestIteration = 4753\n",
      "\n",
      "Shrink model to first 4754 iterations.\n",
      "Our fold 0 CV score is 0.8002812098656482\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 1 with 2023 features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6663197\ttest: 0.6663039\tbest: 0.6663039 (0)\ttotal: 775ms\tremaining: 2h 9m 10s\n",
      "100:\tlearn: 0.2432105\ttest: 0.2447661\tbest: 0.2447661 (100)\ttotal: 1m 12s\tremaining: 1h 59m 3s\n",
      "200:\tlearn: 0.2283197\ttest: 0.2317001\tbest: 0.2317001 (200)\ttotal: 2m 22s\tremaining: 1h 55m 29s\n",
      "300:\tlearn: 0.2226394\ttest: 0.2274801\tbest: 0.2274801 (300)\ttotal: 3m 30s\tremaining: 1h 53m 10s\n",
      "400:\tlearn: 0.2189235\ttest: 0.2251866\tbest: 0.2251866 (400)\ttotal: 4m 39s\tremaining: 1h 51m 19s\n",
      "500:\tlearn: 0.2160137\ttest: 0.2237084\tbest: 0.2237084 (500)\ttotal: 5m 48s\tremaining: 1h 50m 2s\n",
      "600:\tlearn: 0.2135561\ttest: 0.2226505\tbest: 0.2226505 (600)\ttotal: 6m 57s\tremaining: 1h 48m 52s\n",
      "700:\tlearn: 0.2111418\ttest: 0.2218346\tbest: 0.2218346 (700)\ttotal: 8m 8s\tremaining: 1h 47m 57s\n",
      "800:\tlearn: 0.2087545\ttest: 0.2211944\tbest: 0.2211944 (800)\ttotal: 9m 17s\tremaining: 1h 46m 46s\n",
      "900:\tlearn: 0.2064980\ttest: 0.2207277\tbest: 0.2207277 (900)\ttotal: 10m 27s\tremaining: 1h 45m 32s\n",
      "1000:\tlearn: 0.2044044\ttest: 0.2203871\tbest: 0.2203871 (1000)\ttotal: 11m 35s\tremaining: 1h 44m 11s\n",
      "1100:\tlearn: 0.2024660\ttest: 0.2200848\tbest: 0.2200848 (1100)\ttotal: 12m 41s\tremaining: 1h 42m 34s\n",
      "1200:\tlearn: 0.2006895\ttest: 0.2198459\tbest: 0.2198459 (1200)\ttotal: 13m 48s\tremaining: 1h 41m 5s\n",
      "1300:\tlearn: 0.1989527\ttest: 0.2196682\tbest: 0.2196682 (1300)\ttotal: 14m 52s\tremaining: 1h 39m 28s\n",
      "1400:\tlearn: 0.1972626\ttest: 0.2194677\tbest: 0.2194677 (1400)\ttotal: 15m 59s\tremaining: 1h 38m 10s\n",
      "1500:\tlearn: 0.1955955\ttest: 0.2193127\tbest: 0.2193125 (1499)\ttotal: 17m 6s\tremaining: 1h 36m 54s\n",
      "1600:\tlearn: 0.1940383\ttest: 0.2191904\tbest: 0.2191904 (1599)\ttotal: 18m 13s\tremaining: 1h 35m 34s\n",
      "1700:\tlearn: 0.1923419\ttest: 0.2190545\tbest: 0.2190545 (1700)\ttotal: 19m 18s\tremaining: 1h 34m 11s\n",
      "1800:\tlearn: 0.1908367\ttest: 0.2189695\tbest: 0.2189695 (1800)\ttotal: 20m 22s\tremaining: 1h 32m 42s\n",
      "1900:\tlearn: 0.1893951\ttest: 0.2188923\tbest: 0.2188923 (1899)\ttotal: 21m 23s\tremaining: 1h 31m 9s\n",
      "2000:\tlearn: 0.1878936\ttest: 0.2187740\tbest: 0.2187740 (2000)\ttotal: 22m 28s\tremaining: 1h 29m 51s\n",
      "2100:\tlearn: 0.1863764\ttest: 0.2186996\tbest: 0.2186996 (2100)\ttotal: 23m 35s\tremaining: 1h 28m 41s\n",
      "2200:\tlearn: 0.1849090\ttest: 0.2186161\tbest: 0.2186161 (2200)\ttotal: 24m 42s\tremaining: 1h 27m 31s\n",
      "2300:\tlearn: 0.1835977\ttest: 0.2185607\tbest: 0.2185606 (2299)\ttotal: 25m 45s\tremaining: 1h 26m 10s\n",
      "2400:\tlearn: 0.1822154\ttest: 0.2184988\tbest: 0.2184985 (2398)\ttotal: 26m 49s\tremaining: 1h 24m 52s\n",
      "2500:\tlearn: 0.1808878\ttest: 0.2184042\tbest: 0.2184042 (2500)\ttotal: 27m 55s\tremaining: 1h 23m 41s\n",
      "2600:\tlearn: 0.1795575\ttest: 0.2183775\tbest: 0.2183774 (2599)\ttotal: 28m 59s\tremaining: 1h 22m 28s\n",
      "2700:\tlearn: 0.1781998\ttest: 0.2183195\tbest: 0.2183186 (2697)\ttotal: 30m 5s\tremaining: 1h 21m 18s\n",
      "2800:\tlearn: 0.1769131\ttest: 0.2182810\tbest: 0.2182803 (2785)\ttotal: 31m 10s\tremaining: 1h 20m 5s\n",
      "2900:\tlearn: 0.1756356\ttest: 0.2182208\tbest: 0.2182208 (2900)\ttotal: 32m 12s\tremaining: 1h 18m 48s\n",
      "3000:\tlearn: 0.1743573\ttest: 0.2181890\tbest: 0.2181884 (2997)\ttotal: 33m 12s\tremaining: 1h 17m 26s\n",
      "3100:\tlearn: 0.1730363\ttest: 0.2181412\tbest: 0.2181412 (3100)\ttotal: 34m 14s\tremaining: 1h 16m 9s\n",
      "3200:\tlearn: 0.1717561\ttest: 0.2180928\tbest: 0.2180928 (3198)\ttotal: 35m 15s\tremaining: 1h 14m 52s\n",
      "3300:\tlearn: 0.1705041\ttest: 0.2180580\tbest: 0.2180546 (3289)\ttotal: 36m 18s\tremaining: 1h 13m 40s\n",
      "3400:\tlearn: 0.1692547\ttest: 0.2180144\tbest: 0.2180126 (3399)\ttotal: 37m 21s\tremaining: 1h 12m 29s\n",
      "3500:\tlearn: 0.1680890\ttest: 0.2179987\tbest: 0.2179946 (3495)\ttotal: 38m 24s\tremaining: 1h 11m 16s\n",
      "3600:\tlearn: 0.1669069\ttest: 0.2179598\tbest: 0.2179598 (3600)\ttotal: 39m 28s\tremaining: 1h 10m 7s\n",
      "3700:\tlearn: 0.1657144\ttest: 0.2179254\tbest: 0.2179234 (3698)\ttotal: 40m 32s\tremaining: 1h 8m 58s\n",
      "3800:\tlearn: 0.1645181\ttest: 0.2178819\tbest: 0.2178819 (3800)\ttotal: 41m 36s\tremaining: 1h 7m 51s\n",
      "3900:\tlearn: 0.1633470\ttest: 0.2178722\tbest: 0.2178579 (3846)\ttotal: 42m 43s\tremaining: 1h 6m 47s\n",
      "4000:\tlearn: 0.1622530\ttest: 0.2178597\tbest: 0.2178519 (3992)\ttotal: 43m 48s\tremaining: 1h 5m 39s\n",
      "4100:\tlearn: 0.1610982\ttest: 0.2178548\tbest: 0.2178508 (4089)\ttotal: 44m 53s\tremaining: 1h 4m 33s\n",
      "4200:\tlearn: 0.1599509\ttest: 0.2178638\tbest: 0.2178508 (4089)\ttotal: 45m 57s\tremaining: 1h 3m 25s\n",
      "4300:\tlearn: 0.1588241\ttest: 0.2178519\tbest: 0.2178506 (4299)\ttotal: 47m 1s\tremaining: 1h 2m 18s\n",
      "4400:\tlearn: 0.1576882\ttest: 0.2178497\tbest: 0.2178427 (4338)\ttotal: 48m 6s\tremaining: 1h 1m 11s\n",
      "4500:\tlearn: 0.1566083\ttest: 0.2178286\tbest: 0.2178286 (4500)\ttotal: 49m 8s\tremaining: 1h 1s\n",
      "4600:\tlearn: 0.1555144\ttest: 0.2178296\tbest: 0.2178218 (4531)\ttotal: 50m 12s\tremaining: 58m 54s\n",
      "4700:\tlearn: 0.1544696\ttest: 0.2178147\tbest: 0.2178145 (4646)\ttotal: 51m 13s\tremaining: 57m 44s\n",
      "4800:\tlearn: 0.1534283\ttest: 0.2178273\tbest: 0.2178145 (4646)\ttotal: 52m 14s\tremaining: 56m 33s\n",
      "4900:\tlearn: 0.1523744\ttest: 0.2178373\tbest: 0.2178145 (4646)\ttotal: 53m 15s\tremaining: 55m 23s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 0.2178144921\n",
      "bestIteration = 4646\n",
      "\n",
      "Shrink model to first 4647 iterations.\n",
      "Our fold 1 CV score is 0.7911216058897713\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 2 with 2023 features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6663695\ttest: 0.6664397\tbest: 0.6664397 (0)\ttotal: 704ms\tremaining: 1h 57m 17s\n",
      "100:\tlearn: 0.2431038\ttest: 0.2451029\tbest: 0.2451029 (100)\ttotal: 1m 9s\tremaining: 1h 53m 18s\n",
      "200:\tlearn: 0.2283869\ttest: 0.2317666\tbest: 0.2317666 (200)\ttotal: 2m 14s\tremaining: 1h 49m 29s\n",
      "300:\tlearn: 0.2227001\ttest: 0.2274790\tbest: 0.2274790 (300)\ttotal: 3m 20s\tremaining: 1h 47m 53s\n",
      "400:\tlearn: 0.2190049\ttest: 0.2251348\tbest: 0.2251348 (400)\ttotal: 4m 26s\tremaining: 1h 46m 21s\n",
      "500:\tlearn: 0.2161721\ttest: 0.2236208\tbest: 0.2236208 (500)\ttotal: 5m 31s\tremaining: 1h 44m 40s\n",
      "600:\tlearn: 0.2137192\ttest: 0.2225686\tbest: 0.2225686 (600)\ttotal: 6m 36s\tremaining: 1h 43m 17s\n",
      "700:\tlearn: 0.2113207\ttest: 0.2217051\tbest: 0.2217051 (700)\ttotal: 7m 40s\tremaining: 1h 41m 52s\n",
      "800:\tlearn: 0.2090057\ttest: 0.2210156\tbest: 0.2210156 (800)\ttotal: 8m 44s\tremaining: 1h 40m 25s\n",
      "900:\tlearn: 0.2068579\ttest: 0.2204802\tbest: 0.2204802 (900)\ttotal: 9m 46s\tremaining: 1h 38m 44s\n",
      "1000:\tlearn: 0.2048320\ttest: 0.2201189\tbest: 0.2201189 (1000)\ttotal: 10m 49s\tremaining: 1h 37m 22s\n",
      "1100:\tlearn: 0.2028911\ttest: 0.2197768\tbest: 0.2197768 (1100)\ttotal: 11m 51s\tremaining: 1h 35m 53s\n",
      "1200:\tlearn: 0.2009937\ttest: 0.2194831\tbest: 0.2194831 (1200)\ttotal: 12m 54s\tremaining: 1h 34m 35s\n",
      "1300:\tlearn: 0.1992903\ttest: 0.2192376\tbest: 0.2192376 (1300)\ttotal: 13m 55s\tremaining: 1h 33m 5s\n",
      "1400:\tlearn: 0.1976928\ttest: 0.2190177\tbest: 0.2190177 (1400)\ttotal: 14m 55s\tremaining: 1h 31m 38s\n",
      "1500:\tlearn: 0.1961747\ttest: 0.2188417\tbest: 0.2188417 (1500)\ttotal: 15m 54s\tremaining: 1h 30m 6s\n",
      "1600:\tlearn: 0.1945574\ttest: 0.2186890\tbest: 0.2186879 (1598)\ttotal: 16m 56s\tremaining: 1h 28m 51s\n",
      "1700:\tlearn: 0.1929882\ttest: 0.2185483\tbest: 0.2185481 (1698)\ttotal: 17m 56s\tremaining: 1h 27m 32s\n",
      "1800:\tlearn: 0.1915200\ttest: 0.2184354\tbest: 0.2184354 (1800)\ttotal: 18m 57s\tremaining: 1h 26m 16s\n",
      "1900:\tlearn: 0.1900260\ttest: 0.2183223\tbest: 0.2183223 (1900)\ttotal: 19m 57s\tremaining: 1h 25m 1s\n",
      "2000:\tlearn: 0.1885345\ttest: 0.2181895\tbest: 0.2181895 (2000)\ttotal: 20m 59s\tremaining: 1h 23m 55s\n",
      "2100:\tlearn: 0.1871001\ttest: 0.2181004\tbest: 0.2181004 (2100)\ttotal: 22m 1s\tremaining: 1h 22m 47s\n",
      "2200:\tlearn: 0.1856391\ttest: 0.2180298\tbest: 0.2180280 (2189)\ttotal: 23m 4s\tremaining: 1h 21m 44s\n",
      "2300:\tlearn: 0.1842379\ttest: 0.2179799\tbest: 0.2179799 (2300)\ttotal: 24m 5s\tremaining: 1h 20m 36s\n",
      "2400:\tlearn: 0.1828594\ttest: 0.2179071\tbest: 0.2179066 (2395)\ttotal: 25m 6s\tremaining: 1h 19m 28s\n",
      "2500:\tlearn: 0.1815474\ttest: 0.2178204\tbest: 0.2178184 (2498)\ttotal: 26m 6s\tremaining: 1h 18m 15s\n",
      "2600:\tlearn: 0.1802131\ttest: 0.2177450\tbest: 0.2177450 (2600)\ttotal: 27m 7s\tremaining: 1h 17m 9s\n",
      "2700:\tlearn: 0.1789164\ttest: 0.2176839\tbest: 0.2176786 (2688)\ttotal: 28m 7s\tremaining: 1h 15m 59s\n",
      "2800:\tlearn: 0.1776308\ttest: 0.2176095\tbest: 0.2176095 (2800)\ttotal: 29m 8s\tremaining: 1h 14m 52s\n",
      "2900:\tlearn: 0.1763255\ttest: 0.2175422\tbest: 0.2175417 (2899)\ttotal: 30m 8s\tremaining: 1h 13m 44s\n",
      "3000:\tlearn: 0.1750300\ttest: 0.2174764\tbest: 0.2174749 (2999)\ttotal: 31m 9s\tremaining: 1h 12m 38s\n",
      "3100:\tlearn: 0.1737582\ttest: 0.2174287\tbest: 0.2174287 (3100)\ttotal: 32m 9s\tremaining: 1h 11m 32s\n",
      "3200:\tlearn: 0.1724854\ttest: 0.2173774\tbest: 0.2173774 (3200)\ttotal: 33m 11s\tremaining: 1h 10m 28s\n",
      "3300:\tlearn: 0.1713174\ttest: 0.2173198\tbest: 0.2173096 (3288)\ttotal: 34m 10s\tremaining: 1h 9m 21s\n",
      "3400:\tlearn: 0.1700659\ttest: 0.2172856\tbest: 0.2172835 (3394)\ttotal: 35m 12s\tremaining: 1h 8m 17s\n",
      "3500:\tlearn: 0.1688897\ttest: 0.2172430\tbest: 0.2172386 (3488)\ttotal: 36m 11s\tremaining: 1h 7m 10s\n",
      "3600:\tlearn: 0.1676591\ttest: 0.2172152\tbest: 0.2172145 (3597)\ttotal: 37m 13s\tremaining: 1h 6m 7s\n",
      "3700:\tlearn: 0.1664592\ttest: 0.2171988\tbest: 0.2171923 (3684)\ttotal: 38m 13s\tremaining: 1h 5m 3s\n",
      "3800:\tlearn: 0.1652793\ttest: 0.2171618\tbest: 0.2171569 (3795)\ttotal: 39m 14s\tremaining: 1h 3m 59s\n",
      "3900:\tlearn: 0.1641260\ttest: 0.2171217\tbest: 0.2171186 (3899)\ttotal: 40m 15s\tremaining: 1h 2m 55s\n",
      "4000:\tlearn: 0.1629505\ttest: 0.2171207\tbest: 0.2171168 (3918)\ttotal: 41m 16s\tremaining: 1h 1m 52s\n",
      "4100:\tlearn: 0.1617979\ttest: 0.2170779\tbest: 0.2170773 (4099)\ttotal: 42m 17s\tremaining: 1h 48s\n",
      "4200:\tlearn: 0.1606640\ttest: 0.2170398\tbest: 0.2170286 (4189)\ttotal: 43m 18s\tremaining: 59m 45s\n",
      "4300:\tlearn: 0.1595592\ttest: 0.2170342\tbest: 0.2170286 (4189)\ttotal: 44m 19s\tremaining: 58m 42s\n",
      "4400:\tlearn: 0.1584371\ttest: 0.2170235\tbest: 0.2170224 (4396)\ttotal: 45m 20s\tremaining: 57m 40s\n",
      "4500:\tlearn: 0.1573727\ttest: 0.2169840\tbest: 0.2169840 (4500)\ttotal: 46m 21s\tremaining: 56m 37s\n",
      "4600:\tlearn: 0.1563154\ttest: 0.2169541\tbest: 0.2169496 (4592)\ttotal: 47m 21s\tremaining: 55m 34s\n",
      "4700:\tlearn: 0.1552169\ttest: 0.2169415\tbest: 0.2169331 (4684)\ttotal: 48m 22s\tremaining: 54m 31s\n",
      "4800:\tlearn: 0.1542002\ttest: 0.2169164\tbest: 0.2169109 (4760)\ttotal: 49m 22s\tremaining: 53m 27s\n",
      "4900:\tlearn: 0.1531691\ttest: 0.2169078\tbest: 0.2169055 (4822)\ttotal: 50m 23s\tremaining: 52m 25s\n",
      "5000:\tlearn: 0.1521254\ttest: 0.2169011\tbest: 0.2168870 (4972)\ttotal: 51m 24s\tremaining: 51m 22s\n",
      "5100:\tlearn: 0.1511019\ttest: 0.2168742\tbest: 0.2168742 (5100)\ttotal: 52m 26s\tremaining: 50m 20s\n",
      "5200:\tlearn: 0.1500907\ttest: 0.2168499\tbest: 0.2168435 (5199)\ttotal: 53m 26s\tremaining: 49m 18s\n",
      "5300:\tlearn: 0.1490875\ttest: 0.2168157\tbest: 0.2168151 (5299)\ttotal: 54m 27s\tremaining: 48m 16s\n",
      "5400:\tlearn: 0.1481068\ttest: 0.2167958\tbest: 0.2167920 (5396)\ttotal: 55m 29s\tremaining: 47m 14s\n",
      "5500:\tlearn: 0.1471329\ttest: 0.2167742\tbest: 0.2167724 (5495)\ttotal: 56m 31s\tremaining: 46m 12s\n",
      "5600:\tlearn: 0.1462180\ttest: 0.2167529\tbest: 0.2167483 (5583)\ttotal: 57m 31s\tremaining: 45m 10s\n",
      "5700:\tlearn: 0.1452434\ttest: 0.2167731\tbest: 0.2167483 (5583)\ttotal: 58m 33s\tremaining: 44m 8s\n",
      "5800:\tlearn: 0.1442865\ttest: 0.2167610\tbest: 0.2167483 (5583)\ttotal: 59m 33s\tremaining: 43m 6s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 0.2167483289\n",
      "bestIteration = 5583\n",
      "\n",
      "Shrink model to first 5584 iterations.\n",
      "Our fold 2 CV score is 0.795475256167435\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 3 with 2023 features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6672453\ttest: 0.6673725\tbest: 0.6673725 (0)\ttotal: 680ms\tremaining: 1h 53m 15s\n",
      "100:\tlearn: 0.2430787\ttest: 0.2463725\tbest: 0.2463725 (100)\ttotal: 1m 8s\tremaining: 1h 51m 28s\n",
      "200:\tlearn: 0.2281307\ttest: 0.2329538\tbest: 0.2329538 (200)\ttotal: 2m 14s\tremaining: 1h 49m 12s\n",
      "300:\tlearn: 0.2226103\ttest: 0.2288085\tbest: 0.2288085 (300)\ttotal: 3m 19s\tremaining: 1h 47m 11s\n",
      "400:\tlearn: 0.2188789\ttest: 0.2264208\tbest: 0.2264208 (400)\ttotal: 4m 25s\tremaining: 1h 45m 51s\n",
      "500:\tlearn: 0.2160322\ttest: 0.2248972\tbest: 0.2248972 (500)\ttotal: 5m 29s\tremaining: 1h 44m 9s\n",
      "600:\tlearn: 0.2135432\ttest: 0.2237640\tbest: 0.2237640 (600)\ttotal: 6m 34s\tremaining: 1h 42m 51s\n",
      "700:\tlearn: 0.2111571\ttest: 0.2228890\tbest: 0.2228890 (700)\ttotal: 7m 38s\tremaining: 1h 41m 25s\n",
      "800:\tlearn: 0.2087712\ttest: 0.2222017\tbest: 0.2222017 (800)\ttotal: 8m 42s\tremaining: 1h 39m 58s\n",
      "900:\tlearn: 0.2065566\ttest: 0.2216631\tbest: 0.2216631 (900)\ttotal: 9m 45s\tremaining: 1h 38m 35s\n",
      "1000:\tlearn: 0.2045800\ttest: 0.2212732\tbest: 0.2212732 (1000)\ttotal: 10m 47s\tremaining: 1h 36m 59s\n",
      "1100:\tlearn: 0.2026277\ttest: 0.2209338\tbest: 0.2209338 (1100)\ttotal: 11m 49s\tremaining: 1h 35m 37s\n",
      "1200:\tlearn: 0.2007749\ttest: 0.2206633\tbest: 0.2206633 (1200)\ttotal: 12m 51s\tremaining: 1h 34m 12s\n",
      "1300:\tlearn: 0.1989877\ttest: 0.2204379\tbest: 0.2204379 (1300)\ttotal: 13m 54s\tremaining: 1h 32m 57s\n",
      "1400:\tlearn: 0.1972876\ttest: 0.2202509\tbest: 0.2202509 (1400)\ttotal: 14m 55s\tremaining: 1h 31m 32s\n",
      "1500:\tlearn: 0.1956401\ttest: 0.2200918\tbest: 0.2200864 (1496)\ttotal: 15m 57s\tremaining: 1h 30m 20s\n",
      "1600:\tlearn: 0.1940231\ttest: 0.2199473\tbest: 0.2199473 (1600)\ttotal: 16m 58s\tremaining: 1h 29m 3s\n",
      "1700:\tlearn: 0.1924740\ttest: 0.2198455\tbest: 0.2198447 (1694)\ttotal: 18m\tremaining: 1h 27m 52s\n",
      "1800:\tlearn: 0.1909320\ttest: 0.2197310\tbest: 0.2197301 (1798)\ttotal: 19m 1s\tremaining: 1h 26m 36s\n",
      "1900:\tlearn: 0.1894535\ttest: 0.2196325\tbest: 0.2196325 (1900)\ttotal: 20m 3s\tremaining: 1h 25m 24s\n",
      "2000:\tlearn: 0.1879971\ttest: 0.2195200\tbest: 0.2195200 (2000)\ttotal: 21m 3s\tremaining: 1h 24m 9s\n",
      "2100:\tlearn: 0.1866011\ttest: 0.2194170\tbest: 0.2194170 (2100)\ttotal: 22m 4s\tremaining: 1h 22m 58s\n",
      "2200:\tlearn: 0.1852193\ttest: 0.2193207\tbest: 0.2193207 (2200)\ttotal: 23m 5s\tremaining: 1h 21m 47s\n",
      "2300:\tlearn: 0.1838354\ttest: 0.2192780\tbest: 0.2192750 (2294)\ttotal: 24m 6s\tremaining: 1h 20m 38s\n",
      "2400:\tlearn: 0.1825170\ttest: 0.2192417\tbest: 0.2192336 (2381)\ttotal: 25m 5s\tremaining: 1h 19m 25s\n",
      "2500:\tlearn: 0.1812348\ttest: 0.2191671\tbest: 0.2191660 (2499)\ttotal: 26m 6s\tremaining: 1h 18m 16s\n",
      "2600:\tlearn: 0.1799413\ttest: 0.2191221\tbest: 0.2191220 (2592)\ttotal: 27m 6s\tremaining: 1h 17m 6s\n",
      "2700:\tlearn: 0.1785920\ttest: 0.2190575\tbest: 0.2190571 (2699)\ttotal: 28m 9s\tremaining: 1h 16m 5s\n",
      "2800:\tlearn: 0.1773053\ttest: 0.2190036\tbest: 0.2190036 (2800)\ttotal: 29m 11s\tremaining: 1h 15m\n",
      "2900:\tlearn: 0.1760436\ttest: 0.2189512\tbest: 0.2189446 (2897)\ttotal: 30m 13s\tremaining: 1h 13m 56s\n",
      "3000:\tlearn: 0.1747919\ttest: 0.2188842\tbest: 0.2188842 (3000)\ttotal: 31m 14s\tremaining: 1h 12m 51s\n",
      "3100:\tlearn: 0.1735547\ttest: 0.2188632\tbest: 0.2188587 (3054)\ttotal: 32m 15s\tremaining: 1h 11m 46s\n",
      "3200:\tlearn: 0.1723397\ttest: 0.2188141\tbest: 0.2188141 (3200)\ttotal: 33m 15s\tremaining: 1h 10m 38s\n",
      "3300:\tlearn: 0.1710819\ttest: 0.2187641\tbest: 0.2187586 (3295)\ttotal: 34m 17s\tremaining: 1h 9m 35s\n",
      "3400:\tlearn: 0.1698769\ttest: 0.2187204\tbest: 0.2187204 (3400)\ttotal: 35m 17s\tremaining: 1h 8m 28s\n",
      "3500:\tlearn: 0.1686456\ttest: 0.2186589\tbest: 0.2186553 (3496)\ttotal: 36m 19s\tremaining: 1h 7m 25s\n",
      "3600:\tlearn: 0.1674643\ttest: 0.2186448\tbest: 0.2186431 (3590)\ttotal: 37m 19s\tremaining: 1h 6m 19s\n",
      "3700:\tlearn: 0.1663296\ttest: 0.2186181\tbest: 0.2186175 (3669)\ttotal: 38m 21s\tremaining: 1h 5m 15s\n",
      "3800:\tlearn: 0.1652212\ttest: 0.2185947\tbest: 0.2185865 (3785)\ttotal: 39m 20s\tremaining: 1h 4m 9s\n",
      "3900:\tlearn: 0.1640568\ttest: 0.2185723\tbest: 0.2185705 (3896)\ttotal: 40m 22s\tremaining: 1h 3m 6s\n",
      "4000:\tlearn: 0.1629366\ttest: 0.2185216\tbest: 0.2185211 (3999)\ttotal: 41m 22s\tremaining: 1h 2m 1s\n",
      "4100:\tlearn: 0.1617520\ttest: 0.2184952\tbest: 0.2184952 (4100)\ttotal: 42m 25s\tremaining: 1h 1m\n",
      "4200:\tlearn: 0.1606265\ttest: 0.2184807\tbest: 0.2184804 (4199)\ttotal: 43m 26s\tremaining: 59m 56s\n",
      "4300:\tlearn: 0.1595220\ttest: 0.2184667\tbest: 0.2184654 (4261)\ttotal: 44m 27s\tremaining: 58m 53s\n",
      "4400:\tlearn: 0.1583971\ttest: 0.2184411\tbest: 0.2184406 (4398)\ttotal: 45m 28s\tremaining: 57m 50s\n",
      "4500:\tlearn: 0.1573167\ttest: 0.2184024\tbest: 0.2183981 (4496)\ttotal: 46m 29s\tremaining: 56m 47s\n",
      "4600:\tlearn: 0.1562664\ttest: 0.2183888\tbest: 0.2183888 (4600)\ttotal: 47m 29s\tremaining: 55m 43s\n",
      "4700:\tlearn: 0.1552042\ttest: 0.2183957\tbest: 0.2183888 (4600)\ttotal: 48m 30s\tremaining: 54m 40s\n",
      "4800:\tlearn: 0.1541808\ttest: 0.2183868\tbest: 0.2183788 (4747)\ttotal: 49m 31s\tremaining: 53m 37s\n",
      "4900:\tlearn: 0.1531688\ttest: 0.2183711\tbest: 0.2183711 (4900)\ttotal: 50m 32s\tremaining: 52m 34s\n",
      "5000:\tlearn: 0.1520909\ttest: 0.2183638\tbest: 0.2183507 (4961)\ttotal: 51m 33s\tremaining: 51m 31s\n",
      "5100:\tlearn: 0.1510456\ttest: 0.2183791\tbest: 0.2183507 (4961)\ttotal: 52m 35s\tremaining: 50m 29s\n",
      "5200:\tlearn: 0.1500409\ttest: 0.2183651\tbest: 0.2183507 (4961)\ttotal: 53m 35s\tremaining: 49m 26s\n",
      "5300:\tlearn: 0.1490026\ttest: 0.2183581\tbest: 0.2183507 (5257)\ttotal: 54m 37s\tremaining: 48m 24s\n",
      "5400:\tlearn: 0.1480288\ttest: 0.2183473\tbest: 0.2183304 (5345)\ttotal: 55m 37s\tremaining: 47m 21s\n",
      "5500:\tlearn: 0.1470591\ttest: 0.2183715\tbest: 0.2183304 (5345)\ttotal: 56m 38s\tremaining: 46m 18s\n",
      "5600:\tlearn: 0.1460978\ttest: 0.2183610\tbest: 0.2183304 (5345)\ttotal: 57m 38s\tremaining: 45m 16s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 0.2183303514\n",
      "bestIteration = 5345\n",
      "\n",
      "Shrink model to first 5346 iterations.\n",
      "Our fold 3 CV score is 0.7898376957515825\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 4 with 2023 features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6660221\ttest: 0.6660577\tbest: 0.6660577 (0)\ttotal: 732ms\tremaining: 2h 2m 3s\n",
      "100:\tlearn: 0.2435738\ttest: 0.2442220\tbest: 0.2442220 (100)\ttotal: 1m 8s\tremaining: 1h 52m 30s\n",
      "200:\tlearn: 0.2287184\ttest: 0.2304148\tbest: 0.2304148 (200)\ttotal: 2m 14s\tremaining: 1h 49m 22s\n",
      "300:\tlearn: 0.2230916\ttest: 0.2260197\tbest: 0.2260197 (300)\ttotal: 3m 20s\tremaining: 1h 47m 53s\n",
      "400:\tlearn: 0.2195512\ttest: 0.2237657\tbest: 0.2237657 (400)\ttotal: 4m 26s\tremaining: 1h 46m 24s\n",
      "500:\tlearn: 0.2166885\ttest: 0.2222252\tbest: 0.2222252 (500)\ttotal: 5m 33s\tremaining: 1h 45m 24s\n",
      "600:\tlearn: 0.2142303\ttest: 0.2210479\tbest: 0.2210479 (600)\ttotal: 6m 39s\tremaining: 1h 44m\n",
      "700:\tlearn: 0.2118199\ttest: 0.2201134\tbest: 0.2201134 (700)\ttotal: 7m 44s\tremaining: 1h 42m 44s\n",
      "800:\tlearn: 0.2094612\ttest: 0.2193835\tbest: 0.2193835 (800)\ttotal: 8m 48s\tremaining: 1h 41m 6s\n",
      "900:\tlearn: 0.2072819\ttest: 0.2188744\tbest: 0.2188744 (900)\ttotal: 9m 51s\tremaining: 1h 39m 37s\n",
      "1000:\tlearn: 0.2052153\ttest: 0.2184439\tbest: 0.2184439 (1000)\ttotal: 10m 54s\tremaining: 1h 37m 59s\n",
      "1100:\tlearn: 0.2032734\ttest: 0.2180380\tbest: 0.2180380 (1100)\ttotal: 11m 57s\tremaining: 1h 36m 35s\n",
      "1200:\tlearn: 0.2014725\ttest: 0.2177836\tbest: 0.2177836 (1200)\ttotal: 12m 58s\tremaining: 1h 35m 2s\n",
      "1300:\tlearn: 0.1996813\ttest: 0.2175118\tbest: 0.2175118 (1300)\ttotal: 14m\tremaining: 1h 33m 39s\n",
      "1400:\tlearn: 0.1979810\ttest: 0.2173176\tbest: 0.2173176 (1400)\ttotal: 15m 1s\tremaining: 1h 32m 14s\n",
      "1500:\tlearn: 0.1964053\ttest: 0.2171474\tbest: 0.2171474 (1500)\ttotal: 16m 2s\tremaining: 1h 30m 50s\n",
      "1600:\tlearn: 0.1947898\ttest: 0.2169942\tbest: 0.2169931 (1598)\ttotal: 17m 3s\tremaining: 1h 29m 30s\n",
      "1700:\tlearn: 0.1932725\ttest: 0.2168126\tbest: 0.2168126 (1700)\ttotal: 18m 4s\tremaining: 1h 28m 11s\n",
      "1800:\tlearn: 0.1918379\ttest: 0.2166782\tbest: 0.2166782 (1800)\ttotal: 19m 4s\tremaining: 1h 26m 49s\n",
      "1900:\tlearn: 0.1903653\ttest: 0.2165389\tbest: 0.2165368 (1899)\ttotal: 20m 5s\tremaining: 1h 25m 33s\n",
      "2000:\tlearn: 0.1889198\ttest: 0.2164086\tbest: 0.2164086 (2000)\ttotal: 21m 5s\tremaining: 1h 24m 16s\n",
      "2100:\tlearn: 0.1874838\ttest: 0.2163215\tbest: 0.2163203 (2091)\ttotal: 22m 6s\tremaining: 1h 23m 5s\n",
      "2200:\tlearn: 0.1860853\ttest: 0.2161939\tbest: 0.2161927 (2194)\ttotal: 23m 6s\tremaining: 1h 21m 51s\n",
      "2300:\tlearn: 0.1846968\ttest: 0.2161016\tbest: 0.2161016 (2300)\ttotal: 24m 7s\tremaining: 1h 20m 43s\n",
      "2400:\tlearn: 0.1833477\ttest: 0.2160363\tbest: 0.2160308 (2386)\ttotal: 25m 7s\tremaining: 1h 19m 31s\n",
      "2500:\tlearn: 0.1819660\ttest: 0.2159844\tbest: 0.2159834 (2498)\ttotal: 26m 9s\tremaining: 1h 18m 24s\n",
      "2600:\tlearn: 0.1806466\ttest: 0.2159207\tbest: 0.2159207 (2600)\ttotal: 27m 9s\tremaining: 1h 17m 15s\n",
      "2700:\tlearn: 0.1793334\ttest: 0.2158608\tbest: 0.2158580 (2699)\ttotal: 28m 10s\tremaining: 1h 16m 7s\n",
      "2800:\tlearn: 0.1780392\ttest: 0.2157931\tbest: 0.2157908 (2799)\ttotal: 29m 10s\tremaining: 1h 14m 58s\n",
      "2900:\tlearn: 0.1767787\ttest: 0.2157192\tbest: 0.2157188 (2892)\ttotal: 30m 11s\tremaining: 1h 13m 51s\n",
      "3000:\tlearn: 0.1754617\ttest: 0.2156784\tbest: 0.2156765 (2997)\ttotal: 31m 12s\tremaining: 1h 12m 45s\n",
      "3100:\tlearn: 0.1741739\ttest: 0.2156164\tbest: 0.2156164 (3100)\ttotal: 32m 13s\tremaining: 1h 11m 40s\n",
      "3200:\tlearn: 0.1729055\ttest: 0.2155947\tbest: 0.2155831 (3157)\ttotal: 33m 14s\tremaining: 1h 10m 35s\n",
      "3300:\tlearn: 0.1716431\ttest: 0.2155323\tbest: 0.2155323 (3300)\ttotal: 34m 15s\tremaining: 1h 9m 31s\n",
      "3400:\tlearn: 0.1704471\ttest: 0.2154971\tbest: 0.2154970 (3393)\ttotal: 35m 18s\tremaining: 1h 8m 30s\n",
      "3500:\tlearn: 0.1692480\ttest: 0.2154413\tbest: 0.2154413 (3500)\ttotal: 36m 19s\tremaining: 1h 7m 26s\n",
      "3600:\tlearn: 0.1681311\ttest: 0.2154067\tbest: 0.2154067 (3600)\ttotal: 37m 20s\tremaining: 1h 6m 20s\n",
      "3700:\tlearn: 0.1669251\ttest: 0.2153540\tbest: 0.2153540 (3700)\ttotal: 38m 21s\tremaining: 1h 5m 16s\n",
      "3800:\tlearn: 0.1657602\ttest: 0.2153309\tbest: 0.2153284 (3753)\ttotal: 39m 23s\tremaining: 1h 4m 14s\n",
      "3900:\tlearn: 0.1645794\ttest: 0.2153096\tbest: 0.2152989 (3865)\ttotal: 40m 25s\tremaining: 1h 3m 10s\n",
      "4000:\tlearn: 0.1634666\ttest: 0.2152898\tbest: 0.2152811 (3984)\ttotal: 41m 26s\tremaining: 1h 2m 7s\n",
      "4100:\tlearn: 0.1623615\ttest: 0.2152635\tbest: 0.2152614 (4098)\ttotal: 42m 26s\tremaining: 1h 1m 2s\n",
      "4200:\tlearn: 0.1612571\ttest: 0.2152517\tbest: 0.2152491 (4192)\ttotal: 43m 27s\tremaining: 59m 59s\n",
      "4300:\tlearn: 0.1601038\ttest: 0.2152016\tbest: 0.2152002 (4299)\ttotal: 44m 28s\tremaining: 58m 55s\n",
      "4400:\tlearn: 0.1589715\ttest: 0.2151816\tbest: 0.2151765 (4398)\ttotal: 45m 30s\tremaining: 57m 53s\n",
      "4500:\tlearn: 0.1578650\ttest: 0.2151891\tbest: 0.2151765 (4398)\ttotal: 46m 31s\tremaining: 56m 50s\n",
      "4600:\tlearn: 0.1567101\ttest: 0.2151434\tbest: 0.2151414 (4598)\ttotal: 47m 34s\tremaining: 55m 48s\n",
      "4700:\tlearn: 0.1556747\ttest: 0.2151209\tbest: 0.2151158 (4685)\ttotal: 48m 33s\tremaining: 54m 43s\n",
      "4800:\tlearn: 0.1545798\ttest: 0.2151102\tbest: 0.2151100 (4744)\ttotal: 49m 35s\tremaining: 53m 41s\n",
      "4900:\tlearn: 0.1535307\ttest: 0.2151002\tbest: 0.2150846 (4879)\ttotal: 50m 36s\tremaining: 52m 38s\n",
      "5000:\tlearn: 0.1524824\ttest: 0.2150846\tbest: 0.2150733 (4929)\ttotal: 51m 38s\tremaining: 51m 36s\n",
      "5100:\tlearn: 0.1514721\ttest: 0.2150793\tbest: 0.2150733 (4929)\ttotal: 52m 38s\tremaining: 50m 32s\n",
      "5200:\tlearn: 0.1504695\ttest: 0.2150946\tbest: 0.2150733 (4929)\ttotal: 53m 39s\tremaining: 49m 30s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 0.2150733284\n",
      "bestIteration = 4929\n",
      "\n",
      "Shrink model to first 4930 iterations.\n",
      "Our fold 4 CV score is 0.7955060741040987\n",
      "Our out of folds CV score is 0.7945488282341697\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "cat_features = [\n",
    "    \"B_30\",\n",
    "    \"B_38\",\n",
    "    \"D_114\",\n",
    "    \"D_116\",\n",
    "    \"D_117\",\n",
    "    \"D_120\",\n",
    "    \"D_126\",\n",
    "    \"D_63\",\n",
    "    \"D_64\",\n",
    "    \"D_66\",\n",
    "    \"D_68\"\n",
    "]\n",
    "\n",
    "# kmeans_list = [\"kmeans pred 2\",\"kmeans pred 3\",\"kmeans pred 4\"]\n",
    "\n",
    "cat_features = [f\"{cf}_last\" for cf in cat_features]\n",
    "# cat_features.extend(kmeans_list)\n",
    "\n",
    "for cat_col in cat_features:\n",
    "#     print(cat_col)\n",
    "    encoder = LabelEncoder()\n",
    "    train[cat_col] = encoder.fit_transform(train[cat_col])\n",
    "    test[cat_col] = encoder.transform(test[cat_col])\n",
    "\n",
    "\n",
    "features = [col for col in train.columns if col not in ['customer_ID', CFG.target]]\n",
    "\n",
    "prams = {\n",
    "    'depth': 8,\n",
    "    'iterations':9999,#9999\n",
    "    'learning_rate': 0.02,\n",
    "    'random_state':CFG.seed,\n",
    "    'task_type':\"CPU\",\n",
    "    'early_stopping_rounds': 300,\n",
    "    # 'custom_metric' : 'cat_amex'\n",
    "}\n",
    "\n",
    "# Create a numpy array to store test predictions\n",
    "test_predictions = np.zeros(len(test))\n",
    "# Create a numpy array to store out of folds predictions\n",
    "oof_predictions = []\n",
    "\n",
    "cids = []\n",
    "tr_target = []\n",
    "\n",
    "# epoch = [10000,7500,7500,8500,10500]\n",
    "\n",
    "kfold = StratifiedKFold(n_splits = CFG.n_folds, shuffle = True, random_state = CFG.seed)\n",
    "for fold, (trn_ind, val_ind) in enumerate(kfold.split(train, train[CFG.target])):\n",
    "    print(' ')\n",
    "    print('-'*50)\n",
    "    print(f'Training fold {fold} with {len(features)} features...')\n",
    "    x_train, x_val = train[features].iloc[trn_ind], train[features].iloc[val_ind]\n",
    "    y_train, y_val = train[CFG.target].iloc[trn_ind], train[CFG.target].iloc[val_ind]\n",
    "    \n",
    "    # dtrain = xgb.DMatrix(data=x_train, label=y_train)\n",
    "    # dvalid = xgb.DMatrix(data=x_val, label=y_val)\n",
    "    # dtest = xgb.DMatrix(data=test[features])\n",
    "    \n",
    "#     des = DartEarlyStopping(\"valid_1\", CFG.metric, 1000)\n",
    "  \n",
    "    model = CatBoostClassifier(**prams)\n",
    "    \n",
    "    model.fit(x_train, y_train,\n",
    "                  eval_set = [(x_val, y_val)], \n",
    "                  metric_period=100\n",
    "                 )\n",
    "    \n",
    "#     model = lgb.train(\n",
    "#         params = params,\n",
    "#         train_set = lgb_train,\n",
    "#         num_boost_round = epoch[fold],#10500\n",
    "#         valid_sets = [lgb_train, lgb_valid],\n",
    "#         early_stopping_rounds = 1500,\n",
    "# #         eval_metric=[lgb_amex_metric],\n",
    "#         verbose_eval = 500,\n",
    "#         feval = lgb_amex_metric\n",
    "#         )\n",
    "    \n",
    "    # Save best model\n",
    "    model.save_model(f\"{CFG.output_dir}{CFG.model}_fold{fold}_seed{CFG.seed}.cbm\")\n",
    "    joblib.dump(model, f'{CFG.output_dir}lgbm_{CFG.boosting_type}_fold{fold}_seed{CFG.seed}.pkl')\n",
    "    # Predict validation\n",
    "    \n",
    "    val_pred = model.predict_proba(x_val)[:,1]\n",
    "    oof_predictions.extend(val_pred)\n",
    "    \n",
    "    \n",
    "    cids.extend(train[\"customer_ID\"].loc[val_ind])\n",
    "    tr_target.extend(train[\"target\"].loc[val_ind])\n",
    "    \n",
    "    # Predict the test set\n",
    "    test_pred = model.predict_proba(test[features])[:,1]\n",
    "    # test_pred = model.predict(test[features])\n",
    "    test_predictions += test_pred / CFG.n_folds\n",
    "    # Compute fold metric\n",
    "    \n",
    "    score = amex_metric(y_val, val_pred)\n",
    "    print(f'Our fold {fold} CV score is {score}')\n",
    "    del x_train, x_val, y_train, y_val\n",
    "    gc.collect()\n",
    "    \n",
    "# Compute out of folds metric\n",
    "score = amex_metric(tr_target, oof_predictions)\n",
    "print(f'Our out of folds CV score is {score}')\n",
    "\n",
    "\n",
    "# Create a dataframe to store test prediction\n",
    "test_df = pd.DataFrame({'customer_ID': test['customer_ID'], 'prediction': test_predictions})\n",
    "# test_df.to_csv(f'{CFG.output_dir}test_{CFG.model}_{score}_baseline_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)\n",
    "test_df.to_csv(f'{CFG.output_dir}test_{CFG.ver}_{CFG.model}_{score}_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)\n",
    "\n",
    "\n",
    "dic_oof = {\n",
    "    \"customer_ID\":cids,\n",
    "    \"target\":tr_target,\n",
    "    f\"{CFG.ver}_{CFG.model}_oof\":oof_predictions\n",
    "}\n",
    "\n",
    "# Create a dataframe to store out of folds predictions\n",
    "oof_df = pd.DataFrame(dic_oof)\n",
    "# oof_df = pd.DataFrame({'customer_ID': train['customer_ID'], 'target': train[CFG.target], 'prediction': oof_predictions})\n",
    "oof_df.to_csv(f'{CFG.output_dir}oof_{CFG.ver}_{CFG.model}_{score}_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)\n",
    "\n",
    "\n",
    "\n",
    "# # Create a dataframe to store out of folds predictions\n",
    "# oof_df = pd.DataFrame({'customer_ID': train['customer_ID'], 'target': train[CFG.target], 'prediction': oof_predictions})\n",
    "# oof_df.to_csv(f'../output/Amex LGBM Dart CV 0.7977/oof_lgbm_{CFG.boosting_type}_baseline_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)\n",
    "\n",
    "\n",
    "# # Create a dataframe to store test prediction\n",
    "# test_df = pd.DataFrame({'customer_ID': test['customer_ID'], 'prediction': test_predictions})\n",
    "# test_df.to_csv(f'../output/Amex LGBM Dart CV 0.7977/test_lgbm_{CFG.boosting_type}_baseline_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "634fb39d-280e-43dd-82af-6e7d23f4e910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "oof_df[f\"{CFG.ver}_{CFG.model}_oof\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca73b844-d691-4829-aeca-841426a24943",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec43c9c-9829-4275-911c-758a2bb8f8c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aeefba0-9b46-4227-b634-0a45793eb9e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f92108-afb7-45f5-b3e1-706857cb9d93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fed9500-72c1-48b4-893d-bc1fa5d7a2d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6762416b-52f6-4464-94ff-e76c6e7da87e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda1dca5-1edb-4513-82d0-b66ee1b4df81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e494e0-50f8-47ad-88c9-637a1b994414",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f770440-1df8-4a28-80c7-a3499e807a13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f3f7fd-7bd1-4e92-93a9-4a18f035feca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amex",
   "language": "python",
   "name": "amex"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
