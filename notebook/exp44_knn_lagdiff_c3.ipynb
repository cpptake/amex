{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70f58d85-14e4-4371-ad96-458843ea228c",
   "metadata": {},
   "source": [
    "# exp44\n",
    "\n",
    "lag_diff,c3„ÅÆknn\n",
    "\n",
    "\n",
    "https://www.kaggle.com/code/ragnar123/amex-lgbm-dart-cv-0-7977"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "325051a6-7ea3-4398-b022-6a81c18b14eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Library\n",
    "# ====================================================\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "from tqdm.auto import tqdm\n",
    "import itertools\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce478709-32b7-4d68-bda7-4928785a13b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/data/train.parquet'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_28032\\217815574.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;31m# Read & Preprocess Data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m \u001b[0mread_preprocess_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_28032\\217815574.py\u001b[0m in \u001b[0;36mread_preprocess_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;31m# ====================================================\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mread_preprocess_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/data/train.parquet'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m     \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'customer_ID'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'S_2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     cat_features = [\n",
      "\u001b[1;32m~\\anaconda3\\envs\\amex\\lib\\site-packages\\pandas\\io\\parquet.py\u001b[0m in \u001b[0;36mread_parquet\u001b[1;34m(path, engine, columns, storage_options, use_nullable_dtypes, **kwargs)\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    499\u001b[0m         \u001b[0muse_nullable_dtypes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_nullable_dtypes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 500\u001b[1;33m         \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    501\u001b[0m     )\n",
      "\u001b[1;32m~\\anaconda3\\envs\\amex\\lib\\site-packages\\pandas\\io\\parquet.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, path, columns, use_nullable_dtypes, storage_options, **kwargs)\u001b[0m\n\u001b[0;32m    234\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"filesystem\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 236\u001b[1;33m             \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    237\u001b[0m         )\n\u001b[0;32m    238\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\amex\\lib\\site-packages\\pandas\\io\\parquet.py\u001b[0m in \u001b[0;36m_get_path_or_handle\u001b[1;34m(path, fs, storage_options, mode, is_dir)\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[1;31m# this branch is used for example when reading from non-fsspec URLs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         handles = get_handle(\n\u001b[1;32m--> 102\u001b[1;33m             \u001b[0mpath_or_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m         )\n\u001b[0;32m    104\u001b[0m         \u001b[0mfs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\amex\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    709\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m             \u001b[1;31m# Binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 711\u001b[1;33m             \u001b[0mhandle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    712\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    713\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/data/train.parquet'"
     ]
    }
   ],
   "source": [
    "\n",
    "# ====================================================\n",
    "# Get the difference\n",
    "# ====================================================\n",
    "def get_difference(data, num_features):\n",
    "    df1 = []\n",
    "    customer_ids = []\n",
    "    for customer_id, df in tqdm(data.groupby(['customer_ID'])):\n",
    "        # Get the differences\n",
    "        diff_df1 = df[num_features].diff(1).iloc[[-1]].values.astype(np.float32)\n",
    "        # Append to lists\n",
    "        df1.append(diff_df1)\n",
    "        customer_ids.append(customer_id)\n",
    "    # Concatenate\n",
    "    df1 = np.concatenate(df1, axis = 0)\n",
    "    # Transform to dataframe\n",
    "    df1 = pd.DataFrame(df1, columns = [col + '_diff1' for col in df[num_features].columns])\n",
    "    # Add customer id\n",
    "    df1['customer_ID'] = customer_ids\n",
    "    return df1\n",
    "\n",
    "# ====================================================\n",
    "# Read & preprocess data and save it to disk\n",
    "# ====================================================\n",
    "def read_preprocess_data():\n",
    "    train = pd.read_parquet('/content/data/train.parquet')\n",
    "    features = train.drop(['customer_ID', 'S_2'], axis = 1).columns.to_list()\n",
    "    cat_features = [\n",
    "        \"B_30\",\n",
    "        \"B_38\",\n",
    "        \"D_114\",\n",
    "        \"D_116\",\n",
    "        \"D_117\",\n",
    "        \"D_120\",\n",
    "        \"D_126\",\n",
    "        \"D_63\",\n",
    "        \"D_64\",\n",
    "        \"D_66\",\n",
    "        \"D_68\",\n",
    "    ]\n",
    "    num_features = [col for col in features if col not in cat_features]\n",
    "    print('Starting training feature engineer...')\n",
    "    train_num_agg = train.groupby(\"customer_ID\")[num_features].agg(['mean', 'std', 'min', 'max', 'last'])\n",
    "    train_num_agg.columns = ['_'.join(x) for x in train_num_agg.columns]\n",
    "    train_num_agg.reset_index(inplace = True)\n",
    "    train_cat_agg = train.groupby(\"customer_ID\")[cat_features].agg(['count', 'last', 'nunique'])\n",
    "    train_cat_agg.columns = ['_'.join(x) for x in train_cat_agg.columns]\n",
    "    train_cat_agg.reset_index(inplace = True)\n",
    "    train_labels = pd.read_csv('../input/amex-default-prediction/train_labels.csv')\n",
    "    # Transform float64 columns to float32\n",
    "    cols = list(train_num_agg.dtypes[train_num_agg.dtypes == 'float64'].index)\n",
    "    for col in tqdm(cols):\n",
    "        train_num_agg[col] = train_num_agg[col].astype(np.float32)\n",
    "    # Transform int64 columns to int32\n",
    "    cols = list(train_cat_agg.dtypes[train_cat_agg.dtypes == 'int64'].index)\n",
    "    for col in tqdm(cols):\n",
    "        train_cat_agg[col] = train_cat_agg[col].astype(np.int32)\n",
    "    # Get the difference\n",
    "    train_diff = get_difference(train, num_features)\n",
    "    train = train_num_agg.merge(train_cat_agg, how = 'inner', on = 'customer_ID').merge(train_diff, how = 'inner', on = 'customer_ID').merge(train_labels, how = 'inner', on = 'customer_ID')\n",
    "    del train_num_agg, train_cat_agg, train_diff\n",
    "    gc.collect()\n",
    "    test = pd.read_parquet('../input/amex-fe/test_fe.parquet')\n",
    "    print('Starting test feature engineer...')\n",
    "    test_num_agg = test.groupby(\"customer_ID\")[num_features].agg(['mean', 'std', 'min', 'max', 'last'])\n",
    "    test_num_agg.columns = ['_'.join(x) for x in test_num_agg.columns]\n",
    "    test_num_agg.reset_index(inplace = True)\n",
    "    test_cat_agg = test.groupby(\"customer_ID\")[cat_features].agg(['count', 'last', 'nunique'])\n",
    "    test_cat_agg.columns = ['_'.join(x) for x in test_cat_agg.columns]\n",
    "    test_cat_agg.reset_index(inplace = True)\n",
    "    # Transform float64 columns to float32\n",
    "    cols = list(test_num_agg.dtypes[test_num_agg.dtypes == 'float64'].index)\n",
    "    for col in tqdm(cols):\n",
    "        test_num_agg[col] = test_num_agg[col].astype(np.float32)\n",
    "    # Transform int64 columns to int32\n",
    "    cols = list(test_cat_agg.dtypes[test_cat_agg.dtypes == 'int64'].index)\n",
    "    for col in tqdm(cols):\n",
    "        test_cat_agg[col] = test_cat_agg[col].astype(np.int32)\n",
    "    # Get the difference\n",
    "    test_diff = get_difference(test, num_features)\n",
    "    test = test_num_agg.merge(test_cat_agg, how = 'inner', on = 'customer_ID').merge(test_diff, how = 'inner', on = 'customer_ID')\n",
    "    del test_num_agg, test_cat_agg, test_diff\n",
    "    gc.collect()\n",
    "    # Save files to disk\n",
    "    train.to_parquet('../input/amex-fe/train_fe.parquet')\n",
    "    test.to_parquet('../input/amex-fe/test_fe.parquet')\n",
    "\n",
    "# Read & Preprocess Data\n",
    "read_preprocess_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e80847-25f2-4784-97c5-b8012eae1a3e",
   "metadata": {},
   "source": [
    "# Training & Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c68ef141-3c78-4cd6-988b-db0421753882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Library\n",
    "# ====================================================\n",
    "import os\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import random\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import itertools\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import lightgbm as lgb\n",
    "from itertools import combinations\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "\n",
    "# ====================================================\n",
    "# Configurations\n",
    "# ====================================================\n",
    "class CFG:\n",
    "    \n",
    "    \n",
    "    # input_dir = '../feature/exp35_lagdiff/'\n",
    "    input_dir = '../feature/exp03_amex-fe/'\n",
    "    output_dir = '../output/exp44_knn_lagdiff_c3/'\n",
    "    seed = 42\n",
    "    n_folds = 5\n",
    "    target = 'target'\n",
    "    boosting_type = 'dart'\n",
    "    metric = 'binary_logloss'\n",
    "    model = \"extratree\"\n",
    "    ver = \"exp44\"\n",
    "\n",
    "# ====================================================\n",
    "# Seed everything\n",
    "# ====================================================\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "# ====================================================\n",
    "# Read data\n",
    "# ====================================================\n",
    "# def read_data():\n",
    "#     train = pd.read_parquet(CFG.input_dir + 'train_diff.parquet')\n",
    "#     test = pd.read_parquet(CFG.input_dir + 'test_diff.parquet')\n",
    "#     return train, test\n",
    "\n",
    "def read_data():\n",
    "    train = pd.read_parquet(CFG.input_dir + 'train_fe_plus_plus.parquet')\n",
    "    test = pd.read_parquet(CFG.input_dir + 'test_fe_plus_plus.parquet')\n",
    "    return train, test\n",
    "\n",
    "# ====================================================\n",
    "# Amex metric\n",
    "# ====================================================\n",
    "def amex_metric(y_true, y_pred):\n",
    "    labels = np.transpose(np.array([y_true, y_pred]))\n",
    "    labels = labels[labels[:, 1].argsort()[::-1]]\n",
    "    weights = np.where(labels[:,0]==0, 20, 1)\n",
    "    cut_vals = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n",
    "    top_four = np.sum(cut_vals[:,0]) / np.sum(labels[:,0])\n",
    "    gini = [0,0]\n",
    "    for i in [1,0]:\n",
    "        labels = np.transpose(np.array([y_true, y_pred]))\n",
    "        labels = labels[labels[:, i].argsort()[::-1]]\n",
    "        weight = np.where(labels[:,0]==0, 20, 1)\n",
    "        weight_random = np.cumsum(weight / np.sum(weight))\n",
    "        total_pos = np.sum(labels[:, 0] *  weight)\n",
    "        cum_pos_found = np.cumsum(labels[:, 0] * weight)\n",
    "        lorentz = cum_pos_found / total_pos\n",
    "        gini[i] = np.sum((lorentz - weight_random) * weight)\n",
    "    return 0.5 * (gini[1]/gini[0] + top_four)\n",
    "\n",
    "# ====================================================\n",
    "# LGBM amex metric\n",
    "# ====================================================\n",
    "def lgb_amex_metric(y_pred, y_true):\n",
    "    y_true = y_true.get_label()\n",
    "    return 'amex_metric', amex_metric(y_true, y_pred), True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5df5be5-8119-4c74-965b-89abb98ff5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(CFG.seed)\n",
    "\n",
    "train = pd.read_parquet('../feature/exp38_lagdiff_c3/train_lagdiff_c3.parquet')\n",
    "test = pd.read_parquet('../feature/exp38_lagdiff_c3/test_lagdiff_c3.parquet')\n",
    "\n",
    "# train[\"train_test\"] = \"train\"\n",
    "# test[\"train_test\"] = \"test\"\n",
    "\n",
    "# df = pd.concat([train,test],axis = 0)\n",
    "\n",
    "# del train,test\n",
    "# gc.collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1c2c228-d24a-407c-b7e8-f91753246495",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train.fillna(value=0, inplace=True)\n",
    "test.fillna(value=0, inplace=True)\n",
    "\n",
    "# ver1 CV : 0.7810849444263961\n",
    "# train = train.replace([np.inf, -np.inf],1000000000)\n",
    "# test = test.replace([np.inf, -np.inf],1000000000)\n",
    "\n",
    "# ver2 CV : 0.7809413511784129\n",
    "# train = train.replace([np.inf, -np.inf],0)\n",
    "# test = test.replace([np.inf, -np.inf],0)\n",
    "\n",
    "# ver3 CV : 0.7808671773146323\n",
    "# train = train.replace([np.inf, -np.inf],1000000)\n",
    "# test = test.replace([np.inf, -np.inf],1000000)\n",
    "\n",
    "# ver4 CV : 0.781115758105863\n",
    "train = train.replace([np.inf, -np.inf],100000000000)\n",
    "test = test.replace([np.inf, -np.inf],100000000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9604f43d-7828-4e27-bc5a-9ea4df8c0692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ê®ôÊ∫ñÂåñ\n",
    "sc = StandardScaler()\n",
    "\n",
    "features = [col for col in train.columns if col not in ['customer_ID', CFG.target]]\n",
    "\n",
    "sc.fit(train[features])\n",
    "\n",
    "# df_key = df[['customer_ID', CFG.target,\"train_test\"]]\n",
    "train[features] = sc.transform(train[features])\n",
    "test[features] = sc.transform(test[features])\n",
    "\n",
    "## Ê®ôÊ∫ñÂåñ\n",
    "# df = sc.fit_transform(df[features])\n",
    "# x_val = sc.fit_transform(x_val[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30b39a1c-9a21-4c9c-a521-93ccfd443351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function gc.collect(generation=2)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30007ce2-4854-4fd8-8c1b-477936511e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def xgb_amex(y_pred, y_true):\n",
    "    return 'amex', amex_metric_np(y_pred,y_true.get_label())\n",
    "\n",
    "\n",
    "def cat_amex(y_pred, y_true):\n",
    "    return 'amex', amex_metric_np(y_pred,y_true.get_label())\n",
    "\n",
    "\n",
    "def amex_metric_np(preds: np.ndarray, target: np.ndarray) -> float:\n",
    "    indices = np.argsort(preds)[::-1]\n",
    "    preds, target = preds[indices], target[indices]\n",
    "\n",
    "    weight = 20.0 - target * 19.0\n",
    "    cum_norm_weight = (weight / weight.sum()).cumsum()\n",
    "    four_pct_mask = cum_norm_weight <= 0.04\n",
    "    d = np.sum(target[four_pct_mask]) / np.sum(target)\n",
    "\n",
    "    weighted_target = target * weight\n",
    "    lorentz = (weighted_target / weighted_target.sum()).cumsum()\n",
    "    gini = ((lorentz - cum_norm_weight) * weight).sum()\n",
    "\n",
    "    n_pos = np.sum(target)\n",
    "    n_neg = target.shape[0] - n_pos\n",
    "    gini_max = 10 * n_neg * (n_pos + 20 * n_neg - 19) / (n_pos + 20 * n_neg)\n",
    "\n",
    "    g = gini / gini_max\n",
    "    return 0.5 * (g + d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da1aef6c-6e01-413f-b9a0-46be991ca78e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "--------------------------------------------------\n",
      "Training fold 0 with 2011 features...\n",
      "fold 0 fitting\n",
      "fold 0 prediction\n",
      "0 score is :  0.763163706605634\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 1 with 2011 features...\n",
      "fold 1 fitting\n",
      "fold 1 prediction\n",
      "1 score is :  0.7549852941911231\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 2 with 2011 features...\n",
      "fold 2 fitting\n",
      "fold 2 prediction\n",
      "2 score is :  0.7585056703155346\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 3 with 2011 features...\n",
      "fold 3 fitting\n",
      "fold 3 prediction\n",
      "3 score is :  0.7531231768036012\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 4 with 2011 features...\n",
      "fold 4 fitting\n",
      "fold 4 prediction\n",
      "4 score is :  0.7573158784833542\n",
      "Our out of folds CV score is 0.7576550431770449\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "# cat_features = [f\"{cf}_last\" for cf in cat_features]\n",
    "# cat_features.extend(kmeans_list)\n",
    "\n",
    "test_predictions = np.zeros(len(test))\n",
    "oof_predictions = np.zeros(len(train))\n",
    "\n",
    "trainid = train[\"customer_ID\"]\n",
    "testid = test[\"customer_ID\"]\n",
    "\n",
    "\n",
    "pred = []\n",
    "oof_preds = []\n",
    "test_preds = []\n",
    "cids = []\n",
    "tr_target = []\n",
    "\n",
    "prams = {\n",
    "    'depth': 10,#8\n",
    "    'iterations':9999,#9999\n",
    "    'learning_rate': 0.02,\n",
    "    'random_state':CFG.seed,\n",
    "    'task_type':\"CPU\",\n",
    "    # 'min_child_samples':13,\n",
    "    'early_stopping_rounds': 300,\n",
    "    # 'custom_metric' : 'cat_amex'\n",
    "}\n",
    "\n",
    "\n",
    "kfold = StratifiedKFold(n_splits = CFG.n_folds, shuffle = True, random_state = CFG.seed)\n",
    "for fold, (trn_ind, val_ind) in enumerate(kfold.split(train, train[CFG.target])):\n",
    "    print(' ')\n",
    "    print('-'*50)\n",
    "    print(f'Training fold {fold} with {len(features)} features...')\n",
    "    x_train, x_val = train[features].iloc[trn_ind], train[features].iloc[val_ind]\n",
    "    y_train, y_val = train[CFG.target].iloc[trn_ind], train[CFG.target].iloc[val_ind]\n",
    "\n",
    "    print(f\"fold {fold} fitting\")\n",
    "    # model = LogisticRegression(C = 0.5)\n",
    "    # model.fit(x_train, y_train)\n",
    "    # model = KNeighborsClassifier(n_neighbors=3)\n",
    "    model = ExtraTreesClassifier(n_estimators=100, random_state=0)\n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    # Save best model\n",
    "    # file_path = f\"{CFG.output_dir}{CFG.model}_fold{fold}\"\n",
    "    # pickle.dump(model, open(file_path, 'wb'))\n",
    "    \n",
    "    # model.save_model(f\"{CFG.output_dir}{CFG.model}_fold{fold}_seed{CFG.seed}.cbm\")\n",
    "    # joblib.dump(model, f'{CFG.output_dir}lgbm_{CFG.boosting_type}_fold{fold}_seed{CFG.seed}.pkl')\n",
    "    # Predict validation\n",
    "    \n",
    "    print(f\"fold {fold} prediction\")\n",
    "    \n",
    "    # val_pred = model.predict_proba(x_val)[:,1]\n",
    "    pred = model.predict_proba(np.array(x_val))[:, 1]\n",
    "    oof_preds.extend(pred)\n",
    "    tr_target.extend(y_val)\n",
    "    cids.extend(train[\"customer_ID\"].loc[val_ind])\n",
    "    \n",
    "    fold_score = amex_metric(y_val, pred)\n",
    "    print(f\"{fold} score is : \",fold_score)\n",
    "    \n",
    "    test_preds.append(model.predict_proba(sc.fit_transform(test[features]))[:, 1])\n",
    "    \n",
    "    del x_train, x_val, y_train, y_val\n",
    "    gc.collect()\n",
    "    \n",
    "# Compute out of folds metric\n",
    "score = amex_metric(tr_target, oof_preds)\n",
    "print(f'Our out of folds CV score is {score}')\n",
    "\n",
    "\n",
    "# Compute out of folds metric\n",
    "test_predictions = np.mean(test_preds,axis = 0)\n",
    "\n",
    "# Create a dataframe to store test prediction\n",
    "test_df = pd.DataFrame({'customer_ID': test['customer_ID'], 'prediction': test_predictions})\n",
    "# test_df.to_csv(f'{CFG.output_dir}test_{CFG.model}_{score}_baseline_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)\n",
    "test_df.to_csv(f'{CFG.output_dir}test_{CFG.ver}_{CFG.model}_{score}_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)\n",
    "\n",
    "\n",
    "dic_oof = {\n",
    "    \"customer_ID\":cids,\n",
    "    \"target\":tr_target,\n",
    "    f\"{CFG.ver}_{CFG.model}_oof\":oof_preds\n",
    "}\n",
    "\n",
    "\n",
    "# Create a dataframe to store out of folds predictions\n",
    "oof_df = pd.DataFrame(dic_oof)\n",
    "# oof_df = pd.DataFrame({'customer_ID': train['customer_ID'], 'target': train[CFG.target], 'prediction': oof_predictions})\n",
    "oof_df.to_csv(f'{CFG.output_dir}oof_{CFG.ver}_{CFG.model}_{score}_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1f08ac4-d86f-4dcd-b281-4788f52bcce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "oof_df[f\"{CFG.ver}_{CFG.model}_oof\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634fb39d-280e-43dd-82af-6e7d23f4e910",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e494e0-50f8-47ad-88c9-637a1b994414",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f770440-1df8-4a28-80c7-a3499e807a13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f3f7fd-7bd1-4e92-93a9-4a18f035feca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amex",
   "language": "python",
   "name": "amex"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
