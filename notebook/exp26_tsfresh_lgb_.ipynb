{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70f58d85-14e4-4371-ad96-458843ea228c",
   "metadata": {},
   "source": [
    "# exp26\n",
    "\n",
    "exp16にtsfreshのautocorrの特徴量を追加する。\n",
    "\n",
    "\n",
    "exp16のスコア\n",
    "\n",
    "1Fold：0.7959229889532946  　　0.7969883338523035\n",
    "2Fold：0.796323672863839       0.7954764983395108\n",
    "3Fold：0.7959284796989159      0.7941681892822336\n",
    "4Fold：0.7961656161300223      0.7946013318261542\n",
    "5Fold：0.7957363246647742      0.79518510573899\n",
    "\n",
    "\n",
    "https://www.kaggle.com/code/ragnar123/amex-lgbm-dart-cv-0-7977"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "325051a6-7ea3-4398-b022-6a81c18b14eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Library\n",
    "# ====================================================\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "from tqdm.auto import tqdm\n",
    "import itertools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce478709-32b7-4d68-bda7-4928785a13b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/data/train.parquet'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4672\\217815574.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;31m# Read & Preprocess Data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m \u001b[0mread_preprocess_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4672\\217815574.py\u001b[0m in \u001b[0;36mread_preprocess_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;31m# ====================================================\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mread_preprocess_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/data/train.parquet'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m     \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'customer_ID'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'S_2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     cat_features = [\n",
      "\u001b[1;32m~\\anaconda3\\envs\\amex\\lib\\site-packages\\pandas\\io\\parquet.py\u001b[0m in \u001b[0;36mread_parquet\u001b[1;34m(path, engine, columns, storage_options, use_nullable_dtypes, **kwargs)\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    499\u001b[0m         \u001b[0muse_nullable_dtypes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_nullable_dtypes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 500\u001b[1;33m         \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    501\u001b[0m     )\n",
      "\u001b[1;32m~\\anaconda3\\envs\\amex\\lib\\site-packages\\pandas\\io\\parquet.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, path, columns, storage_options, **kwargs)\u001b[0m\n\u001b[0;32m    338\u001b[0m             \u001b[1;31m# this branch is used for example when reading from non-fsspec URLs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m             handles = get_handle(\n\u001b[1;32m--> 340\u001b[1;33m                 \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    341\u001b[0m             )\n\u001b[0;32m    342\u001b[0m             \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\amex\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    709\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m             \u001b[1;31m# Binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 711\u001b[1;33m             \u001b[0mhandle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    712\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    713\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/data/train.parquet'"
     ]
    }
   ],
   "source": [
    "\n",
    "# ====================================================\n",
    "# Get the difference\n",
    "# ====================================================\n",
    "def get_difference(data, num_features):\n",
    "    df1 = []\n",
    "    customer_ids = []\n",
    "    for customer_id, df in tqdm(data.groupby(['customer_ID'])):\n",
    "        # Get the differences\n",
    "        diff_df1 = df[num_features].diff(1).iloc[[-1]].values.astype(np.float32)\n",
    "        # Append to lists\n",
    "        df1.append(diff_df1)\n",
    "        customer_ids.append(customer_id)\n",
    "    # Concatenate\n",
    "    df1 = np.concatenate(df1, axis = 0)\n",
    "    # Transform to dataframe\n",
    "    df1 = pd.DataFrame(df1, columns = [col + '_diff1' for col in df[num_features].columns])\n",
    "    # Add customer id\n",
    "    df1['customer_ID'] = customer_ids\n",
    "    return df1\n",
    "\n",
    "# ====================================================\n",
    "# Read & preprocess data and save it to disk\n",
    "# ====================================================\n",
    "def read_preprocess_data():\n",
    "    train = pd.read_parquet('/content/data/train.parquet')\n",
    "    features = train.drop(['customer_ID', 'S_2'], axis = 1).columns.to_list()\n",
    "    cat_features = [\n",
    "        \"B_30\",\n",
    "        \"B_38\",\n",
    "        \"D_114\",\n",
    "        \"D_116\",\n",
    "        \"D_117\",\n",
    "        \"D_120\",\n",
    "        \"D_126\",\n",
    "        \"D_63\",\n",
    "        \"D_64\",\n",
    "        \"D_66\",\n",
    "        \"D_68\",\n",
    "    ]\n",
    "    num_features = [col for col in features if col not in cat_features]\n",
    "    print('Starting training feature engineer...')\n",
    "    train_num_agg = train.groupby(\"customer_ID\")[num_features].agg(['mean', 'std', 'min', 'max', 'last'])\n",
    "    train_num_agg.columns = ['_'.join(x) for x in train_num_agg.columns]\n",
    "    train_num_agg.reset_index(inplace = True)\n",
    "    train_cat_agg = train.groupby(\"customer_ID\")[cat_features].agg(['count', 'last', 'nunique'])\n",
    "    train_cat_agg.columns = ['_'.join(x) for x in train_cat_agg.columns]\n",
    "    train_cat_agg.reset_index(inplace = True)\n",
    "    train_labels = pd.read_csv('../input/amex-default-prediction/train_labels.csv')\n",
    "    # Transform float64 columns to float32\n",
    "    cols = list(train_num_agg.dtypes[train_num_agg.dtypes == 'float64'].index)\n",
    "    for col in tqdm(cols):\n",
    "        train_num_agg[col] = train_num_agg[col].astype(np.float32)\n",
    "    # Transform int64 columns to int32\n",
    "    cols = list(train_cat_agg.dtypes[train_cat_agg.dtypes == 'int64'].index)\n",
    "    for col in tqdm(cols):\n",
    "        train_cat_agg[col] = train_cat_agg[col].astype(np.int32)\n",
    "    # Get the difference\n",
    "    train_diff = get_difference(train, num_features)\n",
    "    train = train_num_agg.merge(train_cat_agg, how = 'inner', on = 'customer_ID').merge(train_diff, how = 'inner', on = 'customer_ID').merge(train_labels, how = 'inner', on = 'customer_ID')\n",
    "    del train_num_agg, train_cat_agg, train_diff\n",
    "    gc.collect()\n",
    "    test = pd.read_parquet('../input/amex-fe/test_fe.parquet')\n",
    "    print('Starting test feature engineer...')\n",
    "    test_num_agg = test.groupby(\"customer_ID\")[num_features].agg(['mean', 'std', 'min', 'max', 'last'])\n",
    "    test_num_agg.columns = ['_'.join(x) for x in test_num_agg.columns]\n",
    "    test_num_agg.reset_index(inplace = True)\n",
    "    test_cat_agg = test.groupby(\"customer_ID\")[cat_features].agg(['count', 'last', 'nunique'])\n",
    "    test_cat_agg.columns = ['_'.join(x) for x in test_cat_agg.columns]\n",
    "    test_cat_agg.reset_index(inplace = True)\n",
    "    # Transform float64 columns to float32\n",
    "    cols = list(test_num_agg.dtypes[test_num_agg.dtypes == 'float64'].index)\n",
    "    for col in tqdm(cols):\n",
    "        test_num_agg[col] = test_num_agg[col].astype(np.float32)\n",
    "    # Transform int64 columns to int32\n",
    "    cols = list(test_cat_agg.dtypes[test_cat_agg.dtypes == 'int64'].index)\n",
    "    for col in tqdm(cols):\n",
    "        test_cat_agg[col] = test_cat_agg[col].astype(np.int32)\n",
    "    # Get the difference\n",
    "    test_diff = get_difference(test, num_features)\n",
    "    test = test_num_agg.merge(test_cat_agg, how = 'inner', on = 'customer_ID').merge(test_diff, how = 'inner', on = 'customer_ID')\n",
    "    del test_num_agg, test_cat_agg, test_diff\n",
    "    gc.collect()\n",
    "    # Save files to disk\n",
    "    train.to_parquet('../input/amex-fe/train_fe.parquet')\n",
    "    test.to_parquet('../input/amex-fe/test_fe.parquet')\n",
    "\n",
    "# Read & Preprocess Data\n",
    "read_preprocess_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e80847-25f2-4784-97c5-b8012eae1a3e",
   "metadata": {},
   "source": [
    "# Training & Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c68ef141-3c78-4cd6-988b-db0421753882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Library\n",
    "# ====================================================\n",
    "import os\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import random\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import itertools\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import lightgbm as lgb\n",
    "from itertools import combinations\n",
    "\n",
    "# ====================================================\n",
    "# Configurations\n",
    "# ====================================================\n",
    "class CFG:\n",
    "    input_dir = '../feature/exp03_amex-fe/'\n",
    "    output_dir = '../output/exp26_tsfresh_lgb/'\n",
    "    seed = 42\n",
    "    n_folds = 5\n",
    "    target = 'target'\n",
    "    boosting_type = 'dart'\n",
    "    metric = 'binary_logloss'\n",
    "    model = \"lgb\"\n",
    "    ver = \"exp19\"\n",
    "\n",
    "# ====================================================\n",
    "# Seed everything\n",
    "# ====================================================\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "# ====================================================\n",
    "# Read data\n",
    "# ====================================================\n",
    "def read_data():\n",
    "    train = pd.read_parquet(CFG.input_dir + 'train_fe_plus_plus.parquet')\n",
    "    test = pd.read_parquet(CFG.input_dir + 'test_fe_plus_plus.parquet')\n",
    "    return train, test\n",
    "\n",
    "# ====================================================\n",
    "# Amex metric\n",
    "# ====================================================\n",
    "def amex_metric(y_true, y_pred):\n",
    "    labels = np.transpose(np.array([y_true, y_pred]))\n",
    "    labels = labels[labels[:, 1].argsort()[::-1]]\n",
    "    weights = np.where(labels[:,0]==0, 20, 1)\n",
    "    cut_vals = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n",
    "    top_four = np.sum(cut_vals[:,0]) / np.sum(labels[:,0])\n",
    "    gini = [0,0]\n",
    "    for i in [1,0]:\n",
    "        labels = np.transpose(np.array([y_true, y_pred]))\n",
    "        labels = labels[labels[:, i].argsort()[::-1]]\n",
    "        weight = np.where(labels[:,0]==0, 20, 1)\n",
    "        weight_random = np.cumsum(weight / np.sum(weight))\n",
    "        total_pos = np.sum(labels[:, 0] *  weight)\n",
    "        cum_pos_found = np.cumsum(labels[:, 0] * weight)\n",
    "        lorentz = cum_pos_found / total_pos\n",
    "        gini[i] = np.sum((lorentz - weight_random) * weight)\n",
    "    return 0.5 * (gini[1]/gini[0] + top_four)\n",
    "\n",
    "# ====================================================\n",
    "# LGBM amex metric\n",
    "# ====================================================\n",
    "def lgb_amex_metric(y_pred, y_true):\n",
    "    y_true = y_true.get_label()\n",
    "    return 'amex_metric', amex_metric(y_true, y_pred), True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d81e96cc-3556-4978-9d8b-c7148c48d70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(CFG.seed)\n",
    "train, test = read_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30007ce2-4854-4fd8-8c1b-477936511e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tsfresh_trian = pd.read_pickle('../feature/exp18_2_tsfresh/train_autocorr.pkl')\n",
    "tsfresh_test = pd.read_pickle('../feature/exp18_2_tsfresh/test_autocorr.pkl')\n",
    "\n",
    "train = train.merge(tsfresh_trian,on = \"customer_ID\",how = \"left\")\n",
    "test = test.merge(tsfresh_test,on = \"customer_ID\",how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54d5aa37-ce2a-4fd7-a211-d4665fe081b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>P_2_first</th>\n",
       "      <th>P_2_mean</th>\n",
       "      <th>P_2_std</th>\n",
       "      <th>P_2_min</th>\n",
       "      <th>P_2_max</th>\n",
       "      <th>P_2_last</th>\n",
       "      <th>D_39_first</th>\n",
       "      <th>D_39_mean</th>\n",
       "      <th>D_39_std</th>\n",
       "      <th>D_39_min</th>\n",
       "      <th>D_39_max</th>\n",
       "      <th>D_39_last</th>\n",
       "      <th>B_1_first</th>\n",
       "      <th>B_1_mean</th>\n",
       "      <th>B_1_std</th>\n",
       "      <th>B_1_min</th>\n",
       "      <th>B_1_max</th>\n",
       "      <th>B_1_last</th>\n",
       "      <th>B_2_first</th>\n",
       "      <th>B_2_mean</th>\n",
       "      <th>B_2_std</th>\n",
       "      <th>B_2_min</th>\n",
       "      <th>B_2_max</th>\n",
       "      <th>B_2_last</th>\n",
       "      <th>R_1_first</th>\n",
       "      <th>R_1_mean</th>\n",
       "      <th>R_1_std</th>\n",
       "      <th>R_1_min</th>\n",
       "      <th>R_1_max</th>\n",
       "      <th>R_1_last</th>\n",
       "      <th>S_3_first</th>\n",
       "      <th>S_3_mean</th>\n",
       "      <th>S_3_std</th>\n",
       "      <th>S_3_min</th>\n",
       "      <th>S_3_max</th>\n",
       "      <th>S_3_last</th>\n",
       "      <th>D_41_first</th>\n",
       "      <th>D_41_mean</th>\n",
       "      <th>D_41_std</th>\n",
       "      <th>D_41_min</th>\n",
       "      <th>D_41_max</th>\n",
       "      <th>D_41_last</th>\n",
       "      <th>B_3_first</th>\n",
       "      <th>B_3_mean</th>\n",
       "      <th>B_3_std</th>\n",
       "      <th>B_3_min</th>\n",
       "      <th>B_3_max</th>\n",
       "      <th>B_3_last</th>\n",
       "      <th>D_42_first</th>\n",
       "      <th>D_42_mean</th>\n",
       "      <th>D_42_std</th>\n",
       "      <th>D_42_min</th>\n",
       "      <th>D_42_max</th>\n",
       "      <th>D_42_last</th>\n",
       "      <th>D_43_first</th>\n",
       "      <th>D_43_mean</th>\n",
       "      <th>D_43_std</th>\n",
       "      <th>D_43_min</th>\n",
       "      <th>D_43_max</th>\n",
       "      <th>D_43_last</th>\n",
       "      <th>D_44_first</th>\n",
       "      <th>D_44_mean</th>\n",
       "      <th>D_44_std</th>\n",
       "      <th>D_44_min</th>\n",
       "      <th>D_44_max</th>\n",
       "      <th>D_44_last</th>\n",
       "      <th>B_4_first</th>\n",
       "      <th>B_4_mean</th>\n",
       "      <th>B_4_std</th>\n",
       "      <th>B_4_min</th>\n",
       "      <th>B_4_max</th>\n",
       "      <th>B_4_last</th>\n",
       "      <th>D_45_first</th>\n",
       "      <th>D_45_mean</th>\n",
       "      <th>D_45_std</th>\n",
       "      <th>D_45_min</th>\n",
       "      <th>D_45_max</th>\n",
       "      <th>D_45_last</th>\n",
       "      <th>B_5_first</th>\n",
       "      <th>B_5_mean</th>\n",
       "      <th>B_5_std</th>\n",
       "      <th>B_5_min</th>\n",
       "      <th>B_5_max</th>\n",
       "      <th>B_5_last</th>\n",
       "      <th>R_2_first</th>\n",
       "      <th>R_2_mean</th>\n",
       "      <th>R_2_std</th>\n",
       "      <th>R_2_min</th>\n",
       "      <th>R_2_max</th>\n",
       "      <th>R_2_last</th>\n",
       "      <th>D_46_first</th>\n",
       "      <th>D_46_mean</th>\n",
       "      <th>D_46_std</th>\n",
       "      <th>D_46_min</th>\n",
       "      <th>D_46_max</th>\n",
       "      <th>D_46_last</th>\n",
       "      <th>D_47_first</th>\n",
       "      <th>D_47_mean</th>\n",
       "      <th>D_47_std</th>\n",
       "      <th>D_47_min</th>\n",
       "      <th>D_47_max</th>\n",
       "      <th>D_47_last</th>\n",
       "      <th>D_48_first</th>\n",
       "      <th>D_48_mean</th>\n",
       "      <th>D_48_std</th>\n",
       "      <th>D_48_min</th>\n",
       "      <th>D_48_max</th>\n",
       "      <th>D_48_last</th>\n",
       "      <th>D_49_first</th>\n",
       "      <th>D_49_mean</th>\n",
       "      <th>D_49_std</th>\n",
       "      <th>D_49_min</th>\n",
       "      <th>D_49_max</th>\n",
       "      <th>D_49_last</th>\n",
       "      <th>B_6_first</th>\n",
       "      <th>B_6_mean</th>\n",
       "      <th>B_6_std</th>\n",
       "      <th>B_6_min</th>\n",
       "      <th>B_6_max</th>\n",
       "      <th>B_6_last</th>\n",
       "      <th>B_7_first</th>\n",
       "      <th>B_7_mean</th>\n",
       "      <th>B_7_std</th>\n",
       "      <th>B_7_min</th>\n",
       "      <th>B_7_max</th>\n",
       "      <th>B_7_last</th>\n",
       "      <th>B_8_first</th>\n",
       "      <th>B_8_mean</th>\n",
       "      <th>B_8_std</th>\n",
       "      <th>B_8_min</th>\n",
       "      <th>B_8_max</th>\n",
       "      <th>B_8_last</th>\n",
       "      <th>D_50_first</th>\n",
       "      <th>D_50_mean</th>\n",
       "      <th>D_50_std</th>\n",
       "      <th>D_50_min</th>\n",
       "      <th>D_50_max</th>\n",
       "      <th>D_50_last</th>\n",
       "      <th>D_51_first</th>\n",
       "      <th>D_51_mean</th>\n",
       "      <th>D_51_std</th>\n",
       "      <th>D_51_min</th>\n",
       "      <th>D_51_max</th>\n",
       "      <th>D_51_last</th>\n",
       "      <th>B_9_first</th>\n",
       "      <th>B_9_mean</th>\n",
       "      <th>B_9_std</th>\n",
       "      <th>B_9_min</th>\n",
       "      <th>B_9_max</th>\n",
       "      <th>B_9_last</th>\n",
       "      <th>R_3_first</th>\n",
       "      <th>R_3_mean</th>\n",
       "      <th>R_3_std</th>\n",
       "      <th>R_3_min</th>\n",
       "      <th>R_3_max</th>\n",
       "      <th>R_3_last</th>\n",
       "      <th>D_52_first</th>\n",
       "      <th>D_52_mean</th>\n",
       "      <th>D_52_std</th>\n",
       "      <th>D_52_min</th>\n",
       "      <th>D_52_max</th>\n",
       "      <th>D_52_last</th>\n",
       "      <th>P_3_first</th>\n",
       "      <th>P_3_mean</th>\n",
       "      <th>P_3_std</th>\n",
       "      <th>P_3_min</th>\n",
       "      <th>P_3_max</th>\n",
       "      <th>P_3_last</th>\n",
       "      <th>B_10_first</th>\n",
       "      <th>B_10_mean</th>\n",
       "      <th>B_10_std</th>\n",
       "      <th>B_10_min</th>\n",
       "      <th>B_10_max</th>\n",
       "      <th>B_10_last</th>\n",
       "      <th>D_53_first</th>\n",
       "      <th>D_53_mean</th>\n",
       "      <th>D_53_std</th>\n",
       "      <th>D_53_min</th>\n",
       "      <th>D_53_max</th>\n",
       "      <th>D_53_last</th>\n",
       "      <th>S_5_first</th>\n",
       "      <th>S_5_mean</th>\n",
       "      <th>S_5_std</th>\n",
       "      <th>S_5_min</th>\n",
       "      <th>S_5_max</th>\n",
       "      <th>S_5_last</th>\n",
       "      <th>B_11_first</th>\n",
       "      <th>B_11_mean</th>\n",
       "      <th>B_11_std</th>\n",
       "      <th>B_11_min</th>\n",
       "      <th>B_11_max</th>\n",
       "      <th>B_11_last</th>\n",
       "      <th>S_6_first</th>\n",
       "      <th>S_6_mean</th>\n",
       "      <th>S_6_std</th>\n",
       "      <th>S_6_min</th>\n",
       "      <th>S_6_max</th>\n",
       "      <th>S_6_last</th>\n",
       "      <th>D_54_first</th>\n",
       "      <th>D_54_mean</th>\n",
       "      <th>D_54_std</th>\n",
       "      <th>D_54_min</th>\n",
       "      <th>D_54_max</th>\n",
       "      <th>D_54_last</th>\n",
       "      <th>R_4_first</th>\n",
       "      <th>R_4_mean</th>\n",
       "      <th>R_4_std</th>\n",
       "      <th>R_4_min</th>\n",
       "      <th>R_4_max</th>\n",
       "      <th>R_4_last</th>\n",
       "      <th>S_7_first</th>\n",
       "      <th>S_7_mean</th>\n",
       "      <th>S_7_std</th>\n",
       "      <th>S_7_min</th>\n",
       "      <th>S_7_max</th>\n",
       "      <th>S_7_last</th>\n",
       "      <th>B_12_first</th>\n",
       "      <th>B_12_mean</th>\n",
       "      <th>B_12_std</th>\n",
       "      <th>B_12_min</th>\n",
       "      <th>B_12_max</th>\n",
       "      <th>B_12_last</th>\n",
       "      <th>S_8_first</th>\n",
       "      <th>S_8_mean</th>\n",
       "      <th>S_8_std</th>\n",
       "      <th>S_8_min</th>\n",
       "      <th>S_8_max</th>\n",
       "      <th>S_8_last</th>\n",
       "      <th>D_55_first</th>\n",
       "      <th>D_55_mean</th>\n",
       "      <th>D_55_std</th>\n",
       "      <th>D_55_min</th>\n",
       "      <th>D_55_max</th>\n",
       "      <th>D_55_last</th>\n",
       "      <th>D_56_first</th>\n",
       "      <th>D_56_mean</th>\n",
       "      <th>D_56_std</th>\n",
       "      <th>D_56_min</th>\n",
       "      <th>D_56_max</th>\n",
       "      <th>D_56_last</th>\n",
       "      <th>B_13_first</th>\n",
       "      <th>B_13_mean</th>\n",
       "      <th>B_13_std</th>\n",
       "      <th>B_13_min</th>\n",
       "      <th>B_13_max</th>\n",
       "      <th>B_13_last</th>\n",
       "      <th>R_5_first</th>\n",
       "      <th>R_5_mean</th>\n",
       "      <th>R_5_std</th>\n",
       "      <th>...</th>\n",
       "      <th>B_10__autocorrelation__lag_3</th>\n",
       "      <th>B_10__autocorrelation__lag_5</th>\n",
       "      <th>B_10__autocorrelation__lag_7</th>\n",
       "      <th>B_10__autocorrelation__lag_12</th>\n",
       "      <th>S_5__autocorrelation__lag_1</th>\n",
       "      <th>S_5__autocorrelation__lag_3</th>\n",
       "      <th>S_5__autocorrelation__lag_5</th>\n",
       "      <th>S_5__autocorrelation__lag_7</th>\n",
       "      <th>S_5__autocorrelation__lag_12</th>\n",
       "      <th>B_11__autocorrelation__lag_1</th>\n",
       "      <th>B_11__autocorrelation__lag_3</th>\n",
       "      <th>B_11__autocorrelation__lag_5</th>\n",
       "      <th>B_11__autocorrelation__lag_7</th>\n",
       "      <th>B_11__autocorrelation__lag_12</th>\n",
       "      <th>S_7__autocorrelation__lag_1</th>\n",
       "      <th>S_7__autocorrelation__lag_3</th>\n",
       "      <th>S_7__autocorrelation__lag_5</th>\n",
       "      <th>S_7__autocorrelation__lag_7</th>\n",
       "      <th>S_7__autocorrelation__lag_12</th>\n",
       "      <th>B_12__autocorrelation__lag_1</th>\n",
       "      <th>B_12__autocorrelation__lag_3</th>\n",
       "      <th>B_12__autocorrelation__lag_5</th>\n",
       "      <th>B_12__autocorrelation__lag_7</th>\n",
       "      <th>B_12__autocorrelation__lag_12</th>\n",
       "      <th>S_8__autocorrelation__lag_1</th>\n",
       "      <th>S_8__autocorrelation__lag_3</th>\n",
       "      <th>S_8__autocorrelation__lag_5</th>\n",
       "      <th>S_8__autocorrelation__lag_7</th>\n",
       "      <th>S_8__autocorrelation__lag_12</th>\n",
       "      <th>D_55__autocorrelation__lag_1</th>\n",
       "      <th>D_55__autocorrelation__lag_3</th>\n",
       "      <th>D_55__autocorrelation__lag_5</th>\n",
       "      <th>D_55__autocorrelation__lag_7</th>\n",
       "      <th>D_55__autocorrelation__lag_12</th>\n",
       "      <th>B_13__autocorrelation__lag_1</th>\n",
       "      <th>B_13__autocorrelation__lag_3</th>\n",
       "      <th>B_13__autocorrelation__lag_5</th>\n",
       "      <th>B_13__autocorrelation__lag_7</th>\n",
       "      <th>B_13__autocorrelation__lag_12</th>\n",
       "      <th>D_58__autocorrelation__lag_1</th>\n",
       "      <th>D_58__autocorrelation__lag_3</th>\n",
       "      <th>D_58__autocorrelation__lag_5</th>\n",
       "      <th>D_58__autocorrelation__lag_7</th>\n",
       "      <th>D_58__autocorrelation__lag_12</th>\n",
       "      <th>B_14__autocorrelation__lag_1</th>\n",
       "      <th>B_14__autocorrelation__lag_3</th>\n",
       "      <th>B_14__autocorrelation__lag_5</th>\n",
       "      <th>B_14__autocorrelation__lag_7</th>\n",
       "      <th>B_14__autocorrelation__lag_12</th>\n",
       "      <th>D_59__autocorrelation__lag_1</th>\n",
       "      <th>D_59__autocorrelation__lag_3</th>\n",
       "      <th>D_59__autocorrelation__lag_5</th>\n",
       "      <th>D_59__autocorrelation__lag_7</th>\n",
       "      <th>D_59__autocorrelation__lag_12</th>\n",
       "      <th>D_60__autocorrelation__lag_1</th>\n",
       "      <th>D_60__autocorrelation__lag_3</th>\n",
       "      <th>D_60__autocorrelation__lag_5</th>\n",
       "      <th>D_60__autocorrelation__lag_7</th>\n",
       "      <th>D_60__autocorrelation__lag_12</th>\n",
       "      <th>D_61__autocorrelation__lag_1</th>\n",
       "      <th>D_61__autocorrelation__lag_3</th>\n",
       "      <th>D_61__autocorrelation__lag_5</th>\n",
       "      <th>D_61__autocorrelation__lag_7</th>\n",
       "      <th>D_61__autocorrelation__lag_12</th>\n",
       "      <th>B_15__autocorrelation__lag_1</th>\n",
       "      <th>B_15__autocorrelation__lag_3</th>\n",
       "      <th>B_15__autocorrelation__lag_5</th>\n",
       "      <th>B_15__autocorrelation__lag_7</th>\n",
       "      <th>B_15__autocorrelation__lag_12</th>\n",
       "      <th>S_11__autocorrelation__lag_1</th>\n",
       "      <th>S_11__autocorrelation__lag_3</th>\n",
       "      <th>S_11__autocorrelation__lag_5</th>\n",
       "      <th>S_11__autocorrelation__lag_7</th>\n",
       "      <th>S_11__autocorrelation__lag_12</th>\n",
       "      <th>D_62__autocorrelation__lag_1</th>\n",
       "      <th>D_62__autocorrelation__lag_3</th>\n",
       "      <th>D_62__autocorrelation__lag_5</th>\n",
       "      <th>D_62__autocorrelation__lag_7</th>\n",
       "      <th>D_62__autocorrelation__lag_12</th>\n",
       "      <th>B_18__autocorrelation__lag_1</th>\n",
       "      <th>B_18__autocorrelation__lag_3</th>\n",
       "      <th>B_18__autocorrelation__lag_5</th>\n",
       "      <th>B_18__autocorrelation__lag_7</th>\n",
       "      <th>S_12__autocorrelation__lag_1</th>\n",
       "      <th>S_12__autocorrelation__lag_3</th>\n",
       "      <th>S_12__autocorrelation__lag_5</th>\n",
       "      <th>S_12__autocorrelation__lag_7</th>\n",
       "      <th>S_12__autocorrelation__lag_12</th>\n",
       "      <th>R_6__autocorrelation__lag_1</th>\n",
       "      <th>R_6__autocorrelation__lag_3</th>\n",
       "      <th>R_6__autocorrelation__lag_5</th>\n",
       "      <th>R_6__autocorrelation__lag_7</th>\n",
       "      <th>R_6__autocorrelation__lag_12</th>\n",
       "      <th>S_13__autocorrelation__lag_1</th>\n",
       "      <th>B_21__autocorrelation__lag_1</th>\n",
       "      <th>B_21__autocorrelation__lag_3</th>\n",
       "      <th>B_21__autocorrelation__lag_5</th>\n",
       "      <th>B_21__autocorrelation__lag_7</th>\n",
       "      <th>B_21__autocorrelation__lag_12</th>\n",
       "      <th>D_69__autocorrelation__lag_1</th>\n",
       "      <th>D_69__autocorrelation__lag_3</th>\n",
       "      <th>D_69__autocorrelation__lag_5</th>\n",
       "      <th>D_69__autocorrelation__lag_7</th>\n",
       "      <th>D_69__autocorrelation__lag_12</th>\n",
       "      <th>D_71__autocorrelation__lag_1</th>\n",
       "      <th>D_71__autocorrelation__lag_3</th>\n",
       "      <th>D_71__autocorrelation__lag_5</th>\n",
       "      <th>D_71__autocorrelation__lag_7</th>\n",
       "      <th>D_71__autocorrelation__lag_12</th>\n",
       "      <th>S_15__autocorrelation__lag_1</th>\n",
       "      <th>S_15__autocorrelation__lag_3</th>\n",
       "      <th>S_15__autocorrelation__lag_5</th>\n",
       "      <th>S_15__autocorrelation__lag_7</th>\n",
       "      <th>B_23__autocorrelation__lag_1</th>\n",
       "      <th>B_23__autocorrelation__lag_3</th>\n",
       "      <th>B_23__autocorrelation__lag_5</th>\n",
       "      <th>B_23__autocorrelation__lag_7</th>\n",
       "      <th>B_23__autocorrelation__lag_12</th>\n",
       "      <th>D_75__autocorrelation__lag_1</th>\n",
       "      <th>D_75__autocorrelation__lag_3</th>\n",
       "      <th>D_75__autocorrelation__lag_5</th>\n",
       "      <th>B_24__autocorrelation__lag_1</th>\n",
       "      <th>B_24__autocorrelation__lag_3</th>\n",
       "      <th>B_24__autocorrelation__lag_5</th>\n",
       "      <th>B_24__autocorrelation__lag_7</th>\n",
       "      <th>B_24__autocorrelation__lag_12</th>\n",
       "      <th>D_77__autocorrelation__lag_1</th>\n",
       "      <th>D_77__autocorrelation__lag_3</th>\n",
       "      <th>D_77__autocorrelation__lag_5</th>\n",
       "      <th>D_77__autocorrelation__lag_7</th>\n",
       "      <th>B_25__autocorrelation__lag_1</th>\n",
       "      <th>B_25__autocorrelation__lag_3</th>\n",
       "      <th>B_25__autocorrelation__lag_5</th>\n",
       "      <th>B_25__autocorrelation__lag_7</th>\n",
       "      <th>B_25__autocorrelation__lag_12</th>\n",
       "      <th>B_26__autocorrelation__lag_1</th>\n",
       "      <th>B_26__autocorrelation__lag_3</th>\n",
       "      <th>B_26__autocorrelation__lag_5</th>\n",
       "      <th>B_26__autocorrelation__lag_7</th>\n",
       "      <th>B_26__autocorrelation__lag_12</th>\n",
       "      <th>S_16__autocorrelation__lag_1</th>\n",
       "      <th>S_16__autocorrelation__lag_3</th>\n",
       "      <th>S_16__autocorrelation__lag_5</th>\n",
       "      <th>S_16__autocorrelation__lag_7</th>\n",
       "      <th>S_16__autocorrelation__lag_12</th>\n",
       "      <th>B_27__autocorrelation__lag_1</th>\n",
       "      <th>B_27__autocorrelation__lag_3</th>\n",
       "      <th>B_27__autocorrelation__lag_5</th>\n",
       "      <th>B_27__autocorrelation__lag_7</th>\n",
       "      <th>B_27__autocorrelation__lag_12</th>\n",
       "      <th>S_17__autocorrelation__lag_1</th>\n",
       "      <th>S_17__autocorrelation__lag_3</th>\n",
       "      <th>S_17__autocorrelation__lag_5</th>\n",
       "      <th>S_17__autocorrelation__lag_7</th>\n",
       "      <th>S_17__autocorrelation__lag_12</th>\n",
       "      <th>B_28__autocorrelation__lag_1</th>\n",
       "      <th>B_28__autocorrelation__lag_3</th>\n",
       "      <th>B_28__autocorrelation__lag_5</th>\n",
       "      <th>B_28__autocorrelation__lag_7</th>\n",
       "      <th>B_28__autocorrelation__lag_12</th>\n",
       "      <th>S_19__autocorrelation__lag_1</th>\n",
       "      <th>S_19__autocorrelation__lag_3</th>\n",
       "      <th>S_19__autocorrelation__lag_5</th>\n",
       "      <th>S_19__autocorrelation__lag_7</th>\n",
       "      <th>S_19__autocorrelation__lag_12</th>\n",
       "      <th>S_22__autocorrelation__lag_1</th>\n",
       "      <th>S_22__autocorrelation__lag_3</th>\n",
       "      <th>S_22__autocorrelation__lag_5</th>\n",
       "      <th>S_22__autocorrelation__lag_7</th>\n",
       "      <th>S_22__autocorrelation__lag_12</th>\n",
       "      <th>S_23__autocorrelation__lag_1</th>\n",
       "      <th>S_23__autocorrelation__lag_3</th>\n",
       "      <th>S_23__autocorrelation__lag_5</th>\n",
       "      <th>S_23__autocorrelation__lag_7</th>\n",
       "      <th>S_23__autocorrelation__lag_12</th>\n",
       "      <th>S_24__autocorrelation__lag_1</th>\n",
       "      <th>S_24__autocorrelation__lag_3</th>\n",
       "      <th>S_24__autocorrelation__lag_5</th>\n",
       "      <th>S_24__autocorrelation__lag_7</th>\n",
       "      <th>S_24__autocorrelation__lag_12</th>\n",
       "      <th>S_25__autocorrelation__lag_1</th>\n",
       "      <th>S_25__autocorrelation__lag_3</th>\n",
       "      <th>S_25__autocorrelation__lag_5</th>\n",
       "      <th>S_25__autocorrelation__lag_7</th>\n",
       "      <th>S_25__autocorrelation__lag_12</th>\n",
       "      <th>S_26__autocorrelation__lag_1</th>\n",
       "      <th>S_26__autocorrelation__lag_3</th>\n",
       "      <th>S_26__autocorrelation__lag_5</th>\n",
       "      <th>S_26__autocorrelation__lag_7</th>\n",
       "      <th>S_26__autocorrelation__lag_12</th>\n",
       "      <th>D_102__autocorrelation__lag_1</th>\n",
       "      <th>D_102__autocorrelation__lag_3</th>\n",
       "      <th>D_102__autocorrelation__lag_5</th>\n",
       "      <th>D_102__autocorrelation__lag_7</th>\n",
       "      <th>D_102__autocorrelation__lag_12</th>\n",
       "      <th>B_36__autocorrelation__lag_1</th>\n",
       "      <th>B_36__autocorrelation__lag_3</th>\n",
       "      <th>B_36__autocorrelation__lag_5</th>\n",
       "      <th>B_36__autocorrelation__lag_7</th>\n",
       "      <th>B_36__autocorrelation__lag_12</th>\n",
       "      <th>B_37__autocorrelation__lag_1</th>\n",
       "      <th>B_37__autocorrelation__lag_3</th>\n",
       "      <th>B_37__autocorrelation__lag_5</th>\n",
       "      <th>B_37__autocorrelation__lag_7</th>\n",
       "      <th>B_37__autocorrelation__lag_12</th>\n",
       "      <th>R_27__autocorrelation__lag_1</th>\n",
       "      <th>R_27__autocorrelation__lag_3</th>\n",
       "      <th>R_27__autocorrelation__lag_5</th>\n",
       "      <th>R_27__autocorrelation__lag_7</th>\n",
       "      <th>R_27__autocorrelation__lag_12</th>\n",
       "      <th>B_40__autocorrelation__lag_1</th>\n",
       "      <th>B_40__autocorrelation__lag_3</th>\n",
       "      <th>B_40__autocorrelation__lag_5</th>\n",
       "      <th>B_40__autocorrelation__lag_7</th>\n",
       "      <th>B_40__autocorrelation__lag_12</th>\n",
       "      <th>S_27__autocorrelation__lag_1</th>\n",
       "      <th>S_27__autocorrelation__lag_3</th>\n",
       "      <th>S_27__autocorrelation__lag_5</th>\n",
       "      <th>S_27__autocorrelation__lag_7</th>\n",
       "      <th>S_27__autocorrelation__lag_12</th>\n",
       "      <th>D_115__autocorrelation__lag_1</th>\n",
       "      <th>D_115__autocorrelation__lag_3</th>\n",
       "      <th>D_115__autocorrelation__lag_5</th>\n",
       "      <th>D_115__autocorrelation__lag_7</th>\n",
       "      <th>D_115__autocorrelation__lag_12</th>\n",
       "      <th>D_118__autocorrelation__lag_1</th>\n",
       "      <th>D_118__autocorrelation__lag_3</th>\n",
       "      <th>D_118__autocorrelation__lag_5</th>\n",
       "      <th>D_118__autocorrelation__lag_7</th>\n",
       "      <th>D_118__autocorrelation__lag_12</th>\n",
       "      <th>D_119__autocorrelation__lag_1</th>\n",
       "      <th>D_119__autocorrelation__lag_3</th>\n",
       "      <th>D_119__autocorrelation__lag_5</th>\n",
       "      <th>D_119__autocorrelation__lag_7</th>\n",
       "      <th>D_119__autocorrelation__lag_12</th>\n",
       "      <th>D_121__autocorrelation__lag_1</th>\n",
       "      <th>D_121__autocorrelation__lag_3</th>\n",
       "      <th>D_121__autocorrelation__lag_5</th>\n",
       "      <th>D_121__autocorrelation__lag_7</th>\n",
       "      <th>D_121__autocorrelation__lag_12</th>\n",
       "      <th>D_133__autocorrelation__lag_1</th>\n",
       "      <th>D_133__autocorrelation__lag_3</th>\n",
       "      <th>D_133__autocorrelation__lag_5</th>\n",
       "      <th>D_133__autocorrelation__lag_7</th>\n",
       "      <th>D_133__autocorrelation__lag_12</th>\n",
       "      <th>D_144__autocorrelation__lag_1</th>\n",
       "      <th>D_144__autocorrelation__lag_3</th>\n",
       "      <th>D_144__autocorrelation__lag_5</th>\n",
       "      <th>D_144__autocorrelation__lag_7</th>\n",
       "      <th>D_144__autocorrelation__lag_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
       "      <td>0.938469</td>\n",
       "      <td>0.933824</td>\n",
       "      <td>0.024194</td>\n",
       "      <td>0.868580</td>\n",
       "      <td>0.960384</td>\n",
       "      <td>0.934745</td>\n",
       "      <td>0</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.832050</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008724</td>\n",
       "      <td>0.012007</td>\n",
       "      <td>0.006547</td>\n",
       "      <td>0.001930</td>\n",
       "      <td>0.021655</td>\n",
       "      <td>0.009382</td>\n",
       "      <td>1.006838</td>\n",
       "      <td>1.005086</td>\n",
       "      <td>0.003222</td>\n",
       "      <td>1.000242</td>\n",
       "      <td>1.009672</td>\n",
       "      <td>1.007647</td>\n",
       "      <td>0.009228</td>\n",
       "      <td>0.004509</td>\n",
       "      <td>0.003081</td>\n",
       "      <td>0.000263</td>\n",
       "      <td>0.009228</td>\n",
       "      <td>0.006104</td>\n",
       "      <td>0.124035</td>\n",
       "      <td>0.113215</td>\n",
       "      <td>0.011670</td>\n",
       "      <td>0.098882</td>\n",
       "      <td>0.135021</td>\n",
       "      <td>0.135021</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004709</td>\n",
       "      <td>0.006456</td>\n",
       "      <td>0.002942</td>\n",
       "      <td>0.000783</td>\n",
       "      <td>0.009866</td>\n",
       "      <td>0.007174</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2.846154</td>\n",
       "      <td>2.444250</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0.708906</td>\n",
       "      <td>0.725369</td>\n",
       "      <td>0.009515</td>\n",
       "      <td>0.708906</td>\n",
       "      <td>0.740102</td>\n",
       "      <td>0.740102</td>\n",
       "      <td>0.170600</td>\n",
       "      <td>0.146650</td>\n",
       "      <td>0.047205</td>\n",
       "      <td>0.060492</td>\n",
       "      <td>0.231717</td>\n",
       "      <td>0.231717</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.358587</td>\n",
       "      <td>0.378074</td>\n",
       "      <td>0.085674</td>\n",
       "      <td>0.231009</td>\n",
       "      <td>0.519619</td>\n",
       "      <td>0.420521</td>\n",
       "      <td>0.525351</td>\n",
       "      <td>0.532874</td>\n",
       "      <td>0.006578</td>\n",
       "      <td>0.521311</td>\n",
       "      <td>0.542119</td>\n",
       "      <td>0.539715</td>\n",
       "      <td>0.255736</td>\n",
       "      <td>0.240978</td>\n",
       "      <td>0.076875</td>\n",
       "      <td>0.135586</td>\n",
       "      <td>0.403448</td>\n",
       "      <td>0.192376</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.063902</td>\n",
       "      <td>0.113510</td>\n",
       "      <td>0.047360</td>\n",
       "      <td>0.063902</td>\n",
       "      <td>0.221899</td>\n",
       "      <td>0.149564</td>\n",
       "      <td>0.059416</td>\n",
       "      <td>0.036624</td>\n",
       "      <td>0.023195</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.060502</td>\n",
       "      <td>0.058425</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.148698</td>\n",
       "      <td>0.150326</td>\n",
       "      <td>0.002922</td>\n",
       "      <td>0.145179</td>\n",
       "      <td>0.154326</td>\n",
       "      <td>0.153461</td>\n",
       "      <td>4</td>\n",
       "      <td>2.923077</td>\n",
       "      <td>0.954074</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.008207</td>\n",
       "      <td>0.006220</td>\n",
       "      <td>0.003180</td>\n",
       "      <td>0.000519</td>\n",
       "      <td>0.009535</td>\n",
       "      <td>0.009535</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.207334</td>\n",
       "      <td>0.204972</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.200782</td>\n",
       "      <td>0.208214</td>\n",
       "      <td>0.203524</td>\n",
       "      <td>0.736463</td>\n",
       "      <td>0.680138</td>\n",
       "      <td>0.050671</td>\n",
       "      <td>0.581678</td>\n",
       "      <td>0.741813</td>\n",
       "      <td>0.629392</td>\n",
       "      <td>0.096219</td>\n",
       "      <td>0.270280</td>\n",
       "      <td>0.181875</td>\n",
       "      <td>0.096219</td>\n",
       "      <td>0.741934</td>\n",
       "      <td>0.326101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.023381</td>\n",
       "      <td>0.029112</td>\n",
       "      <td>0.014758</td>\n",
       "      <td>0.007165</td>\n",
       "      <td>0.054221</td>\n",
       "      <td>0.034643</td>\n",
       "      <td>0.002768</td>\n",
       "      <td>0.007230</td>\n",
       "      <td>0.003031</td>\n",
       "      <td>0.002749</td>\n",
       "      <td>0.010260</td>\n",
       "      <td>0.010260</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.161345</td>\n",
       "      <td>0.098374</td>\n",
       "      <td>0.026775</td>\n",
       "      <td>0.074646</td>\n",
       "      <td>0.161345</td>\n",
       "      <td>0.105671</td>\n",
       "      <td>0.148266</td>\n",
       "      <td>0.125683</td>\n",
       "      <td>0.011772</td>\n",
       "      <td>0.111060</td>\n",
       "      <td>0.148266</td>\n",
       "      <td>0.112294</td>\n",
       "      <td>2896</td>\n",
       "      <td>2510.000000</td>\n",
       "      <td>429.583519</td>\n",
       "      <td>1544</td>\n",
       "      <td>3166</td>\n",
       "      <td>1544</td>\n",
       "      <td>0.354596</td>\n",
       "      <td>0.224432</td>\n",
       "      <td>0.068116</td>\n",
       "      <td>0.148284</td>\n",
       "      <td>0.354596</td>\n",
       "      <td>0.187285</td>\n",
       "      <td>0.152025</td>\n",
       "      <td>0.158571</td>\n",
       "      <td>0.004747</td>\n",
       "      <td>0.152025</td>\n",
       "      <td>0.166636</td>\n",
       "      <td>0.166636</td>\n",
       "      <td>0.118075</td>\n",
       "      <td>0.100432</td>\n",
       "      <td>0.013723</td>\n",
       "      <td>0.074886</td>\n",
       "      <td>0.120740</td>\n",
       "      <td>0.100107</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.291515</td>\n",
       "      <td>-0.321495</td>\n",
       "      <td>-0.650447</td>\n",
       "      <td>-0.318207</td>\n",
       "      <td>-0.002049</td>\n",
       "      <td>-0.300533</td>\n",
       "      <td>-0.270629</td>\n",
       "      <td>0.012265</td>\n",
       "      <td>-0.157674</td>\n",
       "      <td>-0.003953</td>\n",
       "      <td>-0.145769</td>\n",
       "      <td>0.348698</td>\n",
       "      <td>-0.258077</td>\n",
       "      <td>-1.594819</td>\n",
       "      <td>0.680675</td>\n",
       "      <td>0.183001</td>\n",
       "      <td>-0.185061</td>\n",
       "      <td>-0.633661</td>\n",
       "      <td>0.694321</td>\n",
       "      <td>0.725180</td>\n",
       "      <td>0.268445</td>\n",
       "      <td>-0.120008</td>\n",
       "      <td>-0.391025</td>\n",
       "      <td>-2.363685</td>\n",
       "      <td>0.178740</td>\n",
       "      <td>0.276932</td>\n",
       "      <td>0.038263</td>\n",
       "      <td>-0.558407</td>\n",
       "      <td>-2.188927</td>\n",
       "      <td>0.820823</td>\n",
       "      <td>0.241150</td>\n",
       "      <td>-0.448008</td>\n",
       "      <td>-0.688686</td>\n",
       "      <td>-1.128945</td>\n",
       "      <td>0.657447</td>\n",
       "      <td>0.221620</td>\n",
       "      <td>-0.074619</td>\n",
       "      <td>-0.678136</td>\n",
       "      <td>-0.032963</td>\n",
       "      <td>0.864386</td>\n",
       "      <td>0.422297</td>\n",
       "      <td>-0.273705</td>\n",
       "      <td>-0.965100</td>\n",
       "      <td>-1.214023</td>\n",
       "      <td>-0.465069</td>\n",
       "      <td>-0.078404</td>\n",
       "      <td>-0.114887</td>\n",
       "      <td>-0.377175</td>\n",
       "      <td>0.353591</td>\n",
       "      <td>0.119444</td>\n",
       "      <td>-0.350000</td>\n",
       "      <td>0.191667</td>\n",
       "      <td>-0.133333</td>\n",
       "      <td>0.30000</td>\n",
       "      <td>0.667559</td>\n",
       "      <td>0.015151</td>\n",
       "      <td>-0.786421</td>\n",
       "      <td>-0.472103</td>\n",
       "      <td>0.652642</td>\n",
       "      <td>0.554604</td>\n",
       "      <td>-0.333812</td>\n",
       "      <td>-0.634335</td>\n",
       "      <td>-0.380180</td>\n",
       "      <td>0.403259</td>\n",
       "      <td>-0.415392</td>\n",
       "      <td>-0.138115</td>\n",
       "      <td>0.042015</td>\n",
       "      <td>-0.325953</td>\n",
       "      <td>0.438000</td>\n",
       "      <td>0.473837</td>\n",
       "      <td>0.100465</td>\n",
       "      <td>-0.074128</td>\n",
       "      <td>-0.566667</td>\n",
       "      <td>1.025581</td>\n",
       "      <td>0.481466</td>\n",
       "      <td>-0.190818</td>\n",
       "      <td>-0.353911</td>\n",
       "      <td>-0.034498</td>\n",
       "      <td>-0.303400</td>\n",
       "      <td>0.835660</td>\n",
       "      <td>0.396176</td>\n",
       "      <td>-0.270693</td>\n",
       "      <td>-0.999827</td>\n",
       "      <td>0.287250</td>\n",
       "      <td>0.062934</td>\n",
       "      <td>-0.222288</td>\n",
       "      <td>-0.101989</td>\n",
       "      <td>-0.103639</td>\n",
       "      <td>0.187364</td>\n",
       "      <td>-0.183533</td>\n",
       "      <td>0.238019</td>\n",
       "      <td>-0.115756</td>\n",
       "      <td>-1.093063</td>\n",
       "      <td>0.759773</td>\n",
       "      <td>-0.224651</td>\n",
       "      <td>-0.222830</td>\n",
       "      <td>-0.075052</td>\n",
       "      <td>0.330820</td>\n",
       "      <td>0.070305</td>\n",
       "      <td>0.480488</td>\n",
       "      <td>-0.131812</td>\n",
       "      <td>-0.470987</td>\n",
       "      <td>-0.689279</td>\n",
       "      <td>0.098824</td>\n",
       "      <td>0.803534</td>\n",
       "      <td>0.291896</td>\n",
       "      <td>-0.368946</td>\n",
       "      <td>-0.759459</td>\n",
       "      <td>-0.963049</td>\n",
       "      <td>0.380376</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.074597</td>\n",
       "      <td>-0.755376</td>\n",
       "      <td>0.639577</td>\n",
       "      <td>0.057142</td>\n",
       "      <td>-0.625849</td>\n",
       "      <td>-0.741822</td>\n",
       "      <td>1.154139</td>\n",
       "      <td>0.831349</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>-0.264881</td>\n",
       "      <td>-0.271581</td>\n",
       "      <td>0.025118</td>\n",
       "      <td>0.416220</td>\n",
       "      <td>0.111103</td>\n",
       "      <td>0.256342</td>\n",
       "      <td>0.526964</td>\n",
       "      <td>-0.054544</td>\n",
       "      <td>-0.113633</td>\n",
       "      <td>-0.212115</td>\n",
       "      <td>0.006640</td>\n",
       "      <td>0.148278</td>\n",
       "      <td>0.160686</td>\n",
       "      <td>-0.828616</td>\n",
       "      <td>0.102856</td>\n",
       "      <td>0.240188</td>\n",
       "      <td>-0.456375</td>\n",
       "      <td>0.351104</td>\n",
       "      <td>0.006988</td>\n",
       "      <td>1.191048</td>\n",
       "      <td>0.086655</td>\n",
       "      <td>-0.176514</td>\n",
       "      <td>0.085949</td>\n",
       "      <td>0.302100</td>\n",
       "      <td>1.559940</td>\n",
       "      <td>-0.030590</td>\n",
       "      <td>0.355688</td>\n",
       "      <td>-0.625282</td>\n",
       "      <td>0.306292</td>\n",
       "      <td>-0.614856</td>\n",
       "      <td>-0.645935</td>\n",
       "      <td>-0.216410</td>\n",
       "      <td>0.021920</td>\n",
       "      <td>0.480663</td>\n",
       "      <td>0.693486</td>\n",
       "      <td>0.579599</td>\n",
       "      <td>0.035679</td>\n",
       "      <td>-0.676102</td>\n",
       "      <td>-0.551996</td>\n",
       "      <td>1.037578</td>\n",
       "      <td>-0.095328</td>\n",
       "      <td>0.318010</td>\n",
       "      <td>-0.121828</td>\n",
       "      <td>-0.546602</td>\n",
       "      <td>0.999477</td>\n",
       "      <td>-0.380035</td>\n",
       "      <td>-0.397064</td>\n",
       "      <td>0.363011</td>\n",
       "      <td>-0.220701</td>\n",
       "      <td>-0.146473</td>\n",
       "      <td>-0.175662</td>\n",
       "      <td>0.023506</td>\n",
       "      <td>0.280169</td>\n",
       "      <td>0.093404</td>\n",
       "      <td>-0.277213</td>\n",
       "      <td>-0.457152</td>\n",
       "      <td>-0.165754</td>\n",
       "      <td>0.117417</td>\n",
       "      <td>-0.066341</td>\n",
       "      <td>-0.335786</td>\n",
       "      <td>-0.231057</td>\n",
       "      <td>0.561710</td>\n",
       "      <td>-0.781056</td>\n",
       "      <td>0.544386</td>\n",
       "      <td>0.059783</td>\n",
       "      <td>0.553525</td>\n",
       "      <td>-0.093760</td>\n",
       "      <td>-0.808339</td>\n",
       "      <td>-0.680519</td>\n",
       "      <td>1.561704</td>\n",
       "      <td>0.817360</td>\n",
       "      <td>0.453765</td>\n",
       "      <td>-0.096066</td>\n",
       "      <td>-0.661534</td>\n",
       "      <td>-2.627619</td>\n",
       "      <td>0.001141</td>\n",
       "      <td>0.048006</td>\n",
       "      <td>-0.193599</td>\n",
       "      <td>0.117491</td>\n",
       "      <td>0.980243</td>\n",
       "      <td>-0.382612</td>\n",
       "      <td>-0.257439</td>\n",
       "      <td>0.200261</td>\n",
       "      <td>-0.162480</td>\n",
       "      <td>0.606577</td>\n",
       "      <td>-0.129857</td>\n",
       "      <td>-0.282572</td>\n",
       "      <td>0.194415</td>\n",
       "      <td>0.707581</td>\n",
       "      <td>0.199169</td>\n",
       "      <td>0.806845</td>\n",
       "      <td>0.279575</td>\n",
       "      <td>-0.563220</td>\n",
       "      <td>-0.892028</td>\n",
       "      <td>0.306369</td>\n",
       "      <td>0.380012</td>\n",
       "      <td>-0.137542</td>\n",
       "      <td>0.178246</td>\n",
       "      <td>-0.127935</td>\n",
       "      <td>-2.428539</td>\n",
       "      <td>0.544090</td>\n",
       "      <td>0.408778</td>\n",
       "      <td>-0.115710</td>\n",
       "      <td>-0.618815</td>\n",
       "      <td>-1.953235</td>\n",
       "      <td>0.517730</td>\n",
       "      <td>0.175713</td>\n",
       "      <td>-0.089425</td>\n",
       "      <td>-0.101551</td>\n",
       "      <td>-3.536048</td>\n",
       "      <td>0.444233</td>\n",
       "      <td>0.346846</td>\n",
       "      <td>0.069915</td>\n",
       "      <td>-0.562681</td>\n",
       "      <td>-3.917920</td>\n",
       "      <td>0.483853</td>\n",
       "      <td>0.316808</td>\n",
       "      <td>-0.049567</td>\n",
       "      <td>-0.285690</td>\n",
       "      <td>-2.367318</td>\n",
       "      <td>0.138385</td>\n",
       "      <td>0.192811</td>\n",
       "      <td>-0.641375</td>\n",
       "      <td>-0.435833</td>\n",
       "      <td>-0.067163</td>\n",
       "      <td>-0.104158</td>\n",
       "      <td>-0.052005</td>\n",
       "      <td>0.381391</td>\n",
       "      <td>-0.376558</td>\n",
       "      <td>1.735089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000fd6641609c6ece5454664794f0340ad84dddce9a2...</td>\n",
       "      <td>0.929122</td>\n",
       "      <td>0.899820</td>\n",
       "      <td>0.022119</td>\n",
       "      <td>0.861109</td>\n",
       "      <td>0.929122</td>\n",
       "      <td>0.880519</td>\n",
       "      <td>13</td>\n",
       "      <td>7.153846</td>\n",
       "      <td>6.743468</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>0.025782</td>\n",
       "      <td>0.025654</td>\n",
       "      <td>0.027756</td>\n",
       "      <td>0.006711</td>\n",
       "      <td>0.109644</td>\n",
       "      <td>0.034684</td>\n",
       "      <td>1.002647</td>\n",
       "      <td>0.991083</td>\n",
       "      <td>0.051531</td>\n",
       "      <td>0.819772</td>\n",
       "      <td>1.008534</td>\n",
       "      <td>1.004028</td>\n",
       "      <td>0.005515</td>\n",
       "      <td>0.006246</td>\n",
       "      <td>0.002129</td>\n",
       "      <td>0.001023</td>\n",
       "      <td>0.008996</td>\n",
       "      <td>0.006911</td>\n",
       "      <td>0.089799</td>\n",
       "      <td>0.120578</td>\n",
       "      <td>0.023824</td>\n",
       "      <td>0.089799</td>\n",
       "      <td>0.165509</td>\n",
       "      <td>0.165509</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005830</td>\n",
       "      <td>0.005663</td>\n",
       "      <td>0.003354</td>\n",
       "      <td>0.000861</td>\n",
       "      <td>0.012861</td>\n",
       "      <td>0.005068</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.525600</td>\n",
       "      <td>0.144571</td>\n",
       "      <td>0.169598</td>\n",
       "      <td>0.060646</td>\n",
       "      <td>0.525600</td>\n",
       "      <td>0.060646</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.800641</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.239459</td>\n",
       "      <td>0.256461</td>\n",
       "      <td>0.009261</td>\n",
       "      <td>0.239459</td>\n",
       "      <td>0.267228</td>\n",
       "      <td>0.266275</td>\n",
       "      <td>0.070967</td>\n",
       "      <td>0.035462</td>\n",
       "      <td>0.043899</td>\n",
       "      <td>0.004075</td>\n",
       "      <td>0.165146</td>\n",
       "      <td>0.027000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.457826</td>\n",
       "      <td>0.452041</td>\n",
       "      <td>0.013177</td>\n",
       "      <td>0.432424</td>\n",
       "      <td>0.471737</td>\n",
       "      <td>0.438828</td>\n",
       "      <td>0.382562</td>\n",
       "      <td>0.392433</td>\n",
       "      <td>0.006671</td>\n",
       "      <td>0.382562</td>\n",
       "      <td>0.402878</td>\n",
       "      <td>0.402195</td>\n",
       "      <td>0.059342</td>\n",
       "      <td>0.048203</td>\n",
       "      <td>0.031312</td>\n",
       "      <td>0.010117</td>\n",
       "      <td>0.105999</td>\n",
       "      <td>0.014696</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.201574</td>\n",
       "      <td>0.202270</td>\n",
       "      <td>0.015915</td>\n",
       "      <td>0.167634</td>\n",
       "      <td>0.226641</td>\n",
       "      <td>0.167634</td>\n",
       "      <td>0.032390</td>\n",
       "      <td>0.028049</td>\n",
       "      <td>0.013631</td>\n",
       "      <td>0.015836</td>\n",
       "      <td>0.068204</td>\n",
       "      <td>0.028411</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1.153846</td>\n",
       "      <td>0.375534</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007561</td>\n",
       "      <td>0.010298</td>\n",
       "      <td>0.011024</td>\n",
       "      <td>0.001722</td>\n",
       "      <td>0.045093</td>\n",
       "      <td>0.012926</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.518875</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.110471</td>\n",
       "      <td>0.158313</td>\n",
       "      <td>0.067030</td>\n",
       "      <td>0.103495</td>\n",
       "      <td>0.242366</td>\n",
       "      <td>0.242366</td>\n",
       "      <td>0.619012</td>\n",
       "      <td>0.566665</td>\n",
       "      <td>0.036880</td>\n",
       "      <td>0.510142</td>\n",
       "      <td>0.619012</td>\n",
       "      <td>0.570898</td>\n",
       "      <td>0.302757</td>\n",
       "      <td>0.298815</td>\n",
       "      <td>0.003047</td>\n",
       "      <td>0.294000</td>\n",
       "      <td>0.302757</td>\n",
       "      <td>0.297130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.025802</td>\n",
       "      <td>0.016785</td>\n",
       "      <td>0.017104</td>\n",
       "      <td>0.002045</td>\n",
       "      <td>0.052949</td>\n",
       "      <td>0.043929</td>\n",
       "      <td>0.011677</td>\n",
       "      <td>0.013792</td>\n",
       "      <td>0.021041</td>\n",
       "      <td>0.000416</td>\n",
       "      <td>0.081246</td>\n",
       "      <td>0.014570</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.072583</td>\n",
       "      <td>0.103002</td>\n",
       "      <td>0.035143</td>\n",
       "      <td>0.072583</td>\n",
       "      <td>0.208516</td>\n",
       "      <td>0.208516</td>\n",
       "      <td>0.026337</td>\n",
       "      <td>0.025823</td>\n",
       "      <td>0.004665</td>\n",
       "      <td>0.019050</td>\n",
       "      <td>0.032917</td>\n",
       "      <td>0.019050</td>\n",
       "      <td>1880</td>\n",
       "      <td>1286.461538</td>\n",
       "      <td>772.374544</td>\n",
       "      <td>0</td>\n",
       "      <td>2402</td>\n",
       "      <td>1284</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.048069</td>\n",
       "      <td>0.007596</td>\n",
       "      <td>0.036112</td>\n",
       "      <td>0.060770</td>\n",
       "      <td>0.036112</td>\n",
       "      <td>0.684371</td>\n",
       "      <td>0.705671</td>\n",
       "      <td>0.018540</td>\n",
       "      <td>0.684371</td>\n",
       "      <td>0.748383</td>\n",
       "      <td>0.748383</td>\n",
       "      <td>0.036490</td>\n",
       "      <td>0.046753</td>\n",
       "      <td>0.024456</td>\n",
       "      <td>0.008499</td>\n",
       "      <td>0.073904</td>\n",
       "      <td>0.017684</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.640442</td>\n",
       "      <td>0.008049</td>\n",
       "      <td>-0.391780</td>\n",
       "      <td>-0.775146</td>\n",
       "      <td>0.137537</td>\n",
       "      <td>-0.153068</td>\n",
       "      <td>-0.255156</td>\n",
       "      <td>-0.475800</td>\n",
       "      <td>0.906418</td>\n",
       "      <td>-0.013362</td>\n",
       "      <td>-0.363174</td>\n",
       "      <td>-0.237384</td>\n",
       "      <td>0.067371</td>\n",
       "      <td>-0.004027</td>\n",
       "      <td>0.385144</td>\n",
       "      <td>0.011511</td>\n",
       "      <td>0.043921</td>\n",
       "      <td>-0.084472</td>\n",
       "      <td>-2.815513</td>\n",
       "      <td>0.574890</td>\n",
       "      <td>-0.105825</td>\n",
       "      <td>-0.866482</td>\n",
       "      <td>-0.270812</td>\n",
       "      <td>-0.173263</td>\n",
       "      <td>0.679323</td>\n",
       "      <td>-0.263585</td>\n",
       "      <td>-0.329725</td>\n",
       "      <td>-0.492072</td>\n",
       "      <td>-0.002653</td>\n",
       "      <td>0.612128</td>\n",
       "      <td>0.218820</td>\n",
       "      <td>-0.031887</td>\n",
       "      <td>-0.663814</td>\n",
       "      <td>-1.064819</td>\n",
       "      <td>0.617036</td>\n",
       "      <td>-0.187460</td>\n",
       "      <td>-0.584340</td>\n",
       "      <td>-0.503029</td>\n",
       "      <td>0.540399</td>\n",
       "      <td>0.265609</td>\n",
       "      <td>-0.017814</td>\n",
       "      <td>-0.470635</td>\n",
       "      <td>-0.227403</td>\n",
       "      <td>1.223635</td>\n",
       "      <td>0.010839</td>\n",
       "      <td>-0.405207</td>\n",
       "      <td>-0.138518</td>\n",
       "      <td>0.348070</td>\n",
       "      <td>0.021372</td>\n",
       "      <td>-0.006944</td>\n",
       "      <td>-0.025000</td>\n",
       "      <td>-0.052083</td>\n",
       "      <td>-0.097222</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.051193</td>\n",
       "      <td>-0.371365</td>\n",
       "      <td>-0.120808</td>\n",
       "      <td>0.330974</td>\n",
       "      <td>0.091959</td>\n",
       "      <td>0.327604</td>\n",
       "      <td>-0.110835</td>\n",
       "      <td>-0.144262</td>\n",
       "      <td>-0.822322</td>\n",
       "      <td>-0.050876</td>\n",
       "      <td>-0.123401</td>\n",
       "      <td>0.019259</td>\n",
       "      <td>-0.027633</td>\n",
       "      <td>0.378621</td>\n",
       "      <td>-0.222775</td>\n",
       "      <td>0.212647</td>\n",
       "      <td>0.060110</td>\n",
       "      <td>-0.374543</td>\n",
       "      <td>-0.113276</td>\n",
       "      <td>0.052984</td>\n",
       "      <td>-0.174335</td>\n",
       "      <td>0.147871</td>\n",
       "      <td>-0.428026</td>\n",
       "      <td>0.090024</td>\n",
       "      <td>-0.418554</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.146760</td>\n",
       "      <td>-0.393144</td>\n",
       "      <td>0.133074</td>\n",
       "      <td>0.016893</td>\n",
       "      <td>-0.021925</td>\n",
       "      <td>-0.044140</td>\n",
       "      <td>0.296799</td>\n",
       "      <td>0.007528</td>\n",
       "      <td>-0.305561</td>\n",
       "      <td>-1.156592</td>\n",
       "      <td>0.270833</td>\n",
       "      <td>-0.347421</td>\n",
       "      <td>0.636159</td>\n",
       "      <td>0.087306</td>\n",
       "      <td>-0.520594</td>\n",
       "      <td>0.160171</td>\n",
       "      <td>-0.702757</td>\n",
       "      <td>-0.391291</td>\n",
       "      <td>-0.444370</td>\n",
       "      <td>0.102346</td>\n",
       "      <td>0.267641</td>\n",
       "      <td>-0.199963</td>\n",
       "      <td>0.144985</td>\n",
       "      <td>-0.228699</td>\n",
       "      <td>-0.066602</td>\n",
       "      <td>-1.541499</td>\n",
       "      <td>0.296389</td>\n",
       "      <td>-0.259000</td>\n",
       "      <td>0.240417</td>\n",
       "      <td>-0.357222</td>\n",
       "      <td>-0.121543</td>\n",
       "      <td>-0.039197</td>\n",
       "      <td>-0.349951</td>\n",
       "      <td>-0.014985</td>\n",
       "      <td>0.020709</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.457028</td>\n",
       "      <td>0.148806</td>\n",
       "      <td>0.685348</td>\n",
       "      <td>0.314082</td>\n",
       "      <td>0.760557</td>\n",
       "      <td>-0.167946</td>\n",
       "      <td>-0.261768</td>\n",
       "      <td>0.316078</td>\n",
       "      <td>-0.227381</td>\n",
       "      <td>-0.025005</td>\n",
       "      <td>-0.285566</td>\n",
       "      <td>-0.140152</td>\n",
       "      <td>0.229251</td>\n",
       "      <td>-0.016419</td>\n",
       "      <td>-0.496380</td>\n",
       "      <td>0.265097</td>\n",
       "      <td>-0.216986</td>\n",
       "      <td>0.845523</td>\n",
       "      <td>-0.259695</td>\n",
       "      <td>-0.489087</td>\n",
       "      <td>-0.186750</td>\n",
       "      <td>-0.520381</td>\n",
       "      <td>0.269457</td>\n",
       "      <td>-0.899951</td>\n",
       "      <td>0.251996</td>\n",
       "      <td>-0.699937</td>\n",
       "      <td>0.495561</td>\n",
       "      <td>-0.836835</td>\n",
       "      <td>-0.218724</td>\n",
       "      <td>-0.052303</td>\n",
       "      <td>-0.025683</td>\n",
       "      <td>-0.000577</td>\n",
       "      <td>-0.138405</td>\n",
       "      <td>-0.829197</td>\n",
       "      <td>-0.149847</td>\n",
       "      <td>-0.391023</td>\n",
       "      <td>-0.486948</td>\n",
       "      <td>-0.389997</td>\n",
       "      <td>0.436127</td>\n",
       "      <td>-0.038007</td>\n",
       "      <td>-0.186194</td>\n",
       "      <td>-0.326889</td>\n",
       "      <td>0.163005</td>\n",
       "      <td>0.042730</td>\n",
       "      <td>-0.297713</td>\n",
       "      <td>-0.157730</td>\n",
       "      <td>0.007142</td>\n",
       "      <td>0.267569</td>\n",
       "      <td>0.037623</td>\n",
       "      <td>0.091869</td>\n",
       "      <td>-0.562719</td>\n",
       "      <td>0.297626</td>\n",
       "      <td>-0.105555</td>\n",
       "      <td>0.094522</td>\n",
       "      <td>-0.118541</td>\n",
       "      <td>-0.192225</td>\n",
       "      <td>-0.151486</td>\n",
       "      <td>0.337271</td>\n",
       "      <td>0.158705</td>\n",
       "      <td>-0.322453</td>\n",
       "      <td>-0.142928</td>\n",
       "      <td>-0.405988</td>\n",
       "      <td>-0.478377</td>\n",
       "      <td>0.273043</td>\n",
       "      <td>-0.456351</td>\n",
       "      <td>0.102505</td>\n",
       "      <td>0.178573</td>\n",
       "      <td>0.187638</td>\n",
       "      <td>-0.519241</td>\n",
       "      <td>-0.034035</td>\n",
       "      <td>0.007712</td>\n",
       "      <td>0.000584</td>\n",
       "      <td>-0.102209</td>\n",
       "      <td>0.857307</td>\n",
       "      <td>-0.060868</td>\n",
       "      <td>-0.512561</td>\n",
       "      <td>0.044560</td>\n",
       "      <td>0.203685</td>\n",
       "      <td>-0.183552</td>\n",
       "      <td>0.139136</td>\n",
       "      <td>-0.395435</td>\n",
       "      <td>-0.346664</td>\n",
       "      <td>0.041722</td>\n",
       "      <td>-0.014937</td>\n",
       "      <td>-0.189782</td>\n",
       "      <td>0.439698</td>\n",
       "      <td>-0.121442</td>\n",
       "      <td>-0.277884</td>\n",
       "      <td>-0.304503</td>\n",
       "      <td>0.270639</td>\n",
       "      <td>-0.107014</td>\n",
       "      <td>-0.210241</td>\n",
       "      <td>0.146716</td>\n",
       "      <td>-0.464874</td>\n",
       "      <td>0.104221</td>\n",
       "      <td>-0.215612</td>\n",
       "      <td>-0.252645</td>\n",
       "      <td>0.175138</td>\n",
       "      <td>-0.905549</td>\n",
       "      <td>0.565714</td>\n",
       "      <td>0.313500</td>\n",
       "      <td>-0.071783</td>\n",
       "      <td>-0.587236</td>\n",
       "      <td>-2.230022</td>\n",
       "      <td>0.365810</td>\n",
       "      <td>0.422014</td>\n",
       "      <td>-0.155002</td>\n",
       "      <td>0.130746</td>\n",
       "      <td>-3.984658</td>\n",
       "      <td>0.702565</td>\n",
       "      <td>0.284260</td>\n",
       "      <td>-0.020855</td>\n",
       "      <td>-0.525714</td>\n",
       "      <td>-1.367815</td>\n",
       "      <td>0.380495</td>\n",
       "      <td>0.480116</td>\n",
       "      <td>-0.103145</td>\n",
       "      <td>-0.384052</td>\n",
       "      <td>-3.540150</td>\n",
       "      <td>0.301589</td>\n",
       "      <td>0.255739</td>\n",
       "      <td>0.078983</td>\n",
       "      <td>-0.341393</td>\n",
       "      <td>0.779548</td>\n",
       "      <td>-0.232295</td>\n",
       "      <td>0.127100</td>\n",
       "      <td>-0.118868</td>\n",
       "      <td>0.054102</td>\n",
       "      <td>0.577802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00001b22f846c82c51f6e3958ccd81970162bae8b007e8...</td>\n",
       "      <td>0.876615</td>\n",
       "      <td>0.878454</td>\n",
       "      <td>0.028911</td>\n",
       "      <td>0.797670</td>\n",
       "      <td>0.904482</td>\n",
       "      <td>0.880875</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001472</td>\n",
       "      <td>0.004386</td>\n",
       "      <td>0.002786</td>\n",
       "      <td>0.001472</td>\n",
       "      <td>0.009997</td>\n",
       "      <td>0.004284</td>\n",
       "      <td>0.810796</td>\n",
       "      <td>0.815677</td>\n",
       "      <td>0.003545</td>\n",
       "      <td>0.810796</td>\n",
       "      <td>0.819987</td>\n",
       "      <td>0.812649</td>\n",
       "      <td>0.005955</td>\n",
       "      <td>0.006621</td>\n",
       "      <td>0.001919</td>\n",
       "      <td>0.003540</td>\n",
       "      <td>0.009443</td>\n",
       "      <td>0.006450</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004826</td>\n",
       "      <td>0.005493</td>\n",
       "      <td>0.002834</td>\n",
       "      <td>0.000626</td>\n",
       "      <td>0.009383</td>\n",
       "      <td>0.007196</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.27735</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.230769</td>\n",
       "      <td>1.690850</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.222406</td>\n",
       "      <td>0.236871</td>\n",
       "      <td>0.008896</td>\n",
       "      <td>0.222406</td>\n",
       "      <td>0.251598</td>\n",
       "      <td>0.251598</td>\n",
       "      <td>0.005358</td>\n",
       "      <td>0.004618</td>\n",
       "      <td>0.003043</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>0.008656</td>\n",
       "      <td>0.001557</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.438652</td>\n",
       "      <td>0.464475</td>\n",
       "      <td>0.060166</td>\n",
       "      <td>0.413028</td>\n",
       "      <td>0.647064</td>\n",
       "      <td>0.433713</td>\n",
       "      <td>0.318290</td>\n",
       "      <td>0.328617</td>\n",
       "      <td>0.007183</td>\n",
       "      <td>0.318290</td>\n",
       "      <td>0.339566</td>\n",
       "      <td>0.339125</td>\n",
       "      <td>0.081635</td>\n",
       "      <td>0.092284</td>\n",
       "      <td>0.060616</td>\n",
       "      <td>0.030227</td>\n",
       "      <td>0.255134</td>\n",
       "      <td>0.080370</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.168822</td>\n",
       "      <td>0.176674</td>\n",
       "      <td>0.024615</td>\n",
       "      <td>0.129857</td>\n",
       "      <td>0.213943</td>\n",
       "      <td>0.183628</td>\n",
       "      <td>0.029138</td>\n",
       "      <td>0.034433</td>\n",
       "      <td>0.015459</td>\n",
       "      <td>0.021261</td>\n",
       "      <td>0.079764</td>\n",
       "      <td>0.026981</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.506370</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003663</td>\n",
       "      <td>0.004730</td>\n",
       "      <td>0.003302</td>\n",
       "      <td>0.000422</td>\n",
       "      <td>0.009521</td>\n",
       "      <td>0.009392</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.200082</td>\n",
       "      <td>0.199863</td>\n",
       "      <td>0.002990</td>\n",
       "      <td>0.195188</td>\n",
       "      <td>0.203649</td>\n",
       "      <td>0.202159</td>\n",
       "      <td>0.634722</td>\n",
       "      <td>0.618191</td>\n",
       "      <td>0.075604</td>\n",
       "      <td>0.381123</td>\n",
       "      <td>0.678706</td>\n",
       "      <td>0.628938</td>\n",
       "      <td>0.222126</td>\n",
       "      <td>0.273711</td>\n",
       "      <td>0.052875</td>\n",
       "      <td>0.162125</td>\n",
       "      <td>0.302619</td>\n",
       "      <td>0.296313</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007875</td>\n",
       "      <td>0.005948</td>\n",
       "      <td>0.002943</td>\n",
       "      <td>0.001054</td>\n",
       "      <td>0.008730</td>\n",
       "      <td>0.001824</td>\n",
       "      <td>0.001677</td>\n",
       "      <td>0.004683</td>\n",
       "      <td>0.002312</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.007619</td>\n",
       "      <td>0.005092</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.011923</td>\n",
       "      <td>0.011541</td>\n",
       "      <td>0.002969</td>\n",
       "      <td>0.006100</td>\n",
       "      <td>0.015486</td>\n",
       "      <td>0.007158</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.073229</td>\n",
       "      <td>0.077362</td>\n",
       "      <td>0.016318</td>\n",
       "      <td>0.057529</td>\n",
       "      <td>0.099230</td>\n",
       "      <td>0.098963</td>\n",
       "      <td>0.201530</td>\n",
       "      <td>0.208154</td>\n",
       "      <td>0.003188</td>\n",
       "      <td>0.201530</td>\n",
       "      <td>0.211538</td>\n",
       "      <td>0.209386</td>\n",
       "      <td>0.002824</td>\n",
       "      <td>0.003778</td>\n",
       "      <td>0.002688</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.008332</td>\n",
       "      <td>0.001749</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.087941</td>\n",
       "      <td>-0.179123</td>\n",
       "      <td>-0.307702</td>\n",
       "      <td>-0.451775</td>\n",
       "      <td>0.184237</td>\n",
       "      <td>-0.575687</td>\n",
       "      <td>0.645257</td>\n",
       "      <td>-0.229582</td>\n",
       "      <td>-0.993711</td>\n",
       "      <td>-0.203533</td>\n",
       "      <td>-0.267247</td>\n",
       "      <td>-0.310228</td>\n",
       "      <td>-0.175057</td>\n",
       "      <td>-0.248955</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.013915</td>\n",
       "      <td>0.108534</td>\n",
       "      <td>-0.181705</td>\n",
       "      <td>0.246389</td>\n",
       "      <td>-0.205516</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.681203</td>\n",
       "      <td>0.222490</td>\n",
       "      <td>-0.155827</td>\n",
       "      <td>-0.587732</td>\n",
       "      <td>-0.363174</td>\n",
       "      <td>-0.023059</td>\n",
       "      <td>0.061797</td>\n",
       "      <td>0.075474</td>\n",
       "      <td>-0.096632</td>\n",
       "      <td>0.290578</td>\n",
       "      <td>0.729973</td>\n",
       "      <td>-0.060546</td>\n",
       "      <td>-0.222384</td>\n",
       "      <td>-0.443215</td>\n",
       "      <td>-0.887565</td>\n",
       "      <td>-0.847614</td>\n",
       "      <td>-0.813279</td>\n",
       "      <td>-0.777275</td>\n",
       "      <td>-0.568142</td>\n",
       "      <td>-0.635228</td>\n",
       "      <td>-0.006944</td>\n",
       "      <td>-0.025000</td>\n",
       "      <td>-0.052083</td>\n",
       "      <td>-0.097222</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-0.015536</td>\n",
       "      <td>-0.161224</td>\n",
       "      <td>0.540801</td>\n",
       "      <td>-0.629639</td>\n",
       "      <td>0.672025</td>\n",
       "      <td>0.020514</td>\n",
       "      <td>0.037563</td>\n",
       "      <td>-0.218005</td>\n",
       "      <td>0.282124</td>\n",
       "      <td>-0.472093</td>\n",
       "      <td>0.051799</td>\n",
       "      <td>-0.383249</td>\n",
       "      <td>0.361048</td>\n",
       "      <td>-0.333390</td>\n",
       "      <td>-0.231989</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.088122</td>\n",
       "      <td>-0.157026</td>\n",
       "      <td>-0.049585</td>\n",
       "      <td>-0.066684</td>\n",
       "      <td>0.083974</td>\n",
       "      <td>0.694144</td>\n",
       "      <td>-0.089993</td>\n",
       "      <td>-0.187485</td>\n",
       "      <td>-0.349972</td>\n",
       "      <td>-0.217902</td>\n",
       "      <td>-0.172691</td>\n",
       "      <td>0.709748</td>\n",
       "      <td>-0.079229</td>\n",
       "      <td>0.010350</td>\n",
       "      <td>-0.695358</td>\n",
       "      <td>-0.188444</td>\n",
       "      <td>0.450462</td>\n",
       "      <td>0.237886</td>\n",
       "      <td>1.204669</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.375516</td>\n",
       "      <td>-0.307511</td>\n",
       "      <td>-0.169422</td>\n",
       "      <td>-0.690030</td>\n",
       "      <td>0.492095</td>\n",
       "      <td>-0.555943</td>\n",
       "      <td>-0.395269</td>\n",
       "      <td>0.159900</td>\n",
       "      <td>-0.660197</td>\n",
       "      <td>1.457455</td>\n",
       "      <td>0.006133</td>\n",
       "      <td>-0.180973</td>\n",
       "      <td>-0.248553</td>\n",
       "      <td>-0.674297</td>\n",
       "      <td>1.276107</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.253106</td>\n",
       "      <td>-0.127325</td>\n",
       "      <td>0.058844</td>\n",
       "      <td>0.251449</td>\n",
       "      <td>0.011103</td>\n",
       "      <td>0.697222</td>\n",
       "      <td>-0.090000</td>\n",
       "      <td>-0.187500</td>\n",
       "      <td>-0.394008</td>\n",
       "      <td>-0.653036</td>\n",
       "      <td>-0.419274</td>\n",
       "      <td>-0.611835</td>\n",
       "      <td>-0.736703</td>\n",
       "      <td>-0.102188</td>\n",
       "      <td>-0.133331</td>\n",
       "      <td>-0.041059</td>\n",
       "      <td>-0.113868</td>\n",
       "      <td>0.268577</td>\n",
       "      <td>0.083551</td>\n",
       "      <td>-0.718567</td>\n",
       "      <td>-0.700913</td>\n",
       "      <td>0.449553</td>\n",
       "      <td>-0.274463</td>\n",
       "      <td>0.126128</td>\n",
       "      <td>0.638296</td>\n",
       "      <td>-0.504789</td>\n",
       "      <td>-0.760304</td>\n",
       "      <td>-0.247630</td>\n",
       "      <td>0.092732</td>\n",
       "      <td>-0.639869</td>\n",
       "      <td>-0.497379</td>\n",
       "      <td>3.175819</td>\n",
       "      <td>-0.291652</td>\n",
       "      <td>0.028158</td>\n",
       "      <td>-0.307972</td>\n",
       "      <td>-0.223158</td>\n",
       "      <td>0.609372</td>\n",
       "      <td>0.170658</td>\n",
       "      <td>-0.340540</td>\n",
       "      <td>0.336744</td>\n",
       "      <td>-0.575544</td>\n",
       "      <td>0.090697</td>\n",
       "      <td>-0.285243</td>\n",
       "      <td>-0.041702</td>\n",
       "      <td>0.245028</td>\n",
       "      <td>0.304328</td>\n",
       "      <td>0.029411</td>\n",
       "      <td>-0.423801</td>\n",
       "      <td>-0.157923</td>\n",
       "      <td>0.007586</td>\n",
       "      <td>-0.313025</td>\n",
       "      <td>-0.212258</td>\n",
       "      <td>0.138006</td>\n",
       "      <td>-0.213037</td>\n",
       "      <td>-0.632758</td>\n",
       "      <td>0.613924</td>\n",
       "      <td>-1.227427</td>\n",
       "      <td>-0.370323</td>\n",
       "      <td>0.200690</td>\n",
       "      <td>-0.516252</td>\n",
       "      <td>0.179139</td>\n",
       "      <td>0.684402</td>\n",
       "      <td>0.092495</td>\n",
       "      <td>-0.375719</td>\n",
       "      <td>0.027981</td>\n",
       "      <td>0.020216</td>\n",
       "      <td>0.391358</td>\n",
       "      <td>-0.322914</td>\n",
       "      <td>-0.011372</td>\n",
       "      <td>-0.421537</td>\n",
       "      <td>-0.007626</td>\n",
       "      <td>-0.311461</td>\n",
       "      <td>-0.398431</td>\n",
       "      <td>-0.155454</td>\n",
       "      <td>0.540269</td>\n",
       "      <td>0.476253</td>\n",
       "      <td>-0.074307</td>\n",
       "      <td>0.219904</td>\n",
       "      <td>-0.491950</td>\n",
       "      <td>0.253178</td>\n",
       "      <td>0.147721</td>\n",
       "      <td>1.601073</td>\n",
       "      <td>0.029732</td>\n",
       "      <td>0.167404</td>\n",
       "      <td>-0.290881</td>\n",
       "      <td>-0.037630</td>\n",
       "      <td>0.476133</td>\n",
       "      <td>0.119477</td>\n",
       "      <td>-0.254207</td>\n",
       "      <td>-0.204287</td>\n",
       "      <td>-0.111312</td>\n",
       "      <td>0.039502</td>\n",
       "      <td>-0.298726</td>\n",
       "      <td>0.151240</td>\n",
       "      <td>-0.014791</td>\n",
       "      <td>-0.510045</td>\n",
       "      <td>0.457782</td>\n",
       "      <td>-0.334895</td>\n",
       "      <td>0.045494</td>\n",
       "      <td>0.383480</td>\n",
       "      <td>0.263805</td>\n",
       "      <td>0.123531</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.497497</td>\n",
       "      <td>0.444587</td>\n",
       "      <td>0.089026</td>\n",
       "      <td>-0.609927</td>\n",
       "      <td>-2.541770</td>\n",
       "      <td>0.697518</td>\n",
       "      <td>0.421769</td>\n",
       "      <td>-0.134236</td>\n",
       "      <td>-0.868999</td>\n",
       "      <td>-2.320283</td>\n",
       "      <td>0.364284</td>\n",
       "      <td>0.428514</td>\n",
       "      <td>-0.039417</td>\n",
       "      <td>-0.669263</td>\n",
       "      <td>-3.101376</td>\n",
       "      <td>0.630267</td>\n",
       "      <td>0.321742</td>\n",
       "      <td>-0.009910</td>\n",
       "      <td>-0.474290</td>\n",
       "      <td>-3.336769</td>\n",
       "      <td>-0.252123</td>\n",
       "      <td>-0.321239</td>\n",
       "      <td>0.420012</td>\n",
       "      <td>-0.042483</td>\n",
       "      <td>-1.905534</td>\n",
       "      <td>-0.171315</td>\n",
       "      <td>-0.046841</td>\n",
       "      <td>0.354531</td>\n",
       "      <td>-0.548845</td>\n",
       "      <td>0.831806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000041bdba6ecadd89a52d11886e8eaaec9325906c9723...</td>\n",
       "      <td>0.567442</td>\n",
       "      <td>0.598969</td>\n",
       "      <td>0.020107</td>\n",
       "      <td>0.567442</td>\n",
       "      <td>0.623392</td>\n",
       "      <td>0.621776</td>\n",
       "      <td>9</td>\n",
       "      <td>1.538462</td>\n",
       "      <td>3.017046</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.070311</td>\n",
       "      <td>0.059876</td>\n",
       "      <td>0.080531</td>\n",
       "      <td>0.005910</td>\n",
       "      <td>0.279991</td>\n",
       "      <td>0.012564</td>\n",
       "      <td>0.812053</td>\n",
       "      <td>0.955264</td>\n",
       "      <td>0.080981</td>\n",
       "      <td>0.812053</td>\n",
       "      <td>1.009999</td>\n",
       "      <td>1.006183</td>\n",
       "      <td>0.004228</td>\n",
       "      <td>0.005665</td>\n",
       "      <td>0.003473</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.009915</td>\n",
       "      <td>0.007829</td>\n",
       "      <td>0.407420</td>\n",
       "      <td>0.247750</td>\n",
       "      <td>0.095122</td>\n",
       "      <td>0.149216</td>\n",
       "      <td>0.407420</td>\n",
       "      <td>0.287766</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010927</td>\n",
       "      <td>0.006423</td>\n",
       "      <td>0.003360</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.010927</td>\n",
       "      <td>0.009937</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006633</td>\n",
       "      <td>0.061026</td>\n",
       "      <td>0.041993</td>\n",
       "      <td>0.006633</td>\n",
       "      <td>0.149891</td>\n",
       "      <td>0.046104</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2.230769</td>\n",
       "      <td>2.832956</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.056394</td>\n",
       "      <td>0.069334</td>\n",
       "      <td>0.008501</td>\n",
       "      <td>0.056394</td>\n",
       "      <td>0.085103</td>\n",
       "      <td>0.085103</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.088374</td>\n",
       "      <td>0.074462</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.283781</td>\n",
       "      <td>0.118818</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.471676</td>\n",
       "      <td>0.431905</td>\n",
       "      <td>0.030525</td>\n",
       "      <td>0.384254</td>\n",
       "      <td>0.471676</td>\n",
       "      <td>0.410723</td>\n",
       "      <td>0.392230</td>\n",
       "      <td>0.403269</td>\n",
       "      <td>0.006355</td>\n",
       "      <td>0.392230</td>\n",
       "      <td>0.414224</td>\n",
       "      <td>0.414224</td>\n",
       "      <td>0.176105</td>\n",
       "      <td>0.076686</td>\n",
       "      <td>0.063902</td>\n",
       "      <td>0.005276</td>\n",
       "      <td>0.177252</td>\n",
       "      <td>0.013057</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.079987</td>\n",
       "      <td>0.160625</td>\n",
       "      <td>0.031266</td>\n",
       "      <td>0.079987</td>\n",
       "      <td>0.196887</td>\n",
       "      <td>0.174331</td>\n",
       "      <td>0.252338</td>\n",
       "      <td>0.062130</td>\n",
       "      <td>0.073590</td>\n",
       "      <td>0.004301</td>\n",
       "      <td>0.252338</td>\n",
       "      <td>0.011969</td>\n",
       "      <td>1.004358</td>\n",
       "      <td>1.004676</td>\n",
       "      <td>0.001928</td>\n",
       "      <td>1.002021</td>\n",
       "      <td>1.008767</td>\n",
       "      <td>1.005561</td>\n",
       "      <td>0.341256</td>\n",
       "      <td>0.439581</td>\n",
       "      <td>0.044539</td>\n",
       "      <td>0.341256</td>\n",
       "      <td>0.482535</td>\n",
       "      <td>0.430318</td>\n",
       "      <td>0</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.277350</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.026897</td>\n",
       "      <td>0.052241</td>\n",
       "      <td>0.053342</td>\n",
       "      <td>0.001702</td>\n",
       "      <td>0.176352</td>\n",
       "      <td>0.020526</td>\n",
       "      <td>0</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.650444</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.201745</td>\n",
       "      <td>0.199698</td>\n",
       "      <td>0.002130</td>\n",
       "      <td>0.195300</td>\n",
       "      <td>0.203203</td>\n",
       "      <td>0.198356</td>\n",
       "      <td>0.582652</td>\n",
       "      <td>0.610934</td>\n",
       "      <td>0.090090</td>\n",
       "      <td>0.345100</td>\n",
       "      <td>0.704214</td>\n",
       "      <td>0.672080</td>\n",
       "      <td>0.297839</td>\n",
       "      <td>0.306553</td>\n",
       "      <td>0.079528</td>\n",
       "      <td>0.192981</td>\n",
       "      <td>0.431901</td>\n",
       "      <td>0.411625</td>\n",
       "      <td>0.006409</td>\n",
       "      <td>0.004336</td>\n",
       "      <td>0.003589</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>0.00999</td>\n",
       "      <td>0.001379</td>\n",
       "      <td>0.068346</td>\n",
       "      <td>0.056297</td>\n",
       "      <td>0.044583</td>\n",
       "      <td>0.002999</td>\n",
       "      <td>0.150845</td>\n",
       "      <td>0.022970</td>\n",
       "      <td>0.043140</td>\n",
       "      <td>0.044294</td>\n",
       "      <td>0.071076</td>\n",
       "      <td>0.000672</td>\n",
       "      <td>0.241378</td>\n",
       "      <td>0.005491</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.365518</td>\n",
       "      <td>0.261497</td>\n",
       "      <td>0.078128</td>\n",
       "      <td>0.152622</td>\n",
       "      <td>0.370595</td>\n",
       "      <td>0.279464</td>\n",
       "      <td>0.014082</td>\n",
       "      <td>0.048949</td>\n",
       "      <td>0.025280</td>\n",
       "      <td>0.009411</td>\n",
       "      <td>0.077831</td>\n",
       "      <td>0.074835</td>\n",
       "      <td>1454</td>\n",
       "      <td>961.307692</td>\n",
       "      <td>405.585048</td>\n",
       "      <td>528</td>\n",
       "      <td>1511</td>\n",
       "      <td>528</td>\n",
       "      <td>0.094076</td>\n",
       "      <td>0.061726</td>\n",
       "      <td>0.018374</td>\n",
       "      <td>0.021400</td>\n",
       "      <td>0.094076</td>\n",
       "      <td>0.021400</td>\n",
       "      <td>0.579588</td>\n",
       "      <td>0.564632</td>\n",
       "      <td>0.018147</td>\n",
       "      <td>0.533675</td>\n",
       "      <td>0.580167</td>\n",
       "      <td>0.554483</td>\n",
       "      <td>0.013755</td>\n",
       "      <td>0.081928</td>\n",
       "      <td>0.041875</td>\n",
       "      <td>0.013755</td>\n",
       "      <td>0.124311</td>\n",
       "      <td>0.055897</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.346848</td>\n",
       "      <td>-0.221351</td>\n",
       "      <td>-0.437593</td>\n",
       "      <td>-0.156825</td>\n",
       "      <td>-0.004960</td>\n",
       "      <td>0.158285</td>\n",
       "      <td>-0.057376</td>\n",
       "      <td>-0.096556</td>\n",
       "      <td>-0.218874</td>\n",
       "      <td>0.522961</td>\n",
       "      <td>-0.079184</td>\n",
       "      <td>-0.187307</td>\n",
       "      <td>-0.267886</td>\n",
       "      <td>0.009601</td>\n",
       "      <td>0.658294</td>\n",
       "      <td>-0.073341</td>\n",
       "      <td>-0.670663</td>\n",
       "      <td>-0.587030</td>\n",
       "      <td>0.331702</td>\n",
       "      <td>0.884221</td>\n",
       "      <td>0.346109</td>\n",
       "      <td>-0.102628</td>\n",
       "      <td>-0.676119</td>\n",
       "      <td>-1.529904</td>\n",
       "      <td>0.478479</td>\n",
       "      <td>-0.012534</td>\n",
       "      <td>0.338228</td>\n",
       "      <td>-0.961768</td>\n",
       "      <td>-1.405952</td>\n",
       "      <td>0.533719</td>\n",
       "      <td>0.160830</td>\n",
       "      <td>-0.011115</td>\n",
       "      <td>-0.087637</td>\n",
       "      <td>-4.185893</td>\n",
       "      <td>0.686046</td>\n",
       "      <td>-0.175417</td>\n",
       "      <td>-0.625760</td>\n",
       "      <td>-0.843731</td>\n",
       "      <td>1.096377</td>\n",
       "      <td>0.599291</td>\n",
       "      <td>-0.300478</td>\n",
       "      <td>-0.184279</td>\n",
       "      <td>-0.463094</td>\n",
       "      <td>0.215565</td>\n",
       "      <td>0.540804</td>\n",
       "      <td>-0.291034</td>\n",
       "      <td>-0.151203</td>\n",
       "      <td>-0.062281</td>\n",
       "      <td>0.186092</td>\n",
       "      <td>0.868750</td>\n",
       "      <td>0.448281</td>\n",
       "      <td>-0.149414</td>\n",
       "      <td>-0.881510</td>\n",
       "      <td>-1.65000</td>\n",
       "      <td>0.528191</td>\n",
       "      <td>-0.304921</td>\n",
       "      <td>-0.674641</td>\n",
       "      <td>-0.216377</td>\n",
       "      <td>1.620563</td>\n",
       "      <td>0.295839</td>\n",
       "      <td>-0.274354</td>\n",
       "      <td>-0.083493</td>\n",
       "      <td>-0.084921</td>\n",
       "      <td>-0.583252</td>\n",
       "      <td>-0.394982</td>\n",
       "      <td>-0.065906</td>\n",
       "      <td>-0.325048</td>\n",
       "      <td>0.752350</td>\n",
       "      <td>-0.590158</td>\n",
       "      <td>0.782986</td>\n",
       "      <td>0.393287</td>\n",
       "      <td>-0.191262</td>\n",
       "      <td>-0.884645</td>\n",
       "      <td>-1.481481</td>\n",
       "      <td>0.616453</td>\n",
       "      <td>-0.157896</td>\n",
       "      <td>-0.558826</td>\n",
       "      <td>-0.715575</td>\n",
       "      <td>1.533192</td>\n",
       "      <td>0.616701</td>\n",
       "      <td>-0.322691</td>\n",
       "      <td>-0.180693</td>\n",
       "      <td>-0.337294</td>\n",
       "      <td>-0.082813</td>\n",
       "      <td>0.336824</td>\n",
       "      <td>-0.359918</td>\n",
       "      <td>-0.042269</td>\n",
       "      <td>2.173722</td>\n",
       "      <td>-0.218456</td>\n",
       "      <td>0.149005</td>\n",
       "      <td>-0.366809</td>\n",
       "      <td>0.638944</td>\n",
       "      <td>1.164415</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.132869</td>\n",
       "      <td>-0.259493</td>\n",
       "      <td>-0.036831</td>\n",
       "      <td>0.211612</td>\n",
       "      <td>0.529789</td>\n",
       "      <td>-0.095208</td>\n",
       "      <td>0.009127</td>\n",
       "      <td>-0.085824</td>\n",
       "      <td>0.274420</td>\n",
       "      <td>0.061513</td>\n",
       "      <td>0.538249</td>\n",
       "      <td>-0.158009</td>\n",
       "      <td>-0.551923</td>\n",
       "      <td>-0.052439</td>\n",
       "      <td>0.384066</td>\n",
       "      <td>0.475575</td>\n",
       "      <td>-0.013793</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>-0.962644</td>\n",
       "      <td>0.318320</td>\n",
       "      <td>0.397623</td>\n",
       "      <td>-0.241451</td>\n",
       "      <td>-0.305553</td>\n",
       "      <td>-1.871501</td>\n",
       "      <td>0.588889</td>\n",
       "      <td>-0.350000</td>\n",
       "      <td>-0.187500</td>\n",
       "      <td>-0.036428</td>\n",
       "      <td>-0.478911</td>\n",
       "      <td>0.281918</td>\n",
       "      <td>-0.245378</td>\n",
       "      <td>-0.555464</td>\n",
       "      <td>0.595552</td>\n",
       "      <td>-0.187490</td>\n",
       "      <td>-0.390604</td>\n",
       "      <td>-0.729128</td>\n",
       "      <td>0.516063</td>\n",
       "      <td>-0.363560</td>\n",
       "      <td>-0.139383</td>\n",
       "      <td>0.093858</td>\n",
       "      <td>0.333978</td>\n",
       "      <td>-0.251943</td>\n",
       "      <td>0.639334</td>\n",
       "      <td>-0.778641</td>\n",
       "      <td>0.233212</td>\n",
       "      <td>-0.000688</td>\n",
       "      <td>-0.120991</td>\n",
       "      <td>0.293366</td>\n",
       "      <td>-0.280551</td>\n",
       "      <td>0.266514</td>\n",
       "      <td>-0.095628</td>\n",
       "      <td>-0.123322</td>\n",
       "      <td>-0.211451</td>\n",
       "      <td>0.039278</td>\n",
       "      <td>0.055061</td>\n",
       "      <td>-1.141073</td>\n",
       "      <td>-0.324175</td>\n",
       "      <td>-0.491401</td>\n",
       "      <td>-0.533093</td>\n",
       "      <td>-0.788674</td>\n",
       "      <td>0.289677</td>\n",
       "      <td>0.456487</td>\n",
       "      <td>0.105604</td>\n",
       "      <td>-0.318177</td>\n",
       "      <td>-0.310283</td>\n",
       "      <td>-1.851250</td>\n",
       "      <td>-0.236225</td>\n",
       "      <td>0.236042</td>\n",
       "      <td>-0.465301</td>\n",
       "      <td>0.888109</td>\n",
       "      <td>-0.287283</td>\n",
       "      <td>0.121172</td>\n",
       "      <td>-0.365413</td>\n",
       "      <td>0.073055</td>\n",
       "      <td>-0.388872</td>\n",
       "      <td>0.379045</td>\n",
       "      <td>-0.276845</td>\n",
       "      <td>0.370113</td>\n",
       "      <td>-0.213797</td>\n",
       "      <td>0.377669</td>\n",
       "      <td>-1.231218</td>\n",
       "      <td>-0.136667</td>\n",
       "      <td>-0.305991</td>\n",
       "      <td>0.604625</td>\n",
       "      <td>-0.045750</td>\n",
       "      <td>-0.104679</td>\n",
       "      <td>-0.365556</td>\n",
       "      <td>-0.122505</td>\n",
       "      <td>-0.553117</td>\n",
       "      <td>0.169376</td>\n",
       "      <td>0.013103</td>\n",
       "      <td>0.360340</td>\n",
       "      <td>-0.197225</td>\n",
       "      <td>-0.916257</td>\n",
       "      <td>0.092183</td>\n",
       "      <td>-1.193518</td>\n",
       "      <td>0.469707</td>\n",
       "      <td>-0.370133</td>\n",
       "      <td>-0.005065</td>\n",
       "      <td>-0.235660</td>\n",
       "      <td>-1.057197</td>\n",
       "      <td>-0.159361</td>\n",
       "      <td>0.082989</td>\n",
       "      <td>0.038512</td>\n",
       "      <td>-0.054791</td>\n",
       "      <td>-0.041411</td>\n",
       "      <td>0.563296</td>\n",
       "      <td>-0.067891</td>\n",
       "      <td>-0.177110</td>\n",
       "      <td>-0.296693</td>\n",
       "      <td>-0.122380</td>\n",
       "      <td>-0.455531</td>\n",
       "      <td>-0.290279</td>\n",
       "      <td>-0.439749</td>\n",
       "      <td>-0.213554</td>\n",
       "      <td>0.129565</td>\n",
       "      <td>0.241729</td>\n",
       "      <td>-0.242953</td>\n",
       "      <td>-0.317619</td>\n",
       "      <td>-0.328064</td>\n",
       "      <td>-1.012850</td>\n",
       "      <td>-0.032778</td>\n",
       "      <td>0.209253</td>\n",
       "      <td>0.220997</td>\n",
       "      <td>-0.316490</td>\n",
       "      <td>-2.885003</td>\n",
       "      <td>0.692887</td>\n",
       "      <td>-0.110910</td>\n",
       "      <td>-0.200097</td>\n",
       "      <td>-0.340472</td>\n",
       "      <td>-0.903393</td>\n",
       "      <td>0.651480</td>\n",
       "      <td>0.398993</td>\n",
       "      <td>-0.018483</td>\n",
       "      <td>-0.528058</td>\n",
       "      <td>-2.479991</td>\n",
       "      <td>0.649280</td>\n",
       "      <td>0.267521</td>\n",
       "      <td>-0.079920</td>\n",
       "      <td>-0.533017</td>\n",
       "      <td>-3.319050</td>\n",
       "      <td>0.629333</td>\n",
       "      <td>0.386063</td>\n",
       "      <td>-0.053583</td>\n",
       "      <td>-0.635823</td>\n",
       "      <td>-1.119614</td>\n",
       "      <td>0.183323</td>\n",
       "      <td>-0.012447</td>\n",
       "      <td>0.003072</td>\n",
       "      <td>-0.124413</td>\n",
       "      <td>-0.358415</td>\n",
       "      <td>-0.079493</td>\n",
       "      <td>-0.340753</td>\n",
       "      <td>0.441229</td>\n",
       "      <td>-0.033458</td>\n",
       "      <td>-0.352436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00007889e4fcd2614b6cbe7f8f3d2e5c728eca32d9eb8a...</td>\n",
       "      <td>0.936842</td>\n",
       "      <td>0.891679</td>\n",
       "      <td>0.042325</td>\n",
       "      <td>0.805045</td>\n",
       "      <td>0.940382</td>\n",
       "      <td>0.871900</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003433</td>\n",
       "      <td>0.005941</td>\n",
       "      <td>0.002475</td>\n",
       "      <td>0.000776</td>\n",
       "      <td>0.009806</td>\n",
       "      <td>0.007679</td>\n",
       "      <td>0.818691</td>\n",
       "      <td>0.814543</td>\n",
       "      <td>0.003143</td>\n",
       "      <td>0.810670</td>\n",
       "      <td>0.819947</td>\n",
       "      <td>0.815746</td>\n",
       "      <td>0.007243</td>\n",
       "      <td>0.004180</td>\n",
       "      <td>0.002581</td>\n",
       "      <td>0.000336</td>\n",
       "      <td>0.009076</td>\n",
       "      <td>0.001247</td>\n",
       "      <td>0.166190</td>\n",
       "      <td>0.173102</td>\n",
       "      <td>0.004669</td>\n",
       "      <td>0.166190</td>\n",
       "      <td>0.176403</td>\n",
       "      <td>0.176403</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005927</td>\n",
       "      <td>0.005088</td>\n",
       "      <td>0.002910</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.009686</td>\n",
       "      <td>0.005528</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.061963</td>\n",
       "      <td>0.048778</td>\n",
       "      <td>0.006847</td>\n",
       "      <td>0.037001</td>\n",
       "      <td>0.061963</td>\n",
       "      <td>0.044671</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>11.692308</td>\n",
       "      <td>9.384248</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>21</td>\n",
       "      <td>0.288640</td>\n",
       "      <td>0.209150</td>\n",
       "      <td>0.117203</td>\n",
       "      <td>0.063150</td>\n",
       "      <td>0.305305</td>\n",
       "      <td>0.069952</td>\n",
       "      <td>0.003367</td>\n",
       "      <td>0.004572</td>\n",
       "      <td>0.002297</td>\n",
       "      <td>0.001201</td>\n",
       "      <td>0.007830</td>\n",
       "      <td>0.004855</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.464017</td>\n",
       "      <td>0.474523</td>\n",
       "      <td>0.076167</td>\n",
       "      <td>0.366783</td>\n",
       "      <td>0.694332</td>\n",
       "      <td>0.465525</td>\n",
       "      <td>0.465739</td>\n",
       "      <td>0.471961</td>\n",
       "      <td>0.007588</td>\n",
       "      <td>0.461473</td>\n",
       "      <td>0.484715</td>\n",
       "      <td>0.480303</td>\n",
       "      <td>0.141613</td>\n",
       "      <td>0.253697</td>\n",
       "      <td>0.093176</td>\n",
       "      <td>0.137840</td>\n",
       "      <td>0.491528</td>\n",
       "      <td>0.325121</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.044372</td>\n",
       "      <td>0.075672</td>\n",
       "      <td>0.046857</td>\n",
       "      <td>0.030852</td>\n",
       "      <td>0.195757</td>\n",
       "      <td>0.048857</td>\n",
       "      <td>0.035662</td>\n",
       "      <td>0.115290</td>\n",
       "      <td>0.070823</td>\n",
       "      <td>0.035662</td>\n",
       "      <td>0.216773</td>\n",
       "      <td>0.159818</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.386868</td>\n",
       "      <td>0.509339</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.008826</td>\n",
       "      <td>1.005185</td>\n",
       "      <td>0.136212</td>\n",
       "      <td>0.093218</td>\n",
       "      <td>0.020103</td>\n",
       "      <td>0.073834</td>\n",
       "      <td>0.136212</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>1</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.375534</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005475</td>\n",
       "      <td>0.006685</td>\n",
       "      <td>0.002242</td>\n",
       "      <td>0.002925</td>\n",
       "      <td>0.009847</td>\n",
       "      <td>0.004027</td>\n",
       "      <td>1</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.375534</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.193705</td>\n",
       "      <td>0.233470</td>\n",
       "      <td>0.028414</td>\n",
       "      <td>0.191802</td>\n",
       "      <td>0.256440</td>\n",
       "      <td>0.253811</td>\n",
       "      <td>0.559941</td>\n",
       "      <td>0.527254</td>\n",
       "      <td>0.088509</td>\n",
       "      <td>0.254276</td>\n",
       "      <td>0.584359</td>\n",
       "      <td>0.570419</td>\n",
       "      <td>0.058786</td>\n",
       "      <td>0.100315</td>\n",
       "      <td>0.074579</td>\n",
       "      <td>0.044728</td>\n",
       "      <td>0.260673</td>\n",
       "      <td>0.125195</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008094</td>\n",
       "      <td>0.005051</td>\n",
       "      <td>0.002665</td>\n",
       "      <td>0.002389</td>\n",
       "      <td>0.009350</td>\n",
       "      <td>0.009350</td>\n",
       "      <td>0.009522</td>\n",
       "      <td>0.005017</td>\n",
       "      <td>0.003694</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.009807</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>0</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.375534</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.121961</td>\n",
       "      <td>0.120290</td>\n",
       "      <td>0.008589</td>\n",
       "      <td>0.108082</td>\n",
       "      <td>0.128201</td>\n",
       "      <td>0.122915</td>\n",
       "      <td>0.151135</td>\n",
       "      <td>0.049640</td>\n",
       "      <td>0.060154</td>\n",
       "      <td>0.005756</td>\n",
       "      <td>0.151135</td>\n",
       "      <td>0.013041</td>\n",
       "      <td>0</td>\n",
       "      <td>157.076923</td>\n",
       "      <td>383.420018</td>\n",
       "      <td>0</td>\n",
       "      <td>1021</td>\n",
       "      <td>0</td>\n",
       "      <td>0.125503</td>\n",
       "      <td>0.203298</td>\n",
       "      <td>0.041725</td>\n",
       "      <td>0.125503</td>\n",
       "      <td>0.254067</td>\n",
       "      <td>0.254067</td>\n",
       "      <td>0.172873</td>\n",
       "      <td>0.178482</td>\n",
       "      <td>0.009615</td>\n",
       "      <td>0.163719</td>\n",
       "      <td>0.190924</td>\n",
       "      <td>0.183075</td>\n",
       "      <td>0.001980</td>\n",
       "      <td>0.004422</td>\n",
       "      <td>0.002974</td>\n",
       "      <td>0.000626</td>\n",
       "      <td>0.008859</td>\n",
       "      <td>0.006051</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.213848</td>\n",
       "      <td>-0.077959</td>\n",
       "      <td>-0.187949</td>\n",
       "      <td>-0.201241</td>\n",
       "      <td>0.305355</td>\n",
       "      <td>-0.692199</td>\n",
       "      <td>0.311647</td>\n",
       "      <td>0.381561</td>\n",
       "      <td>1.996520</td>\n",
       "      <td>-0.079125</td>\n",
       "      <td>-0.078748</td>\n",
       "      <td>0.356546</td>\n",
       "      <td>-0.254386</td>\n",
       "      <td>-1.436539</td>\n",
       "      <td>0.026104</td>\n",
       "      <td>-0.408460</td>\n",
       "      <td>-0.089436</td>\n",
       "      <td>0.290467</td>\n",
       "      <td>-1.014460</td>\n",
       "      <td>0.853422</td>\n",
       "      <td>0.171970</td>\n",
       "      <td>-0.299306</td>\n",
       "      <td>-0.551639</td>\n",
       "      <td>-1.112095</td>\n",
       "      <td>-0.212121</td>\n",
       "      <td>-0.290909</td>\n",
       "      <td>-0.409091</td>\n",
       "      <td>-0.212121</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.684889</td>\n",
       "      <td>0.367642</td>\n",
       "      <td>-0.301133</td>\n",
       "      <td>-0.289871</td>\n",
       "      <td>-2.457654</td>\n",
       "      <td>0.012488</td>\n",
       "      <td>-0.091792</td>\n",
       "      <td>-0.249918</td>\n",
       "      <td>-0.306360</td>\n",
       "      <td>-0.487190</td>\n",
       "      <td>0.412540</td>\n",
       "      <td>-0.268688</td>\n",
       "      <td>-0.414007</td>\n",
       "      <td>0.037615</td>\n",
       "      <td>0.116770</td>\n",
       "      <td>0.099422</td>\n",
       "      <td>-0.413446</td>\n",
       "      <td>0.128847</td>\n",
       "      <td>-0.471645</td>\n",
       "      <td>-1.246817</td>\n",
       "      <td>0.880494</td>\n",
       "      <td>0.482266</td>\n",
       "      <td>-0.139972</td>\n",
       "      <td>-0.865212</td>\n",
       "      <td>-1.95961</td>\n",
       "      <td>0.059174</td>\n",
       "      <td>-0.105376</td>\n",
       "      <td>-0.311187</td>\n",
       "      <td>0.615169</td>\n",
       "      <td>-0.049943</td>\n",
       "      <td>0.718219</td>\n",
       "      <td>0.226899</td>\n",
       "      <td>-0.361859</td>\n",
       "      <td>-0.569113</td>\n",
       "      <td>-0.713694</td>\n",
       "      <td>0.135189</td>\n",
       "      <td>-0.212890</td>\n",
       "      <td>0.144989</td>\n",
       "      <td>-0.615223</td>\n",
       "      <td>-0.006885</td>\n",
       "      <td>-0.164183</td>\n",
       "      <td>-0.229470</td>\n",
       "      <td>-0.257450</td>\n",
       "      <td>0.277042</td>\n",
       "      <td>-0.139073</td>\n",
       "      <td>0.857990</td>\n",
       "      <td>0.430890</td>\n",
       "      <td>-0.254502</td>\n",
       "      <td>-0.975654</td>\n",
       "      <td>-1.233691</td>\n",
       "      <td>0.712314</td>\n",
       "      <td>0.205853</td>\n",
       "      <td>-0.456800</td>\n",
       "      <td>-0.481093</td>\n",
       "      <td>-0.445351</td>\n",
       "      <td>-0.166934</td>\n",
       "      <td>-0.066283</td>\n",
       "      <td>0.238206</td>\n",
       "      <td>-2.924776</td>\n",
       "      <td>-0.185457</td>\n",
       "      <td>-0.332985</td>\n",
       "      <td>0.156290</td>\n",
       "      <td>-0.046028</td>\n",
       "      <td>0.060469</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.048483</td>\n",
       "      <td>0.051644</td>\n",
       "      <td>0.161385</td>\n",
       "      <td>-0.255328</td>\n",
       "      <td>0.228381</td>\n",
       "      <td>-0.013651</td>\n",
       "      <td>0.042248</td>\n",
       "      <td>-0.404721</td>\n",
       "      <td>-0.307834</td>\n",
       "      <td>1.128626</td>\n",
       "      <td>0.141917</td>\n",
       "      <td>-0.469957</td>\n",
       "      <td>0.227023</td>\n",
       "      <td>-0.002325</td>\n",
       "      <td>-0.431182</td>\n",
       "      <td>-0.212121</td>\n",
       "      <td>-0.290909</td>\n",
       "      <td>-0.409091</td>\n",
       "      <td>-0.212121</td>\n",
       "      <td>0.509867</td>\n",
       "      <td>0.284719</td>\n",
       "      <td>-0.178009</td>\n",
       "      <td>-0.379363</td>\n",
       "      <td>-0.699264</td>\n",
       "      <td>0.428030</td>\n",
       "      <td>-0.290909</td>\n",
       "      <td>-0.409091</td>\n",
       "      <td>-0.684479</td>\n",
       "      <td>0.234704</td>\n",
       "      <td>0.174614</td>\n",
       "      <td>-0.570186</td>\n",
       "      <td>-0.107505</td>\n",
       "      <td>0.879955</td>\n",
       "      <td>0.385195</td>\n",
       "      <td>-0.302958</td>\n",
       "      <td>-0.913429</td>\n",
       "      <td>-0.125220</td>\n",
       "      <td>-0.427551</td>\n",
       "      <td>0.138023</td>\n",
       "      <td>0.219285</td>\n",
       "      <td>-0.896987</td>\n",
       "      <td>0.115269</td>\n",
       "      <td>0.054536</td>\n",
       "      <td>-0.446831</td>\n",
       "      <td>0.366138</td>\n",
       "      <td>0.423475</td>\n",
       "      <td>-0.005907</td>\n",
       "      <td>-0.050721</td>\n",
       "      <td>-0.644304</td>\n",
       "      <td>0.736890</td>\n",
       "      <td>-0.867295</td>\n",
       "      <td>-0.177637</td>\n",
       "      <td>0.131674</td>\n",
       "      <td>-0.015296</td>\n",
       "      <td>-0.627603</td>\n",
       "      <td>0.922548</td>\n",
       "      <td>-0.134906</td>\n",
       "      <td>-0.217911</td>\n",
       "      <td>-0.187566</td>\n",
       "      <td>0.042166</td>\n",
       "      <td>3.003222</td>\n",
       "      <td>0.802881</td>\n",
       "      <td>0.310564</td>\n",
       "      <td>-0.384890</td>\n",
       "      <td>-0.709457</td>\n",
       "      <td>-0.818447</td>\n",
       "      <td>0.253211</td>\n",
       "      <td>-0.323084</td>\n",
       "      <td>0.178464</td>\n",
       "      <td>0.228628</td>\n",
       "      <td>0.253017</td>\n",
       "      <td>-0.208167</td>\n",
       "      <td>-0.288272</td>\n",
       "      <td>-0.412729</td>\n",
       "      <td>-0.218109</td>\n",
       "      <td>0.187894</td>\n",
       "      <td>-0.030823</td>\n",
       "      <td>0.116346</td>\n",
       "      <td>-0.181318</td>\n",
       "      <td>-0.353919</td>\n",
       "      <td>1.417903</td>\n",
       "      <td>-0.227474</td>\n",
       "      <td>-0.310644</td>\n",
       "      <td>-0.392473</td>\n",
       "      <td>-0.196596</td>\n",
       "      <td>0.168569</td>\n",
       "      <td>-0.017757</td>\n",
       "      <td>0.234860</td>\n",
       "      <td>-0.335239</td>\n",
       "      <td>-0.362815</td>\n",
       "      <td>0.931233</td>\n",
       "      <td>-0.426770</td>\n",
       "      <td>-0.254363</td>\n",
       "      <td>-0.576379</td>\n",
       "      <td>-0.448432</td>\n",
       "      <td>0.625548</td>\n",
       "      <td>0.827261</td>\n",
       "      <td>0.418920</td>\n",
       "      <td>-0.040263</td>\n",
       "      <td>-0.661197</td>\n",
       "      <td>-2.547379</td>\n",
       "      <td>-0.436598</td>\n",
       "      <td>-0.013930</td>\n",
       "      <td>0.185423</td>\n",
       "      <td>0.739915</td>\n",
       "      <td>0.507688</td>\n",
       "      <td>-0.515974</td>\n",
       "      <td>-0.176698</td>\n",
       "      <td>0.074489</td>\n",
       "      <td>0.442351</td>\n",
       "      <td>0.544389</td>\n",
       "      <td>-0.109676</td>\n",
       "      <td>0.270546</td>\n",
       "      <td>-0.578885</td>\n",
       "      <td>0.545340</td>\n",
       "      <td>-0.334632</td>\n",
       "      <td>0.099502</td>\n",
       "      <td>0.024550</td>\n",
       "      <td>-0.042543</td>\n",
       "      <td>-0.189234</td>\n",
       "      <td>-0.500755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686781</td>\n",
       "      <td>0.264899</td>\n",
       "      <td>-0.054854</td>\n",
       "      <td>-0.595322</td>\n",
       "      <td>-1.989770</td>\n",
       "      <td>0.734346</td>\n",
       "      <td>0.414050</td>\n",
       "      <td>-0.154383</td>\n",
       "      <td>-0.688253</td>\n",
       "      <td>-1.983280</td>\n",
       "      <td>0.260332</td>\n",
       "      <td>0.244508</td>\n",
       "      <td>-0.211338</td>\n",
       "      <td>-0.576385</td>\n",
       "      <td>-2.940098</td>\n",
       "      <td>0.727952</td>\n",
       "      <td>0.287123</td>\n",
       "      <td>-0.173553</td>\n",
       "      <td>-0.688503</td>\n",
       "      <td>-2.305585</td>\n",
       "      <td>0.186063</td>\n",
       "      <td>0.157382</td>\n",
       "      <td>0.015212</td>\n",
       "      <td>-0.512134</td>\n",
       "      <td>-0.057377</td>\n",
       "      <td>-0.134475</td>\n",
       "      <td>0.082192</td>\n",
       "      <td>0.284313</td>\n",
       "      <td>-0.272151</td>\n",
       "      <td>-0.205607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1807 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         customer_ID  P_2_first  P_2_mean   P_2_std   P_2_min   P_2_max  P_2_last  D_39_first  D_39_mean  D_39_std  D_39_min  D_39_max  D_39_last  B_1_first  B_1_mean   B_1_std   B_1_min   B_1_max  B_1_last  B_2_first  B_2_mean   B_2_std   B_2_min   B_2_max  B_2_last  R_1_first  R_1_mean   R_1_std   R_1_min   R_1_max  R_1_last  S_3_first  S_3_mean   S_3_std   S_3_min   S_3_max  S_3_last  D_41_first  D_41_mean  D_41_std  D_41_min  D_41_max  D_41_last  B_3_first  B_3_mean   B_3_std   B_3_min   B_3_max  B_3_last  D_42_first  D_42_mean  D_42_std  D_42_min  D_42_max  D_42_last  D_43_first  D_43_mean  D_43_std  D_43_min  D_43_max  D_43_last  D_44_first  D_44_mean  D_44_std  D_44_min  D_44_max  D_44_last  B_4_first   B_4_mean   B_4_std  B_4_min  B_4_max  B_4_last  D_45_first  D_45_mean  D_45_std  D_45_min  D_45_max  D_45_last  B_5_first  B_5_mean   B_5_std   B_5_min   B_5_max  B_5_last  R_2_first  R_2_mean  R_2_std  R_2_min  R_2_max  R_2_last  D_46_first  \\\n",
       "0  0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...   0.938469  0.933824  0.024194  0.868580  0.960384  0.934745           0   0.230769  0.832050         0         3          0   0.008724  0.012007  0.006547  0.001930  0.021655  0.009382   1.006838  1.005086  0.003222  1.000242  1.009672  1.007647   0.009228  0.004509  0.003081  0.000263  0.009228  0.006104   0.124035  0.113215  0.011670  0.098882  0.135021  0.135021         0.0        0.0       0.0       0.0       0.0        0.0   0.004709  0.006456  0.002942  0.000783  0.009866  0.007174         NaN        NaN       NaN       NaN       NaN        NaN         NaN        NaN       NaN       NaN       NaN        NaN           0   0.000000   0.00000         0         0          0          6   2.846154  2.444250        0        6         5    0.708906   0.725369  0.009515  0.708906  0.740102   0.740102   0.170600  0.146650  0.047205  0.060492  0.231717  0.231717          0       0.0      0.0        0        0         0    0.358587   \n",
       "1  00000fd6641609c6ece5454664794f0340ad84dddce9a2...   0.929122  0.899820  0.022119  0.861109  0.929122  0.880519          13   7.153846  6.743468         0        19          6   0.025782  0.025654  0.027756  0.006711  0.109644  0.034684   1.002647  0.991083  0.051531  0.819772  1.008534  1.004028   0.005515  0.006246  0.002129  0.001023  0.008996  0.006911   0.089799  0.120578  0.023824  0.089799  0.165509  0.165509         0.0        0.0       0.0       0.0       0.0        0.0   0.005830  0.005663  0.003354  0.000861  0.012861  0.005068         NaN        NaN       NaN       NaN       NaN        NaN    0.525600   0.144571  0.169598  0.060646  0.525600   0.060646           0   0.000000   0.00000         0         0          0          1   0.846154  0.800641        0        3         1    0.239459   0.256461  0.009261  0.239459  0.267228   0.266275   0.070967  0.035462  0.043899  0.004075  0.165146  0.027000          0       0.0      0.0        0        0         0    0.457826   \n",
       "2  00001b22f846c82c51f6e3958ccd81970162bae8b007e8...   0.876615  0.878454  0.028911  0.797670  0.904482  0.880875           0   0.000000  0.000000         0         0          0   0.001472  0.004386  0.002786  0.001472  0.009997  0.004284   0.810796  0.815677  0.003545  0.810796  0.819987  0.812649   0.005955  0.006621  0.001919  0.003540  0.009443  0.006450        NaN       NaN       NaN       NaN       NaN       NaN         0.0        0.0       0.0       0.0       0.0        0.0   0.004826  0.005493  0.002834  0.000626  0.009383  0.007196         NaN        NaN       NaN       NaN       NaN        NaN         NaN        NaN       NaN       NaN       NaN        NaN           0   0.076923   0.27735         0         1          0          1   2.230769  1.690850        1        7         2    0.222406   0.236871  0.008896  0.222406  0.251598   0.251598   0.005358  0.004618  0.003043  0.000215  0.008656  0.001557          0       0.0      0.0        0        0         0    0.438652   \n",
       "3  000041bdba6ecadd89a52d11886e8eaaec9325906c9723...   0.567442  0.598969  0.020107  0.567442  0.623392  0.621776           9   1.538462  3.017046         0         9          0   0.070311  0.059876  0.080531  0.005910  0.279991  0.012564   0.812053  0.955264  0.080981  0.812053  1.009999  1.006183   0.004228  0.005665  0.003473  0.000199  0.009915  0.007829   0.407420  0.247750  0.095122  0.149216  0.407420  0.287766         0.0        0.0       0.0       0.0       0.0        0.0   0.010927  0.006423  0.003360  0.000053  0.010927  0.009937         NaN        NaN       NaN       NaN       NaN        NaN    0.006633   0.061026  0.041993  0.006633  0.149891   0.046104           0   0.000000   0.00000         0         0          0          8   2.230769  2.832956        0        8         0    0.056394   0.069334  0.008501  0.056394  0.085103   0.085103   0.000228  0.088374  0.074462  0.000228  0.283781  0.118818          0       0.0      0.0        0        0         0    0.471676   \n",
       "4  00007889e4fcd2614b6cbe7f8f3d2e5c728eca32d9eb8a...   0.936842  0.891679  0.042325  0.805045  0.940382  0.871900           0   0.000000  0.000000         0         0          0   0.003433  0.005941  0.002475  0.000776  0.009806  0.007679   0.818691  0.814543  0.003143  0.810670  0.819947  0.815746   0.007243  0.004180  0.002581  0.000336  0.009076  0.001247   0.166190  0.173102  0.004669  0.166190  0.176403  0.176403         0.0        0.0       0.0       0.0       0.0        0.0   0.005927  0.005088  0.002910  0.000049  0.009686  0.005528         NaN        NaN       NaN       NaN       NaN        NaN    0.061963   0.048778  0.006847  0.037001  0.061963   0.044671           0   0.000000   0.00000         0         0          0          5  11.692308  9.384248        3       25        21    0.288640   0.209150  0.117203  0.063150  0.305305   0.069952   0.003367  0.004572  0.002297  0.001201  0.007830  0.004855          0       0.0      0.0        0        0         0    0.464017   \n",
       "\n",
       "   D_46_mean  D_46_std  D_46_min  D_46_max  D_46_last  D_47_first  D_47_mean  D_47_std  D_47_min  D_47_max  D_47_last  D_48_first  D_48_mean  D_48_std  D_48_min  D_48_max  D_48_last  D_49_first  D_49_mean  D_49_std  D_49_min  D_49_max  D_49_last  B_6_first  B_6_mean   B_6_std   B_6_min   B_6_max  B_6_last  B_7_first  B_7_mean   B_7_std   B_7_min   B_7_max  B_7_last  B_8_first  B_8_mean   B_8_std   B_8_min   B_8_max  B_8_last  D_50_first  D_50_mean  D_50_std  D_50_min  D_50_max  D_50_last  D_51_first  D_51_mean  D_51_std  D_51_min  D_51_max  D_51_last  B_9_first  B_9_mean   B_9_std   B_9_min   B_9_max  B_9_last  R_3_first  R_3_mean   R_3_std  R_3_min  R_3_max  R_3_last  D_52_first  D_52_mean  D_52_std  D_52_min  D_52_max  D_52_last  P_3_first  P_3_mean   P_3_std   P_3_min   P_3_max  P_3_last  B_10_first  B_10_mean  B_10_std  B_10_min  B_10_max  B_10_last  D_53_first  D_53_mean  D_53_std  D_53_min  D_53_max  D_53_last  S_5_first  S_5_mean   S_5_std   S_5_min   S_5_max  S_5_last  \\\n",
       "0   0.378074  0.085674  0.231009  0.519619   0.420521    0.525351   0.532874  0.006578  0.521311  0.542119   0.539715    0.255736   0.240978  0.076875  0.135586  0.403448   0.192376          -1       -1.0       0.0        -1        -1         -1   0.063902  0.113510  0.047360  0.063902  0.221899  0.149564   0.059416  0.036624  0.023195  0.001681  0.060502  0.058425   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000    0.148698   0.150326  0.002922  0.145179  0.154326   0.153461           4   2.923077  0.954074         2         4          2   0.008207  0.006220  0.003180  0.000519  0.009535  0.009535          0  0.000000  0.000000        0        0         0    0.207334   0.204972  0.002400  0.200782  0.208214   0.203524   0.736463  0.680138  0.050671  0.581678  0.741813  0.629392    0.096219   0.270280  0.181875  0.096219  0.741934   0.326101         NaN        NaN       NaN       NaN       NaN        NaN   0.023381  0.029112  0.014758  0.007165  0.054221  0.034643   \n",
       "1   0.452041  0.013177  0.432424  0.471737   0.438828    0.382562   0.392433  0.006671  0.382562  0.402878   0.402195    0.059342   0.048203  0.031312  0.010117  0.105999   0.014696          -1       -1.0       0.0        -1        -1         -1   0.201574  0.202270  0.015915  0.167634  0.226641  0.167634   0.032390  0.028049  0.013631  0.015836  0.068204  0.028411   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000         NaN        NaN       NaN       NaN       NaN        NaN           1   1.153846  0.375534         1         2          1   0.007561  0.010298  0.011024  0.001722  0.045093  0.012926          0  0.538462  0.518875        0        1         1    0.110471   0.158313  0.067030  0.103495  0.242366   0.242366   0.619012  0.566665  0.036880  0.510142  0.619012  0.570898    0.302757   0.298815  0.003047  0.294000  0.302757   0.297130         NaN        NaN       NaN       NaN       NaN        NaN   0.025802  0.016785  0.017104  0.002045  0.052949  0.043929   \n",
       "2   0.464475  0.060166  0.413028  0.647064   0.433713    0.318290   0.328617  0.007183  0.318290  0.339566   0.339125    0.081635   0.092284  0.060616  0.030227  0.255134   0.080370          -1       -1.0       0.0        -1        -1         -1   0.168822  0.176674  0.024615  0.129857  0.213943  0.183628   0.029138  0.034433  0.015459  0.021261  0.079764  0.026981   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000         NaN        NaN       NaN       NaN       NaN        NaN           0   0.615385  0.506370         0         1          1   0.003663  0.004730  0.003302  0.000422  0.009521  0.009392          0  0.000000  0.000000        0        0         0    0.200082   0.199863  0.002990  0.195188  0.203649   0.202159   0.634722  0.618191  0.075604  0.381123  0.678706  0.628938    0.222126   0.273711  0.052875  0.162125  0.302619   0.296313         NaN        NaN       NaN       NaN       NaN        NaN   0.007875  0.005948  0.002943  0.001054  0.008730  0.001824   \n",
       "3   0.431905  0.030525  0.384254  0.471676   0.410723    0.392230   0.403269  0.006355  0.392230  0.414224   0.414224    0.176105   0.076686  0.063902  0.005276  0.177252   0.013057          -1       -1.0       0.0        -1        -1         -1   0.079987  0.160625  0.031266  0.079987  0.196887  0.174331   0.252338  0.062130  0.073590  0.004301  0.252338  0.011969   1.004358  1.004676  0.001928  1.002021  1.008767  1.005561    0.341256   0.439581  0.044539  0.341256  0.482535   0.430318           0   0.076923  0.277350         0         1          1   0.026897  0.052241  0.053342  0.001702  0.176352  0.020526          0  0.615385  0.650444        0        2         2    0.201745   0.199698  0.002130  0.195300  0.203203   0.198356   0.582652  0.610934  0.090090  0.345100  0.704214  0.672080    0.297839   0.306553  0.079528  0.192981  0.431901   0.411625    0.006409   0.004336  0.003589  0.000346   0.00999   0.001379   0.068346  0.056297  0.044583  0.002999  0.150845  0.022970   \n",
       "4   0.474523  0.076167  0.366783  0.694332   0.465525    0.465739   0.471961  0.007588  0.461473  0.484715   0.480303    0.141613   0.253697  0.093176  0.137840  0.491528   0.325121          -1       -1.0       0.0        -1        -1         -1   0.044372  0.075672  0.046857  0.030852  0.195757  0.048857   0.035662  0.115290  0.070823  0.035662  0.216773  0.159818   0.000000  0.386868  0.509339  0.000000  1.008826  1.005185    0.136212   0.093218  0.020103  0.073834  0.136212   0.095238           1   0.153846  0.375534         0         1          0   0.005475  0.006685  0.002242  0.002925  0.009847  0.004027          1  0.153846  0.375534        0        1         0    0.193705   0.233470  0.028414  0.191802  0.256440   0.253811   0.559941  0.527254  0.088509  0.254276  0.584359  0.570419    0.058786   0.100315  0.074579  0.044728  0.260673   0.125195         NaN        NaN       NaN       NaN       NaN        NaN   0.008094  0.005051  0.002665  0.002389  0.009350  0.009350   \n",
       "\n",
       "   B_11_first  B_11_mean  B_11_std  B_11_min  B_11_max  B_11_last  S_6_first  S_6_mean   S_6_std  S_6_min  S_6_max  S_6_last  D_54_first  D_54_mean  D_54_std  D_54_min  D_54_max  D_54_last  R_4_first  R_4_mean  R_4_std  R_4_min  R_4_max  R_4_last  S_7_first  S_7_mean   S_7_std   S_7_min   S_7_max  S_7_last  B_12_first  B_12_mean  B_12_std  B_12_min  B_12_max  B_12_last  S_8_first     S_8_mean     S_8_std  S_8_min  S_8_max  S_8_last  D_55_first  D_55_mean  D_55_std  D_55_min  D_55_max  D_55_last  D_56_first  D_56_mean  D_56_std  D_56_min  D_56_max  D_56_last  B_13_first  B_13_mean  B_13_std  B_13_min  B_13_max  B_13_last  R_5_first  R_5_mean  R_5_std  ...  B_10__autocorrelation__lag_3  B_10__autocorrelation__lag_5  B_10__autocorrelation__lag_7  B_10__autocorrelation__lag_12  S_5__autocorrelation__lag_1  S_5__autocorrelation__lag_3  S_5__autocorrelation__lag_5  S_5__autocorrelation__lag_7  S_5__autocorrelation__lag_12  B_11__autocorrelation__lag_1  B_11__autocorrelation__lag_3  \\\n",
       "0    0.002768   0.007230  0.003031  0.002749  0.010260   0.010260          0  0.000000  0.000000        0        0         0         1.0        1.0       0.0       1.0       1.0        1.0          0       0.0      0.0        0        0         0   0.161345  0.098374  0.026775  0.074646  0.161345  0.105671    0.148266   0.125683  0.011772  0.111060  0.148266   0.112294       2896  2510.000000  429.583519     1544     3166      1544    0.354596   0.224432  0.068116  0.148284  0.354596   0.187285    0.152025   0.158571  0.004747  0.152025  0.166636   0.166636    0.118075   0.100432  0.013723  0.074886  0.120740   0.100107          0       0.0      0.0  ...                      0.291515                     -0.321495                     -0.650447                      -0.318207                    -0.002049                    -0.300533                    -0.270629                     0.012265                     -0.157674                     -0.003953                     -0.145769   \n",
       "1    0.011677   0.013792  0.021041  0.000416  0.081246   0.014570          0  0.000000  0.000000        0        0         0         1.0        1.0       0.0       1.0       1.0        1.0          0       0.0      0.0        0        0         0   0.072583  0.103002  0.035143  0.072583  0.208516  0.208516    0.026337   0.025823  0.004665  0.019050  0.032917   0.019050       1880  1286.461538  772.374544        0     2402      1284    0.052813   0.048069  0.007596  0.036112  0.060770   0.036112    0.684371   0.705671  0.018540  0.684371  0.748383   0.748383    0.036490   0.046753  0.024456  0.008499  0.073904   0.017684          0       0.0      0.0  ...                     -0.640442                      0.008049                     -0.391780                      -0.775146                     0.137537                    -0.153068                    -0.255156                    -0.475800                      0.906418                     -0.013362                     -0.363174   \n",
       "2    0.001677   0.004683  0.002312  0.000111  0.007619   0.005092          1  1.000000  0.000000        1        1         1         1.0        1.0       0.0       1.0       1.0        1.0          0       0.0      0.0        0        0         0        NaN       NaN       NaN       NaN       NaN       NaN    0.011923   0.011541  0.002969  0.006100  0.015486   0.007158          0     0.000000    0.000000        0        0         0    0.073229   0.077362  0.016318  0.057529  0.099230   0.098963    0.201530   0.208154  0.003188  0.201530  0.211538   0.209386    0.002824   0.003778  0.002688  0.000427  0.008332   0.001749          0       0.0      0.0  ...                     -0.087941                     -0.179123                     -0.307702                      -0.451775                     0.184237                    -0.575687                     0.645257                    -0.229582                     -0.993711                     -0.203533                     -0.267247   \n",
       "3    0.043140   0.044294  0.071076  0.000672  0.241378   0.005491          0  0.000000  0.000000        0        0         0         1.0        1.0       0.0       1.0       1.0        1.0          0       0.0      0.0        0        0         0   0.365518  0.261497  0.078128  0.152622  0.370595  0.279464    0.014082   0.048949  0.025280  0.009411  0.077831   0.074835       1454   961.307692  405.585048      528     1511       528    0.094076   0.061726  0.018374  0.021400  0.094076   0.021400    0.579588   0.564632  0.018147  0.533675  0.580167   0.554483    0.013755   0.081928  0.041875  0.013755  0.124311   0.055897          0       0.0      0.0  ...                     -0.346848                     -0.221351                     -0.437593                      -0.156825                    -0.004960                     0.158285                    -0.057376                    -0.096556                     -0.218874                      0.522961                     -0.079184   \n",
       "4    0.009522   0.005017  0.003694  0.000714  0.009807   0.001001          0  0.846154  0.375534        0        1         1         1.0        1.0       0.0       1.0       1.0        1.0          0       0.0      0.0        0        0         0   0.121961  0.120290  0.008589  0.108082  0.128201  0.122915    0.151135   0.049640  0.060154  0.005756  0.151135   0.013041          0   157.076923  383.420018        0     1021         0    0.125503   0.203298  0.041725  0.125503  0.254067   0.254067    0.172873   0.178482  0.009615  0.163719  0.190924   0.183075    0.001980   0.004422  0.002974  0.000626  0.008859   0.006051          0       0.0      0.0  ...                     -0.213848                     -0.077959                     -0.187949                      -0.201241                     0.305355                    -0.692199                     0.311647                     0.381561                      1.996520                     -0.079125                     -0.078748   \n",
       "\n",
       "   B_11__autocorrelation__lag_5  B_11__autocorrelation__lag_7  B_11__autocorrelation__lag_12  S_7__autocorrelation__lag_1  S_7__autocorrelation__lag_3  S_7__autocorrelation__lag_5  S_7__autocorrelation__lag_7  S_7__autocorrelation__lag_12  B_12__autocorrelation__lag_1  B_12__autocorrelation__lag_3  B_12__autocorrelation__lag_5  B_12__autocorrelation__lag_7  B_12__autocorrelation__lag_12  S_8__autocorrelation__lag_1  S_8__autocorrelation__lag_3  S_8__autocorrelation__lag_5  S_8__autocorrelation__lag_7  S_8__autocorrelation__lag_12  D_55__autocorrelation__lag_1  D_55__autocorrelation__lag_3  D_55__autocorrelation__lag_5  D_55__autocorrelation__lag_7  D_55__autocorrelation__lag_12  B_13__autocorrelation__lag_1  B_13__autocorrelation__lag_3  B_13__autocorrelation__lag_5  B_13__autocorrelation__lag_7  B_13__autocorrelation__lag_12  D_58__autocorrelation__lag_1  D_58__autocorrelation__lag_3  D_58__autocorrelation__lag_5  D_58__autocorrelation__lag_7  D_58__autocorrelation__lag_12  \\\n",
       "0                      0.348698                     -0.258077                      -1.594819                     0.680675                     0.183001                    -0.185061                    -0.633661                      0.694321                      0.725180                      0.268445                     -0.120008                     -0.391025                      -2.363685                     0.178740                     0.276932                     0.038263                    -0.558407                     -2.188927                      0.820823                      0.241150                     -0.448008                     -0.688686                      -1.128945                      0.657447                      0.221620                     -0.074619                     -0.678136                      -0.032963                      0.864386                      0.422297                     -0.273705                     -0.965100                      -1.214023   \n",
       "1                     -0.237384                      0.067371                      -0.004027                     0.385144                     0.011511                     0.043921                    -0.084472                     -2.815513                      0.574890                     -0.105825                     -0.866482                     -0.270812                      -0.173263                     0.679323                    -0.263585                    -0.329725                    -0.492072                     -0.002653                      0.612128                      0.218820                     -0.031887                     -0.663814                      -1.064819                      0.617036                     -0.187460                     -0.584340                     -0.503029                       0.540399                      0.265609                     -0.017814                     -0.470635                     -0.227403                       1.223635   \n",
       "2                     -0.310228                     -0.175057                      -0.248955                          NaN                          NaN                          NaN                          NaN                           NaN                     -0.013915                      0.108534                     -0.181705                      0.246389                      -0.205516                          NaN                          NaN                          NaN                          NaN                           NaN                      0.681203                      0.222490                     -0.155827                     -0.587732                      -0.363174                     -0.023059                      0.061797                      0.075474                     -0.096632                       0.290578                      0.729973                     -0.060546                     -0.222384                     -0.443215                      -0.887565   \n",
       "3                     -0.187307                     -0.267886                       0.009601                     0.658294                    -0.073341                    -0.670663                    -0.587030                      0.331702                      0.884221                      0.346109                     -0.102628                     -0.676119                      -1.529904                     0.478479                    -0.012534                     0.338228                    -0.961768                     -1.405952                      0.533719                      0.160830                     -0.011115                     -0.087637                      -4.185893                      0.686046                     -0.175417                     -0.625760                     -0.843731                       1.096377                      0.599291                     -0.300478                     -0.184279                     -0.463094                       0.215565   \n",
       "4                      0.356546                     -0.254386                      -1.436539                     0.026104                    -0.408460                    -0.089436                     0.290467                     -1.014460                      0.853422                      0.171970                     -0.299306                     -0.551639                      -1.112095                    -0.212121                    -0.290909                    -0.409091                    -0.212121                      0.181818                      0.684889                      0.367642                     -0.301133                     -0.289871                      -2.457654                      0.012488                     -0.091792                     -0.249918                     -0.306360                      -0.487190                      0.412540                     -0.268688                     -0.414007                      0.037615                       0.116770   \n",
       "\n",
       "   B_14__autocorrelation__lag_1  B_14__autocorrelation__lag_3  B_14__autocorrelation__lag_5  B_14__autocorrelation__lag_7  B_14__autocorrelation__lag_12  D_59__autocorrelation__lag_1  D_59__autocorrelation__lag_3  D_59__autocorrelation__lag_5  D_59__autocorrelation__lag_7  D_59__autocorrelation__lag_12  D_60__autocorrelation__lag_1  D_60__autocorrelation__lag_3  D_60__autocorrelation__lag_5  D_60__autocorrelation__lag_7  D_60__autocorrelation__lag_12  D_61__autocorrelation__lag_1  D_61__autocorrelation__lag_3  D_61__autocorrelation__lag_5  D_61__autocorrelation__lag_7  D_61__autocorrelation__lag_12  B_15__autocorrelation__lag_1  B_15__autocorrelation__lag_3  B_15__autocorrelation__lag_5  B_15__autocorrelation__lag_7  B_15__autocorrelation__lag_12  S_11__autocorrelation__lag_1  S_11__autocorrelation__lag_3  S_11__autocorrelation__lag_5  S_11__autocorrelation__lag_7  S_11__autocorrelation__lag_12  D_62__autocorrelation__lag_1  D_62__autocorrelation__lag_3  D_62__autocorrelation__lag_5  \\\n",
       "0                     -0.465069                     -0.078404                     -0.114887                     -0.377175                       0.353591                      0.119444                     -0.350000                      0.191667                     -0.133333                        0.30000                      0.667559                      0.015151                     -0.786421                     -0.472103                       0.652642                      0.554604                     -0.333812                     -0.634335                     -0.380180                       0.403259                     -0.415392                     -0.138115                      0.042015                     -0.325953                       0.438000                      0.473837                      0.100465                     -0.074128                     -0.566667                       1.025581                      0.481466                     -0.190818                     -0.353911   \n",
       "1                      0.010839                     -0.405207                     -0.138518                      0.348070                       0.021372                     -0.006944                     -0.025000                     -0.052083                     -0.097222                       -1.00000                      0.051193                     -0.371365                     -0.120808                      0.330974                       0.091959                      0.327604                     -0.110835                     -0.144262                     -0.822322                      -0.050876                     -0.123401                      0.019259                     -0.027633                      0.378621                      -0.222775                      0.212647                      0.060110                     -0.374543                     -0.113276                       0.052984                     -0.174335                      0.147871                     -0.428026   \n",
       "2                     -0.847614                     -0.813279                     -0.777275                     -0.568142                      -0.635228                     -0.006944                     -0.025000                     -0.052083                     -0.097222                       -1.00000                     -0.015536                     -0.161224                      0.540801                     -0.629639                       0.672025                      0.020514                      0.037563                     -0.218005                      0.282124                      -0.472093                      0.051799                     -0.383249                      0.361048                     -0.333390                      -0.231989                           NaN                           NaN                           NaN                           NaN                            NaN                     -0.088122                     -0.157026                     -0.049585   \n",
       "3                      0.540804                     -0.291034                     -0.151203                     -0.062281                       0.186092                      0.868750                      0.448281                     -0.149414                     -0.881510                       -1.65000                      0.528191                     -0.304921                     -0.674641                     -0.216377                       1.620563                      0.295839                     -0.274354                     -0.083493                     -0.084921                      -0.583252                     -0.394982                     -0.065906                     -0.325048                      0.752350                      -0.590158                      0.782986                      0.393287                     -0.191262                     -0.884645                      -1.481481                      0.616453                     -0.157896                     -0.558826   \n",
       "4                      0.099422                     -0.413446                      0.128847                     -0.471645                      -1.246817                      0.880494                      0.482266                     -0.139972                     -0.865212                       -1.95961                      0.059174                     -0.105376                     -0.311187                      0.615169                      -0.049943                      0.718219                      0.226899                     -0.361859                     -0.569113                      -0.713694                      0.135189                     -0.212890                      0.144989                     -0.615223                      -0.006885                     -0.164183                     -0.229470                     -0.257450                      0.277042                      -0.139073                      0.857990                      0.430890                     -0.254502   \n",
       "\n",
       "   D_62__autocorrelation__lag_7  D_62__autocorrelation__lag_12  B_18__autocorrelation__lag_1  B_18__autocorrelation__lag_3  B_18__autocorrelation__lag_5  B_18__autocorrelation__lag_7  S_12__autocorrelation__lag_1  S_12__autocorrelation__lag_3  S_12__autocorrelation__lag_5  S_12__autocorrelation__lag_7  S_12__autocorrelation__lag_12  R_6__autocorrelation__lag_1  R_6__autocorrelation__lag_3  R_6__autocorrelation__lag_5  R_6__autocorrelation__lag_7  R_6__autocorrelation__lag_12  S_13__autocorrelation__lag_1  B_21__autocorrelation__lag_1  B_21__autocorrelation__lag_3  B_21__autocorrelation__lag_5  B_21__autocorrelation__lag_7  B_21__autocorrelation__lag_12  D_69__autocorrelation__lag_1  D_69__autocorrelation__lag_3  D_69__autocorrelation__lag_5  D_69__autocorrelation__lag_7  D_69__autocorrelation__lag_12  D_71__autocorrelation__lag_1  D_71__autocorrelation__lag_3  D_71__autocorrelation__lag_5  D_71__autocorrelation__lag_7  D_71__autocorrelation__lag_12  S_15__autocorrelation__lag_1  \\\n",
       "0                     -0.034498                      -0.303400                      0.835660                      0.396176                     -0.270693                     -0.999827                      0.287250                      0.062934                     -0.222288                     -0.101989                      -0.103639                     0.187364                    -0.183533                     0.238019                    -0.115756                     -1.093063                      0.759773                     -0.224651                     -0.222830                     -0.075052                      0.330820                       0.070305                      0.480488                     -0.131812                     -0.470987                     -0.689279                       0.098824                      0.803534                      0.291896                     -0.368946                     -0.759459                      -0.963049                      0.380376   \n",
       "1                      0.090024                      -0.418554                           NaN                           NaN                           NaN                           NaN                      0.146760                     -0.393144                      0.133074                      0.016893                      -0.021925                    -0.044140                     0.296799                     0.007528                    -0.305561                     -1.156592                      0.270833                     -0.347421                      0.636159                      0.087306                     -0.520594                       0.160171                     -0.702757                     -0.391291                     -0.444370                      0.102346                       0.267641                     -0.199963                      0.144985                     -0.228699                     -0.066602                      -1.541499                      0.296389   \n",
       "2                     -0.066684                       0.083974                      0.694144                     -0.089993                     -0.187485                     -0.349972                     -0.217902                     -0.172691                      0.709748                     -0.079229                       0.010350                    -0.695358                    -0.188444                     0.450462                     0.237886                      1.204669                           NaN                     -0.375516                     -0.307511                     -0.169422                     -0.690030                       0.492095                     -0.555943                     -0.395269                      0.159900                     -0.660197                       1.457455                      0.006133                     -0.180973                     -0.248553                     -0.674297                       1.276107                           NaN   \n",
       "3                     -0.715575                       1.533192                      0.616701                     -0.322691                     -0.180693                     -0.337294                     -0.082813                      0.336824                     -0.359918                     -0.042269                       2.173722                    -0.218456                     0.149005                    -0.366809                     0.638944                      1.164415                           NaN                      0.132869                     -0.259493                     -0.036831                      0.211612                       0.529789                     -0.095208                      0.009127                     -0.085824                      0.274420                       0.061513                      0.538249                     -0.158009                     -0.551923                     -0.052439                       0.384066                      0.475575   \n",
       "4                     -0.975654                      -1.233691                      0.712314                      0.205853                     -0.456800                     -0.481093                     -0.445351                     -0.166934                     -0.066283                      0.238206                      -2.924776                    -0.185457                    -0.332985                     0.156290                    -0.046028                      0.060469                           NaN                     -0.048483                      0.051644                      0.161385                     -0.255328                       0.228381                     -0.013651                      0.042248                     -0.404721                     -0.307834                       1.128626                      0.141917                     -0.469957                      0.227023                     -0.002325                      -0.431182                     -0.212121   \n",
       "\n",
       "   S_15__autocorrelation__lag_3  S_15__autocorrelation__lag_5  S_15__autocorrelation__lag_7  B_23__autocorrelation__lag_1  B_23__autocorrelation__lag_3  B_23__autocorrelation__lag_5  B_23__autocorrelation__lag_7  B_23__autocorrelation__lag_12  D_75__autocorrelation__lag_1  D_75__autocorrelation__lag_3  D_75__autocorrelation__lag_5  B_24__autocorrelation__lag_1  B_24__autocorrelation__lag_3  B_24__autocorrelation__lag_5  B_24__autocorrelation__lag_7  B_24__autocorrelation__lag_12  D_77__autocorrelation__lag_1  D_77__autocorrelation__lag_3  D_77__autocorrelation__lag_5  D_77__autocorrelation__lag_7  B_25__autocorrelation__lag_1  B_25__autocorrelation__lag_3  B_25__autocorrelation__lag_5  B_25__autocorrelation__lag_7  B_25__autocorrelation__lag_12  B_26__autocorrelation__lag_1  B_26__autocorrelation__lag_3  B_26__autocorrelation__lag_5  B_26__autocorrelation__lag_7  B_26__autocorrelation__lag_12  S_16__autocorrelation__lag_1  S_16__autocorrelation__lag_3  S_16__autocorrelation__lag_5  \\\n",
       "0                      0.300000                      0.074597                     -0.755376                      0.639577                      0.057142                     -0.625849                     -0.741822                       1.154139                      0.831349                      0.392857                     -0.264881                     -0.271581                      0.025118                      0.416220                      0.111103                       0.256342                      0.526964                     -0.054544                     -0.113633                     -0.212115                      0.006640                      0.148278                      0.160686                     -0.828616                       0.102856                      0.240188                     -0.456375                      0.351104                      0.006988                       1.191048                      0.086655                     -0.176514                      0.085949   \n",
       "1                     -0.259000                      0.240417                     -0.357222                     -0.121543                     -0.039197                     -0.349951                     -0.014985                       0.020709                           NaN                           NaN                           NaN                     -0.457028                      0.148806                      0.685348                      0.314082                       0.760557                     -0.167946                     -0.261768                      0.316078                     -0.227381                     -0.025005                     -0.285566                     -0.140152                      0.229251                      -0.016419                     -0.496380                      0.265097                     -0.216986                      0.845523                      -0.259695                     -0.489087                     -0.186750                     -0.520381   \n",
       "2                           NaN                           NaN                           NaN                     -0.253106                     -0.127325                      0.058844                      0.251449                       0.011103                      0.697222                     -0.090000                     -0.187500                     -0.394008                     -0.653036                     -0.419274                     -0.611835                      -0.736703                     -0.102188                     -0.133331                     -0.041059                     -0.113868                      0.268577                      0.083551                     -0.718567                     -0.700913                       0.449553                     -0.274463                      0.126128                      0.638296                     -0.504789                      -0.760304                     -0.247630                      0.092732                     -0.639869   \n",
       "3                     -0.013793                      0.344828                     -0.962644                      0.318320                      0.397623                     -0.241451                     -0.305553                      -1.871501                      0.588889                     -0.350000                     -0.187500                     -0.036428                     -0.478911                      0.281918                     -0.245378                      -0.555464                      0.595552                     -0.187490                     -0.390604                     -0.729128                      0.516063                     -0.363560                     -0.139383                      0.093858                       0.333978                     -0.251943                      0.639334                     -0.778641                      0.233212                      -0.000688                     -0.120991                      0.293366                     -0.280551   \n",
       "4                     -0.290909                     -0.409091                     -0.212121                      0.509867                      0.284719                     -0.178009                     -0.379363                      -0.699264                      0.428030                     -0.290909                     -0.409091                     -0.684479                      0.234704                      0.174614                     -0.570186                      -0.107505                      0.879955                      0.385195                     -0.302958                     -0.913429                     -0.125220                     -0.427551                      0.138023                      0.219285                      -0.896987                      0.115269                      0.054536                     -0.446831                      0.366138                       0.423475                     -0.005907                     -0.050721                     -0.644304   \n",
       "\n",
       "   S_16__autocorrelation__lag_7  S_16__autocorrelation__lag_12  B_27__autocorrelation__lag_1  B_27__autocorrelation__lag_3  B_27__autocorrelation__lag_5  B_27__autocorrelation__lag_7  B_27__autocorrelation__lag_12  S_17__autocorrelation__lag_1  S_17__autocorrelation__lag_3  S_17__autocorrelation__lag_5  S_17__autocorrelation__lag_7  S_17__autocorrelation__lag_12  B_28__autocorrelation__lag_1  B_28__autocorrelation__lag_3  B_28__autocorrelation__lag_5  B_28__autocorrelation__lag_7  B_28__autocorrelation__lag_12  S_19__autocorrelation__lag_1  S_19__autocorrelation__lag_3  S_19__autocorrelation__lag_5  S_19__autocorrelation__lag_7  S_19__autocorrelation__lag_12  S_22__autocorrelation__lag_1  S_22__autocorrelation__lag_3  S_22__autocorrelation__lag_5  S_22__autocorrelation__lag_7  S_22__autocorrelation__lag_12  S_23__autocorrelation__lag_1  S_23__autocorrelation__lag_3  S_23__autocorrelation__lag_5  S_23__autocorrelation__lag_7  S_23__autocorrelation__lag_12  \\\n",
       "0                      0.302100                       1.559940                     -0.030590                      0.355688                     -0.625282                      0.306292                      -0.614856                     -0.645935                     -0.216410                      0.021920                      0.480663                       0.693486                      0.579599                      0.035679                     -0.676102                     -0.551996                       1.037578                     -0.095328                      0.318010                     -0.121828                     -0.546602                       0.999477                     -0.380035                     -0.397064                      0.363011                     -0.220701                      -0.146473                     -0.175662                      0.023506                      0.280169                      0.093404                      -0.277213   \n",
       "1                      0.269457                      -0.899951                      0.251996                     -0.699937                      0.495561                     -0.836835                      -0.218724                     -0.052303                     -0.025683                     -0.000577                     -0.138405                      -0.829197                     -0.149847                     -0.391023                     -0.486948                     -0.389997                       0.436127                     -0.038007                     -0.186194                     -0.326889                      0.163005                       0.042730                     -0.297713                     -0.157730                      0.007142                      0.267569                       0.037623                      0.091869                     -0.562719                      0.297626                     -0.105555                       0.094522   \n",
       "2                     -0.497379                       3.175819                     -0.291652                      0.028158                     -0.307972                     -0.223158                       0.609372                      0.170658                     -0.340540                      0.336744                     -0.575544                       0.090697                     -0.285243                     -0.041702                      0.245028                      0.304328                       0.029411                     -0.423801                     -0.157923                      0.007586                     -0.313025                      -0.212258                      0.138006                     -0.213037                     -0.632758                      0.613924                      -1.227427                     -0.370323                      0.200690                     -0.516252                      0.179139                       0.684402   \n",
       "3                      0.266514                      -0.095628                     -0.123322                     -0.211451                      0.039278                      0.055061                      -1.141073                     -0.324175                     -0.491401                     -0.533093                     -0.788674                       0.289677                      0.456487                      0.105604                     -0.318177                     -0.310283                      -1.851250                     -0.236225                      0.236042                     -0.465301                      0.888109                      -0.287283                      0.121172                     -0.365413                      0.073055                     -0.388872                       0.379045                     -0.276845                      0.370113                     -0.213797                      0.377669                      -1.231218   \n",
       "4                      0.736890                      -0.867295                     -0.177637                      0.131674                     -0.015296                     -0.627603                       0.922548                     -0.134906                     -0.217911                     -0.187566                      0.042166                       3.003222                      0.802881                      0.310564                     -0.384890                     -0.709457                      -0.818447                      0.253211                     -0.323084                      0.178464                      0.228628                       0.253017                     -0.208167                     -0.288272                     -0.412729                     -0.218109                       0.187894                     -0.030823                      0.116346                     -0.181318                     -0.353919                       1.417903   \n",
       "\n",
       "   S_24__autocorrelation__lag_1  S_24__autocorrelation__lag_3  S_24__autocorrelation__lag_5  S_24__autocorrelation__lag_7  S_24__autocorrelation__lag_12  S_25__autocorrelation__lag_1  S_25__autocorrelation__lag_3  S_25__autocorrelation__lag_5  S_25__autocorrelation__lag_7  S_25__autocorrelation__lag_12  S_26__autocorrelation__lag_1  S_26__autocorrelation__lag_3  S_26__autocorrelation__lag_5  S_26__autocorrelation__lag_7  S_26__autocorrelation__lag_12  D_102__autocorrelation__lag_1  D_102__autocorrelation__lag_3  D_102__autocorrelation__lag_5  D_102__autocorrelation__lag_7  D_102__autocorrelation__lag_12  B_36__autocorrelation__lag_1  B_36__autocorrelation__lag_3  B_36__autocorrelation__lag_5  B_36__autocorrelation__lag_7  B_36__autocorrelation__lag_12  B_37__autocorrelation__lag_1  B_37__autocorrelation__lag_3  B_37__autocorrelation__lag_5  B_37__autocorrelation__lag_7  B_37__autocorrelation__lag_12  R_27__autocorrelation__lag_1  R_27__autocorrelation__lag_3  \\\n",
       "0                     -0.457152                     -0.165754                      0.117417                     -0.066341                      -0.335786                     -0.231057                      0.561710                     -0.781056                      0.544386                       0.059783                      0.553525                     -0.093760                     -0.808339                     -0.680519                       1.561704                       0.817360                       0.453765                      -0.096066                      -0.661534                       -2.627619                      0.001141                      0.048006                     -0.193599                      0.117491                       0.980243                     -0.382612                     -0.257439                      0.200261                     -0.162480                       0.606577                     -0.129857                     -0.282572   \n",
       "1                     -0.118541                     -0.192225                     -0.151486                      0.337271                       0.158705                     -0.322453                     -0.142928                     -0.405988                     -0.478377                       0.273043                     -0.456351                      0.102505                      0.178573                      0.187638                      -0.519241                      -0.034035                       0.007712                       0.000584                      -0.102209                        0.857307                     -0.060868                     -0.512561                      0.044560                      0.203685                      -0.183552                      0.139136                     -0.395435                     -0.346664                      0.041722                      -0.014937                     -0.189782                      0.439698   \n",
       "2                      0.092495                     -0.375719                      0.027981                      0.020216                       0.391358                     -0.322914                     -0.011372                     -0.421537                     -0.007626                      -0.311461                     -0.398431                     -0.155454                      0.540269                      0.476253                      -0.074307                       0.219904                      -0.491950                       0.253178                       0.147721                        1.601073                      0.029732                      0.167404                     -0.290881                     -0.037630                       0.476133                      0.119477                     -0.254207                     -0.204287                     -0.111312                       0.039502                     -0.298726                      0.151240   \n",
       "3                     -0.136667                     -0.305991                      0.604625                     -0.045750                      -0.104679                     -0.365556                     -0.122505                     -0.553117                      0.169376                       0.013103                      0.360340                     -0.197225                     -0.916257                      0.092183                      -1.193518                       0.469707                      -0.370133                      -0.005065                      -0.235660                       -1.057197                     -0.159361                      0.082989                      0.038512                     -0.054791                      -0.041411                      0.563296                     -0.067891                     -0.177110                     -0.296693                      -0.122380                     -0.455531                     -0.290279   \n",
       "4                     -0.227474                     -0.310644                     -0.392473                     -0.196596                       0.168569                     -0.017757                      0.234860                     -0.335239                     -0.362815                       0.931233                     -0.426770                     -0.254363                     -0.576379                     -0.448432                       0.625548                       0.827261                       0.418920                      -0.040263                      -0.661197                       -2.547379                     -0.436598                     -0.013930                      0.185423                      0.739915                       0.507688                     -0.515974                     -0.176698                      0.074489                      0.442351                       0.544389                     -0.109676                      0.270546   \n",
       "\n",
       "   R_27__autocorrelation__lag_5  R_27__autocorrelation__lag_7  R_27__autocorrelation__lag_12  B_40__autocorrelation__lag_1  B_40__autocorrelation__lag_3  B_40__autocorrelation__lag_5  B_40__autocorrelation__lag_7  B_40__autocorrelation__lag_12  S_27__autocorrelation__lag_1  S_27__autocorrelation__lag_3  S_27__autocorrelation__lag_5  S_27__autocorrelation__lag_7  S_27__autocorrelation__lag_12  D_115__autocorrelation__lag_1  D_115__autocorrelation__lag_3  D_115__autocorrelation__lag_5  D_115__autocorrelation__lag_7  D_115__autocorrelation__lag_12  D_118__autocorrelation__lag_1  D_118__autocorrelation__lag_3  D_118__autocorrelation__lag_5  D_118__autocorrelation__lag_7  D_118__autocorrelation__lag_12  D_119__autocorrelation__lag_1  D_119__autocorrelation__lag_3  D_119__autocorrelation__lag_5  D_119__autocorrelation__lag_7  D_119__autocorrelation__lag_12  D_121__autocorrelation__lag_1  D_121__autocorrelation__lag_3  D_121__autocorrelation__lag_5  D_121__autocorrelation__lag_7  \\\n",
       "0                      0.194415                      0.707581                       0.199169                      0.806845                      0.279575                     -0.563220                     -0.892028                       0.306369                      0.380012                     -0.137542                      0.178246                     -0.127935                      -2.428539                       0.544090                       0.408778                      -0.115710                      -0.618815                       -1.953235                       0.517730                       0.175713                      -0.089425                      -0.101551                       -3.536048                       0.444233                       0.346846                       0.069915                      -0.562681                       -3.917920                       0.483853                       0.316808                      -0.049567                      -0.285690   \n",
       "1                     -0.121442                     -0.277884                      -0.304503                      0.270639                     -0.107014                     -0.210241                      0.146716                      -0.464874                      0.104221                     -0.215612                     -0.252645                      0.175138                      -0.905549                       0.565714                       0.313500                      -0.071783                      -0.587236                       -2.230022                       0.365810                       0.422014                      -0.155002                       0.130746                       -3.984658                       0.702565                       0.284260                      -0.020855                      -0.525714                       -1.367815                       0.380495                       0.480116                      -0.103145                      -0.384052   \n",
       "2                     -0.014791                     -0.510045                       0.457782                     -0.334895                      0.045494                      0.383480                      0.263805                       0.123531                           NaN                           NaN                           NaN                           NaN                            NaN                       0.497497                       0.444587                       0.089026                      -0.609927                       -2.541770                       0.697518                       0.421769                      -0.134236                      -0.868999                       -2.320283                       0.364284                       0.428514                      -0.039417                      -0.669263                       -3.101376                       0.630267                       0.321742                      -0.009910                      -0.474290   \n",
       "3                     -0.439749                     -0.213554                       0.129565                      0.241729                     -0.242953                     -0.317619                     -0.328064                      -1.012850                     -0.032778                      0.209253                      0.220997                     -0.316490                      -2.885003                       0.692887                      -0.110910                      -0.200097                      -0.340472                       -0.903393                       0.651480                       0.398993                      -0.018483                      -0.528058                       -2.479991                       0.649280                       0.267521                      -0.079920                      -0.533017                       -3.319050                       0.629333                       0.386063                      -0.053583                      -0.635823   \n",
       "4                     -0.578885                      0.545340                      -0.334632                      0.099502                      0.024550                     -0.042543                     -0.189234                      -0.500755                           NaN                           NaN                           NaN                           NaN                            NaN                       0.686781                       0.264899                      -0.054854                      -0.595322                       -1.989770                       0.734346                       0.414050                      -0.154383                      -0.688253                       -1.983280                       0.260332                       0.244508                      -0.211338                      -0.576385                       -2.940098                       0.727952                       0.287123                      -0.173553                      -0.688503   \n",
       "\n",
       "   D_121__autocorrelation__lag_12  D_133__autocorrelation__lag_1  D_133__autocorrelation__lag_3  D_133__autocorrelation__lag_5  D_133__autocorrelation__lag_7  D_133__autocorrelation__lag_12  D_144__autocorrelation__lag_1  D_144__autocorrelation__lag_3  D_144__autocorrelation__lag_5  D_144__autocorrelation__lag_7  D_144__autocorrelation__lag_12  \n",
       "0                       -2.367318                       0.138385                       0.192811                      -0.641375                      -0.435833                       -0.067163                      -0.104158                      -0.052005                       0.381391                      -0.376558                        1.735089  \n",
       "1                       -3.540150                       0.301589                       0.255739                       0.078983                      -0.341393                        0.779548                      -0.232295                       0.127100                      -0.118868                       0.054102                        0.577802  \n",
       "2                       -3.336769                      -0.252123                      -0.321239                       0.420012                      -0.042483                       -1.905534                      -0.171315                      -0.046841                       0.354531                      -0.548845                        0.831806  \n",
       "3                       -1.119614                       0.183323                      -0.012447                       0.003072                      -0.124413                       -0.358415                      -0.079493                      -0.340753                       0.441229                      -0.033458                       -0.352436  \n",
       "4                       -2.305585                       0.186063                       0.157382                       0.015212                      -0.512134                       -0.057377                      -0.134475                       0.082192                       0.284313                      -0.272151                       -0.205607  \n",
       "\n",
       "[5 rows x 1807 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da1aef6c-6e01-413f-b9a0-46be991ca78e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "--------------------------------------------------\n",
      "Training fold 0 with 1805 features...\n",
      "[LightGBM] [Info] Number of positive: 95062, number of negative: 272068\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 2.134905 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 317559\n",
      "[LightGBM] [Info] Number of data points in the train set: 367130, number of used features: 1796\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258933 -> initscore=-1.051523\n",
      "[LightGBM] [Info] Start training from score -1.051523\n",
      "[500]\ttraining's binary_logloss: 0.337805\ttraining's amex_metric: 0.776869\tvalid_1's binary_logloss: 0.33973\tvalid_1's amex_metric: 0.769559\n",
      "[1000]\ttraining's binary_logloss: 0.246546\ttraining's amex_metric: 0.793763\tvalid_1's binary_logloss: 0.252005\tvalid_1's amex_metric: 0.779661\n",
      "[1500]\ttraining's binary_logloss: 0.222403\ttraining's amex_metric: 0.807815\tvalid_1's binary_logloss: 0.232018\tvalid_1's amex_metric: 0.785866\n",
      "[2000]\ttraining's binary_logloss: 0.208637\ttraining's amex_metric: 0.820941\tvalid_1's binary_logloss: 0.223436\tvalid_1's amex_metric: 0.7908\n",
      "[2500]\ttraining's binary_logloss: 0.201431\ttraining's amex_metric: 0.831825\tvalid_1's binary_logloss: 0.220638\tvalid_1's amex_metric: 0.793445\n",
      "[3000]\ttraining's binary_logloss: 0.194146\ttraining's amex_metric: 0.842624\tvalid_1's binary_logloss: 0.218368\tvalid_1's amex_metric: 0.795974\n",
      "[3500]\ttraining's binary_logloss: 0.187449\ttraining's amex_metric: 0.85307\tvalid_1's binary_logloss: 0.216881\tvalid_1's amex_metric: 0.798182\n",
      "[4000]\ttraining's binary_logloss: 0.181444\ttraining's amex_metric: 0.863378\tvalid_1's binary_logloss: 0.2159\tvalid_1's amex_metric: 0.797956\n",
      "[4500]\ttraining's binary_logloss: 0.175586\ttraining's amex_metric: 0.873626\tvalid_1's binary_logloss: 0.215096\tvalid_1's amex_metric: 0.799119\n",
      "[5000]\ttraining's binary_logloss: 0.169826\ttraining's amex_metric: 0.883941\tvalid_1's binary_logloss: 0.214469\tvalid_1's amex_metric: 0.799718\n",
      "[5500]\ttraining's binary_logloss: 0.164667\ttraining's amex_metric: 0.892497\tvalid_1's binary_logloss: 0.214015\tvalid_1's amex_metric: 0.799968\n",
      "[6000]\ttraining's binary_logloss: 0.16024\ttraining's amex_metric: 0.900604\tvalid_1's binary_logloss: 0.213815\tvalid_1's amex_metric: 0.800597\n",
      "[6500]\ttraining's binary_logloss: 0.155607\ttraining's amex_metric: 0.908344\tvalid_1's binary_logloss: 0.213565\tvalid_1's amex_metric: 0.800793\n",
      "[7000]\ttraining's binary_logloss: 0.150236\ttraining's amex_metric: 0.916927\tvalid_1's binary_logloss: 0.213309\tvalid_1's amex_metric: 0.800795\n",
      "[7500]\ttraining's binary_logloss: 0.145171\ttraining's amex_metric: 0.924866\tvalid_1's binary_logloss: 0.213184\tvalid_1's amex_metric: 0.800753\n",
      "[8000]\ttraining's binary_logloss: 0.14066\ttraining's amex_metric: 0.931923\tvalid_1's binary_logloss: 0.213084\tvalid_1's amex_metric: 0.800689\n",
      "[8500]\ttraining's binary_logloss: 0.136834\ttraining's amex_metric: 0.938751\tvalid_1's binary_logloss: 0.213079\tvalid_1's amex_metric: 0.800765\n",
      "[9000]\ttraining's binary_logloss: 0.132508\ttraining's amex_metric: 0.945322\tvalid_1's binary_logloss: 0.213038\tvalid_1's amex_metric: 0.800623\n",
      "[9500]\ttraining's binary_logloss: 0.128632\ttraining's amex_metric: 0.950914\tvalid_1's binary_logloss: 0.212977\tvalid_1's amex_metric: 0.800597\n",
      "[10000]\ttraining's binary_logloss: 0.124827\ttraining's amex_metric: 0.956049\tvalid_1's binary_logloss: 0.212964\tvalid_1's amex_metric: 0.800218\n",
      "[10500]\ttraining's binary_logloss: 0.121507\ttraining's amex_metric: 0.960841\tvalid_1's binary_logloss: 0.212994\tvalid_1's amex_metric: 0.799975\n",
      "Our fold 0 CV score is 0.7999749498593046\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 1 with 1805 features...\n",
      "[LightGBM] [Info] Number of positive: 95062, number of negative: 272068\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 2.364814 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 317676\n",
      "[LightGBM] [Info] Number of data points in the train set: 367130, number of used features: 1796\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258933 -> initscore=-1.051523\n",
      "[LightGBM] [Info] Start training from score -1.051523\n",
      "[500]\ttraining's binary_logloss: 0.337452\ttraining's amex_metric: 0.779014\tvalid_1's binary_logloss: 0.340718\tvalid_1's amex_metric: 0.762509\n",
      "[1000]\ttraining's binary_logloss: 0.245936\ttraining's amex_metric: 0.795585\tvalid_1's binary_logloss: 0.253802\tvalid_1's amex_metric: 0.772043\n",
      "[1500]\ttraining's binary_logloss: 0.221607\ttraining's amex_metric: 0.810012\tvalid_1's binary_logloss: 0.23424\tvalid_1's amex_metric: 0.77849\n",
      "[2000]\ttraining's binary_logloss: 0.207639\ttraining's amex_metric: 0.823416\tvalid_1's binary_logloss: 0.225967\tvalid_1's amex_metric: 0.783496\n",
      "[2500]\ttraining's binary_logloss: 0.200448\ttraining's amex_metric: 0.833888\tvalid_1's binary_logloss: 0.223355\tvalid_1's amex_metric: 0.78629\n",
      "[3000]\ttraining's binary_logloss: 0.193156\ttraining's amex_metric: 0.844396\tvalid_1's binary_logloss: 0.221235\tvalid_1's amex_metric: 0.787899\n",
      "[3500]\ttraining's binary_logloss: 0.186393\ttraining's amex_metric: 0.855687\tvalid_1's binary_logloss: 0.219917\tvalid_1's amex_metric: 0.789263\n",
      "[4000]\ttraining's binary_logloss: 0.180422\ttraining's amex_metric: 0.865409\tvalid_1's binary_logloss: 0.219151\tvalid_1's amex_metric: 0.789759\n",
      "[4500]\ttraining's binary_logloss: 0.174567\ttraining's amex_metric: 0.875217\tvalid_1's binary_logloss: 0.218492\tvalid_1's amex_metric: 0.790286\n",
      "[5000]\ttraining's binary_logloss: 0.168838\ttraining's amex_metric: 0.885014\tvalid_1's binary_logloss: 0.218004\tvalid_1's amex_metric: 0.791003\n",
      "[5500]\ttraining's binary_logloss: 0.16366\ttraining's amex_metric: 0.893918\tvalid_1's binary_logloss: 0.217727\tvalid_1's amex_metric: 0.791348\n",
      "[6000]\ttraining's binary_logloss: 0.159255\ttraining's amex_metric: 0.902681\tvalid_1's binary_logloss: 0.217605\tvalid_1's amex_metric: 0.791473\n",
      "[6500]\ttraining's binary_logloss: 0.154629\ttraining's amex_metric: 0.909593\tvalid_1's binary_logloss: 0.217408\tvalid_1's amex_metric: 0.791932\n",
      "[7000]\ttraining's binary_logloss: 0.149268\ttraining's amex_metric: 0.918136\tvalid_1's binary_logloss: 0.217219\tvalid_1's amex_metric: 0.791217\n",
      "[7500]\ttraining's binary_logloss: 0.144231\ttraining's amex_metric: 0.926321\tvalid_1's binary_logloss: 0.217134\tvalid_1's amex_metric: 0.791783\n",
      "[8000]\ttraining's binary_logloss: 0.139772\ttraining's amex_metric: 0.9335\tvalid_1's binary_logloss: 0.217093\tvalid_1's amex_metric: 0.792366\n",
      "[8500]\ttraining's binary_logloss: 0.135962\ttraining's amex_metric: 0.939679\tvalid_1's binary_logloss: 0.217032\tvalid_1's amex_metric: 0.792073\n",
      "[9000]\ttraining's binary_logloss: 0.131625\ttraining's amex_metric: 0.945804\tvalid_1's binary_logloss: 0.216941\tvalid_1's amex_metric: 0.792082\n",
      "[9500]\ttraining's binary_logloss: 0.127759\ttraining's amex_metric: 0.95175\tvalid_1's binary_logloss: 0.216917\tvalid_1's amex_metric: 0.791502\n",
      "[10000]\ttraining's binary_logloss: 0.123939\ttraining's amex_metric: 0.957027\tvalid_1's binary_logloss: 0.216957\tvalid_1's amex_metric: 0.7915\n",
      "[10500]\ttraining's binary_logloss: 0.120632\ttraining's amex_metric: 0.961567\tvalid_1's binary_logloss: 0.216996\tvalid_1's amex_metric: 0.791597\n",
      "Our fold 1 CV score is 0.7915974528558163\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 2 with 1805 features...\n",
      "[LightGBM] [Info] Number of positive: 95062, number of negative: 272068\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.981984 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 317586\n",
      "[LightGBM] [Info] Number of data points in the train set: 367130, number of used features: 1796\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258933 -> initscore=-1.051523\n",
      "[LightGBM] [Info] Start training from score -1.051523\n",
      "[500]\ttraining's binary_logloss: 0.33746\ttraining's amex_metric: 0.777437\tvalid_1's binary_logloss: 0.341263\tvalid_1's amex_metric: 0.766369\n",
      "[1000]\ttraining's binary_logloss: 0.245958\ttraining's amex_metric: 0.794253\tvalid_1's binary_logloss: 0.254183\tvalid_1's amex_metric: 0.776733\n",
      "[1500]\ttraining's binary_logloss: 0.221767\ttraining's amex_metric: 0.808645\tvalid_1's binary_logloss: 0.23424\tvalid_1's amex_metric: 0.783583\n",
      "[2000]\ttraining's binary_logloss: 0.207929\ttraining's amex_metric: 0.822088\tvalid_1's binary_logloss: 0.225677\tvalid_1's amex_metric: 0.788791\n",
      "[2500]\ttraining's binary_logloss: 0.200724\ttraining's amex_metric: 0.83342\tvalid_1's binary_logloss: 0.222888\tvalid_1's amex_metric: 0.790748\n",
      "[3000]\ttraining's binary_logloss: 0.193464\ttraining's amex_metric: 0.844037\tvalid_1's binary_logloss: 0.220686\tvalid_1's amex_metric: 0.79271\n",
      "[3500]\ttraining's binary_logloss: 0.186693\ttraining's amex_metric: 0.854477\tvalid_1's binary_logloss: 0.219217\tvalid_1's amex_metric: 0.794117\n",
      "[4000]\ttraining's binary_logloss: 0.180701\ttraining's amex_metric: 0.865154\tvalid_1's binary_logloss: 0.218359\tvalid_1's amex_metric: 0.794454\n",
      "[4500]\ttraining's binary_logloss: 0.174858\ttraining's amex_metric: 0.874812\tvalid_1's binary_logloss: 0.217636\tvalid_1's amex_metric: 0.794739\n",
      "[5000]\ttraining's binary_logloss: 0.169096\ttraining's amex_metric: 0.884396\tvalid_1's binary_logloss: 0.217192\tvalid_1's amex_metric: 0.795144\n",
      "[5500]\ttraining's binary_logloss: 0.163964\ttraining's amex_metric: 0.893527\tvalid_1's binary_logloss: 0.216812\tvalid_1's amex_metric: 0.795437\n",
      "[6000]\ttraining's binary_logloss: 0.159539\ttraining's amex_metric: 0.901578\tvalid_1's binary_logloss: 0.216609\tvalid_1's amex_metric: 0.795209\n",
      "[6500]\ttraining's binary_logloss: 0.154898\ttraining's amex_metric: 0.908922\tvalid_1's binary_logloss: 0.216412\tvalid_1's amex_metric: 0.79574\n",
      "[7000]\ttraining's binary_logloss: 0.149592\ttraining's amex_metric: 0.917475\tvalid_1's binary_logloss: 0.216238\tvalid_1's amex_metric: 0.795449\n",
      "[7500]\ttraining's binary_logloss: 0.144562\ttraining's amex_metric: 0.925398\tvalid_1's binary_logloss: 0.216092\tvalid_1's amex_metric: 0.7957\n",
      "[8000]\ttraining's binary_logloss: 0.140062\ttraining's amex_metric: 0.932636\tvalid_1's binary_logloss: 0.215986\tvalid_1's amex_metric: 0.795475\n",
      "[8500]\ttraining's binary_logloss: 0.13623\ttraining's amex_metric: 0.939257\tvalid_1's binary_logloss: 0.21601\tvalid_1's amex_metric: 0.796263\n",
      "[9000]\ttraining's binary_logloss: 0.131899\ttraining's amex_metric: 0.946004\tvalid_1's binary_logloss: 0.216\tvalid_1's amex_metric: 0.795879\n",
      "[9500]\ttraining's binary_logloss: 0.128038\ttraining's amex_metric: 0.951851\tvalid_1's binary_logloss: 0.215943\tvalid_1's amex_metric: 0.796655\n",
      "[10000]\ttraining's binary_logloss: 0.124229\ttraining's amex_metric: 0.957138\tvalid_1's binary_logloss: 0.215991\tvalid_1's amex_metric: 0.79628\n",
      "[10500]\ttraining's binary_logloss: 0.120928\ttraining's amex_metric: 0.961717\tvalid_1's binary_logloss: 0.216025\tvalid_1's amex_metric: 0.795931\n",
      "Our fold 2 CV score is 0.7959311516526634\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 3 with 1805 features...\n",
      "[LightGBM] [Info] Number of positive: 95063, number of negative: 272068\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 2.239931 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 317607\n",
      "[LightGBM] [Info] Number of data points in the train set: 367131, number of used features: 1796\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258935 -> initscore=-1.051512\n",
      "[LightGBM] [Info] Start training from score -1.051512\n",
      "[500]\ttraining's binary_logloss: 0.337104\ttraining's amex_metric: 0.779304\tvalid_1's binary_logloss: 0.341881\tvalid_1's amex_metric: 0.761285\n",
      "[1000]\ttraining's binary_logloss: 0.245649\ttraining's amex_metric: 0.795922\tvalid_1's binary_logloss: 0.255171\tvalid_1's amex_metric: 0.770272\n",
      "[1500]\ttraining's binary_logloss: 0.221398\ttraining's amex_metric: 0.810671\tvalid_1's binary_logloss: 0.235431\tvalid_1's amex_metric: 0.776331\n",
      "[2000]\ttraining's binary_logloss: 0.207577\ttraining's amex_metric: 0.823667\tvalid_1's binary_logloss: 0.227074\tvalid_1's amex_metric: 0.780259\n",
      "[2500]\ttraining's binary_logloss: 0.200398\ttraining's amex_metric: 0.834372\tvalid_1's binary_logloss: 0.224425\tvalid_1's amex_metric: 0.783872\n",
      "[3000]\ttraining's binary_logloss: 0.19313\ttraining's amex_metric: 0.844979\tvalid_1's binary_logloss: 0.222219\tvalid_1's amex_metric: 0.785582\n",
      "[3500]\ttraining's binary_logloss: 0.186419\ttraining's amex_metric: 0.855138\tvalid_1's binary_logloss: 0.220808\tvalid_1's amex_metric: 0.786198\n",
      "[4000]\ttraining's binary_logloss: 0.18047\ttraining's amex_metric: 0.865651\tvalid_1's binary_logloss: 0.219932\tvalid_1's amex_metric: 0.787704\n",
      "[4500]\ttraining's binary_logloss: 0.174644\ttraining's amex_metric: 0.875335\tvalid_1's binary_logloss: 0.219279\tvalid_1's amex_metric: 0.78804\n",
      "[5000]\ttraining's binary_logloss: 0.168872\ttraining's amex_metric: 0.884994\tvalid_1's binary_logloss: 0.218726\tvalid_1's amex_metric: 0.788613\n",
      "[5500]\ttraining's binary_logloss: 0.163722\ttraining's amex_metric: 0.894106\tvalid_1's binary_logloss: 0.218382\tvalid_1's amex_metric: 0.788975\n",
      "[6000]\ttraining's binary_logloss: 0.159306\ttraining's amex_metric: 0.902465\tvalid_1's binary_logloss: 0.21818\tvalid_1's amex_metric: 0.789\n",
      "[6500]\ttraining's binary_logloss: 0.154665\ttraining's amex_metric: 0.90975\tvalid_1's binary_logloss: 0.217916\tvalid_1's amex_metric: 0.789924\n",
      "[7000]\ttraining's binary_logloss: 0.149341\ttraining's amex_metric: 0.917978\tvalid_1's binary_logloss: 0.217644\tvalid_1's amex_metric: 0.790014\n",
      "[7500]\ttraining's binary_logloss: 0.144278\ttraining's amex_metric: 0.925902\tvalid_1's binary_logloss: 0.217379\tvalid_1's amex_metric: 0.790288\n",
      "[8000]\ttraining's binary_logloss: 0.139787\ttraining's amex_metric: 0.933133\tvalid_1's binary_logloss: 0.217245\tvalid_1's amex_metric: 0.791067\n",
      "[8500]\ttraining's binary_logloss: 0.135957\ttraining's amex_metric: 0.940003\tvalid_1's binary_logloss: 0.21719\tvalid_1's amex_metric: 0.790601\n",
      "[9000]\ttraining's binary_logloss: 0.131639\ttraining's amex_metric: 0.946329\tvalid_1's binary_logloss: 0.217178\tvalid_1's amex_metric: 0.790959\n",
      "[9500]\ttraining's binary_logloss: 0.127781\ttraining's amex_metric: 0.951889\tvalid_1's binary_logloss: 0.217238\tvalid_1's amex_metric: 0.79054\n",
      "[10000]\ttraining's binary_logloss: 0.124013\ttraining's amex_metric: 0.957163\tvalid_1's binary_logloss: 0.217183\tvalid_1's amex_metric: 0.79056\n",
      "[10500]\ttraining's binary_logloss: 0.120726\ttraining's amex_metric: 0.961903\tvalid_1's binary_logloss: 0.217209\tvalid_1's amex_metric: 0.790155\n",
      "Our fold 3 CV score is 0.7901551346843605\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 4 with 1805 features...\n",
      "[LightGBM] [Info] Number of positive: 95063, number of negative: 272068\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 2.007830 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 317562\n",
      "[LightGBM] [Info] Number of data points in the train set: 367131, number of used features: 1796\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258935 -> initscore=-1.051512\n",
      "[LightGBM] [Info] Start training from score -1.051512\n",
      "[500]\ttraining's binary_logloss: 0.337699\ttraining's amex_metric: 0.777814\tvalid_1's binary_logloss: 0.340637\tvalid_1's amex_metric: 0.767135\n",
      "[1000]\ttraining's binary_logloss: 0.246332\ttraining's amex_metric: 0.794412\tvalid_1's binary_logloss: 0.253088\tvalid_1's amex_metric: 0.777849\n",
      "[1500]\ttraining's binary_logloss: 0.222133\ttraining's amex_metric: 0.808891\tvalid_1's binary_logloss: 0.232989\tvalid_1's amex_metric: 0.782699\n",
      "[2000]\ttraining's binary_logloss: 0.208372\ttraining's amex_metric: 0.821958\tvalid_1's binary_logloss: 0.224371\tvalid_1's amex_metric: 0.787207\n",
      "[2500]\ttraining's binary_logloss: 0.201151\ttraining's amex_metric: 0.83273\tvalid_1's binary_logloss: 0.221651\tvalid_1's amex_metric: 0.788895\n",
      "[3000]\ttraining's binary_logloss: 0.193881\ttraining's amex_metric: 0.843414\tvalid_1's binary_logloss: 0.219409\tvalid_1's amex_metric: 0.791266\n",
      "[3500]\ttraining's binary_logloss: 0.187122\ttraining's amex_metric: 0.854202\tvalid_1's binary_logloss: 0.217916\tvalid_1's amex_metric: 0.79183\n",
      "[4000]\ttraining's binary_logloss: 0.181126\ttraining's amex_metric: 0.864647\tvalid_1's binary_logloss: 0.217036\tvalid_1's amex_metric: 0.793354\n",
      "[4500]\ttraining's binary_logloss: 0.175297\ttraining's amex_metric: 0.87427\tvalid_1's binary_logloss: 0.216419\tvalid_1's amex_metric: 0.793949\n",
      "[5000]\ttraining's binary_logloss: 0.169544\ttraining's amex_metric: 0.883869\tvalid_1's binary_logloss: 0.215923\tvalid_1's amex_metric: 0.794802\n",
      "[5500]\ttraining's binary_logloss: 0.164387\ttraining's amex_metric: 0.892796\tvalid_1's binary_logloss: 0.215509\tvalid_1's amex_metric: 0.795439\n",
      "[6000]\ttraining's binary_logloss: 0.159974\ttraining's amex_metric: 0.90069\tvalid_1's binary_logloss: 0.215297\tvalid_1's amex_metric: 0.795483\n",
      "[6500]\ttraining's binary_logloss: 0.155315\ttraining's amex_metric: 0.908384\tvalid_1's binary_logloss: 0.21505\tvalid_1's amex_metric: 0.795854\n",
      "[7000]\ttraining's binary_logloss: 0.149973\ttraining's amex_metric: 0.916857\tvalid_1's binary_logloss: 0.214766\tvalid_1's amex_metric: 0.796112\n",
      "[7500]\ttraining's binary_logloss: 0.144927\ttraining's amex_metric: 0.92518\tvalid_1's binary_logloss: 0.214569\tvalid_1's amex_metric: 0.796245\n",
      "[8000]\ttraining's binary_logloss: 0.140438\ttraining's amex_metric: 0.932649\tvalid_1's binary_logloss: 0.214441\tvalid_1's amex_metric: 0.796609\n",
      "[8500]\ttraining's binary_logloss: 0.136561\ttraining's amex_metric: 0.939215\tvalid_1's binary_logloss: 0.214417\tvalid_1's amex_metric: 0.796062\n",
      "[9000]\ttraining's binary_logloss: 0.13223\ttraining's amex_metric: 0.945265\tvalid_1's binary_logloss: 0.214277\tvalid_1's amex_metric: 0.796999\n",
      "[9500]\ttraining's binary_logloss: 0.128353\ttraining's amex_metric: 0.951323\tvalid_1's binary_logloss: 0.214261\tvalid_1's amex_metric: 0.79731\n",
      "[10000]\ttraining's binary_logloss: 0.124538\ttraining's amex_metric: 0.956621\tvalid_1's binary_logloss: 0.2142\tvalid_1's amex_metric: 0.796948\n",
      "[10500]\ttraining's binary_logloss: 0.121245\ttraining's amex_metric: 0.960981\tvalid_1's binary_logloss: 0.214163\tvalid_1's amex_metric: 0.797193\n",
      "Our fold 4 CV score is 0.7971929908067565\n",
      "Our out of folds CV score is 0.7949247988329309\n"
     ]
    }
   ],
   "source": [
    "cat_features = [\n",
    "    \"B_30\",\n",
    "    \"B_38\",\n",
    "    \"D_114\",\n",
    "    \"D_116\",\n",
    "    \"D_117\",\n",
    "    \"D_120\",\n",
    "    \"D_126\",\n",
    "    \"D_63\",\n",
    "    \"D_64\",\n",
    "    \"D_66\",\n",
    "    \"D_68\"\n",
    "]\n",
    "\n",
    "# kmeans_list = [\"kmeans pred 2\",\"kmeans pred 3\",\"kmeans pred 4\"]\n",
    "\n",
    "cat_features = [f\"{cf}_last\" for cf in cat_features]\n",
    "# cat_features.extend(kmeans_list)\n",
    "\n",
    "for cat_col in cat_features:\n",
    "#     print(cat_col)\n",
    "    encoder = LabelEncoder()\n",
    "    train[cat_col] = encoder.fit_transform(train[cat_col])\n",
    "    test[cat_col] = encoder.transform(test[cat_col])\n",
    "\n",
    "\n",
    "features = [col for col in train.columns if col not in ['customer_ID', CFG.target]]\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': CFG.metric,\n",
    "    'boosting': CFG.boosting_type,\n",
    "    'seed': CFG.seed,\n",
    "    'num_leaves': 100,\n",
    "    'learning_rate': 0.01,\n",
    "    'feature_fraction': 0.20,\n",
    "    'bagging_freq': 10,\n",
    "    'bagging_fraction': 0.50,\n",
    "    'n_jobs': -1,\n",
    "    'lambda_l2': 2,\n",
    "    'min_data_in_leaf': 40,\n",
    "    }\n",
    "# Create a numpy array to store test predictions\n",
    "test_predictions = np.zeros(len(test))\n",
    "# Create a numpy array to store out of folds predictions\n",
    "oof_predictions = np.zeros(len(train))\n",
    "\n",
    "cids = []\n",
    "tr_target = []\n",
    "\n",
    "kfold = StratifiedKFold(n_splits = CFG.n_folds, shuffle = True, random_state = CFG.seed)\n",
    "for fold, (trn_ind, val_ind) in enumerate(kfold.split(train, train[CFG.target])):\n",
    "    print(' ')\n",
    "    print('-'*50)\n",
    "    print(f'Training fold {fold} with {len(features)} features...')\n",
    "    x_train, x_val = train[features].iloc[trn_ind], train[features].iloc[val_ind]\n",
    "    y_train, y_val = train[CFG.target].iloc[trn_ind], train[CFG.target].iloc[val_ind]\n",
    "    lgb_train = lgb.Dataset(x_train, y_train, categorical_feature = cat_features)\n",
    "    lgb_valid = lgb.Dataset(x_val, y_val, categorical_feature = cat_features)\n",
    "    model = lgb.train(\n",
    "        params = params,\n",
    "        train_set = lgb_train,\n",
    "        num_boost_round = 10500,#10500\n",
    "        valid_sets = [lgb_train, lgb_valid],\n",
    "        early_stopping_rounds = 1500,\n",
    "        verbose_eval = 500,\n",
    "        feval = lgb_amex_metric\n",
    "        )\n",
    "    \n",
    "    # Save best model\n",
    "    joblib.dump(model, f'{CFG.output_dir}lgbm_{CFG.boosting_type}_fold{fold}_seed{CFG.seed}.pkl')\n",
    "    # Predict validation\n",
    "    val_pred = model.predict(x_val)\n",
    "    # Add to out of folds array\n",
    "    oof_predictions[val_ind] = val_pred\n",
    "    \n",
    "    cids.extend(train[\"customer_ID\"].loc[val_ind])\n",
    "    tr_target.extend(train[\"target\"].loc[val_ind])\n",
    "    \n",
    "    # Predict the test set\n",
    "    test_pred = model.predict(test[features])\n",
    "    test_predictions += test_pred / CFG.n_folds\n",
    "    # Compute fold metric\n",
    "    score = amex_metric(y_val, val_pred)\n",
    "    print(f'Our fold {fold} CV score is {score}')\n",
    "    del x_train, x_val, y_train, y_val, lgb_train, lgb_valid\n",
    "    gc.collect()\n",
    "    \n",
    "# Compute out of folds metric\n",
    "score = amex_metric(train[CFG.target], oof_predictions)\n",
    "print(f'Our out of folds CV score is {score}')\n",
    "\n",
    "\n",
    "# Create a dataframe to store test prediction\n",
    "test_df = pd.DataFrame({'customer_ID': test['customer_ID'], 'prediction': test_predictions})\n",
    "# test_df.to_csv(f'{CFG.output_dir}test_{CFG.model}_{score}_baseline_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)\n",
    "test_df.to_csv(f'{CFG.output_dir}test_{CFG.model}_{score}_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)\n",
    "\n",
    "\n",
    "dic_oof = {\n",
    "    \"customer_ID\":cids,\n",
    "    \"target\":tr_target,\n",
    "    \"tabnet_oot\":oof_predictions\n",
    "}\n",
    "\n",
    "# Create a dataframe to store out of folds predictions\n",
    "oof_df = pd.DataFrame(dic_oof)\n",
    "# oof_df = pd.DataFrame({'customer_ID': train['customer_ID'], 'target': train[CFG.target], 'prediction': oof_predictions})\n",
    "oof_df.to_csv(f'{CFG.output_dir}oof_{CFG.ver}_{CFG.model}_{score}_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)\n",
    "\n",
    "\n",
    "# # Create a dataframe to store out of folds predictions\n",
    "# oof_df = pd.DataFrame({'customer_ID': train['customer_ID'], 'target': train[CFG.target], 'prediction': oof_predictions})\n",
    "# oof_df.to_csv(f'../output/Amex LGBM Dart CV 0.7977/oof_lgbm_{CFG.boosting_type}_baseline_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)\n",
    "\n",
    "\n",
    "# # Create a dataframe to store test prediction\n",
    "# test_df = pd.DataFrame({'customer_ID': test['customer_ID'], 'prediction': test_predictions})\n",
    "# test_df.to_csv(f'../output/Amex LGBM Dart CV 0.7977/test_lgbm_{CFG.boosting_type}_baseline_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e494e0-50f8-47ad-88c9-637a1b994414",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f770440-1df8-4a28-80c7-a3499e807a13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f3f7fd-7bd1-4e92-93a9-4a18f035feca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amex",
   "language": "python",
   "name": "amex"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
