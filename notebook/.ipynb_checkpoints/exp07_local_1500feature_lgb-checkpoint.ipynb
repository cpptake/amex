{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36a91cb1-484a-4d3d-b856-8235a0af3a02",
   "metadata": {},
   "source": [
    "# 1500 feature\n",
    "\n",
    "特徴量作成Notebook\n",
    "https://www.kaggle.com/code/illidan7/amex-basic-feature-engineering-1500-features\n",
    "\n",
    "上記特徴量にLightGBMでモデリング\n",
    "\n",
    "（Lag特徴量入れたいな。）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3ed8669-5e5b-4f99-b411-8e589913bb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # LOAD LIBRARIES\n",
    "# import pandas as pd, numpy as np # CPU libraries\n",
    "# import cupy, cudf # GPU libraries\n",
    "# import matplotlib.pyplot as plt, gc, os\n",
    "# import seaborn as sns\n",
    "\n",
    "# print('RAPIDS version',cudf.__version__)\n",
    "\n",
    "# ====================================================\n",
    "# Library\n",
    "# ====================================================\n",
    "import os\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "from tqdm.auto import tqdm\n",
    "import itertools\n",
    "\n",
    "import joblib\n",
    "import random\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "from itertools import combinations\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import snappy\n",
    "# from ipywidgets imprt interact, Select\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8762cb84-9650-468f-b2f7-1c28238b53de",
   "metadata": {},
   "source": [
    "# import train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58ad7338-a76c-4753-9960-e539663a3849",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    ver = \"07\"\n",
    "    input_dir = '../feature/exp06 Basic 1500 features/'\n",
    "    output_dir = '../output/exp07 LGB feature1500/'\n",
    "    seed = 46\n",
    "    n_folds = 5\n",
    "    target = 'target'\n",
    "    boosting_type = 'dart'\n",
    "    metric = 'binary_logloss'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30447e22-1e75-40a5-a0ab-6b3cdf963990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = pd.read_parquet('../feature/exp06 Basic 1500 features/train_1500_features.parquet')\n",
    "# train.head()\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "def amex_metric(y_true, y_pred):\n",
    "    labels = np.transpose(np.array([y_true, y_pred]))\n",
    "    labels = labels[labels[:, 1].argsort()[::-1]]\n",
    "    weights = np.where(labels[:,0]==0, 20, 1)\n",
    "    cut_vals = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n",
    "    top_four = np.sum(cut_vals[:,0]) / np.sum(labels[:,0])\n",
    "    gini = [0,0]\n",
    "    for i in [1,0]:\n",
    "        labels = np.transpose(np.array([y_true, y_pred]))\n",
    "        labels = labels[labels[:, i].argsort()[::-1]]\n",
    "        weight = np.where(labels[:,0]==0, 20, 1)\n",
    "        weight_random = np.cumsum(weight / np.sum(weight))\n",
    "        total_pos = np.sum(labels[:, 0] *  weight)\n",
    "        cum_pos_found = np.cumsum(labels[:, 0] * weight)\n",
    "        lorentz = cum_pos_found / total_pos\n",
    "        gini[i] = np.sum((lorentz - weight_random) * weight)\n",
    "    return 0.5 * (gini[1]/gini[0] + top_four)\n",
    "\n",
    "\n",
    "def lgb_amex_metric(y_pred, y_true):\n",
    "    y_true = y_true.get_label()\n",
    "    return 'amex_metric', amex_metric(y_true, y_pred), True\n",
    "\n",
    "\n",
    "def read_data():\n",
    "    train = pd.read_parquet(CFG.input_dir + 'train_1500_features.parquet')\n",
    "    test = pd.read_parquet(CFG.input_dir + 'test_1500features.parquet')\n",
    "    return train,test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afd12d0-99b7-4718-b984-da606adf4a80",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1cbf8ea-9bd9-4d27-ba16-469ca06325f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(CFG.seed)\n",
    "train, test = read_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facd0ebd-ce95-4205-b940-c9a08ffc6eb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca2f90d0-d979-4098-95d6-129ae7e46862",
   "metadata": {},
   "source": [
    "# 1500featureにlagfeatureをマージ\n",
    "\n",
    "exp07 では使わない"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c18176cc-93d7-46b1-9c68-896b1c18193c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_lag = pd.read_parquet( '../feature/exp01_lag_feature/train_lag_feature.parquet')\n",
    "# test_lag = pd.read_parquet( '../feature/exp01_lag_feature/test_lag_feature.parquet')\n",
    "# train_ID = pd.read_parquet( '../feature/costomerID_list/train_costomerID_list.parquet').drop_duplicates()\n",
    "# test_ID = pd.read_parquet( '../feature/costomerID_list/test_costomerID_list.parquet').drop_duplicates()\n",
    "\n",
    "\n",
    "# train_lag = train_lag.merge(train_ID , how = \"left\" , on = \"customer_ID\")\n",
    "# test_lag = test_lag.merge(test_ID , how = \"left\" , on = \"customer_ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "354aab4e-cebd-4734-bca3-5515ae013d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train_lag.head()\n",
    "# train = train.drop(\"customer_ID\",axis = 1).merge(train_lag , how = \"left\" , left_on = \"customer_ID\", right_on = \"customer_ID_hex\").drop(\"customer_ID_hex\",axis = 1)\n",
    "# test = test.drop(\"customer_ID\",axis = 1).merge(test_lag , how = \"left\" , left_on = \"customer_ID\", right_on = \"customer_ID_hex\").drop(\"customer_ID_hex\",axis = 1)\n",
    "\n",
    "\n",
    "# del train_ID,test_ID,train_lag,test_lag\n",
    "# gc.collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00eca22a-2529-49a4-85ea-c41b9a6c0e45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27701620-f108-4c26-a96a-636dee1f7037",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7ff38612-ee4f-41b0-9e34-0ab89723f49c",
   "metadata": {},
   "source": [
    "# train & evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67826999-4135-4e26-bd17-9c2265c6fb8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "--------------------------------------------------\n",
      "Training fold 0 with 1486 features...\n",
      "[LightGBM] [Info] Number of positive: 95062, number of negative: 272068\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 2.017450 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 275871\n",
      "[LightGBM] [Info] Number of data points in the train set: 367130, number of used features: 1480\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258933 -> initscore=-1.051523\n",
      "[LightGBM] [Info] Start training from score -1.051523\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7064\\4210889329.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[0mearly_stopping_rounds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1500\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[0mverbose_eval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m         \u001b[0mfeval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlgb_amex_metric\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m         )\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\amex\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    247\u001b[0m                                     evaluation_result_list=None))\n\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 249\u001b[1;33m         \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\amex\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   2643\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[0;32m   2644\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2645\u001b[1;33m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[0;32m   2646\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mFalse\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2647\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# 特徴量選定\n",
    "features = [col for col in train.columns if col not in ['customer_ID', CFG.target]]\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': CFG.metric,\n",
    "    'boosting': CFG.boosting_type,\n",
    "    'seed': CFG.seed,\n",
    "    'num_leaves': 100,\n",
    "    'learning_rate': 0.01,\n",
    "    'feature_fraction': 0.20,\n",
    "    'bagging_freq': 10,\n",
    "    'bagging_fraction': 0.50,\n",
    "    'n_jobs': -1,\n",
    "    'lambda_l2': 2,\n",
    "    'min_data_in_leaf': 40,\n",
    "    }\n",
    "\n",
    "# Create a numpy array to store test predictions\n",
    "\n",
    "# test_predictions = np.zeros(len(test))\n",
    "\n",
    "\n",
    "# Create a numpy array to store out of folds predictions\n",
    "oof_predictions = np.zeros(len(train))\n",
    "test_predictions = np.zeros(len(test))\n",
    "\n",
    "kfold = StratifiedKFold(n_splits = CFG.n_folds, shuffle = True, random_state = CFG.seed)\n",
    "for fold, (trn_ind, val_ind) in enumerate(kfold.split(train, train[CFG.target])):\n",
    "    print(' ')\n",
    "    print('-'*50)\n",
    "    print(f'Training fold {fold} with {len(features)} features...')\n",
    "#     x_train, x_val = train.iloc[trn_ind], train.iloc[val_ind]\n",
    "#     y_train, y_val = train[CFG.target].iloc[trn_ind], train[CFG.target].iloc[val_ind]\n",
    "    x_train, x_val = train[features].iloc[trn_ind], train[features].iloc[val_ind]\n",
    "    y_train, y_val = train[CFG.target].iloc[trn_ind], train[CFG.target].iloc[val_ind]\n",
    "    \n",
    "    lgb_train = lgb.Dataset(x_train, y_train)\n",
    "    lgb_valid = lgb.Dataset(x_val, y_val)\n",
    "\n",
    "    lgb_train = lgb.Dataset(x_train, y_train)\n",
    "    lgb_valid = lgb.Dataset(x_val, y_val)\n",
    "    model = lgb.train(\n",
    "        params = params,\n",
    "        train_set = lgb_train,\n",
    "        num_boost_round = 10500,#10500\n",
    "        valid_sets = [lgb_train, lgb_valid],\n",
    "        early_stopping_rounds = 1500,\n",
    "        verbose_eval = 500,\n",
    "        feval = lgb_amex_metric\n",
    "        )\n",
    "    \n",
    "    # Save best model\n",
    "    joblib.dump(model, f'{CFG.output_dir}{CFG.ver}_lgbm_{CFG.boosting_type}_fold{fold}_seed{CFG.seed}.pkl')\n",
    "    # Predict validation\n",
    "    val_pred = model.predict(x_val)\n",
    "    # Add to out of folds array\n",
    "    oof_predictions[val_ind] = val_pred\n",
    "    \n",
    "    # Predict the test set\n",
    "    test_pred = model.predict(test[features])\n",
    "    test_predictions += test_pred / CFG.n_folds\n",
    "    \n",
    "    # Compute fold metric\n",
    "    score = amex_metric(y_val, val_pred)\n",
    "    print(f'Our fold {fold} CV score is {score}')\n",
    "    del x_train, x_val, y_train, y_val, lgb_train, lgb_valid\n",
    "    gc.collect()\n",
    "\n",
    "# Compute out of folds metric\n",
    "score = amex_metric(train[CFG.target], oof_predictions)\n",
    "print(f'Our out of folds CV score is {score}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6031c978-6891-4d21-bf7f-86076fba5580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>customer_ID_hex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
       "      <td>-4.532153e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>00000fd6641609c6ece5454664794f0340ad84dddce9a2...</td>\n",
       "      <td>-6.696653e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>00001b22f846c82c51f6e3958ccd81970162bae8b007e8...</td>\n",
       "      <td>7.128960e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>000041bdba6ecadd89a52d11886e8eaaec9325906c9723...</td>\n",
       "      <td>6.537921e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>00007889e4fcd2614b6cbe7f8f3d2e5c728eca32d9eb8a...</td>\n",
       "      <td>2.065104e+18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          customer_ID  customer_ID_hex\n",
       "0   0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...    -4.532153e+18\n",
       "13  00000fd6641609c6ece5454664794f0340ad84dddce9a2...    -6.696653e+18\n",
       "26  00001b22f846c82c51f6e3958ccd81970162bae8b007e8...     7.128960e+18\n",
       "39  000041bdba6ecadd89a52d11886e8eaaec9325906c9723...     6.537921e+18\n",
       "52  00007889e4fcd2614b6cbe7f8f3d2e5c728eca32d9eb8a...     2.065104e+18"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_ID = pd.read_parquet( '../feature/costomerID_list/train_costomerID_list.parquet').drop_duplicates()\n",
    "test_ID = pd.read_parquet( '../feature/costomerID_list/test_costomerID_list.parquet').drop_duplicates()\n",
    "\n",
    "train_ID.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3790a9b-7753-4695-8dd5-26933dd6be0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID_x</th>\n",
       "      <th>prediction</th>\n",
       "      <th>customer_ID_y</th>\n",
       "      <th>customer_ID_hex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-9.223277e+18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-9.223220e+18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-9.223219e+18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-9.223203e+18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-9.223190e+18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_ID_x  prediction customer_ID_y  customer_ID_hex\n",
       "0  -9.223277e+18         0.0           NaN              NaN\n",
       "1  -9.223220e+18         0.0           NaN              NaN\n",
       "2  -9.223219e+18         0.0           NaN              NaN\n",
       "3  -9.223203e+18         0.0           NaN              NaN\n",
       "4  -9.223190e+18         0.0           NaN              NaN"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Create a dataframe to store out of folds predictions\n",
    "oof_df = pd.DataFrame({'customer_ID': train['customer_ID'], 'target': train[CFG.target], 'prediction': oof_predictions})\n",
    "oof_df = oof_df.merge(train_ID , how = \"left\" ,right_on = \"customer_ID_hex\",left_on = \"customer_ID\").drop([\"customer_ID_x\",\"customer_ID_hex\"],axis = 1).rename(columns = {\"customer_ID_y\":\"customer_ID\"})\n",
    "# oof_df.to_csv(f'{CFG.output_dir}oof_{CFG.ver}_lgb_{CFG.boosting_type}_baseline_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)\n",
    "oof_df.reindex(columns=['customer_ID', 'target', 'prediction']).to_csv(f'{CFG.output_dir}oof_{CFG.ver}_lgb_{CFG.boosting_type}_baseline_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)\n",
    "\n",
    "# # Create a dataframe to store test prediction\n",
    "test_df = pd.DataFrame({'customer_ID': test.index, 'prediction': test_predictions})\n",
    "test_df.to_csv(f'{CFG.output_dir}test_lgb_{CFG.boosting_type}_baseline_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)\n",
    "test_df = test_df.merge(test_ID , how = \"left\" ,right_on = \"customer_ID_hex\",left_on = \"customer_ID\")\n",
    "test_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d544f156-f611-43e9-9a6c-1fa166c796ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180a7260-f2eb-4772-ad56-ef10113a85de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amex",
   "language": "python",
   "name": "amex"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
