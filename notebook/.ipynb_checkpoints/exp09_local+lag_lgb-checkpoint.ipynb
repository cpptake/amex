{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70f58d85-14e4-4371-ad96-458843ea228c",
   "metadata": {},
   "source": [
    "# exp09\n",
    "下記のNotebookにLag特徴量を追加\n",
    "* https://www.kaggle.com/code/ragnar123/amex-lgbm-dart-cv-0-7977\n",
    "* https://www.kaggle.com/code/takeshikobayashi/lag-features-are-all-you-need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "325051a6-7ea3-4398-b022-6a81c18b14eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Library\n",
    "# ====================================================\n",
    "import os\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "from tqdm.auto import tqdm\n",
    "import itertools\n",
    "\n",
    "import joblib\n",
    "import random\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "from itertools import combinations\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import snappy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from pytorch_tabnet.pretraining import TabNetPretrainer\n",
    "\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "\n",
    "import torch\n",
    "from pytorch_tabnet.metrics import Metric\n",
    "# from ipywidgets import interact, Select\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ec2aebe-e3be-4eb2-8afc-b969d1f246ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aa = pd.read_csv('../output/exp09_1800feature_lgb/oof_09_lgb_0.7470325254077378_5fold_seed46.csv')\n",
    "# aa['tabnet_oot'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ba22c4-5d3d-46b0-b0c3-8346fda6fa35",
   "metadata": {},
   "source": [
    "# 元特徴量とLag特徴量を結合\n",
    "（最初だけ）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88641f6d-d8f5-4f12-823e-04974e41c0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 元データを結合するときのみ使用\n",
    "\n",
    "# train = pd.read_parquet(\"../feature/exp03_amex-fe/train_fe_plus_plus.parquet\")\n",
    "# test = pd.read_parquet(\"../feature/exp03_amex-fe/test_fe_plus_plus.parquet\")\n",
    "\n",
    "# train_lag = pd.read_parquet(\"../feature/exp01_lag_feature/train_lag_feature.parquet\")\n",
    "# test_lag = pd.read_parquet(\"../feature/exp01_lag_feature/test_lag_feature.parquet\")\n",
    "\n",
    "# train = train.merge(train_lag,on = \"customer_ID\",how = \"left\")\n",
    "# test = test.merge(test_lag,on = \"customer_ID\",how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa44aa74-c4b3-46b7-bb6b-5749b3f945ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train = pd.read_parquet(\"../feature/exp09_1800feature/train_1800.parquet\")\n",
    "test = pd.read_parquet(\"../feature/exp09_1800feature/test_1800.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d2d3532-6e5a-4bdf-8da0-de9be8e8c348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_feature = train.columns.to_list()\n",
    "\n",
    "# num_features0 = [col for col in train_feature if \"last_lag_sub\" in col]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e80847-25f2-4784-97c5-b8012eae1a3e",
   "metadata": {},
   "source": [
    "# Training & Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3638c92e-7e65-43e5-8a69-e2aef6660f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ====================================================\n",
    "# Configurations\n",
    "# ====================================================\n",
    "class CFG:\n",
    "    input_dir = '../input/amex-fe/'\n",
    "    output_dir = '../output/exp09_1800feature_lgb/'\n",
    "    seed = 46\n",
    "    n_folds = 5\n",
    "    target = 'target'\n",
    "    boosting_type = 'dart'\n",
    "    metric = 'binary_logloss'\n",
    "    model = \"lgb\"\n",
    "    ver = \"09\"\n",
    "\n",
    "# ====================================================\n",
    "# Seed everything\n",
    "# ====================================================\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "# ====================================================\n",
    "# Read data\n",
    "# ====================================================\n",
    "def read_data():\n",
    "    train = pd.read_parquet(CFG.input_dir + 'train_fe.parquet')\n",
    "    test = pd.read_parquet(CFG.input_dir + 'test_fe.parquet')\n",
    "    return train, test\n",
    "\n",
    "# ====================================================\n",
    "# XGB train\n",
    "# ====================================================\n",
    "\n",
    "def lgb_amex_metric(y_pred, y_true):\n",
    "    y_true = y_true.get_label()\n",
    "    return 'amex_metric', amex_metric(y_true, y_pred), True\n",
    "\n",
    "def cat_train(x, y, xt, yt,cat_features):\n",
    "    print(\"# of features:\", x.shape[1])\n",
    "    assert x.shape[1] == xt.shape[1]\n",
    "    \n",
    "    prams = {\n",
    "        'depth': 8,\n",
    "        'iterations':5000,\n",
    "#         'learning_rate': 0.05,\n",
    "        'random_state':CFG.seed,\n",
    "    }\n",
    "\n",
    "#     watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "    watchlist = [(x, 'train'), (xt, 'eval')]\n",
    "    clf = CatBoostClassifier(**prams)# 5000\n",
    "    clf.fit(x, y, eval_set=[(xt, yt)], cat_features=cat_features,plot=True, verbose_eval = 100)\n",
    "#     print('best ntree_limit:', clf.best_ntree_limit)\n",
    "#     print('best score:', clf.best_score)\n",
    "    # return clf.predict_proba(xt)[:, 1]\n",
    "    return clf.predict_proba(xt)[:, 1], clf\n",
    "\n",
    "def tabnet_train(x, y, xt, yt,cat_features):\n",
    "    print(\"# of features:\", x.shape[1])\n",
    "    assert x.shape[1] == xt.shape[1]\n",
    "    \n",
    "    prams = {\n",
    "        'depth': 8,\n",
    "        'iterations':5000,\n",
    "#         'learning_rate': 0.05,\n",
    "        'random_state':CFG.seed,\n",
    "    }\n",
    "\n",
    "#     watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "    watchlist = [(x, 'train'), (xt, 'eval')]\n",
    "    clf = CatBoostClassifier(**prams)# 5000\n",
    "    clf.fit(x, y, eval_set=[(xt, yt)], cat_features=cat_features,plot=True, verbose_eval = 100)\n",
    "#     print('best ntree_limit:', clf.best_ntree_limit)\n",
    "#     print('best score:', clf.best_score)\n",
    "    # return clf.predict_proba(xt)[:, 1]\n",
    "    return clf.predict_proba(xt)[:, 1], clf\n",
    "\n",
    "\n",
    "\n",
    "# using amex metric to evaluate tabnet\n",
    "class Amex_tabnet(Metric):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self._name = 'amex_tabnet'\n",
    "        self._maximize = True\n",
    "\n",
    "    def __call__(self, y_true, y_pred):\n",
    "        amex = amex_metric_numpy(y_true, y_pred[:, 1])\n",
    "        return max(amex, 0.)\n",
    "\n",
    "# ====================================================\n",
    "# Amex metric\n",
    "# ====================================================\n",
    "def amex_metric(y_true, y_pred):\n",
    "    labels = np.transpose(np.array([y_true, y_pred]))\n",
    "    labels = labels[labels[:, 1].argsort()[::-1]]\n",
    "    weights = np.where(labels[:,0]==0, 20, 1)\n",
    "    cut_vals = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n",
    "    top_four = np.sum(cut_vals[:,0]) / np.sum(labels[:,0])\n",
    "    gini = [0,0]\n",
    "    for i in [1,0]:\n",
    "        labels = np.transpose(np.array([y_true, y_pred]))\n",
    "        labels = labels[labels[:, i].argsort()[::-1]]\n",
    "        weight = np.where(labels[:,0]==0, 20, 1)\n",
    "        weight_random = np.cumsum(weight / np.sum(weight))\n",
    "        total_pos = np.sum(labels[:, 0] *  weight)\n",
    "        cum_pos_found = np.cumsum(labels[:, 0] * weight)\n",
    "        lorentz = cum_pos_found / total_pos\n",
    "        gini[i] = np.sum((lorentz - weight_random) * weight)\n",
    "    return 0.5 * (gini[1]/gini[0] + top_four)\n",
    "\n",
    "\n",
    "def xgb_amex(y_pred, y_true):\n",
    "    return 'amex', amex_metric_np(y_pred,y_true.get_label())\n",
    "\n",
    "\n",
    "# Created by https://www.kaggle.com/yunchonggan\n",
    "# https://www.kaggle.com/competitions/amex-default-prediction/discussion/328020\n",
    "def amex_metric_np(preds: np.ndarray, target: np.ndarray) -> float:\n",
    "    indices = np.argsort(preds)[::-1]\n",
    "    preds, target = preds[indices], target[indices]\n",
    "\n",
    "    weight = 20.0 - target * 19.0\n",
    "    cum_norm_weight = (weight / weight.sum()).cumsum()\n",
    "    four_pct_mask = cum_norm_weight <= 0.04\n",
    "    d = np.sum(target[four_pct_mask]) / np.sum(target)\n",
    "\n",
    "    weighted_target = target * weight\n",
    "    lorentz = (weighted_target / weighted_target.sum()).cumsum()\n",
    "    gini = ((lorentz - cum_norm_weight) * weight).sum()\n",
    "\n",
    "    n_pos = np.sum(target)\n",
    "    n_neg = target.shape[0] - n_pos\n",
    "    gini_max = 10 * n_neg * (n_pos + 20 * n_neg - 19) / (n_pos + 20 * n_neg)\n",
    "\n",
    "    g = gini / gini_max\n",
    "    return 0.5 * (g + d)\n",
    "\n",
    "def amex_metric_numpy(y_true: np.array, y_pred: np.array) -> float:\n",
    "\n",
    "    # count of positives and negatives\n",
    "    n_pos = y_true.sum()\n",
    "    n_neg = y_true.shape[0] - n_pos\n",
    "\n",
    "    # sorting by descring prediction values\n",
    "    indices = np.argsort(y_pred)[::-1]\n",
    "    preds, target = y_pred[indices], y_true[indices]\n",
    "\n",
    "    # filter the top 4% by cumulative row weights\n",
    "    weight = 20.0 - target * 19.0\n",
    "    cum_norm_weight = (weight / weight.sum()).cumsum()\n",
    "    four_pct_filter = cum_norm_weight <= 0.04\n",
    "\n",
    "    # default rate captured at 4%\n",
    "    d = target[four_pct_filter].sum() / n_pos\n",
    "\n",
    "    # weighted gini coefficient\n",
    "    lorentz = (target / n_pos).cumsum()\n",
    "    gini = ((lorentz - cum_norm_weight) * weight).sum()\n",
    "\n",
    "    # max weighted gini coefficient\n",
    "    gini_max = 10 * n_neg * (1 - 19 / (n_pos + 20 * n_neg))\n",
    "\n",
    "    # normalized weighted gini coefficient\n",
    "    g = gini / gini_max\n",
    "\n",
    "    return 0.5 * (g + d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30007ce2-4854-4fd8-8c1b-477936511e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(CFG.seed)\n",
    "# train, test = read_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "220db67f-9a57-436b-9ec6-8732c6c6fe67",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8284\\649604299.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;31m# Get feature list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'customer_ID'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCFG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m params = {\n\u001b[0;32m     45\u001b[0m     \u001b[1;34m'objective'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'binary'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# cat_features = [\n",
    "#     \"B_30\",\n",
    "#     \"B_38\",\n",
    "#     \"D_114\",\n",
    "#     \"D_116\",\n",
    "#     \"D_117\",\n",
    "#     \"D_120\",\n",
    "#     \"D_126\",\n",
    "#     \"D_63\",\n",
    "#     \"D_64\",\n",
    "#     \"D_66\",\n",
    "#     \"D_68\"\n",
    "# ]\n",
    "\n",
    "# cat_features = [f\"{cf}_last\" for cf in cat_features]\n",
    "# for cat_col in cat_features:\n",
    "#     encoder = LabelEncoder()\n",
    "#     train[cat_col] = encoder.fit_transform(train[cat_col])\n",
    "#     test[cat_col] = encoder.transform(test[cat_col])\n",
    "# # Round last float features to 2 decimal place\n",
    "# num_cols = list(train.dtypes[(train.dtypes == 'float32') | (train.dtypes == 'float64')].index)\n",
    "# num_cols = [col for col in num_cols if 'last' in col]\n",
    "# for col in num_cols:\n",
    "#     train[col + '_round2'] = train[col].round(2)\n",
    "#     test[col + '_round2'] = test[col].round(2)\n",
    "# # Get the difference between last and mean\n",
    "# num_cols = [col for col in train.columns if 'last' in col]\n",
    "# num_cols = [col[:-5] for col in num_cols if 'round' not in col]\n",
    "# for col in num_cols:\n",
    "#     try:\n",
    "#         train[f'{col}_last_mean_diff'] = train[f'{col}_last'] - train[f'{col}_mean']\n",
    "#         test[f'{col}_last_mean_diff'] = test[f'{col}_last'] - test[f'{col}_mean']\n",
    "#     except:\n",
    "#         pass\n",
    "# # Transform float64 and float32 to float16\n",
    "# num_cols = list(train.dtypes[(train.dtypes == 'float32') | (train.dtypes == 'float64')].index)\n",
    "# for col in tqdm(num_cols):\n",
    "#     train[col] = train[col].astype(np.float16)\n",
    "#     test[col] = test[col].astype(np.float16)\n",
    "\n",
    "\n",
    "# Get feature list\n",
    "features = [col for col in train.columns if col not in ['customer_ID', CFG.target]]\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': CFG.metric,\n",
    "    'boosting': CFG.boosting_type,\n",
    "    'seed': CFG.seed,\n",
    "    'num_leaves': 100,\n",
    "    'learning_rate': 0.01,\n",
    "    'feature_fraction': 0.20,\n",
    "    'bagging_freq': 10,\n",
    "    'bagging_fraction': 0.50,\n",
    "    'n_jobs': -1,\n",
    "    'lambda_l2': 2,\n",
    "    'min_data_in_leaf': 40,\n",
    "    }\n",
    "\n",
    "\n",
    "# Get feature list\n",
    "features = [col for col in train.columns if col not in ['customer_ID', CFG.target]]\n",
    "# all_data = features.extend(\"customer_ID\")\n",
    "\n",
    "\n",
    "train.fillna(value=0, inplace=True)\n",
    "test.fillna(value=0, inplace=True)\n",
    "\n",
    "# Create a numpy array to store test predictions\n",
    "test_predictions = np.zeros(len(test))\n",
    "# Create a numpy array to store out of folds predictions\n",
    "oof_predictions = np.zeros(len(train))\n",
    "\n",
    "preds = []\n",
    "cid = []\n",
    "cids = []\n",
    "\n",
    "kfold = StratifiedKFold(n_splits = CFG.n_folds, shuffle = True, random_state = CFG.seed)\n",
    "for fold, (trn_ind, val_ind) in enumerate(kfold.split(train, train[CFG.target])):\n",
    "    print(' ')\n",
    "    print('-'*50)\n",
    "    print(f'Training fold {fold} with {len(features)} features...')\n",
    "    \n",
    "    x_train, x_val = train[features].iloc[trn_ind], train[features].iloc[val_ind]\n",
    "    y_train, y_val = train[CFG.target].iloc[trn_ind], train[CFG.target].iloc[val_ind]\n",
    "    \n",
    "    cid = train[\"customer_ID\"].loc[val_ind]\n",
    "    cids.extend(cid)\n",
    "#     lgb_train = lgb.Dataset(x_train, y_train, categorical_feature = cat_features)\n",
    "#     lgb_valid = lgb.Dataset(x_val, y_val, categorical_feature = cat_features)\n",
    "    \n",
    "    lgb_train = lgb.Dataset(x_train, y_train)\n",
    "    lgb_valid = lgb.Dataset(x_val, y_val)\n",
    "    \n",
    "    model = lgb.train(\n",
    "        params = params,\n",
    "        train_set = lgb_train,\n",
    "        num_boost_round = 10500,#10500\n",
    "        valid_sets = [lgb_train, lgb_valid],\n",
    "        early_stopping_rounds = 1500,\n",
    "        verbose_eval = 500,\n",
    "        feval = lgb_amex_metric\n",
    "        )\n",
    "    \n",
    "    joblib.dump(model, f'{CFG.output_dir}{CFG.model}_{CFG.boosting_type}_fold{fold}_seed{CFG.seed}.pkl')\n",
    "    \n",
    "    val_pred = model.predict(x_val)\n",
    "    oof_predictions[val_ind] = val_pred\n",
    "    \n",
    "    test_pred = model.predict(test[features])\n",
    "    test_predictions += test_pred / CFG.n_folds\n",
    "    \n",
    "    \n",
    "    score = amex_metric(y_val, val_pred)\n",
    "    print(f'Our fold {fold} CV score is {score}')\n",
    "    del x_train, x_val, y_train, y_val, lgb_train, lgb_valid\n",
    "    gc.collect()\n",
    "    \n",
    "\n",
    "# Compute out of folds metric\n",
    "score = amex_metric(train[CFG.target], oof_predictions)\n",
    "print(f'Our out of folds CV score is {score}')\n",
    "# test_predictions = np.mean(preds,axis = 0)\n",
    "\n",
    "dic_oof = {\n",
    "    \"customer_ID\":cids,\n",
    "    \"target\":train[CFG.target],\n",
    "    \"tabnet_oot\":oof_predictions\n",
    "}\n",
    "\n",
    "# Create a dataframe to store out of folds predictions\n",
    "oof_df = pd.DataFrame(dic_oof)\n",
    "# oof_df = pd.DataFrame({'customer_ID': train['customer_ID'], 'target': train[CFG.target], 'prediction': oof_predictions})\n",
    "oof_df.to_csv(f'{CFG.output_dir}oof_{CFG.ver}_{CFG.model}_{score}_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)\n",
    "\n",
    "\n",
    "# Create a dataframe to store test prediction\n",
    "test_df = pd.DataFrame({'customer_ID': test['customer_ID'], 'prediction': test_predictions})\n",
    "test_df.to_csv(f'{CFG.output_dir}test_{CFG.ver}_{CFG.model}_{score}_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5fef6a-6518-423b-ab1d-96d2ee978b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# oof_df.to_csv(f'{CFG.output_dir}oof_{CFG.ver}_{CFG.model}_{score}_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)\n",
    "\n",
    "\n",
    "# # Create a dataframe to store test prediction\n",
    "# test_df = pd.DataFrame({'customer_ID': test['customer_ID'], 'prediction': test_predictions})\n",
    "# test_df.to_csv(f'{CFG.output_dir}test_{CFG.ver}_{CFG.model}_{score}_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbe6d3d-d2c6-4ccc-b311-427a353e431f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa7d701-5131-44ec-bfff-7028c5aa5d99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amex",
   "language": "python",
   "name": "amex"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
