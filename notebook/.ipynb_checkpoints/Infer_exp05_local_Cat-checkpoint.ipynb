{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70f58d85-14e4-4371-ad96-458843ea228c",
   "metadata": {},
   "source": [
    "# exp04\n",
    "\n",
    "exp03 catboostç‰ˆ\n",
    "\n",
    "https://www.kaggle.com/code/ragnar123/amex-lgbm-dart-cv-0-7977"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "325051a6-7ea3-4398-b022-6a81c18b14eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Library\n",
    "# ====================================================\n",
    "import os\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "from tqdm.auto import tqdm\n",
    "import itertools\n",
    "\n",
    "import joblib\n",
    "import random\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "from itertools import combinations\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import snappy\n",
    "# from ipywidgets import interact, Select\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "907983c6-16ce-4155-8267-9beedb6ed221",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/data/train.parquet'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13788\\217815574.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;31m# Read & Preprocess Data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m \u001b[0mread_preprocess_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13788\\217815574.py\u001b[0m in \u001b[0;36mread_preprocess_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;31m# ====================================================\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mread_preprocess_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/data/train.parquet'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m     \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'customer_ID'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'S_2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     cat_features = [\n",
      "\u001b[1;32m~\\anaconda3\\envs\\amex\\lib\\site-packages\\pandas\\io\\parquet.py\u001b[0m in \u001b[0;36mread_parquet\u001b[1;34m(path, engine, columns, storage_options, use_nullable_dtypes, **kwargs)\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    499\u001b[0m         \u001b[0muse_nullable_dtypes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_nullable_dtypes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 500\u001b[1;33m         \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    501\u001b[0m     )\n",
      "\u001b[1;32m~\\anaconda3\\envs\\amex\\lib\\site-packages\\pandas\\io\\parquet.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, path, columns, storage_options, **kwargs)\u001b[0m\n\u001b[0;32m    338\u001b[0m             \u001b[1;31m# this branch is used for example when reading from non-fsspec URLs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m             handles = get_handle(\n\u001b[1;32m--> 340\u001b[1;33m                 \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    341\u001b[0m             )\n\u001b[0;32m    342\u001b[0m             \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\amex\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    709\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m             \u001b[1;31m# Binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 711\u001b[1;33m             \u001b[0mhandle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    712\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    713\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/data/train.parquet'"
     ]
    }
   ],
   "source": [
    "\n",
    "# ====================================================\n",
    "# Get the difference\n",
    "# ====================================================\n",
    "def get_difference(data, num_features):\n",
    "    df1 = []\n",
    "    customer_ids = []\n",
    "    for customer_id, df in tqdm(data.groupby(['customer_ID'])):\n",
    "        # Get the differences\n",
    "        diff_df1 = df[num_features].diff(1).iloc[[-1]].values.astype(np.float32)\n",
    "        # Append to lists\n",
    "        df1.append(diff_df1)\n",
    "        customer_ids.append(customer_id)\n",
    "    # Concatenate\n",
    "    df1 = np.concatenate(df1, axis = 0)\n",
    "    # Transform to dataframe\n",
    "    df1 = pd.DataFrame(df1, columns = [col + '_diff1' for col in df[num_features].columns])\n",
    "    # Add customer id\n",
    "    df1['customer_ID'] = customer_ids\n",
    "    return df1\n",
    "\n",
    "# ====================================================\n",
    "# Read & preprocess data and save it to disk\n",
    "# ====================================================\n",
    "def read_preprocess_data():\n",
    "    train = pd.read_parquet('/content/data/train.parquet')\n",
    "    features = train.drop(['customer_ID', 'S_2'], axis = 1).columns.to_list()\n",
    "    cat_features = [\n",
    "        \"B_30\",\n",
    "        \"B_38\",\n",
    "        \"D_114\",\n",
    "        \"D_116\",\n",
    "        \"D_117\",\n",
    "        \"D_120\",\n",
    "        \"D_126\",\n",
    "        \"D_63\",\n",
    "        \"D_64\",\n",
    "        \"D_66\",\n",
    "        \"D_68\",\n",
    "    ]\n",
    "    num_features = [col for col in features if col not in cat_features]\n",
    "    print('Starting training feature engineer...')\n",
    "    train_num_agg = train.groupby(\"customer_ID\")[num_features].agg(['mean', 'std', 'min', 'max', 'last'])\n",
    "    train_num_agg.columns = ['_'.join(x) for x in train_num_agg.columns]\n",
    "    train_num_agg.reset_index(inplace = True)\n",
    "    train_cat_agg = train.groupby(\"customer_ID\")[cat_features].agg(['count', 'last', 'nunique'])\n",
    "    train_cat_agg.columns = ['_'.join(x) for x in train_cat_agg.columns]\n",
    "    train_cat_agg.reset_index(inplace = True)\n",
    "    train_labels = pd.read_csv('../input/amex-default-prediction/train_labels.csv')\n",
    "    # Transform float64 columns to float32\n",
    "    cols = list(train_num_agg.dtypes[train_num_agg.dtypes == 'float64'].index)\n",
    "    for col in tqdm(cols):\n",
    "        train_num_agg[col] = train_num_agg[col].astype(np.float32)\n",
    "    # Transform int64 columns to int32\n",
    "    cols = list(train_cat_agg.dtypes[train_cat_agg.dtypes == 'int64'].index)\n",
    "    for col in tqdm(cols):\n",
    "        train_cat_agg[col] = train_cat_agg[col].astype(np.int32)\n",
    "    # Get the difference\n",
    "    train_diff = get_difference(train, num_features)\n",
    "    train = train_num_agg.merge(train_cat_agg, how = 'inner', on = 'customer_ID').merge(train_diff, how = 'inner', on = 'customer_ID').merge(train_labels, how = 'inner', on = 'customer_ID')\n",
    "    del train_num_agg, train_cat_agg, train_diff\n",
    "    gc.collect()\n",
    "    test = pd.read_parquet('../input/amex-fe/test_fe.parquet')\n",
    "    print('Starting test feature engineer...')\n",
    "    test_num_agg = test.groupby(\"customer_ID\")[num_features].agg(['mean', 'std', 'min', 'max', 'last'])\n",
    "    test_num_agg.columns = ['_'.join(x) for x in test_num_agg.columns]\n",
    "    test_num_agg.reset_index(inplace = True)\n",
    "    test_cat_agg = test.groupby(\"customer_ID\")[cat_features].agg(['count', 'last', 'nunique'])\n",
    "    test_cat_agg.columns = ['_'.join(x) for x in test_cat_agg.columns]\n",
    "    test_cat_agg.reset_index(inplace = True)\n",
    "    # Transform float64 columns to float32\n",
    "    cols = list(test_num_agg.dtypes[test_num_agg.dtypes == 'float64'].index)\n",
    "    for col in tqdm(cols):\n",
    "        test_num_agg[col] = test_num_agg[col].astype(np.float32)\n",
    "    # Transform int64 columns to int32\n",
    "    cols = list(test_cat_agg.dtypes[test_cat_agg.dtypes == 'int64'].index)\n",
    "    for col in tqdm(cols):\n",
    "        test_cat_agg[col] = test_cat_agg[col].astype(np.int32)\n",
    "    # Get the difference\n",
    "    test_diff = get_difference(test, num_features)\n",
    "    test = test_num_agg.merge(test_cat_agg, how = 'inner', on = 'customer_ID').merge(test_diff, how = 'inner', on = 'customer_ID')\n",
    "    del test_num_agg, test_cat_agg, test_diff\n",
    "    gc.collect()\n",
    "    # Save files to disk\n",
    "    train.to_parquet('../input/amex-fe/train_fe.parquet')\n",
    "    test.to_parquet('../input/amex-fe/test_fe.parquet')\n",
    "\n",
    "# Read & Preprocess Data\n",
    "read_preprocess_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c482ae9b-9b5a-4268-abc9-bcca19042be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    input_dir = '../input/amex-fe/'\n",
    "    seed = 45\n",
    "    n_folds = 5\n",
    "    target = 'target'\n",
    "    boosting_type = 'dart'\n",
    "    metric = 'binary_logloss'\n",
    "    model = \"cat\"\n",
    "\n",
    "# ====================================================\n",
    "# Seed everything\n",
    "# ====================================================\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "# ====================================================\n",
    "# Read data\n",
    "# ====================================================\n",
    "def read_data():\n",
    "    train = pd.read_parquet(CFG.input_dir + 'train_fe.parquet')\n",
    "    test = pd.read_parquet(CFG.input_dir + 'test_fe.parquet')\n",
    "    return train, test\n",
    "\n",
    "# ====================================================\n",
    "# XGB train\n",
    "# ====================================================\n",
    "\n",
    "def cat_train(x, y, xt, yt,cat_features):\n",
    "    print(\"# of features:\", x.shape[1])\n",
    "    assert x.shape[1] == xt.shape[1]\n",
    "#     dtrain = xgb.DMatrix(data=x, label=y)\n",
    "#     dvalid = xgb.DMatrix(data=xt, label=yt)\n",
    "\n",
    "#     watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "    watchlist = [(x, 'train'), (xt, 'eval')]\n",
    "    clf = CatBoostClassifier(iterations=10 , random_state=CFG.seed)# 5000\n",
    "    clf.fit(x, y, eval_set=[(xt, yt)], cat_features=cat_features,plot=True,verbose_eval=100)\n",
    "#     print('best ntree_limit:', clf.best_ntree_limit)\n",
    "#     print('best score:', clf.best_score)\n",
    "    # return clf.predict_proba(xt)[:, 1]\n",
    "    return clf.predict_proba(xt)[:, 1], clf\n",
    "\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# Amex metric\n",
    "# ====================================================\n",
    "def amex_metric(y_true, y_pred):\n",
    "    labels = np.transpose(np.array([y_true, y_pred]))\n",
    "    labels = labels[labels[:, 1].argsort()[::-1]]\n",
    "    weights = np.where(labels[:,0]==0, 20, 1)\n",
    "    cut_vals = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n",
    "    top_four = np.sum(cut_vals[:,0]) / np.sum(labels[:,0])\n",
    "    gini = [0,0]\n",
    "    for i in [1,0]:\n",
    "        labels = np.transpose(np.array([y_true, y_pred]))\n",
    "        labels = labels[labels[:, i].argsort()[::-1]]\n",
    "        weight = np.where(labels[:,0]==0, 20, 1)\n",
    "        weight_random = np.cumsum(weight / np.sum(weight))\n",
    "        total_pos = np.sum(labels[:, 0] *  weight)\n",
    "        cum_pos_found = np.cumsum(labels[:, 0] * weight)\n",
    "        lorentz = cum_pos_found / total_pos\n",
    "        gini[i] = np.sum((lorentz - weight_random) * weight)\n",
    "    return 0.5 * (gini[1]/gini[0] + top_four)\n",
    "\n",
    "\n",
    "def xgb_amex(y_pred, y_true):\n",
    "    return 'amex', amex_metric_np(y_pred,y_true.get_label())\n",
    "\n",
    "\n",
    "# Created by https://www.kaggle.com/yunchonggan\n",
    "# https://www.kaggle.com/competitions/amex-default-prediction/discussion/328020\n",
    "def amex_metric_np(preds: np.ndarray, target: np.ndarray) -> float:\n",
    "    indices = np.argsort(preds)[::-1]\n",
    "    preds, target = preds[indices], target[indices]\n",
    "\n",
    "    weight = 20.0 - target * 19.0\n",
    "    cum_norm_weight = (weight / weight.sum()).cumsum()\n",
    "    four_pct_mask = cum_norm_weight <= 0.04\n",
    "    d = np.sum(target[four_pct_mask]) / np.sum(target)\n",
    "\n",
    "    weighted_target = target * weight\n",
    "    lorentz = (weighted_target / weighted_target.sum()).cumsum()\n",
    "    gini = ((lorentz - cum_norm_weight) * weight).sum()\n",
    "\n",
    "    n_pos = np.sum(target)\n",
    "    n_neg = target.shape[0] - n_pos\n",
    "    gini_max = 10 * n_neg * (n_pos + 20 * n_neg - 19) / (n_pos + 20 * n_neg)\n",
    "\n",
    "    g = gini / gini_max\n",
    "    return 0.5 * (g + d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7aa5b89c-a89c-43a2-a3b8-c0f4a5615df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(CFG.seed)\n",
    "train, test = read_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af590631-19ab-4e71-b90e-c8a15b456271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>P_2_mean</th>\n",
       "      <th>P_2_std</th>\n",
       "      <th>P_2_min</th>\n",
       "      <th>P_2_max</th>\n",
       "      <th>P_2_last</th>\n",
       "      <th>D_39_mean</th>\n",
       "      <th>D_39_std</th>\n",
       "      <th>D_39_min</th>\n",
       "      <th>D_39_max</th>\n",
       "      <th>D_39_last</th>\n",
       "      <th>B_1_mean</th>\n",
       "      <th>B_1_std</th>\n",
       "      <th>B_1_min</th>\n",
       "      <th>B_1_max</th>\n",
       "      <th>B_1_last</th>\n",
       "      <th>B_2_mean</th>\n",
       "      <th>B_2_std</th>\n",
       "      <th>B_2_min</th>\n",
       "      <th>B_2_max</th>\n",
       "      <th>B_2_last</th>\n",
       "      <th>R_1_mean</th>\n",
       "      <th>R_1_std</th>\n",
       "      <th>R_1_min</th>\n",
       "      <th>R_1_max</th>\n",
       "      <th>R_1_last</th>\n",
       "      <th>S_3_mean</th>\n",
       "      <th>S_3_std</th>\n",
       "      <th>S_3_min</th>\n",
       "      <th>S_3_max</th>\n",
       "      <th>S_3_last</th>\n",
       "      <th>D_41_mean</th>\n",
       "      <th>D_41_std</th>\n",
       "      <th>D_41_min</th>\n",
       "      <th>D_41_max</th>\n",
       "      <th>D_41_last</th>\n",
       "      <th>B_3_mean</th>\n",
       "      <th>B_3_std</th>\n",
       "      <th>B_3_min</th>\n",
       "      <th>B_3_max</th>\n",
       "      <th>B_3_last</th>\n",
       "      <th>D_42_mean</th>\n",
       "      <th>D_42_std</th>\n",
       "      <th>D_42_min</th>\n",
       "      <th>D_42_max</th>\n",
       "      <th>D_42_last</th>\n",
       "      <th>D_43_mean</th>\n",
       "      <th>D_43_std</th>\n",
       "      <th>D_43_min</th>\n",
       "      <th>D_43_max</th>\n",
       "      <th>D_43_last</th>\n",
       "      <th>D_44_mean</th>\n",
       "      <th>D_44_std</th>\n",
       "      <th>D_44_min</th>\n",
       "      <th>D_44_max</th>\n",
       "      <th>D_44_last</th>\n",
       "      <th>B_4_mean</th>\n",
       "      <th>B_4_std</th>\n",
       "      <th>B_4_min</th>\n",
       "      <th>B_4_max</th>\n",
       "      <th>B_4_last</th>\n",
       "      <th>D_45_mean</th>\n",
       "      <th>D_45_std</th>\n",
       "      <th>D_45_min</th>\n",
       "      <th>D_45_max</th>\n",
       "      <th>D_45_last</th>\n",
       "      <th>B_5_mean</th>\n",
       "      <th>B_5_std</th>\n",
       "      <th>B_5_min</th>\n",
       "      <th>B_5_max</th>\n",
       "      <th>B_5_last</th>\n",
       "      <th>R_2_mean</th>\n",
       "      <th>R_2_std</th>\n",
       "      <th>R_2_min</th>\n",
       "      <th>R_2_max</th>\n",
       "      <th>R_2_last</th>\n",
       "      <th>D_46_mean</th>\n",
       "      <th>D_46_std</th>\n",
       "      <th>D_46_min</th>\n",
       "      <th>D_46_max</th>\n",
       "      <th>D_46_last</th>\n",
       "      <th>D_47_mean</th>\n",
       "      <th>D_47_std</th>\n",
       "      <th>D_47_min</th>\n",
       "      <th>D_47_max</th>\n",
       "      <th>D_47_last</th>\n",
       "      <th>D_48_mean</th>\n",
       "      <th>D_48_std</th>\n",
       "      <th>D_48_min</th>\n",
       "      <th>D_48_max</th>\n",
       "      <th>D_48_last</th>\n",
       "      <th>D_49_mean</th>\n",
       "      <th>D_49_std</th>\n",
       "      <th>D_49_min</th>\n",
       "      <th>D_49_max</th>\n",
       "      <th>D_49_last</th>\n",
       "      <th>B_6_mean</th>\n",
       "      <th>B_6_std</th>\n",
       "      <th>B_6_min</th>\n",
       "      <th>B_6_max</th>\n",
       "      <th>B_6_last</th>\n",
       "      <th>B_7_mean</th>\n",
       "      <th>B_7_std</th>\n",
       "      <th>B_7_min</th>\n",
       "      <th>B_7_max</th>\n",
       "      <th>B_7_last</th>\n",
       "      <th>B_8_mean</th>\n",
       "      <th>B_8_std</th>\n",
       "      <th>B_8_min</th>\n",
       "      <th>B_8_max</th>\n",
       "      <th>B_8_last</th>\n",
       "      <th>D_50_mean</th>\n",
       "      <th>D_50_std</th>\n",
       "      <th>D_50_min</th>\n",
       "      <th>D_50_max</th>\n",
       "      <th>D_50_last</th>\n",
       "      <th>D_51_mean</th>\n",
       "      <th>D_51_std</th>\n",
       "      <th>D_51_min</th>\n",
       "      <th>D_51_max</th>\n",
       "      <th>D_51_last</th>\n",
       "      <th>B_9_mean</th>\n",
       "      <th>B_9_std</th>\n",
       "      <th>B_9_min</th>\n",
       "      <th>B_9_max</th>\n",
       "      <th>B_9_last</th>\n",
       "      <th>R_3_mean</th>\n",
       "      <th>R_3_std</th>\n",
       "      <th>R_3_min</th>\n",
       "      <th>R_3_max</th>\n",
       "      <th>R_3_last</th>\n",
       "      <th>D_52_mean</th>\n",
       "      <th>D_52_std</th>\n",
       "      <th>D_52_min</th>\n",
       "      <th>D_52_max</th>\n",
       "      <th>D_52_last</th>\n",
       "      <th>P_3_mean</th>\n",
       "      <th>P_3_std</th>\n",
       "      <th>P_3_min</th>\n",
       "      <th>P_3_max</th>\n",
       "      <th>P_3_last</th>\n",
       "      <th>B_10_mean</th>\n",
       "      <th>B_10_std</th>\n",
       "      <th>B_10_min</th>\n",
       "      <th>B_10_max</th>\n",
       "      <th>B_10_last</th>\n",
       "      <th>D_53_mean</th>\n",
       "      <th>D_53_std</th>\n",
       "      <th>D_53_min</th>\n",
       "      <th>D_53_max</th>\n",
       "      <th>D_53_last</th>\n",
       "      <th>S_5_mean</th>\n",
       "      <th>S_5_std</th>\n",
       "      <th>S_5_min</th>\n",
       "      <th>S_5_max</th>\n",
       "      <th>S_5_last</th>\n",
       "      <th>B_11_mean</th>\n",
       "      <th>B_11_std</th>\n",
       "      <th>B_11_min</th>\n",
       "      <th>B_11_max</th>\n",
       "      <th>B_11_last</th>\n",
       "      <th>S_6_mean</th>\n",
       "      <th>S_6_std</th>\n",
       "      <th>S_6_min</th>\n",
       "      <th>S_6_max</th>\n",
       "      <th>S_6_last</th>\n",
       "      <th>D_54_mean</th>\n",
       "      <th>D_54_std</th>\n",
       "      <th>D_54_min</th>\n",
       "      <th>D_54_max</th>\n",
       "      <th>D_54_last</th>\n",
       "      <th>R_4_mean</th>\n",
       "      <th>R_4_std</th>\n",
       "      <th>R_4_min</th>\n",
       "      <th>R_4_max</th>\n",
       "      <th>R_4_last</th>\n",
       "      <th>S_7_mean</th>\n",
       "      <th>S_7_std</th>\n",
       "      <th>S_7_min</th>\n",
       "      <th>S_7_max</th>\n",
       "      <th>S_7_last</th>\n",
       "      <th>B_12_mean</th>\n",
       "      <th>B_12_std</th>\n",
       "      <th>B_12_min</th>\n",
       "      <th>B_12_max</th>\n",
       "      <th>B_12_last</th>\n",
       "      <th>S_8_mean</th>\n",
       "      <th>S_8_std</th>\n",
       "      <th>S_8_min</th>\n",
       "      <th>S_8_max</th>\n",
       "      <th>S_8_last</th>\n",
       "      <th>D_55_mean</th>\n",
       "      <th>D_55_std</th>\n",
       "      <th>D_55_min</th>\n",
       "      <th>D_55_max</th>\n",
       "      <th>D_55_last</th>\n",
       "      <th>D_56_mean</th>\n",
       "      <th>D_56_std</th>\n",
       "      <th>D_56_min</th>\n",
       "      <th>D_56_max</th>\n",
       "      <th>D_56_last</th>\n",
       "      <th>B_13_mean</th>\n",
       "      <th>B_13_std</th>\n",
       "      <th>B_13_min</th>\n",
       "      <th>B_13_max</th>\n",
       "      <th>B_13_last</th>\n",
       "      <th>R_5_mean</th>\n",
       "      <th>R_5_std</th>\n",
       "      <th>R_5_min</th>\n",
       "      <th>R_5_max</th>\n",
       "      <th>R_5_last</th>\n",
       "      <th>D_58_mean</th>\n",
       "      <th>D_58_std</th>\n",
       "      <th>D_58_min</th>\n",
       "      <th>D_58_max</th>\n",
       "      <th>D_58_last</th>\n",
       "      <th>S_9_mean</th>\n",
       "      <th>S_9_std</th>\n",
       "      <th>S_9_min</th>\n",
       "      <th>S_9_max</th>\n",
       "      <th>S_9_last</th>\n",
       "      <th>B_14_mean</th>\n",
       "      <th>B_14_std</th>\n",
       "      <th>B_14_min</th>\n",
       "      <th>B_14_max</th>\n",
       "      <th>B_14_last</th>\n",
       "      <th>D_59_mean</th>\n",
       "      <th>D_59_std</th>\n",
       "      <th>D_59_min</th>\n",
       "      <th>D_59_max</th>\n",
       "      <th>D_59_last</th>\n",
       "      <th>D_60_mean</th>\n",
       "      <th>D_60_std</th>\n",
       "      <th>D_60_min</th>\n",
       "      <th>D_60_max</th>\n",
       "      <th>D_60_last</th>\n",
       "      <th>D_61_mean</th>\n",
       "      <th>D_61_std</th>\n",
       "      <th>D_61_min</th>\n",
       "      <th>D_61_max</th>\n",
       "      <th>D_61_last</th>\n",
       "      <th>B_15_mean</th>\n",
       "      <th>B_15_std</th>\n",
       "      <th>B_15_min</th>\n",
       "      <th>B_15_max</th>\n",
       "      <th>B_15_last</th>\n",
       "      <th>S_11_mean</th>\n",
       "      <th>S_11_std</th>\n",
       "      <th>S_11_min</th>\n",
       "      <th>S_11_max</th>\n",
       "      <th>...</th>\n",
       "      <th>D_107_max</th>\n",
       "      <th>D_107_last</th>\n",
       "      <th>B_36_mean</th>\n",
       "      <th>B_36_std</th>\n",
       "      <th>B_36_min</th>\n",
       "      <th>B_36_max</th>\n",
       "      <th>B_36_last</th>\n",
       "      <th>B_37_mean</th>\n",
       "      <th>B_37_std</th>\n",
       "      <th>B_37_min</th>\n",
       "      <th>B_37_max</th>\n",
       "      <th>B_37_last</th>\n",
       "      <th>R_26_mean</th>\n",
       "      <th>R_26_std</th>\n",
       "      <th>R_26_min</th>\n",
       "      <th>R_26_max</th>\n",
       "      <th>R_26_last</th>\n",
       "      <th>R_27_mean</th>\n",
       "      <th>R_27_std</th>\n",
       "      <th>R_27_min</th>\n",
       "      <th>R_27_max</th>\n",
       "      <th>R_27_last</th>\n",
       "      <th>D_108_mean</th>\n",
       "      <th>D_108_std</th>\n",
       "      <th>D_108_min</th>\n",
       "      <th>D_108_max</th>\n",
       "      <th>D_108_last</th>\n",
       "      <th>D_109_mean</th>\n",
       "      <th>D_109_std</th>\n",
       "      <th>D_109_min</th>\n",
       "      <th>D_109_max</th>\n",
       "      <th>D_109_last</th>\n",
       "      <th>D_110_mean</th>\n",
       "      <th>D_110_std</th>\n",
       "      <th>D_110_min</th>\n",
       "      <th>D_110_max</th>\n",
       "      <th>D_110_last</th>\n",
       "      <th>D_111_mean</th>\n",
       "      <th>D_111_std</th>\n",
       "      <th>D_111_min</th>\n",
       "      <th>D_111_max</th>\n",
       "      <th>D_111_last</th>\n",
       "      <th>B_39_mean</th>\n",
       "      <th>B_39_std</th>\n",
       "      <th>B_39_min</th>\n",
       "      <th>B_39_max</th>\n",
       "      <th>B_39_last</th>\n",
       "      <th>D_112_mean</th>\n",
       "      <th>D_112_std</th>\n",
       "      <th>D_112_min</th>\n",
       "      <th>D_112_max</th>\n",
       "      <th>D_112_last</th>\n",
       "      <th>B_40_mean</th>\n",
       "      <th>B_40_std</th>\n",
       "      <th>B_40_min</th>\n",
       "      <th>B_40_max</th>\n",
       "      <th>B_40_last</th>\n",
       "      <th>S_27_mean</th>\n",
       "      <th>S_27_std</th>\n",
       "      <th>S_27_min</th>\n",
       "      <th>S_27_max</th>\n",
       "      <th>S_27_last</th>\n",
       "      <th>D_113_mean</th>\n",
       "      <th>D_113_std</th>\n",
       "      <th>D_113_min</th>\n",
       "      <th>D_113_max</th>\n",
       "      <th>D_113_last</th>\n",
       "      <th>D_115_mean</th>\n",
       "      <th>D_115_std</th>\n",
       "      <th>D_115_min</th>\n",
       "      <th>D_115_max</th>\n",
       "      <th>D_115_last</th>\n",
       "      <th>D_118_mean</th>\n",
       "      <th>D_118_std</th>\n",
       "      <th>D_118_min</th>\n",
       "      <th>D_118_max</th>\n",
       "      <th>D_118_last</th>\n",
       "      <th>D_119_mean</th>\n",
       "      <th>D_119_std</th>\n",
       "      <th>D_119_min</th>\n",
       "      <th>D_119_max</th>\n",
       "      <th>D_119_last</th>\n",
       "      <th>D_121_mean</th>\n",
       "      <th>D_121_std</th>\n",
       "      <th>D_121_min</th>\n",
       "      <th>D_121_max</th>\n",
       "      <th>D_121_last</th>\n",
       "      <th>D_122_mean</th>\n",
       "      <th>D_122_std</th>\n",
       "      <th>D_122_min</th>\n",
       "      <th>D_122_max</th>\n",
       "      <th>D_122_last</th>\n",
       "      <th>D_123_mean</th>\n",
       "      <th>D_123_std</th>\n",
       "      <th>D_123_min</th>\n",
       "      <th>D_123_max</th>\n",
       "      <th>D_123_last</th>\n",
       "      <th>D_124_mean</th>\n",
       "      <th>D_124_std</th>\n",
       "      <th>D_124_min</th>\n",
       "      <th>D_124_max</th>\n",
       "      <th>D_124_last</th>\n",
       "      <th>D_125_mean</th>\n",
       "      <th>D_125_std</th>\n",
       "      <th>D_125_min</th>\n",
       "      <th>D_125_max</th>\n",
       "      <th>D_125_last</th>\n",
       "      <th>D_127_mean</th>\n",
       "      <th>D_127_std</th>\n",
       "      <th>D_127_min</th>\n",
       "      <th>D_127_max</th>\n",
       "      <th>D_127_last</th>\n",
       "      <th>D_128_mean</th>\n",
       "      <th>D_128_std</th>\n",
       "      <th>D_128_min</th>\n",
       "      <th>D_128_max</th>\n",
       "      <th>D_128_last</th>\n",
       "      <th>D_129_mean</th>\n",
       "      <th>D_129_std</th>\n",
       "      <th>D_129_min</th>\n",
       "      <th>D_129_max</th>\n",
       "      <th>D_129_last</th>\n",
       "      <th>B_41_mean</th>\n",
       "      <th>B_41_std</th>\n",
       "      <th>B_41_min</th>\n",
       "      <th>B_41_max</th>\n",
       "      <th>B_41_last</th>\n",
       "      <th>B_42_mean</th>\n",
       "      <th>B_42_std</th>\n",
       "      <th>B_42_min</th>\n",
       "      <th>B_42_max</th>\n",
       "      <th>B_42_last</th>\n",
       "      <th>D_130_mean</th>\n",
       "      <th>D_130_std</th>\n",
       "      <th>D_130_min</th>\n",
       "      <th>D_130_max</th>\n",
       "      <th>D_130_last</th>\n",
       "      <th>D_131_mean</th>\n",
       "      <th>D_131_std</th>\n",
       "      <th>D_131_min</th>\n",
       "      <th>D_131_max</th>\n",
       "      <th>D_131_last</th>\n",
       "      <th>D_132_mean</th>\n",
       "      <th>D_132_std</th>\n",
       "      <th>D_132_min</th>\n",
       "      <th>D_132_max</th>\n",
       "      <th>D_132_last</th>\n",
       "      <th>D_133_mean</th>\n",
       "      <th>D_133_std</th>\n",
       "      <th>D_133_min</th>\n",
       "      <th>D_133_max</th>\n",
       "      <th>D_133_last</th>\n",
       "      <th>R_28_mean</th>\n",
       "      <th>R_28_std</th>\n",
       "      <th>R_28_min</th>\n",
       "      <th>R_28_max</th>\n",
       "      <th>R_28_last</th>\n",
       "      <th>D_134_mean</th>\n",
       "      <th>D_134_std</th>\n",
       "      <th>D_134_min</th>\n",
       "      <th>D_134_max</th>\n",
       "      <th>D_134_last</th>\n",
       "      <th>D_135_mean</th>\n",
       "      <th>D_135_std</th>\n",
       "      <th>D_135_min</th>\n",
       "      <th>D_135_max</th>\n",
       "      <th>D_135_last</th>\n",
       "      <th>D_136_mean</th>\n",
       "      <th>D_136_std</th>\n",
       "      <th>D_136_min</th>\n",
       "      <th>D_136_max</th>\n",
       "      <th>D_136_last</th>\n",
       "      <th>D_137_mean</th>\n",
       "      <th>D_137_std</th>\n",
       "      <th>D_137_min</th>\n",
       "      <th>D_137_max</th>\n",
       "      <th>D_137_last</th>\n",
       "      <th>D_138_mean</th>\n",
       "      <th>D_138_std</th>\n",
       "      <th>D_138_min</th>\n",
       "      <th>D_138_max</th>\n",
       "      <th>D_138_last</th>\n",
       "      <th>D_139_mean</th>\n",
       "      <th>D_139_std</th>\n",
       "      <th>D_139_min</th>\n",
       "      <th>D_139_max</th>\n",
       "      <th>D_139_last</th>\n",
       "      <th>D_140_mean</th>\n",
       "      <th>D_140_std</th>\n",
       "      <th>D_140_min</th>\n",
       "      <th>D_140_max</th>\n",
       "      <th>D_140_last</th>\n",
       "      <th>D_141_mean</th>\n",
       "      <th>D_141_std</th>\n",
       "      <th>D_141_min</th>\n",
       "      <th>D_141_max</th>\n",
       "      <th>D_141_last</th>\n",
       "      <th>D_142_mean</th>\n",
       "      <th>D_142_std</th>\n",
       "      <th>D_142_min</th>\n",
       "      <th>D_142_max</th>\n",
       "      <th>D_142_last</th>\n",
       "      <th>D_143_mean</th>\n",
       "      <th>D_143_std</th>\n",
       "      <th>D_143_min</th>\n",
       "      <th>D_143_max</th>\n",
       "      <th>D_143_last</th>\n",
       "      <th>D_144_mean</th>\n",
       "      <th>D_144_std</th>\n",
       "      <th>D_144_min</th>\n",
       "      <th>D_144_max</th>\n",
       "      <th>D_144_last</th>\n",
       "      <th>D_145_mean</th>\n",
       "      <th>D_145_std</th>\n",
       "      <th>D_145_min</th>\n",
       "      <th>D_145_max</th>\n",
       "      <th>D_145_last</th>\n",
       "      <th>B_30_count</th>\n",
       "      <th>B_30_last</th>\n",
       "      <th>B_30_nunique</th>\n",
       "      <th>B_38_count</th>\n",
       "      <th>B_38_last</th>\n",
       "      <th>B_38_nunique</th>\n",
       "      <th>D_114_count</th>\n",
       "      <th>D_114_last</th>\n",
       "      <th>D_114_nunique</th>\n",
       "      <th>D_116_count</th>\n",
       "      <th>D_116_last</th>\n",
       "      <th>D_116_nunique</th>\n",
       "      <th>D_117_count</th>\n",
       "      <th>D_117_last</th>\n",
       "      <th>D_117_nunique</th>\n",
       "      <th>D_120_count</th>\n",
       "      <th>D_120_last</th>\n",
       "      <th>D_120_nunique</th>\n",
       "      <th>D_126_count</th>\n",
       "      <th>D_126_last</th>\n",
       "      <th>D_126_nunique</th>\n",
       "      <th>D_63_count</th>\n",
       "      <th>D_63_last</th>\n",
       "      <th>D_63_nunique</th>\n",
       "      <th>D_64_count</th>\n",
       "      <th>D_64_last</th>\n",
       "      <th>D_64_nunique</th>\n",
       "      <th>D_66_count</th>\n",
       "      <th>D_66_last</th>\n",
       "      <th>D_66_nunique</th>\n",
       "      <th>D_68_count</th>\n",
       "      <th>D_68_last</th>\n",
       "      <th>D_68_nunique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000469ba478561f23a92a868bd366de6f6527a684c9a...</td>\n",
       "      <td>0.601387</td>\n",
       "      <td>0.020190</td>\n",
       "      <td>0.568930</td>\n",
       "      <td>0.631315</td>\n",
       "      <td>0.568930</td>\n",
       "      <td>2.222222</td>\n",
       "      <td>3.527668</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.013925</td>\n",
       "      <td>0.004282</td>\n",
       "      <td>0.007959</td>\n",
       "      <td>0.021672</td>\n",
       "      <td>0.010779</td>\n",
       "      <td>0.898289</td>\n",
       "      <td>0.100255</td>\n",
       "      <td>0.810456</td>\n",
       "      <td>1.009347</td>\n",
       "      <td>1.009347</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.188640</td>\n",
       "      <td>0.039397</td>\n",
       "      <td>0.149413</td>\n",
       "      <td>0.266976</td>\n",
       "      <td>0.149413</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009732</td>\n",
       "      <td>0.005783</td>\n",
       "      <td>0.002347</td>\n",
       "      <td>0.019999</td>\n",
       "      <td>0.003576</td>\n",
       "      <td>0.118016</td>\n",
       "      <td>0.006688</td>\n",
       "      <td>0.103745</td>\n",
       "      <td>0.125319</td>\n",
       "      <td>0.103745</td>\n",
       "      <td>0.006835</td>\n",
       "      <td>0.000796</td>\n",
       "      <td>0.006272</td>\n",
       "      <td>0.007398</td>\n",
       "      <td>0.007398</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.888889</td>\n",
       "      <td>0.600925</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>0.011955</td>\n",
       "      <td>0.006328</td>\n",
       "      <td>0.004483</td>\n",
       "      <td>0.025111</td>\n",
       "      <td>0.025111</td>\n",
       "      <td>0.047263</td>\n",
       "      <td>0.044012</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>0.141991</td>\n",
       "      <td>0.050187</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.446102</td>\n",
       "      <td>0.008792</td>\n",
       "      <td>0.440136</td>\n",
       "      <td>0.461334</td>\n",
       "      <td>0.445881</td>\n",
       "      <td>0.479550</td>\n",
       "      <td>0.006161</td>\n",
       "      <td>0.471837</td>\n",
       "      <td>0.489448</td>\n",
       "      <td>0.489448</td>\n",
       "      <td>0.578279</td>\n",
       "      <td>0.048690</td>\n",
       "      <td>0.509876</td>\n",
       "      <td>0.626467</td>\n",
       "      <td>0.517214</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.218059</td>\n",
       "      <td>0.453953</td>\n",
       "      <td>0.023090</td>\n",
       "      <td>1.417059</td>\n",
       "      <td>0.024945</td>\n",
       "      <td>0.283370</td>\n",
       "      <td>0.364071</td>\n",
       "      <td>0.126995</td>\n",
       "      <td>1.250677</td>\n",
       "      <td>0.163441</td>\n",
       "      <td>1.006641</td>\n",
       "      <td>0.002373</td>\n",
       "      <td>1.002937</td>\n",
       "      <td>1.009301</td>\n",
       "      <td>1.008730</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003733</td>\n",
       "      <td>0.003084</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.008429</td>\n",
       "      <td>0.005263</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.117639</td>\n",
       "      <td>0.002922</td>\n",
       "      <td>0.113107</td>\n",
       "      <td>0.120991</td>\n",
       "      <td>0.115930</td>\n",
       "      <td>0.591933</td>\n",
       "      <td>0.043662</td>\n",
       "      <td>0.535311</td>\n",
       "      <td>0.634208</td>\n",
       "      <td>0.560515</td>\n",
       "      <td>0.037069</td>\n",
       "      <td>0.017800</td>\n",
       "      <td>-0.002919</td>\n",
       "      <td>0.063187</td>\n",
       "      <td>0.033599</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006742</td>\n",
       "      <td>0.003650</td>\n",
       "      <td>0.001004</td>\n",
       "      <td>0.011795</td>\n",
       "      <td>0.011795</td>\n",
       "      <td>0.006187</td>\n",
       "      <td>0.003372</td>\n",
       "      <td>0.003296</td>\n",
       "      <td>0.013309</td>\n",
       "      <td>0.005188</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.440959</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.170330</td>\n",
       "      <td>0.032080</td>\n",
       "      <td>0.105587</td>\n",
       "      <td>0.210077</td>\n",
       "      <td>0.159703</td>\n",
       "      <td>0.082867</td>\n",
       "      <td>0.028925</td>\n",
       "      <td>0.049336</td>\n",
       "      <td>0.121490</td>\n",
       "      <td>0.058696</td>\n",
       "      <td>838.888889</td>\n",
       "      <td>328.577405</td>\n",
       "      <td>528</td>\n",
       "      <td>1454</td>\n",
       "      <td>1454</td>\n",
       "      <td>0.317071</td>\n",
       "      <td>0.115253</td>\n",
       "      <td>0.114564</td>\n",
       "      <td>0.458377</td>\n",
       "      <td>0.458377</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.054207</td>\n",
       "      <td>0.016966</td>\n",
       "      <td>0.028347</td>\n",
       "      <td>0.069578</td>\n",
       "      <td>0.063506</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.377217</td>\n",
       "      <td>0.065622</td>\n",
       "      <td>0.205898</td>\n",
       "      <td>0.416276</td>\n",
       "      <td>0.381320</td>\n",
       "      <td>0.015570</td>\n",
       "      <td>0.004108</td>\n",
       "      <td>0.010773</td>\n",
       "      <td>0.022947</td>\n",
       "      <td>0.016998</td>\n",
       "      <td>0.018828</td>\n",
       "      <td>0.008068</td>\n",
       "      <td>0.008621</td>\n",
       "      <td>0.028865</td>\n",
       "      <td>0.008621</td>\n",
       "      <td>18.888889</td>\n",
       "      <td>11.285438</td>\n",
       "      <td>-1</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>0.042616</td>\n",
       "      <td>0.022548</td>\n",
       "      <td>0.013835</td>\n",
       "      <td>0.083740</td>\n",
       "      <td>0.013835</td>\n",
       "      <td>0.597552</td>\n",
       "      <td>0.016234</td>\n",
       "      <td>0.577867</td>\n",
       "      <td>0.622886</td>\n",
       "      <td>0.589184</td>\n",
       "      <td>0.020536</td>\n",
       "      <td>0.008908</td>\n",
       "      <td>0.010489</td>\n",
       "      <td>0.039339</td>\n",
       "      <td>0.014091</td>\n",
       "      <td>45.111111</td>\n",
       "      <td>8.709828</td>\n",
       "      <td>30</td>\n",
       "      <td>56</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004009</td>\n",
       "      <td>0.003770</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.009113</td>\n",
       "      <td>0.001118</td>\n",
       "      <td>0.013483</td>\n",
       "      <td>0.005508</td>\n",
       "      <td>0.005756</td>\n",
       "      <td>0.022383</td>\n",
       "      <td>0.007948</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.006624</td>\n",
       "      <td>0.002284</td>\n",
       "      <td>1.002286</td>\n",
       "      <td>1.009223</td>\n",
       "      <td>1.002286</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.368253</td>\n",
       "      <td>0.039012</td>\n",
       "      <td>0.274203</td>\n",
       "      <td>0.403018</td>\n",
       "      <td>0.375581</td>\n",
       "      <td>0.299671</td>\n",
       "      <td>0.122332</td>\n",
       "      <td>0.004302</td>\n",
       "      <td>0.390859</td>\n",
       "      <td>0.346436</td>\n",
       "      <td>-0.444444</td>\n",
       "      <td>0.527046</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.252104</td>\n",
       "      <td>0.004236</td>\n",
       "      <td>0.247840</td>\n",
       "      <td>0.259002</td>\n",
       "      <td>0.251319</td>\n",
       "      <td>0.246912</td>\n",
       "      <td>0.004773</td>\n",
       "      <td>0.243366</td>\n",
       "      <td>0.255020</td>\n",
       "      <td>0.247260</td>\n",
       "      <td>0.247668</td>\n",
       "      <td>0.004234</td>\n",
       "      <td>0.242564</td>\n",
       "      <td>0.253783</td>\n",
       "      <td>0.253783</td>\n",
       "      <td>0.196751</td>\n",
       "      <td>0.002904</td>\n",
       "      <td>0.192405</td>\n",
       "      <td>0.199254</td>\n",
       "      <td>0.199254</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>1.054093</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.444444</td>\n",
       "      <td>0.527046</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>1.054093</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.444444</td>\n",
       "      <td>0.527046</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.111111</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004254</td>\n",
       "      <td>0.003084</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.008436</td>\n",
       "      <td>0.006273</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.111111</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.111111</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005730</td>\n",
       "      <td>0.002398</td>\n",
       "      <td>0.002156</td>\n",
       "      <td>0.009667</td>\n",
       "      <td>0.003690</td>\n",
       "      <td>-0.111111</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00001bf2e77ff879fab36aa4fac689b9ba411dae63ae39...</td>\n",
       "      <td>0.862166</td>\n",
       "      <td>0.031436</td>\n",
       "      <td>0.794469</td>\n",
       "      <td>0.913501</td>\n",
       "      <td>0.841177</td>\n",
       "      <td>5.076923</td>\n",
       "      <td>6.034091</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>0.052342</td>\n",
       "      <td>0.069067</td>\n",
       "      <td>0.014187</td>\n",
       "      <td>0.276014</td>\n",
       "      <td>0.016562</td>\n",
       "      <td>1.003704</td>\n",
       "      <td>0.002698</td>\n",
       "      <td>1.000782</td>\n",
       "      <td>1.009245</td>\n",
       "      <td>1.009245</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.117233</td>\n",
       "      <td>0.043790</td>\n",
       "      <td>0.055804</td>\n",
       "      <td>0.172991</td>\n",
       "      <td>0.112195</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006160</td>\n",
       "      <td>0.003272</td>\n",
       "      <td>0.001597</td>\n",
       "      <td>0.011634</td>\n",
       "      <td>0.011386</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.384615</td>\n",
       "      <td>2.785033</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.088032</td>\n",
       "      <td>0.008201</td>\n",
       "      <td>0.076225</td>\n",
       "      <td>0.099732</td>\n",
       "      <td>0.099732</td>\n",
       "      <td>0.101462</td>\n",
       "      <td>0.118177</td>\n",
       "      <td>0.015060</td>\n",
       "      <td>0.356280</td>\n",
       "      <td>0.135907</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.454435</td>\n",
       "      <td>0.019146</td>\n",
       "      <td>0.414685</td>\n",
       "      <td>0.479771</td>\n",
       "      <td>0.445957</td>\n",
       "      <td>0.351355</td>\n",
       "      <td>0.006710</td>\n",
       "      <td>0.340429</td>\n",
       "      <td>0.362383</td>\n",
       "      <td>0.362383</td>\n",
       "      <td>0.070145</td>\n",
       "      <td>0.029550</td>\n",
       "      <td>0.004504</td>\n",
       "      <td>0.116785</td>\n",
       "      <td>0.041712</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.195901</td>\n",
       "      <td>0.008910</td>\n",
       "      <td>0.182720</td>\n",
       "      <td>0.213347</td>\n",
       "      <td>0.182720</td>\n",
       "      <td>0.033406</td>\n",
       "      <td>0.018624</td>\n",
       "      <td>0.014466</td>\n",
       "      <td>0.088851</td>\n",
       "      <td>0.014466</td>\n",
       "      <td>1.004206</td>\n",
       "      <td>0.003420</td>\n",
       "      <td>1.000562</td>\n",
       "      <td>1.009380</td>\n",
       "      <td>1.008640</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.518875</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.081637</td>\n",
       "      <td>0.077545</td>\n",
       "      <td>0.017454</td>\n",
       "      <td>0.303140</td>\n",
       "      <td>0.017454</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.148449</td>\n",
       "      <td>0.003027</td>\n",
       "      <td>0.143998</td>\n",
       "      <td>0.152640</td>\n",
       "      <td>0.143998</td>\n",
       "      <td>0.553269</td>\n",
       "      <td>0.082931</td>\n",
       "      <td>0.385655</td>\n",
       "      <td>0.654010</td>\n",
       "      <td>0.525659</td>\n",
       "      <td>0.298050</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.293422</td>\n",
       "      <td>0.303329</td>\n",
       "      <td>0.298735</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.022617</td>\n",
       "      <td>0.016564</td>\n",
       "      <td>0.007517</td>\n",
       "      <td>0.058175</td>\n",
       "      <td>0.009336</td>\n",
       "      <td>0.035716</td>\n",
       "      <td>0.061976</td>\n",
       "      <td>0.001258</td>\n",
       "      <td>0.237034</td>\n",
       "      <td>0.002235</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.078633</td>\n",
       "      <td>0.032018</td>\n",
       "      <td>0.032253</td>\n",
       "      <td>0.124283</td>\n",
       "      <td>0.081717</td>\n",
       "      <td>0.043231</td>\n",
       "      <td>0.013324</td>\n",
       "      <td>0.018395</td>\n",
       "      <td>0.054435</td>\n",
       "      <td>0.054184</td>\n",
       "      <td>2646.615385</td>\n",
       "      <td>350.316414</td>\n",
       "      <td>1898</td>\n",
       "      <td>3166</td>\n",
       "      <td>2402</td>\n",
       "      <td>0.063459</td>\n",
       "      <td>0.007567</td>\n",
       "      <td>0.050986</td>\n",
       "      <td>0.075262</td>\n",
       "      <td>0.053444</td>\n",
       "      <td>0.064233</td>\n",
       "      <td>0.003032</td>\n",
       "      <td>0.060207</td>\n",
       "      <td>0.069648</td>\n",
       "      <td>0.063766</td>\n",
       "      <td>0.099541</td>\n",
       "      <td>0.050890</td>\n",
       "      <td>0.027126</td>\n",
       "      <td>0.147346</td>\n",
       "      <td>0.058585</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005272</td>\n",
       "      <td>0.002983</td>\n",
       "      <td>0.000569</td>\n",
       "      <td>0.009221</td>\n",
       "      <td>0.006375</td>\n",
       "      <td>0.155740</td>\n",
       "      <td>0.184706</td>\n",
       "      <td>0.018508</td>\n",
       "      <td>0.544298</td>\n",
       "      <td>0.018508</td>\n",
       "      <td>0.034238</td>\n",
       "      <td>0.028593</td>\n",
       "      <td>0.009963</td>\n",
       "      <td>0.116171</td>\n",
       "      <td>0.010847</td>\n",
       "      <td>32.846154</td>\n",
       "      <td>2.303843</td>\n",
       "      <td>28</td>\n",
       "      <td>36</td>\n",
       "      <td>34</td>\n",
       "      <td>0.507825</td>\n",
       "      <td>0.191927</td>\n",
       "      <td>0.244265</td>\n",
       "      <td>0.831362</td>\n",
       "      <td>0.685577</td>\n",
       "      <td>0.070053</td>\n",
       "      <td>0.029479</td>\n",
       "      <td>0.000629</td>\n",
       "      <td>0.113120</td>\n",
       "      <td>0.046726</td>\n",
       "      <td>0.004710</td>\n",
       "      <td>0.002485</td>\n",
       "      <td>0.001179</td>\n",
       "      <td>0.009936</td>\n",
       "      <td>0.005461</td>\n",
       "      <td>9.230769</td>\n",
       "      <td>1.589227</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005196</td>\n",
       "      <td>0.003279</td>\n",
       "      <td>0.000363</td>\n",
       "      <td>0.009707</td>\n",
       "      <td>0.007424</td>\n",
       "      <td>0.049217</td>\n",
       "      <td>0.068725</td>\n",
       "      <td>0.005031</td>\n",
       "      <td>0.271571</td>\n",
       "      <td>0.012894</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.004561</td>\n",
       "      <td>0.002922</td>\n",
       "      <td>1.000501</td>\n",
       "      <td>1.008918</td>\n",
       "      <td>1.000501</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.025251</td>\n",
       "      <td>0.008362</td>\n",
       "      <td>0.005498</td>\n",
       "      <td>0.040057</td>\n",
       "      <td>0.005498</td>\n",
       "      <td>0.455466</td>\n",
       "      <td>0.159164</td>\n",
       "      <td>0.130432</td>\n",
       "      <td>0.675456</td>\n",
       "      <td>0.590974</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.309216</td>\n",
       "      <td>0.008609</td>\n",
       "      <td>0.298768</td>\n",
       "      <td>0.320178</td>\n",
       "      <td>0.317455</td>\n",
       "      <td>0.303904</td>\n",
       "      <td>0.009185</td>\n",
       "      <td>0.287581</td>\n",
       "      <td>0.316734</td>\n",
       "      <td>0.316734</td>\n",
       "      <td>0.303837</td>\n",
       "      <td>0.009210</td>\n",
       "      <td>0.285856</td>\n",
       "      <td>0.318151</td>\n",
       "      <td>0.318151</td>\n",
       "      <td>0.842254</td>\n",
       "      <td>0.007938</td>\n",
       "      <td>0.827385</td>\n",
       "      <td>0.854850</td>\n",
       "      <td>0.854850</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.003930</td>\n",
       "      <td>0.003068</td>\n",
       "      <td>0.999254</td>\n",
       "      <td>1.008954</td>\n",
       "      <td>0.999368</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004032</td>\n",
       "      <td>0.002541</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>0.008720</td>\n",
       "      <td>0.002767</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005329</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.009734</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000210045da4f81e5f122c6bde5c2a617d03eef67f82c...</td>\n",
       "      <td>0.748955</td>\n",
       "      <td>0.061456</td>\n",
       "      <td>0.673112</td>\n",
       "      <td>0.835114</td>\n",
       "      <td>0.697522</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0.012762</td>\n",
       "      <td>0.013515</td>\n",
       "      <td>0.001483</td>\n",
       "      <td>0.039697</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.901266</td>\n",
       "      <td>0.100405</td>\n",
       "      <td>0.810072</td>\n",
       "      <td>1.009582</td>\n",
       "      <td>0.810072</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.161460</td>\n",
       "      <td>0.015277</td>\n",
       "      <td>0.132608</td>\n",
       "      <td>0.176586</td>\n",
       "      <td>0.166165</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008552</td>\n",
       "      <td>0.004910</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.015938</td>\n",
       "      <td>0.015938</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.130507</td>\n",
       "      <td>0.038596</td>\n",
       "      <td>0.085228</td>\n",
       "      <td>0.207249</td>\n",
       "      <td>0.105303</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17.307692</td>\n",
       "      <td>12.873646</td>\n",
       "      <td>3</td>\n",
       "      <td>37</td>\n",
       "      <td>32</td>\n",
       "      <td>0.053784</td>\n",
       "      <td>0.008273</td>\n",
       "      <td>0.041670</td>\n",
       "      <td>0.068810</td>\n",
       "      <td>0.068810</td>\n",
       "      <td>0.020789</td>\n",
       "      <td>0.023096</td>\n",
       "      <td>0.001249</td>\n",
       "      <td>0.079263</td>\n",
       "      <td>0.004851</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.609312</td>\n",
       "      <td>0.258284</td>\n",
       "      <td>0.292797</td>\n",
       "      <td>1.073808</td>\n",
       "      <td>0.702994</td>\n",
       "      <td>0.190731</td>\n",
       "      <td>0.007339</td>\n",
       "      <td>0.179846</td>\n",
       "      <td>0.204331</td>\n",
       "      <td>0.204331</td>\n",
       "      <td>0.340703</td>\n",
       "      <td>0.191232</td>\n",
       "      <td>0.087397</td>\n",
       "      <td>0.616486</td>\n",
       "      <td>0.522954</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.141160</td>\n",
       "      <td>0.065130</td>\n",
       "      <td>0.058534</td>\n",
       "      <td>0.241034</td>\n",
       "      <td>0.058534</td>\n",
       "      <td>0.059383</td>\n",
       "      <td>0.029516</td>\n",
       "      <td>0.023160</td>\n",
       "      <td>0.109238</td>\n",
       "      <td>0.090228</td>\n",
       "      <td>1.004163</td>\n",
       "      <td>0.003042</td>\n",
       "      <td>1.000286</td>\n",
       "      <td>1.009375</td>\n",
       "      <td>1.009375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005599</td>\n",
       "      <td>0.002235</td>\n",
       "      <td>0.001413</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>0.008629</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.506370</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.230020</td>\n",
       "      <td>0.018892</td>\n",
       "      <td>0.195193</td>\n",
       "      <td>0.243709</td>\n",
       "      <td>0.235105</td>\n",
       "      <td>0.670820</td>\n",
       "      <td>0.191084</td>\n",
       "      <td>0.381666</td>\n",
       "      <td>0.944176</td>\n",
       "      <td>0.566616</td>\n",
       "      <td>0.192089</td>\n",
       "      <td>0.088916</td>\n",
       "      <td>0.079202</td>\n",
       "      <td>0.298906</td>\n",
       "      <td>0.129189</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007970</td>\n",
       "      <td>0.009604</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.031101</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>0.009048</td>\n",
       "      <td>0.007783</td>\n",
       "      <td>0.001162</td>\n",
       "      <td>0.025379</td>\n",
       "      <td>0.003380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.166638</td>\n",
       "      <td>0.047825</td>\n",
       "      <td>0.082774</td>\n",
       "      <td>0.208820</td>\n",
       "      <td>0.170267</td>\n",
       "      <td>0.056018</td>\n",
       "      <td>0.002512</td>\n",
       "      <td>0.051632</td>\n",
       "      <td>0.059715</td>\n",
       "      <td>0.052914</td>\n",
       "      <td>1048.000000</td>\n",
       "      <td>651.710953</td>\n",
       "      <td>0</td>\n",
       "      <td>2402</td>\n",
       "      <td>379</td>\n",
       "      <td>0.282046</td>\n",
       "      <td>0.070444</td>\n",
       "      <td>0.207001</td>\n",
       "      <td>0.418986</td>\n",
       "      <td>0.418986</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.048400</td>\n",
       "      <td>0.018193</td>\n",
       "      <td>0.015644</td>\n",
       "      <td>0.075478</td>\n",
       "      <td>0.048129</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.131883</td>\n",
       "      <td>0.123385</td>\n",
       "      <td>0.001611</td>\n",
       "      <td>0.277115</td>\n",
       "      <td>0.272541</td>\n",
       "      <td>0.081942</td>\n",
       "      <td>0.175919</td>\n",
       "      <td>0.001582</td>\n",
       "      <td>0.551186</td>\n",
       "      <td>0.009170</td>\n",
       "      <td>0.014231</td>\n",
       "      <td>0.015788</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.043197</td>\n",
       "      <td>0.004427</td>\n",
       "      <td>12.384615</td>\n",
       "      <td>0.506370</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>0.092388</td>\n",
       "      <td>0.152651</td>\n",
       "      <td>0.000776</td>\n",
       "      <td>0.427419</td>\n",
       "      <td>0.003803</td>\n",
       "      <td>0.317425</td>\n",
       "      <td>0.180088</td>\n",
       "      <td>0.064856</td>\n",
       "      <td>0.531674</td>\n",
       "      <td>0.508047</td>\n",
       "      <td>0.016268</td>\n",
       "      <td>0.017308</td>\n",
       "      <td>0.001282</td>\n",
       "      <td>0.047036</td>\n",
       "      <td>0.006497</td>\n",
       "      <td>25.846154</td>\n",
       "      <td>4.963973</td>\n",
       "      <td>14</td>\n",
       "      <td>33</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.005952</td>\n",
       "      <td>0.002576</td>\n",
       "      <td>0.002185</td>\n",
       "      <td>0.009374</td>\n",
       "      <td>0.004671</td>\n",
       "      <td>0.013616</td>\n",
       "      <td>0.013069</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.038614</td>\n",
       "      <td>0.005816</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.005486</td>\n",
       "      <td>0.002778</td>\n",
       "      <td>1.001447</td>\n",
       "      <td>1.009816</td>\n",
       "      <td>1.004291</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.849524</td>\n",
       "      <td>0.367313</td>\n",
       "      <td>0.017070</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.055623</td>\n",
       "      <td>0.036971</td>\n",
       "      <td>0.011564</td>\n",
       "      <td>0.112604</td>\n",
       "      <td>0.096783</td>\n",
       "      <td>0.325662</td>\n",
       "      <td>0.309288</td>\n",
       "      <td>0.001439</td>\n",
       "      <td>0.631245</td>\n",
       "      <td>0.007752</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.269961</td>\n",
       "      <td>0.084998</td>\n",
       "      <td>0.078751</td>\n",
       "      <td>0.316599</td>\n",
       "      <td>0.079162</td>\n",
       "      <td>0.065339</td>\n",
       "      <td>0.009612</td>\n",
       "      <td>0.052496</td>\n",
       "      <td>0.082892</td>\n",
       "      <td>0.079331</td>\n",
       "      <td>0.064979</td>\n",
       "      <td>0.009726</td>\n",
       "      <td>0.051375</td>\n",
       "      <td>0.082290</td>\n",
       "      <td>0.079235</td>\n",
       "      <td>0.272082</td>\n",
       "      <td>0.006140</td>\n",
       "      <td>0.262928</td>\n",
       "      <td>0.280907</td>\n",
       "      <td>0.279283</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.004558</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>1.000023</td>\n",
       "      <td>1.009844</td>\n",
       "      <td>1.00389</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005083</td>\n",
       "      <td>0.002324</td>\n",
       "      <td>0.001968</td>\n",
       "      <td>0.008024</td>\n",
       "      <td>0.002045</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.887847</td>\n",
       "      <td>0.005267</td>\n",
       "      <td>0.879781</td>\n",
       "      <td>0.896891</td>\n",
       "      <td>0.896224</td>\n",
       "      <td>0.128100</td>\n",
       "      <td>0.015235</td>\n",
       "      <td>0.103164</td>\n",
       "      <td>0.150203</td>\n",
       "      <td>0.150203</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.387283</td>\n",
       "      <td>0.042557</td>\n",
       "      <td>0.322121</td>\n",
       "      <td>0.457819</td>\n",
       "      <td>0.457819</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00003b41e58ede33b8daf61ab56d9952f17c9ad1c3976c...</td>\n",
       "      <td>0.474728</td>\n",
       "      <td>0.028856</td>\n",
       "      <td>0.428457</td>\n",
       "      <td>0.514222</td>\n",
       "      <td>0.513186</td>\n",
       "      <td>15.846154</td>\n",
       "      <td>4.355957</td>\n",
       "      <td>7</td>\n",
       "      <td>23</td>\n",
       "      <td>11</td>\n",
       "      <td>0.284608</td>\n",
       "      <td>0.042549</td>\n",
       "      <td>0.149511</td>\n",
       "      <td>0.309129</td>\n",
       "      <td>0.149511</td>\n",
       "      <td>0.090901</td>\n",
       "      <td>0.045854</td>\n",
       "      <td>0.032696</td>\n",
       "      <td>0.205678</td>\n",
       "      <td>0.205678</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.294408</td>\n",
       "      <td>0.063746</td>\n",
       "      <td>0.181200</td>\n",
       "      <td>0.382242</td>\n",
       "      <td>0.181200</td>\n",
       "      <td>0.060098</td>\n",
       "      <td>0.044833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.168233</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666754</td>\n",
       "      <td>0.146841</td>\n",
       "      <td>0.389167</td>\n",
       "      <td>0.960779</td>\n",
       "      <td>0.498516</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.301156</td>\n",
       "      <td>0.066513</td>\n",
       "      <td>0.211615</td>\n",
       "      <td>0.410494</td>\n",
       "      <td>0.211615</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.816497</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>29.230769</td>\n",
       "      <td>3.443686</td>\n",
       "      <td>19</td>\n",
       "      <td>33</td>\n",
       "      <td>19</td>\n",
       "      <td>0.221210</td>\n",
       "      <td>0.009088</td>\n",
       "      <td>0.204183</td>\n",
       "      <td>0.237480</td>\n",
       "      <td>0.237480</td>\n",
       "      <td>0.031221</td>\n",
       "      <td>0.009832</td>\n",
       "      <td>0.017731</td>\n",
       "      <td>0.050078</td>\n",
       "      <td>0.022947</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.439887</td>\n",
       "      <td>0.023862</td>\n",
       "      <td>0.414299</td>\n",
       "      <td>0.502695</td>\n",
       "      <td>0.414899</td>\n",
       "      <td>0.157993</td>\n",
       "      <td>0.008991</td>\n",
       "      <td>0.142214</td>\n",
       "      <td>0.171934</td>\n",
       "      <td>0.171934</td>\n",
       "      <td>0.551178</td>\n",
       "      <td>0.038229</td>\n",
       "      <td>0.495017</td>\n",
       "      <td>0.603837</td>\n",
       "      <td>0.602520</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.014650</td>\n",
       "      <td>0.004947</td>\n",
       "      <td>0.006839</td>\n",
       "      <td>0.023546</td>\n",
       "      <td>0.023546</td>\n",
       "      <td>0.313388</td>\n",
       "      <td>0.036721</td>\n",
       "      <td>0.206215</td>\n",
       "      <td>0.354177</td>\n",
       "      <td>0.206215</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.449816</td>\n",
       "      <td>0.083461</td>\n",
       "      <td>0.185255</td>\n",
       "      <td>0.508892</td>\n",
       "      <td>0.185255</td>\n",
       "      <td>2.307692</td>\n",
       "      <td>1.436698</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.077970</td>\n",
       "      <td>0.003008</td>\n",
       "      <td>0.073267</td>\n",
       "      <td>0.082623</td>\n",
       "      <td>0.078085</td>\n",
       "      <td>0.610769</td>\n",
       "      <td>0.087494</td>\n",
       "      <td>0.464951</td>\n",
       "      <td>0.794439</td>\n",
       "      <td>0.628619</td>\n",
       "      <td>0.024276</td>\n",
       "      <td>0.006008</td>\n",
       "      <td>0.013830</td>\n",
       "      <td>0.032124</td>\n",
       "      <td>0.032124</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.251280</td>\n",
       "      <td>0.110203</td>\n",
       "      <td>0.037088</td>\n",
       "      <td>0.360818</td>\n",
       "      <td>0.320184</td>\n",
       "      <td>0.293207</td>\n",
       "      <td>0.048930</td>\n",
       "      <td>0.139062</td>\n",
       "      <td>0.326395</td>\n",
       "      <td>0.139062</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.557075</td>\n",
       "      <td>0.043996</td>\n",
       "      <td>0.461584</td>\n",
       "      <td>0.598874</td>\n",
       "      <td>0.552729</td>\n",
       "      <td>0.080164</td>\n",
       "      <td>0.007026</td>\n",
       "      <td>0.074469</td>\n",
       "      <td>0.098741</td>\n",
       "      <td>0.098741</td>\n",
       "      <td>1737.307692</td>\n",
       "      <td>364.872897</td>\n",
       "      <td>1454</td>\n",
       "      <td>2380</td>\n",
       "      <td>1511</td>\n",
       "      <td>0.553918</td>\n",
       "      <td>0.024364</td>\n",
       "      <td>0.518958</td>\n",
       "      <td>0.596307</td>\n",
       "      <td>0.524700</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.080247</td>\n",
       "      <td>0.030293</td>\n",
       "      <td>0.034572</td>\n",
       "      <td>0.147453</td>\n",
       "      <td>0.147453</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.598498</td>\n",
       "      <td>0.107069</td>\n",
       "      <td>0.421512</td>\n",
       "      <td>0.733892</td>\n",
       "      <td>0.516813</td>\n",
       "      <td>0.010063</td>\n",
       "      <td>0.004278</td>\n",
       "      <td>0.002308</td>\n",
       "      <td>0.016637</td>\n",
       "      <td>0.012878</td>\n",
       "      <td>0.447280</td>\n",
       "      <td>0.056774</td>\n",
       "      <td>0.269620</td>\n",
       "      <td>0.481235</td>\n",
       "      <td>0.269620</td>\n",
       "      <td>38.538462</td>\n",
       "      <td>4.370648</td>\n",
       "      <td>31</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>0.672443</td>\n",
       "      <td>0.031605</td>\n",
       "      <td>0.632045</td>\n",
       "      <td>0.734601</td>\n",
       "      <td>0.641422</td>\n",
       "      <td>0.724770</td>\n",
       "      <td>0.042873</td>\n",
       "      <td>0.683347</td>\n",
       "      <td>0.845192</td>\n",
       "      <td>0.845192</td>\n",
       "      <td>0.368783</td>\n",
       "      <td>0.044457</td>\n",
       "      <td>0.252890</td>\n",
       "      <td>0.414407</td>\n",
       "      <td>0.252890</td>\n",
       "      <td>19.846154</td>\n",
       "      <td>4.862204</td>\n",
       "      <td>16</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.004172</td>\n",
       "      <td>0.002816</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>0.009784</td>\n",
       "      <td>0.002787</td>\n",
       "      <td>0.284763</td>\n",
       "      <td>0.043461</td>\n",
       "      <td>0.146753</td>\n",
       "      <td>0.309507</td>\n",
       "      <td>0.146753</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.003950</td>\n",
       "      <td>0.002583</td>\n",
       "      <td>1.000877</td>\n",
       "      <td>1.008107</td>\n",
       "      <td>1.001619</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.012544</td>\n",
       "      <td>0.004701</td>\n",
       "      <td>0.003437</td>\n",
       "      <td>0.021126</td>\n",
       "      <td>0.018601</td>\n",
       "      <td>0.359120</td>\n",
       "      <td>0.089880</td>\n",
       "      <td>0.206974</td>\n",
       "      <td>0.489678</td>\n",
       "      <td>0.228404</td>\n",
       "      <td>0.587414</td>\n",
       "      <td>0.201886</td>\n",
       "      <td>0.328769</td>\n",
       "      <td>1.045025</td>\n",
       "      <td>1.045025</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.021235</td>\n",
       "      <td>0.007864</td>\n",
       "      <td>0.005301</td>\n",
       "      <td>0.032392</td>\n",
       "      <td>0.032392</td>\n",
       "      <td>0.054029</td>\n",
       "      <td>0.069606</td>\n",
       "      <td>0.015212</td>\n",
       "      <td>0.212120</td>\n",
       "      <td>0.037828</td>\n",
       "      <td>0.050274</td>\n",
       "      <td>0.070854</td>\n",
       "      <td>0.012080</td>\n",
       "      <td>0.210552</td>\n",
       "      <td>0.032970</td>\n",
       "      <td>0.210834</td>\n",
       "      <td>0.008739</td>\n",
       "      <td>0.198072</td>\n",
       "      <td>0.223874</td>\n",
       "      <td>0.223874</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.506370</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.506370</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004191</td>\n",
       "      <td>0.002647</td>\n",
       "      <td>0.000903</td>\n",
       "      <td>0.009377</td>\n",
       "      <td>0.009377</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.909851</td>\n",
       "      <td>0.005265</td>\n",
       "      <td>0.901160</td>\n",
       "      <td>0.919774</td>\n",
       "      <td>0.919774</td>\n",
       "      <td>0.233945</td>\n",
       "      <td>0.015900</td>\n",
       "      <td>0.202383</td>\n",
       "      <td>0.257951</td>\n",
       "      <td>0.255263</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.439592</td>\n",
       "      <td>0.084648</td>\n",
       "      <td>0.333893</td>\n",
       "      <td>0.508652</td>\n",
       "      <td>0.500924</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00004b22eaeeeb0ec976890c1d9bfc14fd9427e98c4ee9...</td>\n",
       "      <td>0.324100</td>\n",
       "      <td>0.049865</td>\n",
       "      <td>0.254478</td>\n",
       "      <td>0.425764</td>\n",
       "      <td>0.254478</td>\n",
       "      <td>11.846154</td>\n",
       "      <td>6.681394</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>0.456779</td>\n",
       "      <td>0.073459</td>\n",
       "      <td>0.357828</td>\n",
       "      <td>0.563603</td>\n",
       "      <td>0.563603</td>\n",
       "      <td>0.041933</td>\n",
       "      <td>0.024121</td>\n",
       "      <td>0.020167</td>\n",
       "      <td>0.106739</td>\n",
       "      <td>0.038021</td>\n",
       "      <td>0.155275</td>\n",
       "      <td>0.242427</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.507303</td>\n",
       "      <td>0.503154</td>\n",
       "      <td>0.165107</td>\n",
       "      <td>0.005727</td>\n",
       "      <td>0.155480</td>\n",
       "      <td>0.174962</td>\n",
       "      <td>0.168317</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.616494</td>\n",
       "      <td>0.184379</td>\n",
       "      <td>0.350645</td>\n",
       "      <td>0.889529</td>\n",
       "      <td>0.830857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.226945</td>\n",
       "      <td>0.086766</td>\n",
       "      <td>0.071884</td>\n",
       "      <td>0.370614</td>\n",
       "      <td>0.071884</td>\n",
       "      <td>1.923077</td>\n",
       "      <td>0.640513</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>18.076923</td>\n",
       "      <td>1.441153</td>\n",
       "      <td>16</td>\n",
       "      <td>21</td>\n",
       "      <td>18</td>\n",
       "      <td>0.058567</td>\n",
       "      <td>0.008263</td>\n",
       "      <td>0.046922</td>\n",
       "      <td>0.069520</td>\n",
       "      <td>0.068580</td>\n",
       "      <td>0.010636</td>\n",
       "      <td>0.005156</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>0.024733</td>\n",
       "      <td>0.011126</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.456593</td>\n",
       "      <td>0.014304</td>\n",
       "      <td>0.426422</td>\n",
       "      <td>0.485177</td>\n",
       "      <td>0.472838</td>\n",
       "      <td>0.027406</td>\n",
       "      <td>0.006662</td>\n",
       "      <td>0.015988</td>\n",
       "      <td>0.039700</td>\n",
       "      <td>0.039700</td>\n",
       "      <td>0.814439</td>\n",
       "      <td>0.114909</td>\n",
       "      <td>0.544361</td>\n",
       "      <td>0.959607</td>\n",
       "      <td>0.959607</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.018187</td>\n",
       "      <td>0.004998</td>\n",
       "      <td>0.011244</td>\n",
       "      <td>0.026594</td>\n",
       "      <td>0.011244</td>\n",
       "      <td>0.270518</td>\n",
       "      <td>0.073986</td>\n",
       "      <td>0.175081</td>\n",
       "      <td>0.371814</td>\n",
       "      <td>0.261831</td>\n",
       "      <td>1.005365</td>\n",
       "      <td>0.003282</td>\n",
       "      <td>1.000343</td>\n",
       "      <td>1.009943</td>\n",
       "      <td>1.006200</td>\n",
       "      <td>0.025771</td>\n",
       "      <td>0.024183</td>\n",
       "      <td>0.002235</td>\n",
       "      <td>0.057087</td>\n",
       "      <td>0.039149</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.610471</td>\n",
       "      <td>0.036083</td>\n",
       "      <td>0.553405</td>\n",
       "      <td>0.656698</td>\n",
       "      <td>0.656698</td>\n",
       "      <td>2.230769</td>\n",
       "      <td>1.535895</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.017059</td>\n",
       "      <td>0.006432</td>\n",
       "      <td>0.003154</td>\n",
       "      <td>0.022643</td>\n",
       "      <td>0.021903</td>\n",
       "      <td>0.634829</td>\n",
       "      <td>0.126103</td>\n",
       "      <td>0.467448</td>\n",
       "      <td>0.877291</td>\n",
       "      <td>0.569771</td>\n",
       "      <td>0.024420</td>\n",
       "      <td>0.008093</td>\n",
       "      <td>0.012340</td>\n",
       "      <td>0.038865</td>\n",
       "      <td>0.022026</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.078128</td>\n",
       "      <td>0.021831</td>\n",
       "      <td>0.053537</td>\n",
       "      <td>0.111731</td>\n",
       "      <td>0.064127</td>\n",
       "      <td>0.419153</td>\n",
       "      <td>0.070155</td>\n",
       "      <td>0.323723</td>\n",
       "      <td>0.514632</td>\n",
       "      <td>0.514632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.123415</td>\n",
       "      <td>0.017923</td>\n",
       "      <td>0.105129</td>\n",
       "      <td>0.151144</td>\n",
       "      <td>0.115010</td>\n",
       "      <td>0.015217</td>\n",
       "      <td>0.002851</td>\n",
       "      <td>0.010822</td>\n",
       "      <td>0.019775</td>\n",
       "      <td>0.016391</td>\n",
       "      <td>876.769231</td>\n",
       "      <td>749.660607</td>\n",
       "      <td>0</td>\n",
       "      <td>1898</td>\n",
       "      <td>772</td>\n",
       "      <td>0.619949</td>\n",
       "      <td>0.027672</td>\n",
       "      <td>0.573654</td>\n",
       "      <td>0.673749</td>\n",
       "      <td>0.673749</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.019157</td>\n",
       "      <td>0.007573</td>\n",
       "      <td>0.006022</td>\n",
       "      <td>0.037534</td>\n",
       "      <td>0.006022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.257452</td>\n",
       "      <td>0.072315</td>\n",
       "      <td>0.082906</td>\n",
       "      <td>0.373130</td>\n",
       "      <td>0.182204</td>\n",
       "      <td>0.006081</td>\n",
       "      <td>0.003206</td>\n",
       "      <td>0.000601</td>\n",
       "      <td>0.009322</td>\n",
       "      <td>0.006939</td>\n",
       "      <td>0.142080</td>\n",
       "      <td>0.010468</td>\n",
       "      <td>0.125347</td>\n",
       "      <td>0.157513</td>\n",
       "      <td>0.157513</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>24</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>0.755093</td>\n",
       "      <td>0.042926</td>\n",
       "      <td>0.696405</td>\n",
       "      <td>0.858238</td>\n",
       "      <td>0.800289</td>\n",
       "      <td>0.804654</td>\n",
       "      <td>0.074316</td>\n",
       "      <td>0.614470</td>\n",
       "      <td>0.934916</td>\n",
       "      <td>0.893650</td>\n",
       "      <td>0.004243</td>\n",
       "      <td>0.002986</td>\n",
       "      <td>0.000375</td>\n",
       "      <td>0.009431</td>\n",
       "      <td>0.006982</td>\n",
       "      <td>15.846154</td>\n",
       "      <td>2.640901</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004175</td>\n",
       "      <td>0.002946</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.009777</td>\n",
       "      <td>0.009777</td>\n",
       "      <td>0.459646</td>\n",
       "      <td>0.073802</td>\n",
       "      <td>0.357523</td>\n",
       "      <td>0.558505</td>\n",
       "      <td>0.558505</td>\n",
       "      <td>-0.230769</td>\n",
       "      <td>1.012739</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.624714</td>\n",
       "      <td>0.501737</td>\n",
       "      <td>0.010850</td>\n",
       "      <td>1.008433</td>\n",
       "      <td>0.011080</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.068337</td>\n",
       "      <td>0.016252</td>\n",
       "      <td>0.051541</td>\n",
       "      <td>0.105340</td>\n",
       "      <td>0.081060</td>\n",
       "      <td>0.004661</td>\n",
       "      <td>0.001941</td>\n",
       "      <td>0.001691</td>\n",
       "      <td>0.006829</td>\n",
       "      <td>0.006672</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.126596</td>\n",
       "      <td>0.095712</td>\n",
       "      <td>0.006662</td>\n",
       "      <td>0.205729</td>\n",
       "      <td>0.015457</td>\n",
       "      <td>0.200060</td>\n",
       "      <td>0.007764</td>\n",
       "      <td>0.187697</td>\n",
       "      <td>0.210910</td>\n",
       "      <td>0.210910</td>\n",
       "      <td>0.199646</td>\n",
       "      <td>0.007656</td>\n",
       "      <td>0.187352</td>\n",
       "      <td>0.214071</td>\n",
       "      <td>0.214071</td>\n",
       "      <td>0.154799</td>\n",
       "      <td>0.008773</td>\n",
       "      <td>0.141394</td>\n",
       "      <td>0.170112</td>\n",
       "      <td>0.167715</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.540397</td>\n",
       "      <td>0.520745</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.008702</td>\n",
       "      <td>1.003109</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.518875</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005403</td>\n",
       "      <td>0.002284</td>\n",
       "      <td>0.000998</td>\n",
       "      <td>0.008477</td>\n",
       "      <td>0.007940</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004425</td>\n",
       "      <td>0.003232</td>\n",
       "      <td>0.000907</td>\n",
       "      <td>0.009656</td>\n",
       "      <td>0.001558</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 919 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         customer_ID  P_2_mean   P_2_std   P_2_min   P_2_max  P_2_last  D_39_mean  D_39_std  D_39_min  D_39_max  D_39_last  B_1_mean   B_1_std   B_1_min   B_1_max  B_1_last  B_2_mean   B_2_std   B_2_min   B_2_max  B_2_last  R_1_mean   R_1_std  R_1_min   R_1_max  R_1_last  S_3_mean   S_3_std   S_3_min   S_3_max  S_3_last  D_41_mean  D_41_std  D_41_min  D_41_max  D_41_last  B_3_mean   B_3_std   B_3_min   B_3_max  B_3_last  D_42_mean  D_42_std  D_42_min  D_42_max  D_42_last  D_43_mean  D_43_std  D_43_min  D_43_max  D_43_last  D_44_mean  D_44_std  D_44_min  D_44_max  D_44_last   B_4_mean    B_4_std  B_4_min  B_4_max  B_4_last  D_45_mean  D_45_std  D_45_min  D_45_max  D_45_last  B_5_mean   B_5_std   B_5_min   B_5_max  B_5_last  R_2_mean  R_2_std  R_2_min  R_2_max  R_2_last  D_46_mean  D_46_std  D_46_min  D_46_max  D_46_last  D_47_mean  D_47_std  D_47_min  D_47_max  D_47_last  D_48_mean  D_48_std  D_48_min  D_48_max  D_48_last  D_49_mean  D_49_std  D_49_min  \\\n",
       "0  00000469ba478561f23a92a868bd366de6f6527a684c9a...  0.601387  0.020190  0.568930  0.631315  0.568930   2.222222  3.527668         0         8          4  0.013925  0.004282  0.007959  0.021672  0.010779  0.898289  0.100255  0.810456  1.009347  1.009347  0.000000  0.000000      0.0  0.000000  0.000000  0.188640  0.039397  0.149413  0.266976  0.149413   0.000000  0.000000       0.0  0.000000        0.0  0.009732  0.005783  0.002347  0.019999  0.003576   0.118016  0.006688  0.103745  0.125319   0.103745   0.006835  0.000796  0.006272  0.007398   0.007398   0.000000  0.000000         0         0          0   9.888889   0.600925        9       11         9   0.011955  0.006328  0.004483  0.025111   0.025111  0.047263  0.044012  0.003400  0.141991  0.050187       0.0      0.0        0        0         0   0.446102  0.008792  0.440136  0.461334   0.445881   0.479550  0.006161  0.471837  0.489448   0.489448   0.578279  0.048690  0.509876  0.626467   0.517214       -1.0       0.0        -1   \n",
       "1  00001bf2e77ff879fab36aa4fac689b9ba411dae63ae39...  0.862166  0.031436  0.794469  0.913501  0.841177   5.076923  6.034091         0        17          4  0.052342  0.069067  0.014187  0.276014  0.016562  1.003704  0.002698  1.000782  1.009245  1.009245  0.000000  0.000000      0.0  0.000000  0.000000  0.117233  0.043790  0.055804  0.172991  0.112195   0.000000  0.000000       0.0  0.000000        0.0  0.006160  0.003272  0.001597  0.011634  0.011386        NaN       NaN       NaN       NaN        NaN        NaN       NaN       NaN       NaN        NaN   0.000000  0.000000         0         0          0   4.384615   2.785033        1       12         1   0.088032  0.008201  0.076225  0.099732   0.099732  0.101462  0.118177  0.015060  0.356280  0.135907       0.0      0.0        0        0         0   0.454435  0.019146  0.414685  0.479771   0.445957   0.351355  0.006710  0.340429  0.362383   0.362383   0.070145  0.029550  0.004504  0.116785   0.041712       -1.0       0.0        -1   \n",
       "2  0000210045da4f81e5f122c6bde5c2a617d03eef67f82c...  0.748955  0.061456  0.673112  0.835114  0.697522   6.000000  9.000000         0        23          0  0.012762  0.013515  0.001483  0.039697  0.001484  0.901266  0.100405  0.810072  1.009582  0.810072  0.000000  0.000000      0.0  0.000000  0.000000  0.161460  0.015277  0.132608  0.176586  0.166165   0.000000  0.000000       0.0  0.000000        0.0  0.008552  0.004910  0.000155  0.015938  0.015938        NaN       NaN       NaN       NaN        NaN   0.130507  0.038596  0.085228  0.207249   0.105303   0.000000  0.000000         0         0          0  17.307692  12.873646        3       37        32   0.053784  0.008273  0.041670  0.068810   0.068810  0.020789  0.023096  0.001249  0.079263  0.004851       0.0      0.0        0        0         0   0.609312  0.258284  0.292797  1.073808   0.702994   0.190731  0.007339  0.179846  0.204331   0.204331   0.340703  0.191232  0.087397  0.616486   0.522954       -1.0       0.0        -1   \n",
       "3  00003b41e58ede33b8daf61ab56d9952f17c9ad1c3976c...  0.474728  0.028856  0.428457  0.514222  0.513186  15.846154  4.355957         7        23         11  0.284608  0.042549  0.149511  0.309129  0.149511  0.090901  0.045854  0.032696  0.205678  0.205678  0.000000  0.000000      0.0  0.000000  0.000000  0.294408  0.063746  0.181200  0.382242  0.181200   0.060098  0.044833       0.0  0.168233        0.0  0.666754  0.146841  0.389167  0.960779  0.498516        NaN       NaN       NaN       NaN        NaN   0.301156  0.066513  0.211615  0.410494   0.211615   3.000000  0.816497         2         4          2  29.230769   3.443686       19       33        19   0.221210  0.009088  0.204183  0.237480   0.237480  0.031221  0.009832  0.017731  0.050078  0.022947       0.0      0.0        0        0         0   0.439887  0.023862  0.414299  0.502695   0.414899   0.157993  0.008991  0.142214  0.171934   0.171934   0.551178  0.038229  0.495017  0.603837   0.602520       -1.0       0.0        -1   \n",
       "4  00004b22eaeeeb0ec976890c1d9bfc14fd9427e98c4ee9...  0.324100  0.049865  0.254478  0.425764  0.254478  11.846154  6.681394         1        26         26  0.456779  0.073459  0.357828  0.563603  0.563603  0.041933  0.024121  0.020167  0.106739  0.038021  0.155275  0.242427      0.0  0.507303  0.503154  0.165107  0.005727  0.155480  0.174962  0.168317   0.000000  0.000000       0.0  0.000000        0.0  0.616494  0.184379  0.350645  0.889529  0.830857        NaN       NaN       NaN       NaN        NaN   0.226945  0.086766  0.071884  0.370614   0.071884   1.923077  0.640513         1         3          3  18.076923   1.441153       16       21        18   0.058567  0.008263  0.046922  0.069520   0.068580  0.010636  0.005156  0.005274  0.024733  0.011126       0.0      0.0        0        0         0   0.456593  0.014304  0.426422  0.485177   0.472838   0.027406  0.006662  0.015988  0.039700   0.039700   0.814439  0.114909  0.544361  0.959607   0.959607       -1.0       0.0        -1   \n",
       "\n",
       "   D_49_max  D_49_last  B_6_mean   B_6_std   B_6_min   B_6_max  B_6_last  B_7_mean   B_7_std   B_7_min   B_7_max  B_7_last  B_8_mean   B_8_std   B_8_min   B_8_max  B_8_last  D_50_mean  D_50_std  D_50_min  D_50_max  D_50_last  D_51_mean  D_51_std  D_51_min  D_51_max  D_51_last  B_9_mean   B_9_std   B_9_min   B_9_max  B_9_last  R_3_mean   R_3_std  R_3_min  R_3_max  R_3_last  D_52_mean  D_52_std  D_52_min  D_52_max  D_52_last  P_3_mean   P_3_std   P_3_min   P_3_max  P_3_last  B_10_mean  B_10_std  B_10_min  B_10_max  B_10_last  D_53_mean  D_53_std  D_53_min  D_53_max  D_53_last  S_5_mean   S_5_std   S_5_min   S_5_max  S_5_last  B_11_mean  B_11_std  B_11_min  B_11_max  B_11_last  S_6_mean   S_6_std  S_6_min  S_6_max  S_6_last  D_54_mean  D_54_std  D_54_min  D_54_max  D_54_last  R_4_mean  R_4_std  R_4_min  R_4_max  R_4_last  S_7_mean   S_7_std   S_7_min   S_7_max  S_7_last  B_12_mean  B_12_std  B_12_min  B_12_max  B_12_last     S_8_mean     S_8_std  S_8_min  S_8_max  S_8_last  D_55_mean  \\\n",
       "0        -1         -1  0.218059  0.453953  0.023090  1.417059  0.024945  0.283370  0.364071  0.126995  1.250677  0.163441  1.006641  0.002373  1.002937  1.009301  1.008730        NaN       NaN       NaN       NaN        NaN   0.111111  0.333333         0         1          1  0.003733  0.003084  0.000023  0.008429  0.005263  1.000000  0.000000        1        1         1   0.117639  0.002922  0.113107  0.120991   0.115930  0.591933  0.043662  0.535311  0.634208  0.560515   0.037069  0.017800 -0.002919  0.063187   0.033599        NaN       NaN       NaN       NaN        NaN  0.006742  0.003650  0.001004  0.011795  0.011795   0.006187  0.003372  0.003296  0.013309   0.005188  0.222222  0.440959        0        1         0        1.0       0.0       1.0       1.0        1.0       0.0      0.0        0        0         0  0.170330  0.032080  0.105587  0.210077  0.159703   0.082867  0.028925  0.049336  0.121490   0.058696   838.888889  328.577405      528     1454      1454   0.317071   \n",
       "1        -1         -1  0.195901  0.008910  0.182720  0.213347  0.182720  0.033406  0.018624  0.014466  0.088851  0.014466  1.004206  0.003420  1.000562  1.009380  1.008640        NaN       NaN       NaN       NaN        NaN   0.461538  0.518875         0         1          0  0.081637  0.077545  0.017454  0.303140  0.017454  0.000000  0.000000        0        0         0   0.148449  0.003027  0.143998  0.152640   0.143998  0.553269  0.082931  0.385655  0.654010  0.525659   0.298050  0.002700  0.293422  0.303329   0.298735        NaN       NaN       NaN       NaN        NaN  0.022617  0.016564  0.007517  0.058175  0.009336   0.035716  0.061976  0.001258  0.237034   0.002235  0.000000  0.000000        0        0         0        1.0       0.0       1.0       1.0        1.0       0.0      0.0        0        0         0  0.078633  0.032018  0.032253  0.124283  0.081717   0.043231  0.013324  0.018395  0.054435   0.054184  2646.615385  350.316414     1898     3166      2402   0.063459   \n",
       "2        -1         -1  0.141160  0.065130  0.058534  0.241034  0.058534  0.059383  0.029516  0.023160  0.109238  0.090228  1.004163  0.003042  1.000286  1.009375  1.009375        NaN       NaN       NaN       NaN        NaN   0.000000  0.000000         0         0          0  0.005599  0.002235  0.001413  0.009300  0.008629  0.384615  0.506370        0        1         0   0.230020  0.018892  0.195193  0.243709   0.235105  0.670820  0.191084  0.381666  0.944176  0.566616   0.192089  0.088916  0.079202  0.298906   0.129189        NaN       NaN       NaN       NaN        NaN  0.007970  0.009604  0.000020  0.031101  0.004455   0.009048  0.007783  0.001162  0.025379   0.003380  0.000000  0.000000        0        0         0        1.0       0.0       1.0       1.0        1.0       0.0      0.0        0        0         0  0.166638  0.047825  0.082774  0.208820  0.170267   0.056018  0.002512  0.051632  0.059715   0.052914  1048.000000  651.710953        0     2402       379   0.282046   \n",
       "3        -1         -1  0.014650  0.004947  0.006839  0.023546  0.023546  0.313388  0.036721  0.206215  0.354177  0.206215  0.000000  0.000000  0.000000  0.000000  0.000000        NaN       NaN       NaN       NaN        NaN   0.000000  0.000000         0         0          0  0.449816  0.083461  0.185255  0.508892  0.185255  2.307692  1.436698        1        5         1   0.077970  0.003008  0.073267  0.082623   0.078085  0.610769  0.087494  0.464951  0.794439  0.628619   0.024276  0.006008  0.013830  0.032124   0.032124        NaN       NaN       NaN       NaN        NaN  0.251280  0.110203  0.037088  0.360818  0.320184   0.293207  0.048930  0.139062  0.326395   0.139062  0.000000  0.000000        0        0         0        1.0       0.0       1.0       1.0        1.0       0.0      0.0        0        0         0  0.557075  0.043996  0.461584  0.598874  0.552729   0.080164  0.007026  0.074469  0.098741   0.098741  1737.307692  364.872897     1454     2380      1511   0.553918   \n",
       "4        -1         -1  0.018187  0.004998  0.011244  0.026594  0.011244  0.270518  0.073986  0.175081  0.371814  0.261831  1.005365  0.003282  1.000343  1.009943  1.006200   0.025771  0.024183  0.002235  0.057087   0.039149   0.000000  0.000000         0         0          0  0.610471  0.036083  0.553405  0.656698  0.656698  2.230769  1.535895        0        4         0   0.017059  0.006432  0.003154  0.022643   0.021903  0.634829  0.126103  0.467448  0.877291  0.569771   0.024420  0.008093  0.012340  0.038865   0.022026        NaN       NaN       NaN       NaN        NaN  0.078128  0.021831  0.053537  0.111731  0.064127   0.419153  0.070155  0.323723  0.514632   0.514632  0.000000  0.000000        0        0         0        1.0       0.0       1.0       1.0        1.0       0.0      0.0        0        0         0  0.123415  0.017923  0.105129  0.151144  0.115010   0.015217  0.002851  0.010822  0.019775   0.016391   876.769231  749.660607        0     1898       772   0.619949   \n",
       "\n",
       "   D_55_std  D_55_min  D_55_max  D_55_last  D_56_mean  D_56_std  D_56_min  D_56_max  D_56_last  B_13_mean  B_13_std  B_13_min  B_13_max  B_13_last  R_5_mean  R_5_std  R_5_min  R_5_max  R_5_last  D_58_mean  D_58_std  D_58_min  D_58_max  D_58_last  S_9_mean   S_9_std   S_9_min   S_9_max  S_9_last  B_14_mean  B_14_std  B_14_min  B_14_max  B_14_last  D_59_mean   D_59_std  D_59_min  D_59_max  D_59_last  D_60_mean  D_60_std  D_60_min  D_60_max  D_60_last  D_61_mean  D_61_std  D_61_min  D_61_max  D_61_last  B_15_mean  B_15_std  B_15_min  B_15_max  B_15_last  S_11_mean  S_11_std  S_11_min  S_11_max  ...  D_107_max  D_107_last  B_36_mean  B_36_std  B_36_min  B_36_max  B_36_last  B_37_mean  B_37_std  B_37_min  B_37_max  B_37_last  R_26_mean  R_26_std  R_26_min  R_26_max  R_26_last  R_27_mean  R_27_std  R_27_min  R_27_max  R_27_last  D_108_mean  D_108_std  D_108_min  D_108_max  D_108_last  D_109_mean  D_109_std  D_109_min  D_109_max  D_109_last  D_110_mean  D_110_std  D_110_min  D_110_max  \\\n",
       "0  0.115253  0.114564  0.458377   0.458377        NaN       NaN       NaN       NaN        NaN   0.054207  0.016966  0.028347  0.069578   0.063506       0.0      0.0        0        0         0   0.377217  0.065622  0.205898  0.416276   0.381320  0.015570  0.004108  0.010773  0.022947  0.016998   0.018828  0.008068  0.008621  0.028865   0.008621  18.888889  11.285438        -1        25         25   0.042616  0.022548  0.013835  0.083740   0.013835   0.597552  0.016234  0.577867  0.622886   0.589184   0.020536  0.008908  0.010489  0.039339   0.014091  45.111111  8.709828        30        56  ...          0           0   0.004009  0.003770  0.000078  0.009113   0.001118   0.013483  0.005508  0.005756  0.022383   0.007948  -1.000000  0.000000        -1        -1         -1   1.006624  0.002284  1.002286  1.009223   1.002286        -1.0        0.0         -1         -1          -1         0.0        0.0          0          0           0         NaN        NaN        NaN        NaN   \n",
       "1  0.007567  0.050986  0.075262   0.053444   0.064233  0.003032  0.060207  0.069648   0.063766   0.099541  0.050890  0.027126  0.147346   0.058585       0.0      0.0        0        0         0   0.005272  0.002983  0.000569  0.009221   0.006375  0.155740  0.184706  0.018508  0.544298  0.018508   0.034238  0.028593  0.009963  0.116171   0.010847  32.846154   2.303843        28        36         34   0.507825  0.191927  0.244265  0.831362   0.685577   0.070053  0.029479  0.000629  0.113120   0.046726   0.004710  0.002485  0.001179  0.009936   0.005461   9.230769  1.589227         7        12  ...          0           0   0.005196  0.003279  0.000363  0.009707   0.007424   0.049217  0.068725  0.005031  0.271571   0.012894  -1.000000  0.000000        -1        -1         -1   1.004561  0.002922  1.000501  1.008918   1.000501        -1.0        0.0         -1         -1          -1         0.0        0.0          0          0           0         NaN        NaN        NaN        NaN   \n",
       "2  0.070444  0.207001  0.418986   0.418986        NaN       NaN       NaN       NaN        NaN   0.048400  0.018193  0.015644  0.075478   0.048129       0.0      0.0        0        0         0   0.131883  0.123385  0.001611  0.277115   0.272541  0.081942  0.175919  0.001582  0.551186  0.009170   0.014231  0.015788  0.000490  0.043197   0.004427  12.384615   0.506370        12        13         12   0.092388  0.152651  0.000776  0.427419   0.003803   0.317425  0.180088  0.064856  0.531674   0.508047   0.016268  0.017308  0.001282  0.047036   0.006497  25.846154  4.963973        14        33  ...          1           1   0.005952  0.002576  0.002185  0.009374   0.004671   0.013616  0.013069  0.001484  0.038614   0.005816  -1.000000  0.000000        -1        -1         -1   1.005486  0.002778  1.001447  1.009816   1.004291        -1.0        0.0         -1         -1          -1         0.0        0.0          0          0           0         NaN        NaN        NaN        NaN   \n",
       "3  0.024364  0.518958  0.596307   0.524700        NaN       NaN       NaN       NaN        NaN   0.080247  0.030293  0.034572  0.147453   0.147453       0.0      0.0        0        0         0   0.598498  0.107069  0.421512  0.733892   0.516813  0.010063  0.004278  0.002308  0.016637  0.012878   0.447280  0.056774  0.269620  0.481235   0.269620  38.538462   4.370648        31        43         43   0.672443  0.031605  0.632045  0.734601   0.641422   0.724770  0.042873  0.683347  0.845192   0.845192   0.368783  0.044457  0.252890  0.414407   0.252890  19.846154  4.862204        16        30  ...          1           1   0.004172  0.002816  0.000302  0.009784   0.002787   0.284763  0.043461  0.146753  0.309507   0.146753  -1.000000  0.000000        -1        -1         -1   1.003950  0.002583  1.000877  1.008107   1.001619        -1.0        0.0         -1         -1          -1         0.0        0.0          0          0           0         NaN        NaN        NaN        NaN   \n",
       "4  0.027672  0.573654  0.673749   0.673749        NaN       NaN       NaN       NaN        NaN   0.019157  0.007573  0.006022  0.037534   0.006022       0.0      0.0        0        0         0   0.257452  0.072315  0.082906  0.373130   0.182204  0.006081  0.003206  0.000601  0.009322  0.006939   0.142080  0.010468  0.125347  0.157513   0.157513  28.000000   1.414214        24        29         29   0.755093  0.042926  0.696405  0.858238   0.800289   0.804654  0.074316  0.614470  0.934916   0.893650   0.004243  0.002986  0.000375  0.009431   0.006982  15.846154  2.640901        11        20  ...          0           0   0.004175  0.002946  0.000347  0.009777   0.009777   0.459646  0.073802  0.357523  0.558505   0.558505  -0.230769  1.012739        -1         1          1   0.624714  0.501737  0.010850  1.008433   0.011080        -1.0        0.0         -1         -1          -1         0.0        0.0          0          0           0         NaN        NaN        NaN        NaN   \n",
       "\n",
       "   D_110_last  D_111_mean  D_111_std  D_111_min  D_111_max  D_111_last  B_39_mean  B_39_std  B_39_min  B_39_max  B_39_last  D_112_mean  D_112_std  D_112_min  D_112_max  D_112_last  B_40_mean  B_40_std  B_40_min  B_40_max  B_40_last  S_27_mean  S_27_std  S_27_min  S_27_max  S_27_last  D_113_mean  D_113_std  D_113_min  D_113_max  D_113_last  D_115_mean  D_115_std  D_115_min  D_115_max  D_115_last  D_118_mean  D_118_std  D_118_min  D_118_max  D_118_last  D_119_mean  D_119_std  D_119_min  D_119_max  D_119_last  D_121_mean  D_121_std  D_121_min  D_121_max  D_121_last  D_122_mean  D_122_std  D_122_min  D_122_max  D_122_last  D_123_mean  D_123_std  D_123_min  D_123_max  D_123_last  D_124_mean  D_124_std  D_124_min  D_124_max  D_124_last  D_125_mean  D_125_std  D_125_min  D_125_max  D_125_last  D_127_mean  D_127_std  D_127_min  D_127_max  D_127_last  D_128_mean  D_128_std  D_128_min  D_128_max  D_128_last  D_129_mean  D_129_std  D_129_min  D_129_max  D_129_last  B_41_mean  B_41_std  \\\n",
       "0         NaN        -1.0        0.0         -1         -1          -1        NaN       NaN       NaN       NaN        NaN    1.000000   0.000000   1.000000   1.000000    1.000000   0.368253  0.039012  0.274203  0.403018   0.375581   0.299671  0.122332  0.004302  0.390859   0.346436   -0.444444   0.527046         -1          0           0    0.252104   0.004236   0.247840   0.259002    0.251319    0.246912   0.004773   0.243366   0.255020    0.247260    0.247668   0.004234   0.242564   0.253783    0.253783    0.196751   0.002904   0.192405   0.199254    0.199254    0.111111   1.054093         -1          1           1   -0.444444   0.527046         -1          0           0    0.111111   1.054093         -1          1           1   -0.444444   0.527046         -1          0           0         0.0        0.0          0          0           0    0.000000   0.000000   0.000000   0.000000    0.000000   -0.111111   0.333333         -1          0           0        0.0       0.0   \n",
       "1         NaN        -1.0        0.0         -1         -1          -1        NaN       NaN       NaN       NaN        NaN    1.000000   0.000000   1.000000   1.000000    1.000000   0.025251  0.008362  0.005498  0.040057   0.005498   0.455466  0.159164  0.130432  0.675456   0.590974    0.000000   0.000000          0          0           0    0.309216   0.008609   0.298768   0.320178    0.317455    0.303904   0.009185   0.287581   0.316734    0.316734    0.303837   0.009210   0.285856   0.318151    0.318151    0.842254   0.007938   0.827385   0.854850    0.854850    4.000000   0.000000          4          4           4    0.000000   0.000000          0          0           0   15.000000   0.000000         15         15          15    0.000000   0.000000          0          0           0         0.0        0.0          0          0           0    1.003930   0.003068   0.999254   1.008954    0.999368    0.000000   0.000000          0          0           0        0.0       0.0   \n",
       "2         NaN        -1.0        0.0         -1         -1          -1        NaN       NaN       NaN       NaN        NaN    0.849524   0.367313   0.017070   1.000000    1.000000   0.055623  0.036971  0.011564  0.112604   0.096783   0.325662  0.309288  0.001439  0.631245   0.007752    2.000000   0.000000          2          2           2    0.269961   0.084998   0.078751   0.316599    0.079162    0.065339   0.009612   0.052496   0.082892    0.079331    0.064979   0.009726   0.051375   0.082290    0.079235    0.272082   0.006140   0.262928   0.280907    0.279283    2.000000   0.000000          2          2           2    0.000000   0.000000          0          0           0    7.000000   0.000000          7          7           7    0.000000   0.000000          0          0           0         0.0        0.0          0          0           0    0.000000   0.000000   0.000000   0.000000    0.000000    0.000000   0.000000          0          0           0        0.0       0.0   \n",
       "3         NaN        -1.0        0.0         -1         -1          -1        NaN       NaN       NaN       NaN        NaN    0.012544   0.004701   0.003437   0.021126    0.018601   0.359120  0.089880  0.206974  0.489678   0.228404   0.587414  0.201886  0.328769  1.045025   1.045025    1.000000   0.000000          1          1           1    0.021235   0.007864   0.005301   0.032392    0.032392    0.054029   0.069606   0.015212   0.212120    0.037828    0.050274   0.070854   0.012080   0.210552    0.032970    0.210834   0.008739   0.198072   0.223874    0.223874    1.000000   0.000000          1          1           1    0.384615   0.506370          0          1           0    4.000000   0.000000          4          4           4    0.384615   0.506370          0          1           0         0.0        0.0          0          0           0    0.000000   0.000000   0.000000   0.000000    0.000000    0.000000   0.000000          0          0           0        0.0       0.0   \n",
       "4         NaN        -1.0        0.0         -1         -1          -1        NaN       NaN       NaN       NaN        NaN    1.000000   0.000000   1.000000   1.000000    1.000000   0.068337  0.016252  0.051541  0.105340   0.081060   0.004661  0.001941  0.001691  0.006829   0.006672    0.000000   0.000000          0          0           0    0.126596   0.095712   0.006662   0.205729    0.015457    0.200060   0.007764   0.187697   0.210910    0.210910    0.199646   0.007656   0.187352   0.214071    0.214071    0.154799   0.008773   0.141394   0.170112    0.167715    1.000000   0.000000          1          1           1    0.000000   0.000000          0          0           0    1.000000   0.000000          1          1           1    0.000000   0.000000          0          0           0         0.0        0.0          0          0           0    0.540397   0.520745   0.000000   1.008702    1.003109    0.538462   0.518875          0          1           1        0.0       0.0   \n",
       "\n",
       "   B_41_min  B_41_max  B_41_last  B_42_mean  B_42_std  B_42_min  B_42_max  B_42_last  D_130_mean  D_130_std  D_130_min  D_130_max  D_130_last  D_131_mean  D_131_std  D_131_min  D_131_max  D_131_last  D_132_mean  D_132_std  D_132_min  D_132_max  D_132_last  D_133_mean  D_133_std  D_133_min  D_133_max  D_133_last  R_28_mean  R_28_std  R_28_min  R_28_max  R_28_last  D_134_mean  D_134_std  D_134_min  D_134_max  D_134_last  D_135_mean  D_135_std  D_135_min  D_135_max  D_135_last  D_136_mean  D_136_std  D_136_min  D_136_max  D_136_last  D_137_mean  D_137_std  D_137_min  D_137_max  D_137_last  D_138_mean  D_138_std  D_138_min  D_138_max  D_138_last  D_139_mean  D_139_std  D_139_min  D_139_max  D_139_last  D_140_mean  D_140_std  D_140_min  D_140_max  D_140_last  D_141_mean  D_141_std  D_141_min  D_141_max  D_141_last  D_142_mean  D_142_std  D_142_min  D_142_max  D_142_last  D_143_mean  D_143_std  D_143_min  D_143_max  D_143_last  D_144_mean  D_144_std  D_144_min  D_144_max  D_144_last  \\\n",
       "0         0         0          0        NaN       NaN       NaN       NaN        NaN    0.000000   0.000000   0.000000   0.000000     0.00000         0.0        0.0        0.0        0.0         0.0         NaN        NaN        NaN        NaN         NaN    0.004254   0.003084   0.000225   0.008436    0.006273        0.0       0.0         0         0          0         NaN        NaN        NaN        NaN         NaN        -1.0        0.0         -1         -1          -1        -1.0        0.0         -1         -1          -1        -1.0        0.0         -1         -1          -1        -1.0        0.0         -1         -1          -1   -0.111111   0.333333         -1          0           0         0.0        0.0          0          0           0    0.000000   0.000000   0.000000   0.000000    0.000000         NaN        NaN        NaN        NaN         NaN   -0.111111   0.333333         -1          0           0    0.005730   0.002398   0.002156   0.009667    0.003690   \n",
       "1         0         0          0        NaN       NaN       NaN       NaN        NaN    0.000000   0.000000   0.000000   0.000000     0.00000         0.0        0.0        0.0        0.0         0.0         NaN        NaN        NaN        NaN         NaN    0.004032   0.002541   0.000275   0.008720    0.002767        0.0       0.0         0         0          0         NaN        NaN        NaN        NaN         NaN        -1.0        0.0         -1         -1          -1        -1.0        0.0         -1         -1          -1        -1.0        0.0         -1         -1          -1        -1.0        0.0         -1         -1          -1    0.000000   0.000000          0          0           0         0.0        0.0          0          0           0    0.000000   0.000000   0.000000   0.000000    0.000000         NaN        NaN        NaN        NaN         NaN    0.000000   0.000000          0          0           0    0.005329   0.003125   0.000247   0.009734    0.000247   \n",
       "2         0         0          0        NaN       NaN       NaN       NaN        NaN    1.004558   0.003125   1.000023   1.009844     1.00389         0.0        0.0        0.0        0.0         0.0         NaN        NaN        NaN        NaN         NaN    0.005083   0.002324   0.001968   0.008024    0.002045        0.0       0.0         0         0          0         NaN        NaN        NaN        NaN         NaN        -1.0        0.0         -1         -1          -1        -1.0        0.0         -1         -1          -1        -1.0        0.0         -1         -1          -1        -1.0        0.0         -1         -1          -1    1.000000   0.000000          1          1           1         0.0        0.0          0          0           0    0.887847   0.005267   0.879781   0.896891    0.896224    0.128100   0.015235   0.103164   0.150203    0.150203    1.000000   0.000000          1          1           1    0.387283   0.042557   0.322121   0.457819    0.457819   \n",
       "3         0         0          0        NaN       NaN       NaN       NaN        NaN    0.000000   0.000000   0.000000   0.000000     0.00000         0.0        0.0        0.0        0.0         0.0         NaN        NaN        NaN        NaN         NaN    0.004191   0.002647   0.000903   0.009377    0.009377        0.0       0.0         0         0          0         NaN        NaN        NaN        NaN         NaN        -1.0        0.0         -1         -1          -1        -1.0        0.0         -1         -1          -1        -1.0        0.0         -1         -1          -1        -1.0        0.0         -1         -1          -1    1.000000   0.000000          1          1           1         0.0        0.0          0          0           0    0.909851   0.005265   0.901160   0.919774    0.919774    0.233945   0.015900   0.202383   0.257951    0.255263    1.000000   0.000000          1          1           1    0.439592   0.084648   0.333893   0.508652    0.500924   \n",
       "4         0         0          0        NaN       NaN       NaN       NaN        NaN    0.000000   0.000000   0.000000   0.000000     0.00000         0.0        0.0        0.0        0.0         0.0         NaN        NaN        NaN        NaN         NaN    0.005403   0.002284   0.000998   0.008477    0.007940        0.0       0.0         0         0          0         NaN        NaN        NaN        NaN         NaN        -1.0        0.0         -1         -1          -1        -1.0        0.0         -1         -1          -1        -1.0        0.0         -1         -1          -1        -1.0        0.0         -1         -1          -1    0.000000   0.000000          0          0           0         0.0        0.0          0          0           0    0.000000   0.000000   0.000000   0.000000    0.000000         NaN        NaN        NaN        NaN         NaN    0.000000   0.000000          0          0           0    0.004425   0.003232   0.000907   0.009656    0.001558   \n",
       "\n",
       "   D_145_mean  D_145_std  D_145_min  D_145_max  D_145_last  B_30_count  B_30_last  B_30_nunique  B_38_count  B_38_last  B_38_nunique  D_114_count  D_114_last  D_114_nunique  D_116_count  D_116_last  D_116_nunique  D_117_count  D_117_last  D_117_nunique  D_120_count  D_120_last  D_120_nunique  D_126_count  D_126_last  D_126_nunique  D_63_count  D_63_last  D_63_nunique  D_64_count  D_64_last  D_64_nunique  D_66_count  D_66_last  D_66_nunique  D_68_count  D_68_last  D_68_nunique  \n",
       "0   -0.111111   0.333333         -1          0           0           9          0             1           9          2             2            9           0              2            9           0              2            9           0              2            9           1              2            9           1              1           9          0             1           9          3             2           9         -1             1           9          6             2  \n",
       "1    0.000000   0.000000          0          0           0          13          0             1          13          2             2           13           1              1           13           0              1           13           4              1           13           0              1           13           2              1          13          3             1          13          0             1          13         -1             1          13          6             1  \n",
       "2    1.000000   0.000000          1          1           1          13          0             1          13          2             1           13           0              1           13           0              1           13           4              2           13           0              1           13           1              2          13          0             1          13          3             2          13          1             1          13          4             2  \n",
       "3    2.000000   0.000000          2          2           2          13          0             2          13          3             1           13           0              1           13           0              1           13           5              3           13           0              2           13           2              1          13          4             1          13          2             1          13         -1             1          13          5             1  \n",
       "4    0.000000   0.000000          0          0           0          13          1             2          13          6             3           13           0              1           13           0              1           13           0              1           13           1              2           13           1              1          13          3             1          13          2             2          13         -1             1          13          5             2  \n",
       "\n",
       "[5 rows x 919 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83979ae6-a3cf-487d-ac94-da96dfc1d93b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c6ceee6884346b694fd352569d728c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/903 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1188"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    \n",
    "cat_features = [\n",
    "    \"B_30\",\n",
    "    \"B_38\",\n",
    "    \"D_114\",\n",
    "    \"D_116\",\n",
    "    \"D_117\",\n",
    "    \"D_120\",\n",
    "    \"D_126\",\n",
    "    \"D_63\",\n",
    "    \"D_64\",\n",
    "    \"D_66\",\n",
    "    \"D_68\"\n",
    "]\n",
    "cat_features = [f\"{cf}_last\" for cf in cat_features]\n",
    "for cat_col in cat_features:\n",
    "    encoder = LabelEncoder()\n",
    "    train[cat_col] = encoder.fit_transform(train[cat_col])\n",
    "    test[cat_col] = encoder.transform(test[cat_col])\n",
    "# Round last float features to 2 decimal place\n",
    "num_cols = list(train.dtypes[(train.dtypes == 'float32') | (train.dtypes == 'float64')].index)\n",
    "num_cols = [col for col in num_cols if 'last' in col]\n",
    "for col in num_cols:\n",
    "    train[col + '_round2'] = train[col].round(2)\n",
    "    test[col + '_round2'] = test[col].round(2)\n",
    "# Get the difference between last and mean\n",
    "num_cols = [col for col in train.columns if 'last' in col]\n",
    "num_cols = [col[:-5] for col in num_cols if 'round' not in col]\n",
    "for col in num_cols:\n",
    "    try:\n",
    "        train[f'{col}_last_mean_diff'] = train[f'{col}_last'] - train[f'{col}_mean']\n",
    "        test[f'{col}_last_mean_diff'] = test[f'{col}_last'] - test[f'{col}_mean']\n",
    "    except:\n",
    "        pass\n",
    "# Transform float64 and float32 to float16\n",
    "num_cols = list(train.dtypes[(train.dtypes == 'float32') | (train.dtypes == 'float64')].index)\n",
    "for col in tqdm(num_cols):\n",
    "#     train[col] = train[col].astype(np.float16)\n",
    "    test[col] = test[col].astype(np.float16)\n",
    "# Get feature list\n",
    "features = [col for col in train.columns if col not in ['customer_ID', CFG.target]]\n",
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2967ddf-8f33-4966-b9a4-0c8cde55a911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "918"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e61853-72d3-4591-a311-28e2655b3b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold  :   0\n",
      "fold  :   1\n",
      "fold  :   2\n",
      "fold  :   3\n",
      "fold  :   4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "preds = []\n",
    "\n",
    "for fold in range(CFG.n_folds):\n",
    "    print('fold  :  ',fold)\n",
    "    model = CatBoostClassifier()\n",
    "    model.load_model(f\"../output/exp05 Cat lag feature/catboost_fold{fold}.cbm\")\n",
    "    \n",
    "    pred = model.predict_proba(test[features])[:, 1]\n",
    "    preds.append(pred)\n",
    "    del pred\n",
    "# score = amex_metric(train[CFG.target], oof_predictions)\n",
    "    \n",
    "test_predictions = np.mean(preds,axis = 0)\n",
    "\n",
    "# Create a dataframe to store out of folds predictions\n",
    "# oof_df = pd.DataFrame({'customer_ID': train['customer_ID'], 'target': train[CFG.target], 'prediction': oof_predictions})\n",
    "# oof_df.to_csv(f'../output/exp05 Cat lag feature/oof_{CFG.model}_{score}_baseline_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)\n",
    "# Create a dataframe to store test prediction\n",
    "test_df = pd.DataFrame({'customer_ID': test['customer_ID'], 'prediction': test_predictions})\n",
    "test_df.to_csv(f'../output/exp05 Cat lag feature/test_{CFG.model}_baseline_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed68bc1d-e73d-4113-bd4e-ab55fd4288a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a5a60d-4df5-48de-bc9a-1dced7a2cf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['prediction'].hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8f8cac-e289-4bf3-b916-c570f5f5f830",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d23ba6d-f35b-4ff5-8774-101425fd7671",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce478709-32b7-4d68-bda7-4928785a13b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/data/train.parquet'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19168\\217815574.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;31m# Read & Preprocess Data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m \u001b[0mread_preprocess_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19168\\217815574.py\u001b[0m in \u001b[0;36mread_preprocess_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;31m# ====================================================\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mread_preprocess_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/data/train.parquet'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m     \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'customer_ID'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'S_2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     cat_features = [\n",
      "\u001b[1;32m~\\anaconda3\\envs\\amex\\lib\\site-packages\\pandas\\io\\parquet.py\u001b[0m in \u001b[0;36mread_parquet\u001b[1;34m(path, engine, columns, storage_options, use_nullable_dtypes, **kwargs)\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    499\u001b[0m         \u001b[0muse_nullable_dtypes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_nullable_dtypes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 500\u001b[1;33m         \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    501\u001b[0m     )\n",
      "\u001b[1;32m~\\anaconda3\\envs\\amex\\lib\\site-packages\\pandas\\io\\parquet.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, path, columns, storage_options, **kwargs)\u001b[0m\n\u001b[0;32m    338\u001b[0m             \u001b[1;31m# this branch is used for example when reading from non-fsspec URLs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m             handles = get_handle(\n\u001b[1;32m--> 340\u001b[1;33m                 \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    341\u001b[0m             )\n\u001b[0;32m    342\u001b[0m             \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\amex\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    709\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m             \u001b[1;31m# Binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 711\u001b[1;33m             \u001b[0mhandle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    712\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    713\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/data/train.parquet'"
     ]
    }
   ],
   "source": [
    "\n",
    "# ====================================================\n",
    "# Get the difference\n",
    "# ====================================================\n",
    "def get_difference(data, num_features):\n",
    "    df1 = []\n",
    "    customer_ids = []\n",
    "    for customer_id, df in tqdm(data.groupby(['customer_ID'])):\n",
    "        # Get the differences\n",
    "        diff_df1 = df[num_features].diff(1).iloc[[-1]].values.astype(np.float32)\n",
    "        # Append to lists\n",
    "        df1.append(diff_df1)\n",
    "        customer_ids.append(customer_id)\n",
    "    # Concatenate\n",
    "    df1 = np.concatenate(df1, axis = 0)\n",
    "    # Transform to dataframe\n",
    "    df1 = pd.DataFrame(df1, columns = [col + '_diff1' for col in df[num_features].columns])\n",
    "    # Add customer id\n",
    "    df1['customer_ID'] = customer_ids\n",
    "    return df1\n",
    "\n",
    "# ====================================================\n",
    "# Read & preprocess data and save it to disk\n",
    "# ====================================================\n",
    "def read_preprocess_data():\n",
    "    train = pd.read_parquet('/content/data/train.parquet')\n",
    "    features = train.drop(['customer_ID', 'S_2'], axis = 1).columns.to_list()\n",
    "    cat_features = [\n",
    "        \"B_30\",\n",
    "        \"B_38\",\n",
    "        \"D_114\",\n",
    "        \"D_116\",\n",
    "        \"D_117\",\n",
    "        \"D_120\",\n",
    "        \"D_126\",\n",
    "        \"D_63\",\n",
    "        \"D_64\",\n",
    "        \"D_66\",\n",
    "        \"D_68\",\n",
    "    ]\n",
    "    num_features = [col for col in features if col not in cat_features]\n",
    "    print('Starting training feature engineer...')\n",
    "    train_num_agg = train.groupby(\"customer_ID\")[num_features].agg(['mean', 'std', 'min', 'max', 'last'])\n",
    "    train_num_agg.columns = ['_'.join(x) for x in train_num_agg.columns]\n",
    "    train_num_agg.reset_index(inplace = True)\n",
    "    train_cat_agg = train.groupby(\"customer_ID\")[cat_features].agg(['count', 'last', 'nunique'])\n",
    "    train_cat_agg.columns = ['_'.join(x) for x in train_cat_agg.columns]\n",
    "    train_cat_agg.reset_index(inplace = True)\n",
    "    train_labels = pd.read_csv('../input/amex-default-prediction/train_labels.csv')\n",
    "    # Transform float64 columns to float32\n",
    "    cols = list(train_num_agg.dtypes[train_num_agg.dtypes == 'float64'].index)\n",
    "    for col in tqdm(cols):\n",
    "        train_num_agg[col] = train_num_agg[col].astype(np.float32)\n",
    "    # Transform int64 columns to int32\n",
    "    cols = list(train_cat_agg.dtypes[train_cat_agg.dtypes == 'int64'].index)\n",
    "    for col in tqdm(cols):\n",
    "        train_cat_agg[col] = train_cat_agg[col].astype(np.int32)\n",
    "    # Get the difference\n",
    "    train_diff = get_difference(train, num_features)\n",
    "    train = train_num_agg.merge(train_cat_agg, how = 'inner', on = 'customer_ID').merge(train_diff, how = 'inner', on = 'customer_ID').merge(train_labels, how = 'inner', on = 'customer_ID')\n",
    "    del train_num_agg, train_cat_agg, train_diff\n",
    "    gc.collect()\n",
    "    test = pd.read_parquet('../input/amex-fe/test_fe.parquet')\n",
    "    print('Starting test feature engineer...')\n",
    "    test_num_agg = test.groupby(\"customer_ID\")[num_features].agg(['mean', 'std', 'min', 'max', 'last'])\n",
    "    test_num_agg.columns = ['_'.join(x) for x in test_num_agg.columns]\n",
    "    test_num_agg.reset_index(inplace = True)\n",
    "    test_cat_agg = test.groupby(\"customer_ID\")[cat_features].agg(['count', 'last', 'nunique'])\n",
    "    test_cat_agg.columns = ['_'.join(x) for x in test_cat_agg.columns]\n",
    "    test_cat_agg.reset_index(inplace = True)\n",
    "    # Transform float64 columns to float32\n",
    "    cols = list(test_num_agg.dtypes[test_num_agg.dtypes == 'float64'].index)\n",
    "    for col in tqdm(cols):\n",
    "        test_num_agg[col] = test_num_agg[col].astype(np.float32)\n",
    "    # Transform int64 columns to int32\n",
    "    cols = list(test_cat_agg.dtypes[test_cat_agg.dtypes == 'int64'].index)\n",
    "    for col in tqdm(cols):\n",
    "        test_cat_agg[col] = test_cat_agg[col].astype(np.int32)\n",
    "    # Get the difference\n",
    "    test_diff = get_difference(test, num_features)\n",
    "    test = test_num_agg.merge(test_cat_agg, how = 'inner', on = 'customer_ID').merge(test_diff, how = 'inner', on = 'customer_ID')\n",
    "    del test_num_agg, test_cat_agg, test_diff\n",
    "    gc.collect()\n",
    "    # Save files to disk\n",
    "    train.to_parquet('../input/amex-fe/train_fe.parquet')\n",
    "    test.to_parquet('../input/amex-fe/test_fe.parquet')\n",
    "\n",
    "# Read & Preprocess Data\n",
    "read_preprocess_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e80847-25f2-4784-97c5-b8012eae1a3e",
   "metadata": {},
   "source": [
    "# Training & Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c68ef141-3c78-4cd6-988b-db0421753882",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# # ====================================================\n",
    "# # Configurations\n",
    "# # ====================================================\n",
    "# class CFG:\n",
    "#     input_dir = '../input/amex-fe/'\n",
    "#     seed = 45\n",
    "#     n_folds = 5\n",
    "#     target = 'target'\n",
    "#     boosting_type = 'dart'\n",
    "#     metric = 'binary_logloss'\n",
    "#     model = \"XGB\"\n",
    "\n",
    "# # ====================================================\n",
    "# # Seed everything\n",
    "# # ====================================================\n",
    "# def seed_everything(seed):\n",
    "#     random.seed(seed)\n",
    "#     np.random.seed(seed)\n",
    "#     os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "# # ====================================================\n",
    "# # Read data\n",
    "# # ====================================================\n",
    "# def read_data():\n",
    "#     train = pd.read_parquet(CFG.input_dir + 'train_fe.parquet')\n",
    "#     test = pd.read_parquet(CFG.input_dir + 'test_fe.parquet')\n",
    "#     return train, test\n",
    "\n",
    "# # ====================================================\n",
    "# # XGB train\n",
    "# # ====================================================\n",
    "\n",
    "# def cat_train(x, y, xt, yt,cat_features):\n",
    "#     print(\"# of features:\", x.shape[1])\n",
    "#     assert x.shape[1] == xt.shape[1]\n",
    "# #     dtrain = xgb.DMatrix(data=x, label=y)\n",
    "# #     dvalid = xgb.DMatrix(data=xt, label=yt)\n",
    "\n",
    "# #     watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "#     watchlist = [(x, 'train'), (xt, 'eval')]\n",
    "#     clf = CatBoostClassifier(iterations=10, random_state=CFG.seed)# 5000\n",
    "#     clf.fit(x, y, eval_set=[(xt, yt)], cat_features=cat_features,plot=True,verbose_eval=100)\n",
    "#     print('best ntree_limit:', bst.best_ntree_limit)\n",
    "#     print('best score:', bst.best_score)\n",
    "#     # return clf.predict_proba(xt)[:, 1]\n",
    "#     return clf.predict_proba(xt)[:, 1], clf\n",
    "\n",
    "\n",
    "\n",
    "# # ====================================================\n",
    "# # Amex metric\n",
    "# # ====================================================\n",
    "# def amex_metric(y_true, y_pred):\n",
    "#     labels = np.transpose(np.array([y_true, y_pred]))\n",
    "#     labels = labels[labels[:, 1].argsort()[::-1]]\n",
    "#     weights = np.where(labels[:,0]==0, 20, 1)\n",
    "#     cut_vals = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n",
    "#     top_four = np.sum(cut_vals[:,0]) / np.sum(labels[:,0])\n",
    "#     gini = [0,0]\n",
    "#     for i in [1,0]:\n",
    "#         labels = np.transpose(np.array([y_true, y_pred]))\n",
    "#         labels = labels[labels[:, i].argsort()[::-1]]\n",
    "#         weight = np.where(labels[:,0]==0, 20, 1)\n",
    "#         weight_random = np.cumsum(weight / np.sum(weight))\n",
    "#         total_pos = np.sum(labels[:, 0] *  weight)\n",
    "#         cum_pos_found = np.cumsum(labels[:, 0] * weight)\n",
    "#         lorentz = cum_pos_found / total_pos\n",
    "#         gini[i] = np.sum((lorentz - weight_random) * weight)\n",
    "#     return 0.5 * (gini[1]/gini[0] + top_four)\n",
    "\n",
    "\n",
    "# def xgb_amex(y_pred, y_true):\n",
    "#     return 'amex', amex_metric_np(y_pred,y_true.get_label())\n",
    "\n",
    "\n",
    "# # Created by https://www.kaggle.com/yunchonggan\n",
    "# # https://www.kaggle.com/competitions/amex-default-prediction/discussion/328020\n",
    "# def amex_metric_np(preds: np.ndarray, target: np.ndarray) -> float:\n",
    "#     indices = np.argsort(preds)[::-1]\n",
    "#     preds, target = preds[indices], target[indices]\n",
    "\n",
    "#     weight = 20.0 - target * 19.0\n",
    "#     cum_norm_weight = (weight / weight.sum()).cumsum()\n",
    "#     four_pct_mask = cum_norm_weight <= 0.04\n",
    "#     d = np.sum(target[four_pct_mask]) / np.sum(target)\n",
    "\n",
    "#     weighted_target = target * weight\n",
    "#     lorentz = (weighted_target / weighted_target.sum()).cumsum()\n",
    "#     gini = ((lorentz - cum_norm_weight) * weight).sum()\n",
    "\n",
    "#     n_pos = np.sum(target)\n",
    "#     n_neg = target.shape[0] - n_pos\n",
    "#     gini_max = 10 * n_neg * (n_pos + 20 * n_neg - 19) / (n_pos + 20 * n_neg)\n",
    "\n",
    "#     g = gini / gini_max\n",
    "#     return 0.5 * (g + d)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # ====================================================\n",
    "# # Train & Evaluate\n",
    "# # ====================================================\n",
    "# def train_and_evaluate(train, test):\n",
    "#     # Label encode categorical features\n",
    "#     cat_features = [\n",
    "#         \"B_30\",\n",
    "#         \"B_38\",\n",
    "#         \"D_114\",\n",
    "#         \"D_116\",\n",
    "#         \"D_117\",\n",
    "#         \"D_120\",\n",
    "#         \"D_126\",\n",
    "#         \"D_63\",\n",
    "#         \"D_64\",\n",
    "#         \"D_66\",\n",
    "#         \"D_68\"\n",
    "#     ]\n",
    "#     cat_features = [f\"{cf}_last\" for cf in cat_features]\n",
    "#     for cat_col in cat_features:\n",
    "#         encoder = LabelEncoder()\n",
    "#         train[cat_col] = encoder.fit_transform(train[cat_col])\n",
    "#         test[cat_col] = encoder.transform(test[cat_col])\n",
    "#     # Round last float features to 2 decimal place\n",
    "#     num_cols = list(train.dtypes[(train.dtypes == 'float32') | (train.dtypes == 'float64')].index)\n",
    "#     num_cols = [col for col in num_cols if 'last' in col]\n",
    "#     for col in num_cols:\n",
    "#         train[col + '_round2'] = train[col].round(2)\n",
    "#         test[col + '_round2'] = test[col].round(2)\n",
    "#     # Get the difference between last and mean\n",
    "#     num_cols = [col for col in train.columns if 'last' in col]\n",
    "#     num_cols = [col[:-5] for col in num_cols if 'round' not in col]\n",
    "#     for col in num_cols:\n",
    "#         try:\n",
    "#             train[f'{col}_last_mean_diff'] = train[f'{col}_last'] - train[f'{col}_mean']\n",
    "#             test[f'{col}_last_mean_diff'] = test[f'{col}_last'] - test[f'{col}_mean']\n",
    "#         except:\n",
    "#             pass\n",
    "#     # Transform float64 and float32 to float16\n",
    "#     num_cols = list(train.dtypes[(train.dtypes == 'float32') | (train.dtypes == 'float64')].index)\n",
    "#     for col in tqdm(num_cols):\n",
    "#         train[col] = train[col].astype(np.float16)\n",
    "#         test[col] = test[col].astype(np.float16)\n",
    "#     # Get feature list\n",
    "#     features = [col for col in train.columns if col not in ['customer_ID', CFG.target]]\n",
    "    \n",
    "# #     params = {\n",
    "# #         'objective': 'binary:logistic', \n",
    "# #         'tree_method': 'hist', #gpu_hist #hist\n",
    "# #         'max_depth': 7,\n",
    "# #         'subsample':0.88,\n",
    "# #         'colsample_bytree': 0.5,\n",
    "# #         'gamma':1.5,\n",
    "# #         'min_child_weight':8,\n",
    "# #         'lambda':70,\n",
    "# #         'eta':0.03}\n",
    "    \n",
    "#     # Create a numpy array to store test predictions\n",
    "#     test_predictions = np.zeros(len(test))\n",
    "#     # Create a numpy array to store out of folds predictions\n",
    "#     oof_predictions = np.zeros(len(train))\n",
    "#     kfold = StratifiedKFold(n_splits = CFG.n_folds, shuffle = True, random_state = CFG.seed)\n",
    "#     for fold, (trn_ind, val_ind) in enumerate(kfold.split(train, train[CFG.target])):\n",
    "#         print(' ')\n",
    "#         print('-'*50)\n",
    "#         print(f'Training fold {fold} with {len(features)} features...')\n",
    "#         x_train, x_val = train[features].iloc[trn_ind], train[features].iloc[val_ind]\n",
    "#         y_train, y_val = train[CFG.target].iloc[trn_ind], train[CFG.target].iloc[val_ind]\n",
    "#         # lgb_train = lgb.Dataset(x_train, y_train, categorical_feature = cat_features)\n",
    "#         # lgb_valid = lgb.Dataset(x_val, y_val, categorical_feature = cat_features)\n",
    "        \n",
    "#         val_pred , model = cat_train(x_train, y_train, x_val, y_val,cat_features)\n",
    "        \n",
    "#         model.save_model(f\"../output/exp05 Cat lag feature/catboost_fold{fold}.cbm\")\n",
    "#         # Save best model\n",
    "#         # joblib.dump(model, f'../output/exp04 XGB lag feature/{CFG.model}_{CFG.boosting_type}_fold{fold}_seed{CFG.seed}.pkl')\n",
    "#         # Predict validation\n",
    "        \n",
    "#         # val_pred = model.predict(x_val)\n",
    "        \n",
    "#         # Add to out of folds array\n",
    "#         oof_predictions[val_ind] = val_pred\n",
    "#         # Predict the test set\n",
    "        \n",
    "        \n",
    "#         dtest = xgb.DMatrix(data=test[features])\n",
    "#         test_pred = model.predict(dtest)\n",
    "#         test_predictions += test_pred / CFG.n_folds\n",
    "        \n",
    "#         # Compute fold metric\n",
    "#         score = amex_metric(y_val, val_pred)\n",
    "#         print(f'Our fold {fold} CV score is {score}')\n",
    "#         del x_train, x_val, y_train, y_val\n",
    "#         gc.collect()\n",
    "#     # Compute out of folds metric\n",
    "#     score = amex_metric(train[CFG.target], oof_predictions)\n",
    "#     print(f'Our out of folds CV score is {score}')\n",
    "#     # Create a dataframe to store out of folds predictions\n",
    "#     oof_df = pd.DataFrame({'customer_ID': train['customer_ID'], 'target': train[CFG.target], 'prediction': oof_predictions})\n",
    "#     oof_df.to_csv(f'../output/exp05 Cat lag feature/oof_{CFG.model}_{CFG.boosting_type}_baseline_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)\n",
    "#     # Create a dataframe to store test prediction\n",
    "#     test_df = pd.DataFrame({'customer_ID': test['customer_ID'], 'prediction': test_predictions})\n",
    "#     test_df.to_csv(f'../output/exp05 Cat lag feature/test_{CFG.model}_{CFG.boosting_type}_baseline_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3638c92e-7e65-43e5-8a69-e2aef6660f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ====================================================\n",
    "# Configurations\n",
    "# ====================================================\n",
    "class CFG:\n",
    "    input_dir = '../input/amex-fe/'\n",
    "    seed = 45\n",
    "    n_folds = 5\n",
    "    target = 'target'\n",
    "    boosting_type = 'dart'\n",
    "    metric = 'binary_logloss'\n",
    "    model = \"cat\"\n",
    "\n",
    "# ====================================================\n",
    "# Seed everything\n",
    "# ====================================================\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "# ====================================================\n",
    "# Read data\n",
    "# ====================================================\n",
    "def read_data():\n",
    "    train = pd.read_parquet(CFG.input_dir + 'train_fe.parquet')\n",
    "    test = pd.read_parquet(CFG.input_dir + 'test_fe.parquet')\n",
    "    return train, test\n",
    "\n",
    "# ====================================================\n",
    "# XGB train\n",
    "# ====================================================\n",
    "\n",
    "def cat_train(x, y, xt, yt,cat_features):\n",
    "    print(\"# of features:\", x.shape[1])\n",
    "    assert x.shape[1] == xt.shape[1]\n",
    "#     dtrain = xgb.DMatrix(data=x, label=y)\n",
    "#     dvalid = xgb.DMatrix(data=xt, label=yt)\n",
    "\n",
    "#     watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "    watchlist = [(x, 'train'), (xt, 'eval')]\n",
    "    clf = CatBoostClassifier(iterations=10 , random_state=CFG.seed)# 5000\n",
    "    clf.fit(x, y, eval_set=[(xt, yt)], cat_features=cat_features,plot=True,verbose_eval=100)\n",
    "#     print('best ntree_limit:', clf.best_ntree_limit)\n",
    "#     print('best score:', clf.best_score)\n",
    "    # return clf.predict_proba(xt)[:, 1]\n",
    "    return clf.predict_proba(xt)[:, 1], clf\n",
    "\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# Amex metric\n",
    "# ====================================================\n",
    "def amex_metric(y_true, y_pred):\n",
    "    labels = np.transpose(np.array([y_true, y_pred]))\n",
    "    labels = labels[labels[:, 1].argsort()[::-1]]\n",
    "    weights = np.where(labels[:,0]==0, 20, 1)\n",
    "    cut_vals = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n",
    "    top_four = np.sum(cut_vals[:,0]) / np.sum(labels[:,0])\n",
    "    gini = [0,0]\n",
    "    for i in [1,0]:\n",
    "        labels = np.transpose(np.array([y_true, y_pred]))\n",
    "        labels = labels[labels[:, i].argsort()[::-1]]\n",
    "        weight = np.where(labels[:,0]==0, 20, 1)\n",
    "        weight_random = np.cumsum(weight / np.sum(weight))\n",
    "        total_pos = np.sum(labels[:, 0] *  weight)\n",
    "        cum_pos_found = np.cumsum(labels[:, 0] * weight)\n",
    "        lorentz = cum_pos_found / total_pos\n",
    "        gini[i] = np.sum((lorentz - weight_random) * weight)\n",
    "    return 0.5 * (gini[1]/gini[0] + top_four)\n",
    "\n",
    "\n",
    "def xgb_amex(y_pred, y_true):\n",
    "    return 'amex', amex_metric_np(y_pred,y_true.get_label())\n",
    "\n",
    "\n",
    "# Created by https://www.kaggle.com/yunchonggan\n",
    "# https://www.kaggle.com/competitions/amex-default-prediction/discussion/328020\n",
    "def amex_metric_np(preds: np.ndarray, target: np.ndarray) -> float:\n",
    "    indices = np.argsort(preds)[::-1]\n",
    "    preds, target = preds[indices], target[indices]\n",
    "\n",
    "    weight = 20.0 - target * 19.0\n",
    "    cum_norm_weight = (weight / weight.sum()).cumsum()\n",
    "    four_pct_mask = cum_norm_weight <= 0.04\n",
    "    d = np.sum(target[four_pct_mask]) / np.sum(target)\n",
    "\n",
    "    weighted_target = target * weight\n",
    "    lorentz = (weighted_target / weighted_target.sum()).cumsum()\n",
    "    gini = ((lorentz - cum_norm_weight) * weight).sum()\n",
    "\n",
    "    n_pos = np.sum(target)\n",
    "    n_neg = target.shape[0] - n_pos\n",
    "    gini_max = 10 * n_neg * (n_pos + 20 * n_neg - 19) / (n_pos + 20 * n_neg)\n",
    "\n",
    "    g = gini / gini_max\n",
    "    return 0.5 * (g + d)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30007ce2-4854-4fd8-8c1b-477936511e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(CFG.seed)\n",
    "train, test = read_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54d5aa37-ce2a-4fd7-a211-d4665fe081b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_and_evaluate(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b719cd4-45c3-4dba-8955-cb37b93b1f31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f8228e8c7184bfba358deb2b8b0c59e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/903 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "--------------------------------------------------\n",
      "Training fold 0 with 1188 features...\n",
      "# of features: 1188\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "244603bdb45c4092b1c8a1e5a28421bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.5\n",
      "0:\tlearn: 0.3468797\ttest: 0.3458842\tbest: 0.3458842 (0)\ttotal: 509ms\tremaining: 4.58s\n",
      "9:\tlearn: 0.2362416\ttest: 0.2372715\tbest: 0.2372715 (9)\ttotal: 3.49s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2372715242\n",
      "bestIteration = 9\n",
      "\n",
      "Our fold 0 CV score is 0.7635021297863451\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 1 with 1188 features...\n",
      "# of features: 1188\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb7b910cb4194a6bbb997c26d206ae8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.5\n",
      "0:\tlearn: 0.3422674\ttest: 0.3409969\tbest: 0.3409969 (0)\ttotal: 349ms\tremaining: 3.14s\n",
      "9:\tlearn: 0.2368210\ttest: 0.2341594\tbest: 0.2341594 (9)\ttotal: 3.2s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2341593566\n",
      "bestIteration = 9\n",
      "\n",
      "Our fold 1 CV score is 0.7706715796909434\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 2 with 1188 features...\n",
      "# of features: 1188\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# Train & Evaluate\n",
    "# ====================================================\n",
    "# def train_and_evaluate(train, test):\n",
    "    # Label encode categorical features\n",
    "    \n",
    "cat_features = [\n",
    "    \"B_30\",\n",
    "    \"B_38\",\n",
    "    \"D_114\",\n",
    "    \"D_116\",\n",
    "    \"D_117\",\n",
    "    \"D_120\",\n",
    "    \"D_126\",\n",
    "    \"D_63\",\n",
    "    \"D_64\",\n",
    "    \"D_66\",\n",
    "    \"D_68\"\n",
    "]\n",
    "cat_features = [f\"{cf}_last\" for cf in cat_features]\n",
    "for cat_col in cat_features:\n",
    "    encoder = LabelEncoder()\n",
    "    train[cat_col] = encoder.fit_transform(train[cat_col])\n",
    "    test[cat_col] = encoder.transform(test[cat_col])\n",
    "# Round last float features to 2 decimal place\n",
    "num_cols = list(train.dtypes[(train.dtypes == 'float32') | (train.dtypes == 'float64')].index)\n",
    "num_cols = [col for col in num_cols if 'last' in col]\n",
    "for col in num_cols:\n",
    "    train[col + '_round2'] = train[col].round(2)\n",
    "    test[col + '_round2'] = test[col].round(2)\n",
    "# Get the difference between last and mean\n",
    "num_cols = [col for col in train.columns if 'last' in col]\n",
    "num_cols = [col[:-5] for col in num_cols if 'round' not in col]\n",
    "for col in num_cols:\n",
    "    try:\n",
    "        train[f'{col}_last_mean_diff'] = train[f'{col}_last'] - train[f'{col}_mean']\n",
    "        test[f'{col}_last_mean_diff'] = test[f'{col}_last'] - test[f'{col}_mean']\n",
    "    except:\n",
    "        pass\n",
    "# Transform float64 and float32 to float16\n",
    "num_cols = list(train.dtypes[(train.dtypes == 'float32') | (train.dtypes == 'float64')].index)\n",
    "for col in tqdm(num_cols):\n",
    "    train[col] = train[col].astype(np.float16)\n",
    "    test[col] = test[col].astype(np.float16)\n",
    "# Get feature list\n",
    "features = [col for col in train.columns if col not in ['customer_ID', CFG.target]]\n",
    "\n",
    "#     params = {\n",
    "#         'objective': 'binary:logistic', \n",
    "#         'tree_method': 'hist', #gpu_hist #hist\n",
    "#         'max_depth': 7,\n",
    "#         'subsample':0.88,\n",
    "#         'colsample_bytree': 0.5,\n",
    "#         'gamma':1.5,\n",
    "#         'min_child_weight':8,\n",
    "#         'lambda':70,\n",
    "#         'eta':0.03}\n",
    "\n",
    "# Create a numpy array to store test predictions\n",
    "test_predictions = np.zeros(len(test))\n",
    "# Create a numpy array to store out of folds predictions\n",
    "oof_predictions = np.zeros(len(train))\n",
    "\n",
    "# cid = []\n",
    "# cids = []\n",
    "\n",
    "preds = []\n",
    "\n",
    "kfold = StratifiedKFold(n_splits = CFG.n_folds, shuffle = True, random_state = CFG.seed)\n",
    "for fold, (trn_ind, val_ind) in enumerate(kfold.split(train, train[CFG.target])):\n",
    "    print(' ')\n",
    "    print('-'*50)\n",
    "    print(f'Training fold {fold} with {len(features)} features...')\n",
    "    \n",
    "    x_train, x_val = train[features].iloc[trn_ind], train[features].iloc[val_ind]\n",
    "    y_train, y_val = train[CFG.target].iloc[trn_ind], train[CFG.target].iloc[val_ind]\n",
    "    # lgb_train = lgb.Dataset(x_train, y_train, categorical_feature = cat_features)\n",
    "    # lgb_valid = lgb.Dataset(x_val, y_val, categorical_feature = cat_features)\n",
    "\n",
    "    val_pred , model = cat_train(x_train, y_train, x_val, y_val,cat_features)\n",
    "\n",
    "    model.save_model(f\"../output/exp05 Cat lag feature/catboost_fold{fold}.cbm\")\n",
    "    # Save best model\n",
    "    # joblib.dump(model, f'../output/exp04 XGB lag feature/{CFG.model}_{CFG.boosting_type}_fold{fold}_seed{CFG.seed}.pkl')\n",
    "    # Predict validation\n",
    "\n",
    "    # val_pred = model.predict(x_val)\n",
    "\n",
    "    # Add to out of folds array\n",
    "    oof_predictions[val_ind] = val_pred\n",
    "    # Predict the test set\n",
    "\n",
    "\n",
    "#     dtest = xgb.DMatrix(data=test[features])\n",
    "    pred = model.predict_proba(test[features])[:, 1]\n",
    "    preds.append(pred)\n",
    "    \n",
    "#     test_predictions += test_pred / CFG.n_folds\n",
    "\n",
    "    # Compute fold metric\n",
    "    score = amex_metric(y_val, val_pred)\n",
    "    print(f'Our fold {fold} CV score is {score}')\n",
    "    del x_train, x_val, y_train, y_val, pred\n",
    "    gc.collect()\n",
    "# Compute out of folds metric\n",
    "score = amex_metric(train[CFG.target], oof_predictions)\n",
    "print(f'Our out of folds CV score is {score}')\n",
    "\n",
    "test_predictions = np.mean(preds,axis = 0)\n",
    "\n",
    "# Create a dataframe to store out of folds predictions\n",
    "oof_df = pd.DataFrame({'customer_ID': train['customer_ID'], 'target': train[CFG.target], 'prediction': oof_predictions})\n",
    "oof_df.to_csv(f'../output/exp05 Cat lag feature/oof_{CFG.model}_{score}_baseline_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)\n",
    "# Create a dataframe to store test prediction\n",
    "test_df = pd.DataFrame({'customer_ID': test['customer_ID'], 'prediction': test_predictions})\n",
    "test_df.to_csv(f'../output/exp05 Cat lag feature/test_{CFG.model}_{score}_baseline_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6031cf-f767-4551-afb2-6feb6efd9dba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220db67f-9a57-436b-9ec6-8732c6c6fe67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f770440-1df8-4a28-80c7-a3499e807a13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f3f7fd-7bd1-4e92-93a9-4a18f035feca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amex",
   "language": "python",
   "name": "amex"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
