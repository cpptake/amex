{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36a91cb1-484a-4d3d-b856-8235a0af3a02",
   "metadata": {},
   "source": [
    "# 1500 feature\n",
    "\n",
    "特徴量作成Notebook\n",
    "https://www.kaggle.com/code/illidan7/amex-basic-feature-engineering-1500-features\n",
    "\n",
    "\n",
    "## やってること\n",
    "### read_file\n",
    "S_2_dayofweek（曜日特徴量）、S_2_dayofmonth（日付特徴量　：　１日なら”１”、など）  \n",
    "S_2_diff(days_since_1970 から何日経っているか),S_2_diff（）\n",
    "\n",
    "\"after pay\" features　　\n",
    "「後払い」機能 (https://www.kaggle.com/code/jiweiliu/rapids-cudf-feature-engineering-xgb)\n",
    "\n",
    "\n",
    "Null列の処理\n",
    "\n",
    "* >30%以上のNULLの場合、NULLを数える\n",
    "* >90%以上のNULLの場合、最後の1つだけを残す\n",
    "\n",
    "### process_and_feature_engineer\n",
    "\n",
    "* cat1特徴量 (コンペデータ・ページで言及されたカテゴリカル特徴量) https://www.kaggle.com/competitions/amex-default-prediction/data\n",
    "* cat2特徴量 (低カーディナリティ特徴量; <=4 unique values)\n",
    "* cat3特徴量 (低カーディナリティ特徴量; >=8 および <=21 ユニーク値)\n",
    "\n",
    "* 最後 - 最初 (https://www.kaggle.com/code/thedevastator/lag-features-are-all-you-need)\n",
    "* 最後の特徴 - 平均特徴 (https://www.kaggle.com/code/ragnar123/amex-lgbm-dart-cv-0-7977)\n",
    "\n",
    "\n",
    "# 参考文献\n",
    "https://www.kaggle.com/code/cdeotte/xgboost-starter-0-793\n",
    "https://www.kaggle.com/competitions/amex-default-prediction/discussion/333940\n",
    "https://www.kaggle.com/datasets/raddar/amex-data-integer-dtypes-parquet-format\n",
    "\n",
    "\n",
    "# 感想\n",
    "これにLag特徴量加えたらいいのでは？\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3ed8669-5e5b-4f99-b411-8e589913bb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # LOAD LIBRARIES\n",
    "# import pandas as pd, numpy as np # CPU libraries\n",
    "# import cupy, cudf # GPU libraries\n",
    "# import matplotlib.pyplot as plt, gc, os\n",
    "# import seaborn as sns\n",
    "\n",
    "# print('RAPIDS version',cudf.__version__)\n",
    "\n",
    "# ====================================================\n",
    "# Library\n",
    "# ====================================================\n",
    "import os\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "from tqdm.auto import tqdm\n",
    "import itertools\n",
    "\n",
    "import joblib\n",
    "import random\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "from itertools import combinations\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import snappy\n",
    "# from ipywidgets import interact, Select\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1875e8d-bbc0-4bf6-8371-c43377800a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CFG:\n",
    "#     input_dir = '../input/amex-fe/'\n",
    "#     seed = 45\n",
    "#     n_folds = 5\n",
    "#     target = 'target'\n",
    "#     boosting_type = 'dart'\n",
    "#     metric = 'binary_logloss'\n",
    "#     model = \"cat\"\n",
    "# train = pd.read_parquet(CFG.input_dir + 'train_fe.parquet')\n",
    "# # train2 = pd.read_csv('../input/amex-default-prediction/train_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64b4862-631a-4fd4-9aa7-ae84cc16f06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def read_file(path = '', usecols = None):\n",
    "    \n",
    "    # LOAD DATAFRAME\n",
    "    if usecols is not None: df = cudf.read_parquet(path, columns=usecols)\n",
    "    else: df = cudf.read_parquet(path)\n",
    "    \n",
    "    # REDUCE DTYPE FOR CUSTOMER AND DATE\n",
    "    df['customer_ID'] = df['customer_ID'].str[-16:].str.hex_to_int().astype('int64')\n",
    "    df.S_2 = cudf.to_datetime( df.S_2 )\n",
    "    df = df.sort_values(['customer_ID','S_2'])\n",
    "                    \n",
    "    #################################\n",
    "    # Compute date based features\n",
    "    #################################\n",
    "    \n",
    "    df['S_2_dayofweek'] = df['S_2'].dt.weekday\n",
    "    df['S_2_dayofmonth'] = df['S_2'].dt.day\n",
    "    \n",
    "    df['days_since_1970'] = df.S_2.astype('int64')/1e9/(60*60*24)\n",
    "    df['S_2_diff'] = df.days_since_1970.diff()\n",
    "    df['x'] = df.groupby('customer_ID').S_2.agg('cumcount')\n",
    "    df.loc[df.x==0,'S_2_diff'] = 0\n",
    "    df = df.drop(['days_since_1970','x'], axis=1)\n",
    "    \n",
    "    #################################\n",
    "    # Compute \"after pay\" features\n",
    "    #################################\n",
    "    \n",
    "    for bcol in [f'B_{i}' for i in [1,2,3,4,5,9,11,14,17,24]]+['D_39','D_131']+[f'S_{i}' for i in [16,23]]:\n",
    "        for pcol in ['P_2','P_3']:\n",
    "            if bcol in df.columns:\n",
    "                df[f'{bcol}-{pcol}'] = df[bcol] - df[pcol]\n",
    "    \n",
    "    ###########################\n",
    "    # Null columns handling\n",
    "    ###########################\n",
    "    \n",
    "    nullvals = df.isnull().sum() / df.shape[0]\n",
    "    nullCols = nullvals[nullvals>0.3].index.to_arrow().to_pylist()\n",
    "    \n",
    "    for col in nullCols:\n",
    "        df[col+'_null'] = df[col].isnull().astype(int)\n",
    "    \n",
    "    # Drop raw date column\n",
    "    df = df.drop(columns=['S_2'])\n",
    "    \n",
    "    print('shape of data:', df.shape)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# print('Reading train data...')\n",
    "# TRAIN_PATH = '../input/amex-data-integer-dtypes-parquet-format/train.parquet'\n",
    "# train = read_file(path = TRAIN_PATH)\n",
    "\n",
    "\n",
    "print('Reading test data...')\n",
    "TEST_PATH = '../input/amex-data-integer-dtypes-parquet-format/test.parquet'\n",
    "test = read_file(path = TEST_PATH)\n",
    "\n",
    "\n",
    "# print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654efb3c-1377-48c8-8044-d1055d816cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def process_and_feature_engineer(df):\n",
    "    \n",
    "    all_cols = [c for c in list(df.columns) if c not in ['customer_ID','S_2']]\n",
    "    ## ホストからカテゴリカルであるといわれている特徴量\n",
    "    cat1_features = [\"B_30\",\"B_38\",\"D_114\",\"D_116\",\"D_117\",\"D_120\",\"D_126\",\"D_63\",\"D_64\",\"D_66\",\"D_68\"]\n",
    "    \n",
    "    ##　ユニークな値が４つ以下の低濃度特徴量（Low cardinality features）\n",
    "    cat2_features = [\n",
    "                    'B_31','B_32','B_33','D_103','D_109','D_111','D_127',\n",
    "                    'D_129','D_135','D_137','D_139','D_140','D_143','D_86',\n",
    "                    'D_87','D_92','D_93','D_94','D_96','R_15','R_19','R_2','R_21',\n",
    "                    'R_22','R_23','R_24','R_25','R_28','R_4','S_18','S_20','S_6'\n",
    "                       ]\n",
    "    \n",
    "    ##　ユニークな値が８以上２１以下の低濃度特徴量（Low cardinality features）\n",
    "    cat3_features = [\n",
    "                    'R_9','R_18','R_10','R_11','D_89','D_91','D_81','D_82','D_136',\n",
    "                    'D_138','D_51','D_123','D_125','D_108','B_41','B_22',\n",
    "                       ]\n",
    "    \n",
    "    nullvals = df.isnull().sum() / df.shape[0]\n",
    "    exclnullCols = nullvals[nullvals>0.9].index.to_arrow().to_pylist()\n",
    "    nullCols = nullvals[nullvals>0.3].index.to_arrow().to_pylist()\n",
    "    nullAggCols = [col + \"_null\" for col in nullCols]\n",
    "    \n",
    "    cat_features = cat1_features + cat2_features + cat3_features + exclnullCols + nullAggCols\n",
    "    \n",
    "    num_features = [col for col in all_cols if col not in cat_features]\n",
    "    \n",
    "    ## 上記のリストに入らなかった数値データの特徴量\n",
    "    test_num_agg = df.groupby(\"customer_ID\")[num_features].agg(['first','mean', 'std', 'min', 'max', 'last'])\n",
    "    test_num_agg.columns = ['_'.join(x) for x in test_num_agg.columns]\n",
    "        \n",
    "    # Diff/Div columns\n",
    "    for col in test_num_agg.columns:\n",
    "        \n",
    "        # 最初-最後\n",
    "        if 'last' in col and col.replace('last', 'first') in test_num_agg.columns:\n",
    "            test_num_agg[col + '_life_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'first')]\n",
    "  #             test_num_agg[col + '_life_div'] = cupy.where((test_num_agg[col.replace('last', 'first')].isnull()), 0, \n",
    "#                                                          cupy.where((test_num_agg[col.replace('last', 'first')]==0), 0, test_num_agg[col] / test_num_agg[col.replace('last', 'first')]))\n",
    "        # 最後の特徴 - 平均特徴 \n",
    "        if 'last' in col and col.replace('last', 'mean') in test_num_agg.columns:\n",
    "            test_num_agg[col + '_lmean_sub'] = test_num_agg[col] - test_num_agg[col.replace('last', 'mean')]\n",
    "#             test_num_agg[col + '_lmean_div'] = cupy.where((test_num_agg[col.replace('last', 'first')].isnull()) | (test_num_agg[col.replace('last', 'first')]==0), 0, test_num_agg[col] / test_num_agg[col.replace('last', 'first')])\n",
    "    \n",
    "    test_cat1_agg = df.groupby(\"customer_ID\")[cat1_features].agg(['first', 'last', 'nunique'])\n",
    "    test_cat1_agg.columns = ['_'.join(x) for x in test_cat1_agg.columns]\n",
    "    \n",
    "    test_cat2_agg = df.groupby(\"customer_ID\")[cat2_features].agg(['first', 'last', 'nunique'])\n",
    "    test_cat2_agg.columns = ['_'.join(x) for x in test_cat2_agg.columns]\n",
    "    \n",
    "    test_cat3_agg = df.groupby(\"customer_ID\")[cat3_features].agg(['first', 'last', 'nunique','min', 'max','mean', 'std'])\n",
    "    test_cat3_agg.columns = ['_'.join(x) for x in test_cat3_agg.columns]\n",
    "    \n",
    "    test_null_agg = df.groupby(\"customer_ID\")[nullAggCols].agg(['count'])\n",
    "    test_null_agg.columns = ['_'.join(x) for x in test_null_agg.columns]\n",
    "    \n",
    "    test_exclnull_agg = df.groupby(\"customer_ID\")[exclnullCols].agg(['last'])\n",
    "    test_exclnull_agg.columns = ['_'.join(x) for x in test_exclnull_agg.columns]\n",
    "         \n",
    "    temp1 = df.groupby(['customer_ID'])['P_2'].count()\n",
    "    temp1 = temp1.reset_index()\n",
    "    temp1.columns = ['customer_ID','num_statements']\n",
    "    temp1 = temp1.set_index('customer_ID')\n",
    " \n",
    "    df = cudf.concat([test_num_agg, test_cat1_agg, test_cat2_agg, test_cat3_agg, temp1, test_null_agg, test_exclnull_agg], axis=1) #test_bal_agg\n",
    "    del test_num_agg, test_cat1_agg, test_cat2_agg, test_cat3_agg, temp1, test_null_agg, test_exclnull_agg\n",
    "    _ = gc.collect()\n",
    "     \n",
    "    print('shape after engineering', df.shape )\n",
    "    \n",
    "    return df\n",
    "\n",
    "train = process_and_feature_engineer(train)\n",
    "\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f55e289-1399-4d33-943f-821f7e7ce886",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# ADD TARGETS\n",
    "targets = cudf.read_csv('../input/amex-default-prediction/train_labels.csv')\n",
    "targets['customer_ID'] = targets['customer_ID'].str[-16:].str.hex_to_int().astype('int64')\n",
    "targets = targets.set_index('customer_ID')\n",
    "\n",
    "train = train.merge(targets, left_index=True, right_index=True, how='left')\n",
    "train.target = train.target.astype('int8')\n",
    "del targets\n",
    "_ = gc.collect()\n",
    "\n",
    "# NEEDED TO MAKE CV DETERMINISTIC (cudf merge above randomly shuffles rows)\n",
    "train = train.sort_index().reset_index()\n",
    "\n",
    "# FEATURES\n",
    "print(f'There are {len(train.columns[1:-1])} features!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cdee92-67ab-4007-993d-3cf57d7f8184",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "train.to_parquet(\"train_features.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e618c251-2731-4f4d-8425-7ee6ca566e8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3790a9b-7753-4695-8dd5-26933dd6be0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef628a53-a35c-4737-b991-d07945b28f01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93b0839-76bd-4ec1-b84b-25abd4e4acb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694e3374-e2b0-4463-857f-9a10743b05dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d544f156-f611-43e9-9a6c-1fa166c796ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c95d25-e62d-4b44-9961-30f481e9c6a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amex",
   "language": "python",
   "name": "amex"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
