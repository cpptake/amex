{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70f58d85-14e4-4371-ad96-458843ea228c",
   "metadata": {},
   "source": [
    "# exp41\n",
    "\n",
    "lag_diff„ÅÆcatboost\n",
    "\n",
    "\n",
    "https://www.kaggle.com/code/ragnar123/amex-lgbm-dart-cv-0-7977"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "325051a6-7ea3-4398-b022-6a81c18b14eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Library\n",
    "# ====================================================\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "from tqdm.auto import tqdm\n",
    "import itertools\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce478709-32b7-4d68-bda7-4928785a13b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/data/train.parquet'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_33500\\217815574.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;31m# Read & Preprocess Data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m \u001b[0mread_preprocess_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_33500\\217815574.py\u001b[0m in \u001b[0;36mread_preprocess_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;31m# ====================================================\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mread_preprocess_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/data/train.parquet'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m     \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'customer_ID'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'S_2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     cat_features = [\n",
      "\u001b[1;32m~\\anaconda3\\envs\\amex\\lib\\site-packages\\pandas\\io\\parquet.py\u001b[0m in \u001b[0;36mread_parquet\u001b[1;34m(path, engine, columns, storage_options, use_nullable_dtypes, **kwargs)\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    499\u001b[0m         \u001b[0muse_nullable_dtypes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_nullable_dtypes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 500\u001b[1;33m         \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    501\u001b[0m     )\n",
      "\u001b[1;32m~\\anaconda3\\envs\\amex\\lib\\site-packages\\pandas\\io\\parquet.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, path, columns, use_nullable_dtypes, storage_options, **kwargs)\u001b[0m\n\u001b[0;32m    234\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"filesystem\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 236\u001b[1;33m             \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    237\u001b[0m         )\n\u001b[0;32m    238\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\amex\\lib\\site-packages\\pandas\\io\\parquet.py\u001b[0m in \u001b[0;36m_get_path_or_handle\u001b[1;34m(path, fs, storage_options, mode, is_dir)\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[1;31m# this branch is used for example when reading from non-fsspec URLs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         handles = get_handle(\n\u001b[1;32m--> 102\u001b[1;33m             \u001b[0mpath_or_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m         )\n\u001b[0;32m    104\u001b[0m         \u001b[0mfs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\amex\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    709\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m             \u001b[1;31m# Binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 711\u001b[1;33m             \u001b[0mhandle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    712\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    713\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/data/train.parquet'"
     ]
    }
   ],
   "source": [
    "\n",
    "# ====================================================\n",
    "# Get the difference\n",
    "# ====================================================\n",
    "def get_difference(data, num_features):\n",
    "    df1 = []\n",
    "    customer_ids = []\n",
    "    for customer_id, df in tqdm(data.groupby(['customer_ID'])):\n",
    "        # Get the differences\n",
    "        diff_df1 = df[num_features].diff(1).iloc[[-1]].values.astype(np.float32)\n",
    "        # Append to lists\n",
    "        df1.append(diff_df1)\n",
    "        customer_ids.append(customer_id)\n",
    "    # Concatenate\n",
    "    df1 = np.concatenate(df1, axis = 0)\n",
    "    # Transform to dataframe\n",
    "    df1 = pd.DataFrame(df1, columns = [col + '_diff1' for col in df[num_features].columns])\n",
    "    # Add customer id\n",
    "    df1['customer_ID'] = customer_ids\n",
    "    return df1\n",
    "\n",
    "# ====================================================\n",
    "# Read & preprocess data and save it to disk\n",
    "# ====================================================\n",
    "def read_preprocess_data():\n",
    "    train = pd.read_parquet('/content/data/train.parquet')\n",
    "    features = train.drop(['customer_ID', 'S_2'], axis = 1).columns.to_list()\n",
    "    cat_features = [\n",
    "        \"B_30\",\n",
    "        \"B_38\",\n",
    "        \"D_114\",\n",
    "        \"D_116\",\n",
    "        \"D_117\",\n",
    "        \"D_120\",\n",
    "        \"D_126\",\n",
    "        \"D_63\",\n",
    "        \"D_64\",\n",
    "        \"D_66\",\n",
    "        \"D_68\",\n",
    "    ]\n",
    "    num_features = [col for col in features if col not in cat_features]\n",
    "    print('Starting training feature engineer...')\n",
    "    train_num_agg = train.groupby(\"customer_ID\")[num_features].agg(['mean', 'std', 'min', 'max', 'last'])\n",
    "    train_num_agg.columns = ['_'.join(x) for x in train_num_agg.columns]\n",
    "    train_num_agg.reset_index(inplace = True)\n",
    "    train_cat_agg = train.groupby(\"customer_ID\")[cat_features].agg(['count', 'last', 'nunique'])\n",
    "    train_cat_agg.columns = ['_'.join(x) for x in train_cat_agg.columns]\n",
    "    train_cat_agg.reset_index(inplace = True)\n",
    "    train_labels = pd.read_csv('../input/amex-default-prediction/train_labels.csv')\n",
    "    # Transform float64 columns to float32\n",
    "    cols = list(train_num_agg.dtypes[train_num_agg.dtypes == 'float64'].index)\n",
    "    for col in tqdm(cols):\n",
    "        train_num_agg[col] = train_num_agg[col].astype(np.float32)\n",
    "    # Transform int64 columns to int32\n",
    "    cols = list(train_cat_agg.dtypes[train_cat_agg.dtypes == 'int64'].index)\n",
    "    for col in tqdm(cols):\n",
    "        train_cat_agg[col] = train_cat_agg[col].astype(np.int32)\n",
    "    # Get the difference\n",
    "    train_diff = get_difference(train, num_features)\n",
    "    train = train_num_agg.merge(train_cat_agg, how = 'inner', on = 'customer_ID').merge(train_diff, how = 'inner', on = 'customer_ID').merge(train_labels, how = 'inner', on = 'customer_ID')\n",
    "    del train_num_agg, train_cat_agg, train_diff\n",
    "    gc.collect()\n",
    "    test = pd.read_parquet('../input/amex-fe/test_fe.parquet')\n",
    "    print('Starting test feature engineer...')\n",
    "    test_num_agg = test.groupby(\"customer_ID\")[num_features].agg(['mean', 'std', 'min', 'max', 'last'])\n",
    "    test_num_agg.columns = ['_'.join(x) for x in test_num_agg.columns]\n",
    "    test_num_agg.reset_index(inplace = True)\n",
    "    test_cat_agg = test.groupby(\"customer_ID\")[cat_features].agg(['count', 'last', 'nunique'])\n",
    "    test_cat_agg.columns = ['_'.join(x) for x in test_cat_agg.columns]\n",
    "    test_cat_agg.reset_index(inplace = True)\n",
    "    # Transform float64 columns to float32\n",
    "    cols = list(test_num_agg.dtypes[test_num_agg.dtypes == 'float64'].index)\n",
    "    for col in tqdm(cols):\n",
    "        test_num_agg[col] = test_num_agg[col].astype(np.float32)\n",
    "    # Transform int64 columns to int32\n",
    "    cols = list(test_cat_agg.dtypes[test_cat_agg.dtypes == 'int64'].index)\n",
    "    for col in tqdm(cols):\n",
    "        test_cat_agg[col] = test_cat_agg[col].astype(np.int32)\n",
    "    # Get the difference\n",
    "    test_diff = get_difference(test, num_features)\n",
    "    test = test_num_agg.merge(test_cat_agg, how = 'inner', on = 'customer_ID').merge(test_diff, how = 'inner', on = 'customer_ID')\n",
    "    del test_num_agg, test_cat_agg, test_diff\n",
    "    gc.collect()\n",
    "    # Save files to disk\n",
    "    train.to_parquet('../input/amex-fe/train_fe.parquet')\n",
    "    test.to_parquet('../input/amex-fe/test_fe.parquet')\n",
    "\n",
    "# Read & Preprocess Data\n",
    "read_preprocess_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e80847-25f2-4784-97c5-b8012eae1a3e",
   "metadata": {},
   "source": [
    "# Training & Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c68ef141-3c78-4cd6-988b-db0421753882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Library\n",
    "# ====================================================\n",
    "import os\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import random\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import itertools\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import lightgbm as lgb\n",
    "from itertools import combinations\n",
    "\n",
    "import pickle\n",
    "\n",
    "# ====================================================\n",
    "# Configurations\n",
    "# ====================================================\n",
    "class CFG:\n",
    "    \n",
    "    \n",
    "    # input_dir = '../feature/exp35_lagdiff/'\n",
    "    input_dir = '../feature/exp03_amex-fe/'\n",
    "    output_dir = '../output/exp47_optuna/'\n",
    "    seed = 42\n",
    "    n_folds = 5\n",
    "    target = 'target'\n",
    "    boosting_type = 'dart'\n",
    "    metric = 'binary_logloss'\n",
    "    model = \"cat\"\n",
    "    ver = \"exp47\"\n",
    "\n",
    "# ====================================================\n",
    "# Seed everything\n",
    "# ====================================================\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "# ====================================================\n",
    "# Read data\n",
    "# ====================================================\n",
    "# def read_data():\n",
    "#     train = pd.read_parquet(CFG.input_dir + 'train_diff.parquet')\n",
    "#     test = pd.read_parquet(CFG.input_dir + 'test_diff.parquet')\n",
    "#     return train, test\n",
    "\n",
    "def read_data():\n",
    "    train = pd.read_parquet(CFG.input_dir + 'train_fe_plus_plus.parquet')\n",
    "    test = pd.read_parquet(CFG.input_dir + 'test_fe_plus_plus.parquet')\n",
    "    return train, test\n",
    "\n",
    "# ====================================================\n",
    "# Amex metric\n",
    "# ====================================================\n",
    "def amex_metric(y_true, y_pred):\n",
    "    labels = np.transpose(np.array([y_true, y_pred]))\n",
    "    labels = labels[labels[:, 1].argsort()[::-1]]\n",
    "    weights = np.where(labels[:,0]==0, 20, 1)\n",
    "    cut_vals = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n",
    "    top_four = np.sum(cut_vals[:,0]) / np.sum(labels[:,0])\n",
    "    gini = [0,0]\n",
    "    for i in [1,0]:\n",
    "        labels = np.transpose(np.array([y_true, y_pred]))\n",
    "        labels = labels[labels[:, i].argsort()[::-1]]\n",
    "        weight = np.where(labels[:,0]==0, 20, 1)\n",
    "        weight_random = np.cumsum(weight / np.sum(weight))\n",
    "        total_pos = np.sum(labels[:, 0] *  weight)\n",
    "        cum_pos_found = np.cumsum(labels[:, 0] * weight)\n",
    "        lorentz = cum_pos_found / total_pos\n",
    "        gini[i] = np.sum((lorentz - weight_random) * weight)\n",
    "    return 0.5 * (gini[1]/gini[0] + top_four)\n",
    "\n",
    "# ====================================================\n",
    "# LGBM amex metric\n",
    "# ====================================================\n",
    "def lgb_amex_metric(y_pred, y_true):\n",
    "    y_true = y_true.get_label()\n",
    "    return 'amex_metric', amex_metric(y_true, y_pred), True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5df5be5-8119-4c74-965b-89abb98ff5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(CFG.seed)\n",
    "\n",
    "train = pd.read_parquet('../feature/exp38_lagdiff_c3/train_lagdiff_c3.parquet')\n",
    "test = pd.read_parquet('../feature/exp38_lagdiff_c3/test_lagdiff_c3.parquet')\n",
    "\n",
    "# train = pd.read_parquet('../feature/exp35_lagdiff/train_lagdiff.parquet')\n",
    "# test = pd.read_parquet('../feature/exp35_lagdiff/test_lagdiff.parquet')\n",
    "\n",
    "# # train, test = read_data()\n",
    "\n",
    "# train_c3 = pd.read_pickle('../feature/exp18_4_tsfresh/train_c3.pkl')\n",
    "# test_c3 = pd.read_pickle('../feature/exp18_4_tsfresh/test_c3.pkl')\n",
    "\n",
    "# train = train.merge(train_c3,on = \"customer_ID\",how = \"left\")\n",
    "# test = test.merge(test_c3,on = \"customer_ID\",how = \"left\")\n",
    "\n",
    "# del train_c3,test_c3\n",
    "# gc.collect\n",
    "\n",
    "# print(train.shape)\n",
    "# print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30007ce2-4854-4fd8-8c1b-477936511e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def xgb_amex(y_pred, y_true):\n",
    "    return 'amex', amex_metric_np(y_pred,y_true.get_label())\n",
    "\n",
    "\n",
    "def cat_amex(y_pred, y_true):\n",
    "    return 'amex', amex_metric_np(y_pred,y_true.get_label())\n",
    "\n",
    "\n",
    "def amex_metric_np(preds: np.ndarray, target: np.ndarray) -> float:\n",
    "    indices = np.argsort(preds)[::-1]\n",
    "    preds, target = preds[indices], target[indices]\n",
    "\n",
    "    weight = 20.0 - target * 19.0\n",
    "    cum_norm_weight = (weight / weight.sum()).cumsum()\n",
    "    four_pct_mask = cum_norm_weight <= 0.04\n",
    "    d = np.sum(target[four_pct_mask]) / np.sum(target)\n",
    "\n",
    "    weighted_target = target * weight\n",
    "    lorentz = (weighted_target / weighted_target.sum()).cumsum()\n",
    "    gini = ((lorentz - cum_norm_weight) * weight).sum()\n",
    "\n",
    "    n_pos = np.sum(target)\n",
    "    n_neg = target.shape[0] - n_pos\n",
    "    gini_max = 10 * n_neg * (n_pos + 20 * n_neg - 19) / (n_pos + 20 * n_neg)\n",
    "\n",
    "    g = gini / gini_max\n",
    "    return 0.5 * (g + d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f5f272d-2129-4b46-a8de-80d78b84a600",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "def objective(trial):\n",
    "    # {'depth': 10, 'min_child': 13, 'rate': 0.052641561760702615}\n",
    "    # depth = trial.suggest_int(\"depth\", 10, 10)\n",
    "    # min_child = trial.suggest_int(\"min_child\", 12, 13)\n",
    "    rate = trial.suggest_float(\"rate\", 0.0001, 0.05)\n",
    "\n",
    "    cat_features = [\n",
    "        \"B_30\",\n",
    "        \"B_38\",\n",
    "        \"D_114\",\n",
    "        \"D_116\",\n",
    "        \"D_117\",\n",
    "        \"D_120\",\n",
    "        \"D_126\",\n",
    "        \"D_63\",\n",
    "        \"D_64\",\n",
    "        \"D_66\",\n",
    "        \"D_68\"\n",
    "    ]\n",
    "\n",
    "    # kmeans_list = [\"kmeans pred 2\",\"kmeans pred 3\",\"kmeans pred 4\"]\n",
    "\n",
    "    cat_features = [f\"{cf}_last\" for cf in cat_features]\n",
    "    # cat_features.extend(kmeans_list)\n",
    "\n",
    "    # for cat_col in cat_features:\n",
    "    # #     print(cat_col)\n",
    "    #     encoder = LabelEncoder()\n",
    "    #     train[cat_col] = encoder.fit_transform(train[cat_col])\n",
    "    #     test[cat_col] = encoder.transform(test[cat_col])\n",
    "\n",
    "\n",
    "    features = [col for col in train.columns if col not in ['customer_ID', CFG.target]]\n",
    "\n",
    "\n",
    "    prams = {\n",
    "        'depth': 10,\n",
    "        'iterations':9999,#9999\n",
    "        'learning_rate': 0.02,\n",
    "        'random_state':CFG.seed,\n",
    "        'task_type':\"CPU\",\n",
    "        'learning_rate':rate,\n",
    "        'min_child_samples':13,\n",
    "        'early_stopping_rounds': 300,\n",
    "        # 'custom_metric' : 'cat_amex'\n",
    "    }\n",
    "\n",
    "    # Create a numpy array to store test predictions\n",
    "    test_predictions = np.zeros(len(test))\n",
    "    # Create a numpy array to store out of folds predictions\n",
    "    oof_predictions = []\n",
    "\n",
    "    cids = []\n",
    "    tr_target = []\n",
    "\n",
    "    # epoch = [10000,7500,7500,8500,10500]\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits = CFG.n_folds, shuffle = True, random_state = CFG.seed)\n",
    "    for fold, (trn_ind, val_ind) in enumerate(kfold.split(train, train[CFG.target])):\n",
    "        \n",
    "        if fold == 1:\n",
    "            break\n",
    "            \n",
    "        print(' ')\n",
    "        print('-'*50)\n",
    "        print(f'Training fold {fold} with {len(features)} features...')\n",
    "        \n",
    "        \n",
    "        x_train, x_val = train[features].iloc[trn_ind], train[features].iloc[val_ind]\n",
    "        y_train, y_val = train[CFG.target].iloc[trn_ind], train[CFG.target].iloc[val_ind]\n",
    "\n",
    "        model = CatBoostClassifier(**prams)\n",
    "    \n",
    "        model.fit(x_train, y_train,\n",
    "                  eval_set = [(x_val, y_val)], \n",
    "                  metric_period=100,\n",
    "                  # eval_metrics = cat_amex\n",
    "                 )\n",
    "\n",
    "        # Save best model\n",
    "        # model.save_model(f'{CFG.output_dir}{CFG.model}_{CFG.ver}_{CFG.boosting_type}_fold{fold}_seed{CFG.seed}.xgb')\n",
    "    #     joblib.dump(model, f'{CFG.output_dir}lgbm_{CFG.boosting_type}_fold{fold}_seed{CFG.seed}.pkl')\n",
    "        # Predict validation\n",
    "        val_pred = model.predict_proba(x_val)[:,1]\n",
    "        # Add to out of folds array\n",
    "        oof_predictions.extend(val_pred)\n",
    "        cids.extend(train[\"customer_ID\"].loc[val_ind])\n",
    "        tr_target.extend(train[\"target\"].loc[val_ind])\n",
    "\n",
    "        # Compute fold metric\n",
    "        score = amex_metric(y_val, val_pred)\n",
    "        print(f'Our fold {fold} CV score is {score}')\n",
    "        del x_train, x_val, y_train, y_val\n",
    "        gc.collect()\n",
    "\n",
    "    # Compute out of folds metric\n",
    "    # score = amex_metric(train[CFG.target], oof_predictions)\n",
    "    # print(f'Our out of folds CV score is {score}')\n",
    "\n",
    "    return 1 - score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f980b292-35c6-4c96-a0c1-bc05c4f311c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-07 10:45:11,223]\u001b[0m A new study created in memory with name: no-name-9dd2c12c-b797-4ac7-9e68-f0f00bcb6728\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "--------------------------------------------------\n",
      "Training fold 0 with 2011 features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6674994\ttest: 0.6674338\tbest: 0.6674338 (0)\ttotal: 3.36s\tremaining: 9h 19m 30s\n",
      "100:\tlearn: 0.2393860\ttest: 0.2414169\tbest: 0.2414169 (100)\ttotal: 5m 29s\tremaining: 8h 57m 56s\n",
      "200:\tlearn: 0.2230588\ttest: 0.2280321\tbest: 0.2280321 (200)\ttotal: 10m 56s\tremaining: 8h 53m 40s\n",
      "300:\tlearn: 0.2157886\ttest: 0.2238421\tbest: 0.2238421 (300)\ttotal: 16m 27s\tremaining: 8h 50m 5s\n",
      "400:\tlearn: 0.2103440\ttest: 0.2216153\tbest: 0.2216153 (400)\ttotal: 21m 52s\tremaining: 8h 43m 40s\n",
      "500:\tlearn: 0.2058733\ttest: 0.2201787\tbest: 0.2201787 (500)\ttotal: 27m 17s\tremaining: 8h 37m 24s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_33500\\3097939721.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mstudy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msampler\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptuna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msamplers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTPESampler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\amex\\lib\\site-packages\\optuna\\study\\study.py\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    407\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m             \u001b[0mgc_after_trial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgc_after_trial\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 409\u001b[1;33m             \u001b[0mshow_progress_bar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    410\u001b[0m         )\n\u001b[0;32m    411\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\amex\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     74\u001b[0m                 \u001b[0mreseed_sampler_rng\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m                 \u001b[0mtime_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m                 \u001b[0mprogress_bar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m             )\n\u001b[0;32m     78\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\amex\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m             \u001b[0mtrial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m             \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\amex\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 213\u001b[1;33m         \u001b[0mvalue_or_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    214\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[1;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_33500\\3788892722.py\u001b[0m in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     76\u001b[0m         model.fit(x_train, y_train,\n\u001b[0;32m     77\u001b[0m                   \u001b[0meval_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m                   \u001b[0mmetric_period\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m                   \u001b[1;31m# eval_metrics = cat_amex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m                  )\n",
      "\u001b[1;32m~\\anaconda3\\envs\\amex\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[0;32m   4675\u001b[0m         self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n\u001b[0;32m   4676\u001b[0m                   \u001b[0meval_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogging_level\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn_description\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric_period\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4677\u001b[1;33m                   silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\n\u001b[0m\u001b[0;32m   4678\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\amex\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[0;32m   2000\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2001\u001b[0m                 \u001b[0mallow_clear_pool\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2002\u001b[1;33m                 \u001b[0mtrain_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"init_model\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2003\u001b[0m             )\n\u001b[0;32m   2004\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\amex\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36m_train\u001b[1;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[0;32m   1426\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1427\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1428\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_object\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_object\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0minit_model\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1429\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_trained_model_attributes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "study = optuna.create_study(sampler=optuna.samplers.TPESampler(seed=42))\n",
    "study.optimize(objective, n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1aef6c-6e01-413f-b9a0-46be991ca78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from catboost import CatBoostClassifier\n",
    "\n",
    "# cat_features = [\n",
    "#     \"B_30\",\n",
    "#     \"B_38\",\n",
    "#     \"D_114\",\n",
    "#     \"D_116\",\n",
    "#     \"D_117\",\n",
    "#     \"D_120\",\n",
    "#     \"D_126\",\n",
    "#     \"D_63\",\n",
    "#     \"D_64\",\n",
    "#     \"D_66\",\n",
    "#     \"D_68\"\n",
    "# ]\n",
    "\n",
    "# # kmeans_list = [\"kmeans pred 2\",\"kmeans pred 3\",\"kmeans pred 4\"]\n",
    "\n",
    "# cat_features = [f\"{cf}_last\" for cf in cat_features]\n",
    "# # cat_features.extend(kmeans_list)\n",
    "\n",
    "# for cat_col in cat_features:\n",
    "# #     print(cat_col)\n",
    "#     encoder = LabelEncoder()\n",
    "#     train[cat_col] = encoder.fit_transform(train[cat_col])\n",
    "#     test[cat_col] = encoder.transform(test[cat_col])\n",
    "\n",
    "\n",
    "# features = [col for col in train.columns if col not in ['customer_ID', CFG.target]]\n",
    "\n",
    "# prams = {\n",
    "#     'depth': 8,\n",
    "#     'iterations':9999,#9999\n",
    "#     'learning_rate': 0.02,\n",
    "#     'random_state':CFG.seed,\n",
    "#     'task_type':\"CPU\",\n",
    "#     'early_stopping_rounds': 300,\n",
    "#     # 'custom_metric' : 'cat_amex'\n",
    "# }\n",
    "\n",
    "# # Create a numpy array to store test predictions\n",
    "# test_predictions = np.zeros(len(test))\n",
    "# # Create a numpy array to store out of folds predictions\n",
    "# oof_predictions = []\n",
    "\n",
    "# cids = []\n",
    "# tr_target = []\n",
    "\n",
    "# kfold = StratifiedKFold(n_splits = CFG.n_folds, shuffle = True, random_state = CFG.seed)\n",
    "# for fold, (trn_ind, val_ind) in enumerate(kfold.split(train, train[CFG.target])):\n",
    "#     print(' ')\n",
    "#     print('-'*50)\n",
    "#     print(f'Training fold {fold} with {len(features)} features...')\n",
    "#     x_train, x_val = train[features].iloc[trn_ind], train[features].iloc[val_ind]\n",
    "#     y_train, y_val = train[CFG.target].iloc[trn_ind], train[CFG.target].iloc[val_ind]\n",
    "# #     lgb_train = lgb.Dataset(x_train, y_train, categorical_feature = cat_features)\n",
    "# #     lgb_valid = lgb.Dataset(x_val, y_val, categorical_feature = cat_features)\n",
    "    \n",
    "# #     des = DartEarlyStopping(\"valid_1\", CFG.metric, 1000)\n",
    "    \n",
    "#     model = CatBoostClassifier(**prams)\n",
    "    \n",
    "#     model.fit(x_train, y_train,\n",
    "#                   eval_set = [(x_val, y_val)], \n",
    "#                   metric_period=100\n",
    "#                  )\n",
    "    \n",
    "# #     model = lgb.train(\n",
    "# #         params = params,\n",
    "# #         train_set = lgb_train,\n",
    "# #         num_boost_round = epoch[fold],#10500\n",
    "# #         valid_sets = [lgb_train, lgb_valid],\n",
    "# #         early_stopping_rounds = 1500,\n",
    "# # #         eval_metric=[lgb_amex_metric],\n",
    "# #         verbose_eval = 500,\n",
    "# #         feval = lgb_amex_metric\n",
    "# #         )\n",
    "    \n",
    "#     # Save best model\n",
    "#     model.save_model(f\"{CFG.output_dir}{CFG.model}_fold{fold}_seed{CFG.seed}.cbm\")\n",
    "#     joblib.dump(model, f'{CFG.output_dir}lgbm_{CFG.boosting_type}_fold{fold}_seed{CFG.seed}.pkl')\n",
    "#     # Predict validation\n",
    "    \n",
    "#     val_pred = model.predict_proba(x_val)[:,1]\n",
    "#     oof_predictions.extend(val_pred)\n",
    "    \n",
    "    \n",
    "#     cids.extend(train[\"customer_ID\"].loc[val_ind])\n",
    "#     tr_target.extend(train[\"target\"].loc[val_ind])\n",
    "    \n",
    "#     # Predict the test set\n",
    "#     test_pred = model.predict_proba(test[features])[:,1]\n",
    "#     # test_pred = model.predict(test[features])\n",
    "#     test_predictions += test_pred / CFG.n_folds\n",
    "#     # Compute fold metric\n",
    "    \n",
    "#     score = amex_metric(y_val, val_pred)\n",
    "#     print(f'Our fold {fold} CV score is {score}')\n",
    "#     del x_train, x_val, y_train, y_val\n",
    "#     gc.collect()\n",
    "    \n",
    "# # Compute out of folds metric\n",
    "# score = amex_metric(tr_target, oof_predictions)\n",
    "# print(f'Our out of folds CV score is {score}')\n",
    "\n",
    "\n",
    "# # Create a dataframe to store test prediction\n",
    "# test_df = pd.DataFrame({'customer_ID': test['customer_ID'], 'prediction': test_predictions})\n",
    "# # test_df.to_csv(f'{CFG.output_dir}test_{CFG.model}_{score}_baseline_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)\n",
    "# test_df.to_csv(f'{CFG.output_dir}test_{CFG.ver}_{CFG.model}_{score}_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)\n",
    "\n",
    "\n",
    "# dic_oof = {\n",
    "#     \"customer_ID\":cids,\n",
    "#     \"target\":tr_target,\n",
    "#     f\"{CFG.ver}_{CFG.model}_oof\":oof_predictions\n",
    "# }\n",
    "\n",
    "# # Create a dataframe to store out of folds predictions\n",
    "# oof_df = pd.DataFrame(dic_oof)\n",
    "# # oof_df = pd.DataFrame({'customer_ID': train['customer_ID'], 'target': train[CFG.target], 'prediction': oof_predictions})\n",
    "# oof_df.to_csv(f'{CFG.output_dir}oof_{CFG.ver}_{CFG.model}_{score}_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)\n",
    "\n",
    "\n",
    "# # # Create a dataframe to store out of folds predictions\n",
    "# # oof_df = pd.DataFrame({'customer_ID': train['customer_ID'], 'target': train[CFG.target], 'prediction': oof_predictions})\n",
    "# # oof_df.to_csv(f'../output/Amex LGBM Dart CV 0.7977/oof_lgbm_{CFG.boosting_type}_baseline_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)\n",
    "\n",
    "\n",
    "# # # Create a dataframe to store test prediction\n",
    "# # test_df = pd.DataFrame({'customer_ID': test['customer_ID'], 'prediction': test_predictions})\n",
    "# # test_df.to_csv(f'../output/Amex LGBM Dart CV 0.7977/test_lgbm_{CFG.boosting_type}_baseline_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1f08ac4-d86f-4dcd-b281-4788f52bcce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "oof_df[f\"{CFG.ver}_{CFG.model}_oof\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634fb39d-280e-43dd-82af-6e7d23f4e910",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ec43c9c-9829-4275-911c-758a2bb8f8c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "458913"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(oof_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aeefba0-9b46-4227-b634-0a45793eb9e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f92108-afb7-45f5-b3e1-706857cb9d93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fed9500-72c1-48b4-893d-bc1fa5d7a2d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6762416b-52f6-4464-94ff-e76c6e7da87e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda1dca5-1edb-4513-82d0-b66ee1b4df81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e494e0-50f8-47ad-88c9-637a1b994414",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f770440-1df8-4a28-80c7-a3499e807a13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f3f7fd-7bd1-4e92-93a9-4a18f035feca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amex",
   "language": "python",
   "name": "amex"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
