{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70f58d85-14e4-4371-ad96-458843ea228c",
   "metadata": {},
   "source": [
    "# exp05\n",
    "\n",
    "exp03 catboostç‰ˆ\n",
    "\n",
    "https://www.kaggle.com/code/ragnar123/amex-lgbm-dart-cv-0-7977"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "325051a6-7ea3-4398-b022-6a81c18b14eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Library\n",
    "# ====================================================\n",
    "import os\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "from tqdm.auto import tqdm\n",
    "import itertools\n",
    "\n",
    "import joblib\n",
    "import random\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "from itertools import combinations\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import snappy\n",
    "# from ipywidgets import interact, Select\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce478709-32b7-4d68-bda7-4928785a13b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/data/train.parquet'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_27176\\2741697934.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;31m# Read & Preprocess Data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m \u001b[0mread_preprocess_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_27176\\2741697934.py\u001b[0m in \u001b[0;36mread_preprocess_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;31m# ====================================================\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mread_preprocess_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/data/train.parquet'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m     \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'customer_ID'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'S_2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     cat_features = [\n",
      "\u001b[1;32m~\\anaconda3\\envs\\amex\\lib\\site-packages\\pandas\\io\\parquet.py\u001b[0m in \u001b[0;36mread_parquet\u001b[1;34m(path, engine, columns, storage_options, use_nullable_dtypes, **kwargs)\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    499\u001b[0m         \u001b[0muse_nullable_dtypes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_nullable_dtypes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 500\u001b[1;33m         \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    501\u001b[0m     )\n",
      "\u001b[1;32m~\\anaconda3\\envs\\amex\\lib\\site-packages\\pandas\\io\\parquet.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, path, columns, storage_options, **kwargs)\u001b[0m\n\u001b[0;32m    338\u001b[0m             \u001b[1;31m# this branch is used for example when reading from non-fsspec URLs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m             handles = get_handle(\n\u001b[1;32m--> 340\u001b[1;33m                 \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    341\u001b[0m             )\n\u001b[0;32m    342\u001b[0m             \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\amex\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    709\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m             \u001b[1;31m# Binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 711\u001b[1;33m             \u001b[0mhandle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    712\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    713\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/data/train.parquet'"
     ]
    }
   ],
   "source": [
    "\n",
    "# ====================================================\n",
    "# Get the difference\n",
    "# ====================================================\n",
    "def get_difference(data, num_features):\n",
    "    df1 = []\n",
    "    customer_ids = []\n",
    "    for customer_id, df in tqdm(data.groupby(['customer_ID'])):\n",
    "        # Get the differences\n",
    "        diff_df1 = df[num_features].diff(1).iloc[[-1]].values.astype(np.float32)\n",
    "        # Append to lists\n",
    "        df1.append(diff_df1)\n",
    "        customer_ids.append(customer_id)\n",
    "    # Concatenate\n",
    "    df1 = np.concatenate(df1, axis = 0)\n",
    "    # Transform to dataframe\n",
    "    df1 = pd.DataFrame(df1, columns = [col + '_diff1' for col in df[num_features].columns])\n",
    "    # Add customer id\n",
    "    df1['customer_ID'] = customer_ids\n",
    "    return df1\n",
    "\n",
    "# ====================================================\n",
    "# Read & preprocess data and save it to disk\n",
    "# ====================================================\n",
    "def read_preprocess_data():\n",
    "    train = pd.read_parquet('/content/data/train.parquet')\n",
    "    features = train.drop(['customer_ID', 'S_2'], axis = 1).columns.to_list()\n",
    "    cat_features = [\n",
    "        \"B_30\",\n",
    "        \"B_38\",\n",
    "        \"D_114\",\n",
    "        \"D_116\",\n",
    "        \"D_117\",\n",
    "        \"D_120\",\n",
    "        \"D_126\",\n",
    "        \"D_63\",\n",
    "        \"D_64\",\n",
    "        \"D_66\",\n",
    "        \"D_68\",\n",
    "    ]\n",
    "    num_features = [col for col in features if col not in cat_features]\n",
    "    print('Starting training feature engineer...')\n",
    "    train_num_agg = train.groupby(\"customer_ID\")[num_features].agg(['mean', 'std', 'min', 'max', 'last'])\n",
    "    train_num_agg.columns = ['_'.join(x) for x in train_num_agg.columns]\n",
    "    train_num_agg.reset_index(inplace = True)\n",
    "    train_cat_agg = train.groupby(\"customer_ID\")[cat_features].agg(['count', 'last', 'nunique'])\n",
    "    train_cat_agg.columns = ['_'.join(x) for x in train_cat_agg.columns]\n",
    "    train_cat_agg.reset_index(inplace = True)\n",
    "    train_labels = pd.read_csv('../input/amex-default-prediction/train_labels.csv')\n",
    "    # Transform float64 columns to float32\n",
    "    cols = list(train_num_agg.dtypes[train_num_agg.dtypes == 'float64'].index)\n",
    "    for col in tqdm(cols):\n",
    "        train_num_agg[col] = train_num_agg[col].astype(np.float32)\n",
    "    # Transform int64 columns to int32\n",
    "    cols = list(train_cat_agg.dtypes[train_cat_agg.dtypes == 'int64'].index)\n",
    "    for col in tqdm(cols):\n",
    "        train_cat_agg[col] = train_cat_agg[col].astype(np.int32)\n",
    "    # Get the difference\n",
    "    train_diff = get_difference(train, num_features)\n",
    "    train = train_num_agg.merge(train_cat_agg, how = 'inner', on = 'customer_ID').merge(train_diff, how = 'inner', on = 'customer_ID').merge(train_labels, how = 'inner', on = 'customer_ID')\n",
    "    del train_num_agg, train_cat_agg, train_diff\n",
    "    gc.collect()\n",
    "    test = pd.read_parquet('../input/amex-fe/test_fe.parquet')\n",
    "    print('Starting test feature engineer...')\n",
    "    test_num_agg = test.groupby(\"customer_ID\")[num_features].agg(['mean', 'std', 'min', 'max', 'last'])\n",
    "    test_num_agg.columns = ['_'.join(x) for x in test_num_agg.columns]\n",
    "    test_num_agg.reset_index(inplace = True)\n",
    "    test_cat_agg = test.groupby(\"customer_ID\")[cat_features].agg(['count', 'last', 'nunique'])\n",
    "    test_cat_agg.columns = ['_'.join(x) for x in test_cat_agg.columns]\n",
    "    test_cat_agg.reset_index(inplace = True)\n",
    "    # Transform float64 columns to float32\n",
    "    cols = list(test_num_agg.dtypes[test_num_agg.dtypes == 'float64'].index)\n",
    "    for col in tqdm(cols):\n",
    "        test_num_agg[col] = test_num_agg[col].astype(np.float32)\n",
    "    # Transform int64 columns to int32\n",
    "    cols = list(test_cat_agg.dtypes[test_cat_agg.dtypes == 'int64'].index)\n",
    "    for col in tqdm(cols):\n",
    "        test_cat_agg[col] = test_cat_agg[col].astype(np.int32)\n",
    "    # Get the difference\n",
    "    test_diff = get_difference(test, num_featusres)\n",
    "    test = test_num_agg.merge(test_cat_agg, how = 'inner', on = 'customer_ID').merge(test_diff, how = 'inner', on = 'customer_ID')\n",
    "    del test_num_agg, test_cat_agg, test_diff\n",
    "    gc.collect()\n",
    "    # Save files to disk\n",
    "    train.to_parquet('../input/amex-fe/train_fe.parquet')\n",
    "    test.to_parquet('../input/amex-fe/test_fe.parquet')\n",
    "\n",
    "# Read & Preprocess Data\n",
    "read_preprocess_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e80847-25f2-4784-97c5-b8012eae1a3e",
   "metadata": {},
   "source": [
    "# Training & Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c68ef141-3c78-4cd6-988b-db0421753882",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# # ====================================================\n",
    "# # Configurations\n",
    "# # ====================================================\n",
    "# class CFG:\n",
    "#     input_dir = '../input/amex-fe/'\n",
    "#     seed = 45\n",
    "#     n_folds = 5\n",
    "#     target = 'target'\n",
    "#     boosting_type = 'dart'\n",
    "#     metric = 'binary_logloss'\n",
    "#     model = \"XGB\"\n",
    "\n",
    "# # ====================================================\n",
    "# # Seed everything\n",
    "# # ====================================================\n",
    "# def seed_everything(seed):\n",
    "#     random.seed(seed)\n",
    "#     np.random.seed(seed)\n",
    "#     os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "# # ====================================================\n",
    "# # Read data\n",
    "# # ====================================================\n",
    "# def read_data():\n",
    "#     train = pd.read_parquet(CFG.input_dir + 'train_fe.parquet')\n",
    "#     test = pd.read_parquet(CFG.input_dir + 'test_fe.parquet')\n",
    "#     return train, test\n",
    "\n",
    "# # ====================================================\n",
    "# # XGB train\n",
    "# # ====================================================\n",
    "\n",
    "# def cat_train(x, y, xt, yt,cat_features):\n",
    "#     print(\"# of features:\", x.shape[1])\n",
    "#     assert x.shape[1] == xt.shape[1]\n",
    "# #     dtrain = xgb.DMatrix(data=x, label=y)\n",
    "# #     dvalid = xgb.DMatrix(data=xt, label=yt)\n",
    "\n",
    "# #     watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "#     watchlist = [(x, 'train'), (xt, 'eval')]\n",
    "#     clf = CatBoostClassifier(iterations=10, random_state=CFG.seed)# 5000\n",
    "#     clf.fit(x, y, eval_set=[(xt, yt)], cat_features=cat_features,plot=True,verbose_eval=100)\n",
    "#     print('best ntree_limit:', bst.best_ntree_limit)\n",
    "#     print('best score:', bst.best_score)\n",
    "#     # return clf.predict_proba(xt)[:, 1]\n",
    "#     return clf.predict_proba(xt)[:, 1], clf\n",
    "\n",
    "\n",
    "\n",
    "# # ====================================================\n",
    "# # Amex metric\n",
    "# # ====================================================\n",
    "# def amex_metric(y_true, y_pred):\n",
    "#     labels = np.transpose(np.array([y_true, y_pred]))\n",
    "#     labels = labels[labels[:, 1].argsort()[::-1]]\n",
    "#     weights = np.where(labels[:,0]==0, 20, 1)\n",
    "#     cut_vals = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n",
    "#     top_four = np.sum(cut_vals[:,0]) / np.sum(labels[:,0])\n",
    "#     gini = [0,0]\n",
    "#     for i in [1,0]:\n",
    "#         labels = np.transpose(np.array([y_true, y_pred]))\n",
    "#         labels = labels[labels[:, i].argsort()[::-1]]\n",
    "#         weight = np.where(labels[:,0]==0, 20, 1)\n",
    "#         weight_random = np.cumsum(weight / np.sum(weight))\n",
    "#         total_pos = np.sum(labels[:, 0] *  weight)\n",
    "#         cum_pos_found = np.cumsum(labels[:, 0] * weight)\n",
    "#         lorentz = cum_pos_found / total_pos\n",
    "#         gini[i] = np.sum((lorentz - weight_random) * weight)\n",
    "#     return 0.5 * (gini[1]/gini[0] + top_four)\n",
    "\n",
    "\n",
    "# def xgb_amex(y_pred, y_true):\n",
    "#     return 'amex', amex_metric_np(y_pred,y_true.get_label())\n",
    "\n",
    "\n",
    "# # Created by https://www.kaggle.com/yunchonggan\n",
    "# # https://www.kaggle.com/competitions/amex-default-prediction/discussion/328020\n",
    "# def amex_metric_np(preds: np.ndarray, target: np.ndarray) -> float:\n",
    "#     indices = np.argsort(preds)[::-1]\n",
    "#     preds, target = preds[indices], target[indices]\n",
    "\n",
    "#     weight = 20.0 - target * 19.0\n",
    "#     cum_norm_weight = (weight / weight.sum()).cumsum()\n",
    "#     four_pct_mask = cum_norm_weight <= 0.04\n",
    "#     d = np.sum(target[four_pct_mask]) / np.sum(target)\n",
    "\n",
    "#     weighted_target = target * weight\n",
    "#     lorentz = (weighted_target / weighted_target.sum()).cumsum()\n",
    "#     gini = ((lorentz - cum_norm_weight) * weight).sum()\n",
    "\n",
    "#     n_pos = np.sum(target)\n",
    "#     n_neg = target.shape[0] - n_pos\n",
    "#     gini_max = 10 * n_neg * (n_pos + 20 * n_neg - 19) / (n_pos + 20 * n_neg)\n",
    "\n",
    "#     g = gini / gini_max\n",
    "#     return 0.5 * (g + d)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # ====================================================\n",
    "# # Train & Evaluate\n",
    "# # ====================================================\n",
    "# def train_and_evaluate(train, test):\n",
    "#     # Label encode categorical features\n",
    "#     cat_features = [\n",
    "#         \"B_30\",\n",
    "#         \"B_38\",\n",
    "#         \"D_114\",\n",
    "#         \"D_116\",\n",
    "#         \"D_117\",\n",
    "#         \"D_120\",\n",
    "#         \"D_126\",\n",
    "#         \"D_63\",\n",
    "#         \"D_64\",\n",
    "#         \"D_66\",\n",
    "#         \"D_68\"\n",
    "#     ]\n",
    "#     cat_features = [f\"{cf}_last\" for cf in cat_features]\n",
    "#     for cat_col in cat_features:\n",
    "#         encoder = LabelEncoder()\n",
    "#         train[cat_col] = encoder.fit_transform(train[cat_col])\n",
    "#         test[cat_col] = encoder.transform(test[cat_col])\n",
    "#     # Round last float features to 2 decimal place\n",
    "#     num_cols = list(train.dtypes[(train.dtypes == 'float32') | (train.dtypes == 'float64')].index)\n",
    "#     num_cols = [col for col in num_cols if 'last' in col]\n",
    "#     for col in num_cols:\n",
    "#         train[col + '_round2'] = train[col].round(2)\n",
    "#         test[col + '_round2'] = test[col].round(2)\n",
    "#     # Get the difference between last and mean\n",
    "#     num_cols = [col for col in train.columns if 'last' in col]\n",
    "#     num_cols = [col[:-5] for col in num_cols if 'round' not in col]\n",
    "#     for col in num_cols:\n",
    "#         try:\n",
    "#             train[f'{col}_last_mean_diff'] = train[f'{col}_last'] - train[f'{col}_mean']\n",
    "#             test[f'{col}_last_mean_diff'] = test[f'{col}_last'] - test[f'{col}_mean']\n",
    "#         except:\n",
    "#             pass\n",
    "#     # Transform float64 and float32 to float16\n",
    "#     num_cols = list(train.dtypes[(train.dtypes == 'float32') | (train.dtypes == 'float64')].index)\n",
    "#     for col in tqdm(num_cols):\n",
    "#         train[col] = train[col].astype(np.float16)\n",
    "#         test[col] = test[col].astype(np.float16)\n",
    "#     # Get feature list\n",
    "#     features = [col for col in train.columns if col not in ['customer_ID', CFG.target]]\n",
    "    \n",
    "# #     params = {\n",
    "# #         'objective': 'binary:logistic', \n",
    "# #         'tree_method': 'hist', #gpu_hist #hist\n",
    "# #         'max_depth': 7,\n",
    "# #         'subsample':0.88,\n",
    "# #         'colsample_bytree': 0.5,\n",
    "# #         'gamma':1.5,\n",
    "# #         'min_child_weight':8,\n",
    "# #         'lambda':70,\n",
    "# #         'eta':0.03}\n",
    "    \n",
    "#     # Create a numpy array to store test predictions\n",
    "#     test_predictions = np.zeros(len(test))\n",
    "#     # Create a numpy array to store out of folds predictions\n",
    "#     oof_predictions = np.zeros(len(train))\n",
    "#     kfold = StratifiedKFold(n_splits = CFG.n_folds, shuffle = True, random_state = CFG.seed)\n",
    "#     for fold, (trn_ind, val_ind) in enumerate(kfold.split(train, train[CFG.target])):\n",
    "#         print(' ')\n",
    "#         print('-'*50)\n",
    "#         print(f'Training fold {fold} with {len(features)} features...')\n",
    "#         x_train, x_val = train[features].iloc[trn_ind], train[features].iloc[val_ind]\n",
    "#         y_train, y_val = train[CFG.target].iloc[trn_ind], train[CFG.target].iloc[val_ind]\n",
    "#         # lgb_train = lgb.Dataset(x_train, y_train, categorical_feature = cat_features)\n",
    "#         # lgb_valid = lgb.Dataset(x_val, y_val, categorical_feature = cat_features)\n",
    "        \n",
    "#         val_pred , model = cat_train(x_train, y_train, x_val, y_val,cat_features)\n",
    "        \n",
    "#         model.save_model(f\"../output/exp05 Cat lag feature/catboost_fold{fold}.cbm\")\n",
    "#         # Save best model\n",
    "#         # joblib.dump(model, f'../output/exp04 XGB lag feature/{CFG.model}_{CFG.boosting_type}_fold{fold}_seed{CFG.seed}.pkl')\n",
    "#         # Predict validation\n",
    "        \n",
    "#         # val_pred = model.predict(x_val)\n",
    "        \n",
    "#         # Add to out of folds array\n",
    "#         oof_predictions[val_ind] = val_pred\n",
    "#         # Predict the test set\n",
    "        \n",
    "        \n",
    "#         dtest = xgb.DMatrix(data=test[features])\n",
    "#         test_pred = model.predict(dtest)\n",
    "#         test_predictions += test_pred / CFG.n_folds\n",
    "        \n",
    "#         # Compute fold metric\n",
    "#         score = amex_metric(y_val, val_pred)\n",
    "#         print(f'Our fold {fold} CV score is {score}')\n",
    "#         del x_train, x_val, y_train, y_val\n",
    "#         gc.collect()\n",
    "#     # Compute out of folds metric\n",
    "#     score = amex_metric(train[CFG.target], oof_predictions)\n",
    "#     print(f'Our out of folds CV score is {score}')\n",
    "#     # Create a dataframe to store out of folds predictions\n",
    "#     oof_df = pd.DataFrame({'customer_ID': train['customer_ID'], 'target': train[CFG.target], 'prediction': oof_predictions})\n",
    "#     oof_df.to_csv(f'../output/exp05 Cat lag feature/oof_{CFG.model}_{CFG.boosting_type}_baseline_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)\n",
    "#     # Create a dataframe to store test prediction\n",
    "#     test_df = pd.DataFrame({'customer_ID': test['customer_ID'], 'prediction': test_predictions})\n",
    "#     test_df.to_csv(f'../output/exp05 Cat lag feature/test_{CFG.model}_{CFG.boosting_type}_baseline_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3638c92e-7e65-43e5-8a69-e2aef6660f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ====================================================\n",
    "# Configurations\n",
    "# ====================================================\n",
    "class CFG:\n",
    "    input_dir = '../input/amex-fe/'\n",
    "    seed = 45\n",
    "    n_folds = 5\n",
    "    target = 'target'\n",
    "    boosting_type = 'dart'\n",
    "    metric = 'binary_logloss'\n",
    "    model = \"cat\"\n",
    "\n",
    "# ====================================================\n",
    "# Seed everything\n",
    "# ====================================================\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "# ====================================================\n",
    "# Read data\n",
    "# ====================================================\n",
    "def read_data():\n",
    "    train = pd.read_parquet(CFG.input_dir + 'train_fe.parquet')\n",
    "    test = pd.read_parquet(CFG.input_dir + 'test_fe.parquet')\n",
    "    return train, test\n",
    "\n",
    "# ====================================================\n",
    "# XGB train\n",
    "# ====================================================\n",
    "\n",
    "def cat_train(x, y, xt, yt,cat_features):\n",
    "    print(\"# of features:\", x.shape[1])\n",
    "    assert x.shape[1] == xt.shape[1]\n",
    "    \n",
    "    prams = {\n",
    "        'depth': 8,\n",
    "        'iterations':5000,\n",
    "#         'learning_rate': 0.05,\n",
    "        'random_state':CFG.seed,\n",
    "    }\n",
    "\n",
    "#     watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "    watchlist = [(x, 'train'), (xt, 'eval')]\n",
    "    clf = CatBoostClassifier(**prams)# 5000\n",
    "    clf.fit(x, y, eval_set=[(xt, yt)], cat_features=cat_features,plot=True, verbose_eval = 100)\n",
    "#     print('best ntree_limit:', clf.best_ntree_limit)\n",
    "#     print('best score:', clf.best_score)\n",
    "    # return clf.predict_proba(xt)[:, 1]\n",
    "    return clf.predict_proba(xt)[:, 1], clf\n",
    "\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# Amex metric\n",
    "# ====================================================\n",
    "def amex_metric(y_true, y_pred):\n",
    "    labels = np.transpose(np.array([y_true, y_pred]))\n",
    "    labels = labels[labels[:, 1].argsort()[::-1]]\n",
    "    weights = np.where(labels[:,0]==0, 20, 1)\n",
    "    cut_vals = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n",
    "    top_four = np.sum(cut_vals[:,0]) / np.sum(labels[:,0])\n",
    "    gini = [0,0]\n",
    "    for i in [1,0]:\n",
    "        labels = np.transpose(np.array([y_true, y_pred]))\n",
    "        labels = labels[labels[:, i].argsort()[::-1]]\n",
    "        weight = np.where(labels[:,0]==0, 20, 1)\n",
    "        weight_random = np.cumsum(weight / np.sum(weight))\n",
    "        total_pos = np.sum(labels[:, 0] *  weight)\n",
    "        cum_pos_found = np.cumsum(labels[:, 0] * weight)\n",
    "        lorentz = cum_pos_found / total_pos\n",
    "        gini[i] = np.sum((lorentz - weight_random) * weight)\n",
    "    return 0.5 * (gini[1]/gini[0] + top_four)\n",
    "\n",
    "\n",
    "def xgb_amex(y_pred, y_true):\n",
    "    return 'amex', amex_metric_np(y_pred,y_true.get_label())\n",
    "\n",
    "\n",
    "# Created by https://www.kaggle.com/yunchonggan\n",
    "# https://www.kaggle.com/competitions/amex-default-prediction/discussion/328020\n",
    "def amex_metric_np(preds: np.ndarray, target: np.ndarray) -> float:\n",
    "    indices = np.argsort(preds)[::-1]\n",
    "    preds, target = preds[indices], target[indices]\n",
    "\n",
    "    weight = 20.0 - target * 19.0\n",
    "    cum_norm_weight = (weight / weight.sum()).cumsum()\n",
    "    four_pct_mask = cum_norm_weight <= 0.04\n",
    "    d = np.sum(target[four_pct_mask]) / np.sum(target)\n",
    "\n",
    "    weighted_target = target * weight\n",
    "    lorentz = (weighted_target / weighted_target.sum()).cumsum()\n",
    "    gini = ((lorentz - cum_norm_weight) * weight).sum()\n",
    "\n",
    "    n_pos = np.sum(target)\n",
    "    n_neg = target.shape[0] - n_pos\n",
    "    gini_max = 10 * n_neg * (n_pos + 20 * n_neg - 19) / (n_pos + 20 * n_neg)\n",
    "\n",
    "    g = gini / gini_max\n",
    "    return 0.5 * (g + d)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30007ce2-4854-4fd8-8c1b-477936511e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(CFG.seed)\n",
    "train, test = read_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54d5aa37-ce2a-4fd7-a211-d4665fe081b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_and_evaluate(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b719cd4-45c3-4dba-8955-cb37b93b1f31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41b70d3b44024db1ad77128abc6eeaf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/903 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "--------------------------------------------------\n",
      "Training fold 0 with 1188 features...\n",
      "# of features: 1188\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac4564df5d6b46f1a1648ae7bd067c9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.067666\n",
      "0:\tlearn: 0.6065603\ttest: 0.6065922\tbest: 0.6065922 (0)\ttotal: 902ms\tremaining: 1h 15m 7s\n",
      "100:\tlearn: 0.2213740\ttest: 0.2257566\tbest: 0.2257566 (100)\ttotal: 1m 9s\tremaining: 56m 10s\n",
      "200:\tlearn: 0.2127444\ttest: 0.2215959\tbest: 0.2215959 (200)\ttotal: 2m 15s\tremaining: 53m 58s\n",
      "300:\tlearn: 0.2057095\ttest: 0.2198187\tbest: 0.2198187 (300)\ttotal: 3m 21s\tremaining: 52m 19s\n",
      "400:\tlearn: 0.1997982\ttest: 0.2188949\tbest: 0.2188949 (400)\ttotal: 4m 26s\tremaining: 50m 53s\n",
      "500:\tlearn: 0.1945083\ttest: 0.2184726\tbest: 0.2184726 (500)\ttotal: 5m 33s\tremaining: 49m 52s\n",
      "600:\tlearn: 0.1897354\ttest: 0.2182379\tbest: 0.2182345 (593)\ttotal: 6m 37s\tremaining: 48m 31s\n",
      "700:\tlearn: 0.1852421\ttest: 0.2181327\tbest: 0.2181327 (694)\ttotal: 7m 42s\tremaining: 47m 13s\n",
      "800:\tlearn: 0.1810323\ttest: 0.2181069\tbest: 0.2181069 (800)\ttotal: 8m 46s\tremaining: 45m 57s\n",
      "900:\tlearn: 0.1769531\ttest: 0.2180664\tbest: 0.2180411 (832)\ttotal: 9m 50s\tremaining: 44m 47s\n",
      "1000:\tlearn: 0.1728920\ttest: 0.2179553\tbest: 0.2179171 (955)\ttotal: 10m 54s\tremaining: 43m 33s\n",
      "1100:\tlearn: 0.1690126\ttest: 0.2179170\tbest: 0.2179170 (1100)\ttotal: 11m 58s\tremaining: 42m 24s\n",
      "1200:\tlearn: 0.1653779\ttest: 0.2178301\tbest: 0.2178159 (1198)\ttotal: 13m 2s\tremaining: 41m 15s\n",
      "1300:\tlearn: 0.1618343\ttest: 0.2178361\tbest: 0.2178159 (1198)\ttotal: 14m 7s\tremaining: 40m 8s\n",
      "1400:\tlearn: 0.1582241\ttest: 0.2177874\tbest: 0.2177872 (1397)\ttotal: 15m 11s\tremaining: 39m 2s\n",
      "1500:\tlearn: 0.1548990\ttest: 0.2177146\tbest: 0.2177127 (1499)\ttotal: 16m 16s\tremaining: 37m 55s\n",
      "1600:\tlearn: 0.1516142\ttest: 0.2178137\tbest: 0.2177127 (1499)\ttotal: 17m 20s\tremaining: 36m 48s\n",
      "1700:\tlearn: 0.1483805\ttest: 0.2178652\tbest: 0.2177127 (1499)\ttotal: 18m 24s\tremaining: 35m 42s\n",
      "1800:\tlearn: 0.1452026\ttest: 0.2179068\tbest: 0.2177127 (1499)\ttotal: 19m 29s\tremaining: 34m 36s\n",
      "1900:\tlearn: 0.1421136\ttest: 0.2180668\tbest: 0.2177127 (1499)\ttotal: 20m 33s\tremaining: 33m 31s\n",
      "2000:\tlearn: 0.1391110\ttest: 0.2181226\tbest: 0.2177127 (1499)\ttotal: 21m 37s\tremaining: 32m 25s\n",
      "2100:\tlearn: 0.1361423\ttest: 0.2181866\tbest: 0.2177127 (1499)\ttotal: 22m 42s\tremaining: 31m 20s\n",
      "2200:\tlearn: 0.1332637\ttest: 0.2182606\tbest: 0.2177127 (1499)\ttotal: 23m 47s\tremaining: 30m 15s\n",
      "2300:\tlearn: 0.1306118\ttest: 0.2182885\tbest: 0.2177127 (1499)\ttotal: 24m 52s\tremaining: 29m 10s\n",
      "2400:\tlearn: 0.1281452\ttest: 0.2184171\tbest: 0.2177127 (1499)\ttotal: 25m 56s\tremaining: 28m 4s\n",
      "2500:\tlearn: 0.1254531\ttest: 0.2185411\tbest: 0.2177127 (1499)\ttotal: 27m 1s\tremaining: 27m\n",
      "2600:\tlearn: 0.1229175\ttest: 0.2186661\tbest: 0.2177127 (1499)\ttotal: 28m 7s\tremaining: 25m 56s\n",
      "2700:\tlearn: 0.1205076\ttest: 0.2187127\tbest: 0.2177127 (1499)\ttotal: 29m 11s\tremaining: 24m 50s\n",
      "2800:\tlearn: 0.1181663\ttest: 0.2188111\tbest: 0.2177127 (1499)\ttotal: 30m 16s\tremaining: 23m 45s\n",
      "2900:\tlearn: 0.1157440\ttest: 0.2189390\tbest: 0.2177127 (1499)\ttotal: 31m 21s\tremaining: 22m 41s\n",
      "3000:\tlearn: 0.1135540\ttest: 0.2190057\tbest: 0.2177127 (1499)\ttotal: 32m 25s\tremaining: 21m 36s\n",
      "3100:\tlearn: 0.1113857\ttest: 0.2190619\tbest: 0.2177127 (1499)\ttotal: 33m 30s\tremaining: 20m 31s\n",
      "3200:\tlearn: 0.1091330\ttest: 0.2192335\tbest: 0.2177127 (1499)\ttotal: 34m 36s\tremaining: 19m 27s\n",
      "3300:\tlearn: 0.1071146\ttest: 0.2193497\tbest: 0.2177127 (1499)\ttotal: 35m 42s\tremaining: 18m 22s\n",
      "3400:\tlearn: 0.1049771\ttest: 0.2194877\tbest: 0.2177127 (1499)\ttotal: 36m 47s\tremaining: 17m 17s\n",
      "3500:\tlearn: 0.1028826\ttest: 0.2196621\tbest: 0.2177127 (1499)\ttotal: 37m 53s\tremaining: 16m 13s\n",
      "3600:\tlearn: 0.1009199\ttest: 0.2197968\tbest: 0.2177127 (1499)\ttotal: 38m 59s\tremaining: 15m 8s\n",
      "3700:\tlearn: 0.0988524\ttest: 0.2199648\tbest: 0.2177127 (1499)\ttotal: 40m 5s\tremaining: 14m 4s\n",
      "3800:\tlearn: 0.0971926\ttest: 0.2200318\tbest: 0.2177127 (1499)\ttotal: 41m 10s\tremaining: 12m 59s\n",
      "3900:\tlearn: 0.0953995\ttest: 0.2200976\tbest: 0.2177127 (1499)\ttotal: 42m 15s\tremaining: 11m 54s\n",
      "4000:\tlearn: 0.0934084\ttest: 0.2202271\tbest: 0.2177127 (1499)\ttotal: 43m 21s\tremaining: 10m 49s\n",
      "4100:\tlearn: 0.0915995\ttest: 0.2203925\tbest: 0.2177127 (1499)\ttotal: 44m 27s\tremaining: 9m 44s\n",
      "4200:\tlearn: 0.0899950\ttest: 0.2205456\tbest: 0.2177127 (1499)\ttotal: 45m 32s\tremaining: 8m 39s\n",
      "4300:\tlearn: 0.0884333\ttest: 0.2206713\tbest: 0.2177127 (1499)\ttotal: 46m 38s\tremaining: 7m 34s\n",
      "4400:\tlearn: 0.0865871\ttest: 0.2208896\tbest: 0.2177127 (1499)\ttotal: 47m 44s\tremaining: 6m 29s\n",
      "4500:\tlearn: 0.0849368\ttest: 0.2209872\tbest: 0.2177127 (1499)\ttotal: 48m 50s\tremaining: 5m 24s\n",
      "4600:\tlearn: 0.0834087\ttest: 0.2211334\tbest: 0.2177127 (1499)\ttotal: 49m 55s\tremaining: 4m 19s\n",
      "4700:\tlearn: 0.0820214\ttest: 0.2213702\tbest: 0.2177127 (1499)\ttotal: 51m\tremaining: 3m 14s\n",
      "4800:\tlearn: 0.0806404\ttest: 0.2214051\tbest: 0.2177127 (1499)\ttotal: 52m 5s\tremaining: 2m 9s\n",
      "4900:\tlearn: 0.0792934\ttest: 0.2215837\tbest: 0.2177127 (1499)\ttotal: 53m 10s\tremaining: 1m 4s\n",
      "4999:\tlearn: 0.0778946\ttest: 0.2218023\tbest: 0.2177127 (1499)\ttotal: 54m 15s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2177127071\n",
      "bestIteration = 1499\n",
      "\n",
      "Shrink model to first 1500 iterations.\n",
      "Our fold 0 CV score is 0.7919409180105704\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 1 with 1188 features...\n",
      "# of features: 1188\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9980c21e3bd4b7abfec6e952bdfdf1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.067666\n",
      "0:\tlearn: 0.6086894\ttest: 0.6085355\tbest: 0.6085355 (0)\ttotal: 749ms\tremaining: 1h 2m 23s\n",
      "100:\tlearn: 0.2222551\ttest: 0.2233587\tbest: 0.2233587 (100)\ttotal: 1m 8s\tremaining: 55m 41s\n",
      "200:\tlearn: 0.2134200\ttest: 0.2188517\tbest: 0.2188517 (200)\ttotal: 2m 16s\tremaining: 54m 13s\n",
      "300:\tlearn: 0.2062317\ttest: 0.2171113\tbest: 0.2171113 (300)\ttotal: 3m 21s\tremaining: 52m 30s\n",
      "400:\tlearn: 0.2005486\ttest: 0.2163181\tbest: 0.2163181 (400)\ttotal: 4m 27s\tremaining: 51m 3s\n",
      "500:\tlearn: 0.1954013\ttest: 0.2158072\tbest: 0.2158072 (500)\ttotal: 5m 31s\tremaining: 49m 33s\n",
      "600:\tlearn: 0.1907380\ttest: 0.2154073\tbest: 0.2154073 (600)\ttotal: 6m 35s\tremaining: 48m 13s\n",
      "700:\tlearn: 0.1861134\ttest: 0.2152455\tbest: 0.2152415 (678)\ttotal: 7m 38s\tremaining: 46m 54s\n",
      "800:\tlearn: 0.1817837\ttest: 0.2151808\tbest: 0.2151583 (734)\ttotal: 8m 42s\tremaining: 45m 41s\n",
      "900:\tlearn: 0.1779369\ttest: 0.2149684\tbest: 0.2149637 (899)\ttotal: 9m 46s\tremaining: 44m 30s\n",
      "1000:\tlearn: 0.1738200\ttest: 0.2149552\tbest: 0.2149058 (948)\ttotal: 10m 53s\tremaining: 43m 30s\n",
      "1100:\tlearn: 0.1700497\ttest: 0.2149611\tbest: 0.2149058 (948)\ttotal: 11m 58s\tremaining: 42m 24s\n",
      "1200:\tlearn: 0.1662314\ttest: 0.2149448\tbest: 0.2149058 (948)\ttotal: 13m 4s\tremaining: 41m 22s\n",
      "1300:\tlearn: 0.1627254\ttest: 0.2149298\tbest: 0.2149013 (1250)\ttotal: 14m 9s\tremaining: 40m 13s\n",
      "1400:\tlearn: 0.1593006\ttest: 0.2149333\tbest: 0.2148950 (1373)\ttotal: 15m 14s\tremaining: 39m 8s\n",
      "1500:\tlearn: 0.1558530\ttest: 0.2150206\tbest: 0.2148950 (1373)\ttotal: 16m 19s\tremaining: 38m 2s\n",
      "1600:\tlearn: 0.1526701\ttest: 0.2150592\tbest: 0.2148950 (1373)\ttotal: 17m 23s\tremaining: 36m 56s\n",
      "1700:\tlearn: 0.1494609\ttest: 0.2151223\tbest: 0.2148950 (1373)\ttotal: 18m 29s\tremaining: 35m 52s\n",
      "1800:\tlearn: 0.1463482\ttest: 0.2151898\tbest: 0.2148950 (1373)\ttotal: 19m 34s\tremaining: 34m 46s\n",
      "1900:\tlearn: 0.1432945\ttest: 0.2152737\tbest: 0.2148950 (1373)\ttotal: 20m 40s\tremaining: 33m 41s\n",
      "2000:\tlearn: 0.1401715\ttest: 0.2152808\tbest: 0.2148950 (1373)\ttotal: 21m 45s\tremaining: 32m 37s\n",
      "2100:\tlearn: 0.1373617\ttest: 0.2153784\tbest: 0.2148950 (1373)\ttotal: 22m 50s\tremaining: 31m 31s\n",
      "2200:\tlearn: 0.1345732\ttest: 0.2154330\tbest: 0.2148950 (1373)\ttotal: 23m 56s\tremaining: 30m 26s\n",
      "2300:\tlearn: 0.1317654\ttest: 0.2153782\tbest: 0.2148950 (1373)\ttotal: 25m 2s\tremaining: 29m 22s\n",
      "2400:\tlearn: 0.1290922\ttest: 0.2156261\tbest: 0.2148950 (1373)\ttotal: 26m 8s\tremaining: 28m 17s\n",
      "2500:\tlearn: 0.1265473\ttest: 0.2157162\tbest: 0.2148950 (1373)\ttotal: 27m 13s\tremaining: 27m 12s\n",
      "2600:\tlearn: 0.1239011\ttest: 0.2158104\tbest: 0.2148950 (1373)\ttotal: 28m 19s\tremaining: 26m 7s\n",
      "2700:\tlearn: 0.1214517\ttest: 0.2159132\tbest: 0.2148950 (1373)\ttotal: 29m 24s\tremaining: 25m 2s\n",
      "2800:\tlearn: 0.1190451\ttest: 0.2160892\tbest: 0.2148950 (1373)\ttotal: 30m 30s\tremaining: 23m 57s\n",
      "2900:\tlearn: 0.1167581\ttest: 0.2161743\tbest: 0.2148950 (1373)\ttotal: 31m 35s\tremaining: 22m 51s\n",
      "3000:\tlearn: 0.1144462\ttest: 0.2162763\tbest: 0.2148950 (1373)\ttotal: 32m 41s\tremaining: 21m 46s\n",
      "3100:\tlearn: 0.1121412\ttest: 0.2163633\tbest: 0.2148950 (1373)\ttotal: 33m 47s\tremaining: 20m 41s\n",
      "3200:\tlearn: 0.1099488\ttest: 0.2165072\tbest: 0.2148950 (1373)\ttotal: 34m 53s\tremaining: 19m 36s\n",
      "3300:\tlearn: 0.1079414\ttest: 0.2166767\tbest: 0.2148950 (1373)\ttotal: 35m 59s\tremaining: 18m 31s\n",
      "3400:\tlearn: 0.1058973\ttest: 0.2168574\tbest: 0.2148950 (1373)\ttotal: 37m 5s\tremaining: 17m 26s\n",
      "3500:\tlearn: 0.1038851\ttest: 0.2170142\tbest: 0.2148950 (1373)\ttotal: 38m 11s\tremaining: 16m 21s\n",
      "3600:\tlearn: 0.1018264\ttest: 0.2171751\tbest: 0.2148950 (1373)\ttotal: 39m 17s\tremaining: 15m 16s\n",
      "3700:\tlearn: 0.0999347\ttest: 0.2173789\tbest: 0.2148950 (1373)\ttotal: 40m 24s\tremaining: 14m 10s\n",
      "3800:\tlearn: 0.0980772\ttest: 0.2175040\tbest: 0.2148950 (1373)\ttotal: 41m 30s\tremaining: 13m 5s\n",
      "3900:\tlearn: 0.0961903\ttest: 0.2176061\tbest: 0.2148950 (1373)\ttotal: 42m 37s\tremaining: 12m\n",
      "4000:\tlearn: 0.0944258\ttest: 0.2177276\tbest: 0.2148950 (1373)\ttotal: 43m 42s\tremaining: 10m 54s\n",
      "4100:\tlearn: 0.0927137\ttest: 0.2178306\tbest: 0.2148950 (1373)\ttotal: 44m 48s\tremaining: 9m 49s\n",
      "4200:\tlearn: 0.0909449\ttest: 0.2180632\tbest: 0.2148950 (1373)\ttotal: 45m 54s\tremaining: 8m 43s\n",
      "4300:\tlearn: 0.0892593\ttest: 0.2182017\tbest: 0.2148950 (1373)\ttotal: 47m 1s\tremaining: 7m 38s\n",
      "4400:\tlearn: 0.0875898\ttest: 0.2183250\tbest: 0.2148950 (1373)\ttotal: 48m 7s\tremaining: 6m 32s\n",
      "4500:\tlearn: 0.0859730\ttest: 0.2184728\tbest: 0.2148950 (1373)\ttotal: 49m 15s\tremaining: 5m 27s\n",
      "4600:\tlearn: 0.0844102\ttest: 0.2186305\tbest: 0.2148950 (1373)\ttotal: 50m 22s\tremaining: 4m 22s\n",
      "4700:\tlearn: 0.0827025\ttest: 0.2187594\tbest: 0.2148950 (1373)\ttotal: 51m 29s\tremaining: 3m 16s\n",
      "4800:\tlearn: 0.0811755\ttest: 0.2189443\tbest: 0.2148950 (1373)\ttotal: 52m 36s\tremaining: 2m 10s\n",
      "4900:\tlearn: 0.0797266\ttest: 0.2191224\tbest: 0.2148950 (1373)\ttotal: 53m 42s\tremaining: 1m 5s\n",
      "4999:\tlearn: 0.0782006\ttest: 0.2192296\tbest: 0.2148950 (1373)\ttotal: 54m 48s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2148950266\n",
      "bestIteration = 1373\n",
      "\n",
      "Shrink model to first 1374 iterations.\n",
      "Our fold 1 CV score is 0.795627134806028\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 2 with 1188 features...\n",
      "# of features: 1188\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4af46bdb269f41efaf4914d593a92059",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.067666\n",
      "0:\tlearn: 0.6096071\ttest: 0.6096955\tbest: 0.6096955 (0)\ttotal: 757ms\tremaining: 1h 3m 2s\n",
      "100:\tlearn: 0.2216433\ttest: 0.2266338\tbest: 0.2266338 (100)\ttotal: 1m 9s\tremaining: 56m 30s\n",
      "200:\tlearn: 0.2129568\ttest: 0.2219427\tbest: 0.2219427 (200)\ttotal: 2m 17s\tremaining: 54m 32s\n",
      "300:\tlearn: 0.2057162\ttest: 0.2201414\tbest: 0.2201414 (300)\ttotal: 3m 24s\tremaining: 53m 6s\n",
      "400:\tlearn: 0.1996964\ttest: 0.2191850\tbest: 0.2191850 (400)\ttotal: 4m 30s\tremaining: 51m 37s\n",
      "500:\tlearn: 0.1946461\ttest: 0.2185865\tbest: 0.2185810 (499)\ttotal: 5m 35s\tremaining: 50m 11s\n",
      "600:\tlearn: 0.1899713\ttest: 0.2182657\tbest: 0.2182657 (600)\ttotal: 6m 40s\tremaining: 48m 51s\n",
      "700:\tlearn: 0.1855842\ttest: 0.2180708\tbest: 0.2180708 (700)\ttotal: 7m 45s\tremaining: 47m 33s\n",
      "800:\tlearn: 0.1811299\ttest: 0.2178842\tbest: 0.2178825 (791)\ttotal: 8m 50s\tremaining: 46m 20s\n",
      "900:\tlearn: 0.1771616\ttest: 0.2177575\tbest: 0.2177575 (900)\ttotal: 9m 55s\tremaining: 45m 7s\n",
      "1000:\tlearn: 0.1731954\ttest: 0.2176790\tbest: 0.2176687 (998)\ttotal: 11m 1s\tremaining: 44m 2s\n",
      "1100:\tlearn: 0.1694250\ttest: 0.2176704\tbest: 0.2176261 (1030)\ttotal: 12m 6s\tremaining: 42m 51s\n",
      "1200:\tlearn: 0.1657971\ttest: 0.2176637\tbest: 0.2175983 (1169)\ttotal: 13m 11s\tremaining: 41m 44s\n",
      "1300:\tlearn: 0.1620219\ttest: 0.2176593\tbest: 0.2175983 (1169)\ttotal: 14m 17s\tremaining: 40m 37s\n",
      "1400:\tlearn: 0.1585021\ttest: 0.2177445\tbest: 0.2175983 (1169)\ttotal: 15m 23s\tremaining: 39m 31s\n",
      "1500:\tlearn: 0.1550811\ttest: 0.2177225\tbest: 0.2175983 (1169)\ttotal: 16m 28s\tremaining: 38m 24s\n",
      "1600:\tlearn: 0.1518147\ttest: 0.2178038\tbest: 0.2175983 (1169)\ttotal: 17m 34s\tremaining: 37m 18s\n",
      "1700:\tlearn: 0.1485986\ttest: 0.2178541\tbest: 0.2175983 (1169)\ttotal: 18m 40s\tremaining: 36m 12s\n",
      "1800:\tlearn: 0.1452664\ttest: 0.2179120\tbest: 0.2175983 (1169)\ttotal: 19m 46s\tremaining: 35m 7s\n",
      "1900:\tlearn: 0.1422697\ttest: 0.2179240\tbest: 0.2175983 (1169)\ttotal: 20m 53s\tremaining: 34m 3s\n",
      "2000:\tlearn: 0.1391646\ttest: 0.2179736\tbest: 0.2175983 (1169)\ttotal: 22m\tremaining: 32m 58s\n",
      "2100:\tlearn: 0.1363118\ttest: 0.2180610\tbest: 0.2175983 (1169)\ttotal: 23m 6s\tremaining: 31m 52s\n",
      "2200:\tlearn: 0.1336046\ttest: 0.2180834\tbest: 0.2175983 (1169)\ttotal: 24m 11s\tremaining: 30m 45s\n",
      "2300:\tlearn: 0.1307653\ttest: 0.2181037\tbest: 0.2175983 (1169)\ttotal: 25m 18s\tremaining: 29m 41s\n",
      "2400:\tlearn: 0.1280541\ttest: 0.2181839\tbest: 0.2175983 (1169)\ttotal: 26m 25s\tremaining: 28m 36s\n",
      "2500:\tlearn: 0.1254723\ttest: 0.2182611\tbest: 0.2175983 (1169)\ttotal: 27m 32s\tremaining: 27m 31s\n",
      "2600:\tlearn: 0.1231216\ttest: 0.2183328\tbest: 0.2175983 (1169)\ttotal: 28m 38s\tremaining: 26m 25s\n",
      "2700:\tlearn: 0.1205545\ttest: 0.2185094\tbest: 0.2175983 (1169)\ttotal: 29m 45s\tremaining: 25m 19s\n",
      "2800:\tlearn: 0.1182286\ttest: 0.2185776\tbest: 0.2175983 (1169)\ttotal: 30m 51s\tremaining: 24m 13s\n",
      "2900:\tlearn: 0.1158183\ttest: 0.2186120\tbest: 0.2175983 (1169)\ttotal: 31m 58s\tremaining: 23m 8s\n",
      "3000:\tlearn: 0.1135954\ttest: 0.2186969\tbest: 0.2175983 (1169)\ttotal: 33m 5s\tremaining: 22m 2s\n",
      "3100:\tlearn: 0.1113205\ttest: 0.2187912\tbest: 0.2175983 (1169)\ttotal: 34m 11s\tremaining: 20m 56s\n",
      "3200:\tlearn: 0.1092197\ttest: 0.2189185\tbest: 0.2175983 (1169)\ttotal: 35m 18s\tremaining: 19m 50s\n",
      "3300:\tlearn: 0.1070935\ttest: 0.2190780\tbest: 0.2175983 (1169)\ttotal: 36m 25s\tremaining: 18m 44s\n",
      "3400:\tlearn: 0.1050296\ttest: 0.2191047\tbest: 0.2175983 (1169)\ttotal: 37m 31s\tremaining: 17m 38s\n",
      "3500:\tlearn: 0.1029407\ttest: 0.2192971\tbest: 0.2175983 (1169)\ttotal: 38m 39s\tremaining: 16m 33s\n",
      "3600:\tlearn: 0.1010605\ttest: 0.2193814\tbest: 0.2175983 (1169)\ttotal: 39m 45s\tremaining: 15m 26s\n",
      "3700:\tlearn: 0.0991524\ttest: 0.2195367\tbest: 0.2175983 (1169)\ttotal: 40m 52s\tremaining: 14m 20s\n",
      "3800:\tlearn: 0.0973196\ttest: 0.2196767\tbest: 0.2175983 (1169)\ttotal: 41m 59s\tremaining: 13m 14s\n",
      "3900:\tlearn: 0.0956057\ttest: 0.2198333\tbest: 0.2175983 (1169)\ttotal: 43m 5s\tremaining: 12m 8s\n",
      "4000:\tlearn: 0.0939050\ttest: 0.2199795\tbest: 0.2175983 (1169)\ttotal: 44m 11s\tremaining: 11m 2s\n",
      "4100:\tlearn: 0.0921177\ttest: 0.2201725\tbest: 0.2175983 (1169)\ttotal: 45m 18s\tremaining: 9m 55s\n",
      "4200:\tlearn: 0.0903662\ttest: 0.2202993\tbest: 0.2175983 (1169)\ttotal: 46m 25s\tremaining: 8m 49s\n",
      "4300:\tlearn: 0.0888042\ttest: 0.2205203\tbest: 0.2175983 (1169)\ttotal: 47m 31s\tremaining: 7m 43s\n",
      "4400:\tlearn: 0.0872350\ttest: 0.2206883\tbest: 0.2175983 (1169)\ttotal: 48m 37s\tremaining: 6m 37s\n",
      "4500:\tlearn: 0.0857172\ttest: 0.2208580\tbest: 0.2175983 (1169)\ttotal: 49m 45s\tremaining: 5m 30s\n",
      "4600:\tlearn: 0.0841414\ttest: 0.2209599\tbest: 0.2175983 (1169)\ttotal: 50m 52s\tremaining: 4m 24s\n",
      "4700:\tlearn: 0.0825096\ttest: 0.2211202\tbest: 0.2175983 (1169)\ttotal: 52m\tremaining: 3m 18s\n",
      "4800:\tlearn: 0.0808081\ttest: 0.2213004\tbest: 0.2175983 (1169)\ttotal: 53m 9s\tremaining: 2m 12s\n",
      "4900:\tlearn: 0.0794089\ttest: 0.2214682\tbest: 0.2175983 (1169)\ttotal: 54m 17s\tremaining: 1m 5s\n",
      "4999:\tlearn: 0.0779160\ttest: 0.2215567\tbest: 0.2175983 (1169)\ttotal: 55m 24s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2175983224\n",
      "bestIteration = 1169\n",
      "\n",
      "Shrink model to first 1170 iterations.\n",
      "Our fold 2 CV score is 0.7929466395688562\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 3 with 1188 features...\n",
      "# of features: 1188\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82e489e14cd1420ab93bc1f488747b94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.067666\n",
      "0:\tlearn: 0.6062717\ttest: 0.6065356\tbest: 0.6065356 (0)\ttotal: 664ms\tremaining: 55m 20s\n",
      "100:\tlearn: 0.2210687\ttest: 0.2280274\tbest: 0.2280274 (100)\ttotal: 1m 9s\tremaining: 56m 15s\n",
      "200:\tlearn: 0.2122680\ttest: 0.2239263\tbest: 0.2239263 (200)\ttotal: 2m 16s\tremaining: 54m 27s\n",
      "300:\tlearn: 0.2051685\ttest: 0.2223710\tbest: 0.2223659 (298)\ttotal: 3m 22s\tremaining: 52m 45s\n",
      "400:\tlearn: 0.1993078\ttest: 0.2215360\tbest: 0.2215347 (399)\ttotal: 4m 29s\tremaining: 51m 25s\n",
      "500:\tlearn: 0.1945325\ttest: 0.2210387\tbest: 0.2210297 (496)\ttotal: 5m 33s\tremaining: 49m 57s\n",
      "600:\tlearn: 0.1902760\ttest: 0.2207943\tbest: 0.2207943 (600)\ttotal: 6m 37s\tremaining: 48m 31s\n",
      "700:\tlearn: 0.1857507\ttest: 0.2204757\tbest: 0.2204757 (700)\ttotal: 7m 43s\tremaining: 47m 19s\n",
      "800:\tlearn: 0.1817267\ttest: 0.2202418\tbest: 0.2202082 (791)\ttotal: 8m 47s\tremaining: 46m 3s\n",
      "900:\tlearn: 0.1774941\ttest: 0.2201164\tbest: 0.2201164 (900)\ttotal: 9m 51s\tremaining: 44m 53s\n",
      "1000:\tlearn: 0.1735979\ttest: 0.2201299\tbest: 0.2201032 (918)\ttotal: 10m 57s\tremaining: 43m 45s\n",
      "1100:\tlearn: 0.1698689\ttest: 0.2201511\tbest: 0.2200831 (1071)\ttotal: 12m 1s\tremaining: 42m 35s\n",
      "1200:\tlearn: 0.1660261\ttest: 0.2201240\tbest: 0.2200831 (1071)\ttotal: 13m 7s\tremaining: 41m 31s\n",
      "1300:\tlearn: 0.1623558\ttest: 0.2201503\tbest: 0.2200831 (1071)\ttotal: 14m 13s\tremaining: 40m 26s\n",
      "1400:\tlearn: 0.1589097\ttest: 0.2201734\tbest: 0.2200831 (1071)\ttotal: 15m 19s\tremaining: 39m 22s\n",
      "1500:\tlearn: 0.1554565\ttest: 0.2202217\tbest: 0.2200831 (1071)\ttotal: 16m 26s\tremaining: 38m 18s\n",
      "1600:\tlearn: 0.1521773\ttest: 0.2201938\tbest: 0.2200831 (1071)\ttotal: 17m 31s\tremaining: 37m 12s\n",
      "1700:\tlearn: 0.1489570\ttest: 0.2202551\tbest: 0.2200831 (1071)\ttotal: 18m 37s\tremaining: 36m 8s\n",
      "1800:\tlearn: 0.1457086\ttest: 0.2203000\tbest: 0.2200831 (1071)\ttotal: 19m 43s\tremaining: 35m 2s\n",
      "1900:\tlearn: 0.1424795\ttest: 0.2204199\tbest: 0.2200831 (1071)\ttotal: 20m 50s\tremaining: 33m 58s\n",
      "2000:\tlearn: 0.1395093\ttest: 0.2205192\tbest: 0.2200831 (1071)\ttotal: 21m 56s\tremaining: 32m 52s\n",
      "2100:\tlearn: 0.1365408\ttest: 0.2205835\tbest: 0.2200831 (1071)\ttotal: 23m 3s\tremaining: 31m 49s\n",
      "2200:\tlearn: 0.1337855\ttest: 0.2207372\tbest: 0.2200831 (1071)\ttotal: 24m 10s\tremaining: 30m 45s\n",
      "2300:\tlearn: 0.1309653\ttest: 0.2208399\tbest: 0.2200831 (1071)\ttotal: 25m 17s\tremaining: 29m 39s\n",
      "2400:\tlearn: 0.1282340\ttest: 0.2209058\tbest: 0.2200831 (1071)\ttotal: 26m 24s\tremaining: 28m 34s\n",
      "2500:\tlearn: 0.1257737\ttest: 0.2210814\tbest: 0.2200831 (1071)\ttotal: 27m 29s\tremaining: 27m 28s\n",
      "2600:\tlearn: 0.1232253\ttest: 0.2212141\tbest: 0.2200831 (1071)\ttotal: 28m 36s\tremaining: 26m 22s\n",
      "2700:\tlearn: 0.1207306\ttest: 0.2213272\tbest: 0.2200831 (1071)\ttotal: 29m 41s\tremaining: 25m 16s\n",
      "2800:\tlearn: 0.1183702\ttest: 0.2214181\tbest: 0.2200831 (1071)\ttotal: 30m 48s\tremaining: 24m 11s\n",
      "2900:\tlearn: 0.1159835\ttest: 0.2215528\tbest: 0.2200831 (1071)\ttotal: 31m 54s\tremaining: 23m 5s\n",
      "3000:\tlearn: 0.1137517\ttest: 0.2216023\tbest: 0.2200831 (1071)\ttotal: 33m 1s\tremaining: 21m 59s\n",
      "3100:\tlearn: 0.1114033\ttest: 0.2217679\tbest: 0.2200831 (1071)\ttotal: 34m 8s\tremaining: 20m 54s\n",
      "3200:\tlearn: 0.1091173\ttest: 0.2219218\tbest: 0.2200831 (1071)\ttotal: 35m 15s\tremaining: 19m 48s\n",
      "3300:\tlearn: 0.1068401\ttest: 0.2220256\tbest: 0.2200831 (1071)\ttotal: 36m 22s\tremaining: 18m 43s\n",
      "3400:\tlearn: 0.1046914\ttest: 0.2221588\tbest: 0.2200831 (1071)\ttotal: 37m 28s\tremaining: 17m 37s\n",
      "3500:\tlearn: 0.1027852\ttest: 0.2223040\tbest: 0.2200831 (1071)\ttotal: 38m 34s\tremaining: 16m 31s\n",
      "3600:\tlearn: 0.1007613\ttest: 0.2224706\tbest: 0.2200831 (1071)\ttotal: 39m 42s\tremaining: 15m 25s\n",
      "3700:\tlearn: 0.0988689\ttest: 0.2225460\tbest: 0.2200831 (1071)\ttotal: 40m 48s\tremaining: 14m 19s\n",
      "3800:\tlearn: 0.0970964\ttest: 0.2226701\tbest: 0.2200831 (1071)\ttotal: 41m 54s\tremaining: 13m 13s\n",
      "3900:\tlearn: 0.0952585\ttest: 0.2228651\tbest: 0.2200831 (1071)\ttotal: 43m 1s\tremaining: 12m 7s\n",
      "4000:\tlearn: 0.0934856\ttest: 0.2230755\tbest: 0.2200831 (1071)\ttotal: 44m 7s\tremaining: 11m 1s\n",
      "4100:\tlearn: 0.0918885\ttest: 0.2231541\tbest: 0.2200831 (1071)\ttotal: 45m 13s\tremaining: 9m 54s\n",
      "4200:\tlearn: 0.0901611\ttest: 0.2232484\tbest: 0.2200831 (1071)\ttotal: 46m 20s\tremaining: 8m 48s\n",
      "4300:\tlearn: 0.0884545\ttest: 0.2234464\tbest: 0.2200831 (1071)\ttotal: 47m 27s\tremaining: 7m 42s\n",
      "4400:\tlearn: 0.0867613\ttest: 0.2236660\tbest: 0.2200831 (1071)\ttotal: 48m 35s\tremaining: 6m 36s\n",
      "4500:\tlearn: 0.0852721\ttest: 0.2238169\tbest: 0.2200831 (1071)\ttotal: 49m 41s\tremaining: 5m 30s\n",
      "4600:\tlearn: 0.0836172\ttest: 0.2239803\tbest: 0.2200831 (1071)\ttotal: 50m 49s\tremaining: 4m 24s\n",
      "4700:\tlearn: 0.0820590\ttest: 0.2241589\tbest: 0.2200831 (1071)\ttotal: 51m 55s\tremaining: 3m 18s\n",
      "4800:\tlearn: 0.0805891\ttest: 0.2243006\tbest: 0.2200831 (1071)\ttotal: 53m 3s\tremaining: 2m 11s\n",
      "4900:\tlearn: 0.0792200\ttest: 0.2244150\tbest: 0.2200831 (1071)\ttotal: 54m 10s\tremaining: 1m 5s\n",
      "4999:\tlearn: 0.0777698\ttest: 0.2246586\tbest: 0.2200831 (1071)\ttotal: 55m 18s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.220083092\n",
      "bestIteration = 1071\n",
      "\n",
      "Shrink model to first 1072 iterations.\n",
      "Our fold 3 CV score is 0.7911614830437721\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 4 with 1188 features...\n",
      "# of features: 1188\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35a5968c067c43fb8fd3fca0a1456b59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.067666\n",
      "0:\tlearn: 0.6102061\ttest: 0.6104152\tbest: 0.6104152 (0)\ttotal: 666ms\tremaining: 55m 29s\n",
      "100:\tlearn: 0.2215105\ttest: 0.2266697\tbest: 0.2266697 (100)\ttotal: 1m 9s\tremaining: 56m 29s\n",
      "200:\tlearn: 0.2128081\ttest: 0.2223111\tbest: 0.2223111 (200)\ttotal: 2m 17s\tremaining: 54m 35s\n",
      "300:\tlearn: 0.2058147\ttest: 0.2204938\tbest: 0.2204938 (300)\ttotal: 3m 23s\tremaining: 53m 1s\n",
      "400:\tlearn: 0.2001478\ttest: 0.2195306\tbest: 0.2195292 (399)\ttotal: 4m 29s\tremaining: 51m 30s\n",
      "500:\tlearn: 0.1950436\ttest: 0.2190489\tbest: 0.2190473 (490)\ttotal: 5m 35s\tremaining: 50m 10s\n",
      "600:\tlearn: 0.1901630\ttest: 0.2187953\tbest: 0.2187953 (600)\ttotal: 6m 40s\tremaining: 48m 54s\n",
      "700:\tlearn: 0.1857236\ttest: 0.2186276\tbest: 0.2186241 (698)\ttotal: 7m 45s\tremaining: 47m 34s\n",
      "800:\tlearn: 0.1812505\ttest: 0.2184971\tbest: 0.2184933 (765)\ttotal: 8m 51s\tremaining: 46m 25s\n",
      "900:\tlearn: 0.1771929\ttest: 0.2182983\tbest: 0.2182845 (893)\ttotal: 9m 55s\tremaining: 45m 10s\n",
      "1000:\tlearn: 0.1733924\ttest: 0.2182743\tbest: 0.2182341 (956)\ttotal: 11m 1s\tremaining: 44m\n",
      "1100:\tlearn: 0.1695582\ttest: 0.2181916\tbest: 0.2181766 (1034)\ttotal: 12m 5s\tremaining: 42m 50s\n",
      "1200:\tlearn: 0.1659044\ttest: 0.2181855\tbest: 0.2181604 (1153)\ttotal: 13m 11s\tremaining: 41m 43s\n",
      "1300:\tlearn: 0.1624050\ttest: 0.2182370\tbest: 0.2181604 (1153)\ttotal: 14m 16s\tremaining: 40m 35s\n",
      "1400:\tlearn: 0.1589398\ttest: 0.2182728\tbest: 0.2181604 (1153)\ttotal: 15m 22s\tremaining: 39m 29s\n",
      "1500:\tlearn: 0.1554084\ttest: 0.2183420\tbest: 0.2181604 (1153)\ttotal: 16m 28s\tremaining: 38m 23s\n",
      "1600:\tlearn: 0.1521536\ttest: 0.2184206\tbest: 0.2181604 (1153)\ttotal: 17m 33s\tremaining: 37m 17s\n",
      "1700:\tlearn: 0.1488217\ttest: 0.2184368\tbest: 0.2181604 (1153)\ttotal: 18m 40s\tremaining: 36m 12s\n",
      "1800:\tlearn: 0.1456331\ttest: 0.2184644\tbest: 0.2181604 (1153)\ttotal: 19m 46s\tremaining: 35m 7s\n",
      "1900:\tlearn: 0.1424260\ttest: 0.2185635\tbest: 0.2181604 (1153)\ttotal: 20m 52s\tremaining: 34m 2s\n",
      "2000:\tlearn: 0.1395268\ttest: 0.2186529\tbest: 0.2181604 (1153)\ttotal: 21m 58s\tremaining: 32m 55s\n",
      "2100:\tlearn: 0.1366056\ttest: 0.2187534\tbest: 0.2181604 (1153)\ttotal: 23m 5s\tremaining: 31m 51s\n",
      "2200:\tlearn: 0.1335705\ttest: 0.2188219\tbest: 0.2181604 (1153)\ttotal: 24m 11s\tremaining: 30m 46s\n",
      "2300:\tlearn: 0.1307573\ttest: 0.2189771\tbest: 0.2181604 (1153)\ttotal: 25m 18s\tremaining: 29m 40s\n",
      "2400:\tlearn: 0.1281324\ttest: 0.2189945\tbest: 0.2181604 (1153)\ttotal: 26m 25s\tremaining: 28m 35s\n",
      "2500:\tlearn: 0.1255597\ttest: 0.2190892\tbest: 0.2181604 (1153)\ttotal: 27m 31s\tremaining: 27m 30s\n",
      "2600:\tlearn: 0.1229300\ttest: 0.2193122\tbest: 0.2181604 (1153)\ttotal: 28m 38s\tremaining: 26m 24s\n",
      "2700:\tlearn: 0.1206497\ttest: 0.2194753\tbest: 0.2181604 (1153)\ttotal: 29m 43s\tremaining: 25m 18s\n",
      "2800:\tlearn: 0.1181928\ttest: 0.2196484\tbest: 0.2181604 (1153)\ttotal: 30m 50s\tremaining: 24m 12s\n",
      "2900:\tlearn: 0.1159321\ttest: 0.2197577\tbest: 0.2181604 (1153)\ttotal: 31m 55s\tremaining: 23m 5s\n",
      "3000:\tlearn: 0.1136975\ttest: 0.2198745\tbest: 0.2181604 (1153)\ttotal: 33m 1s\tremaining: 21m 59s\n",
      "3100:\tlearn: 0.1114225\ttest: 0.2199990\tbest: 0.2181604 (1153)\ttotal: 34m 7s\tremaining: 20m 53s\n",
      "3200:\tlearn: 0.1091517\ttest: 0.2201690\tbest: 0.2181604 (1153)\ttotal: 35m 14s\tremaining: 19m 48s\n",
      "3300:\tlearn: 0.1072133\ttest: 0.2202732\tbest: 0.2181604 (1153)\ttotal: 36m 19s\tremaining: 18m 42s\n",
      "3400:\tlearn: 0.1051668\ttest: 0.2204305\tbest: 0.2181604 (1153)\ttotal: 37m 26s\tremaining: 17m 36s\n",
      "3500:\tlearn: 0.1032996\ttest: 0.2205760\tbest: 0.2181604 (1153)\ttotal: 38m 32s\tremaining: 16m 29s\n",
      "3600:\tlearn: 0.1012447\ttest: 0.2207112\tbest: 0.2181604 (1153)\ttotal: 39m 38s\tremaining: 15m 24s\n",
      "3700:\tlearn: 0.0992314\ttest: 0.2208084\tbest: 0.2181604 (1153)\ttotal: 40m 46s\tremaining: 14m 18s\n",
      "3800:\tlearn: 0.0971140\ttest: 0.2210345\tbest: 0.2181604 (1153)\ttotal: 41m 53s\tremaining: 13m 12s\n",
      "3900:\tlearn: 0.0952907\ttest: 0.2211932\tbest: 0.2181604 (1153)\ttotal: 43m\tremaining: 12m 6s\n",
      "4000:\tlearn: 0.0936099\ttest: 0.2213689\tbest: 0.2181604 (1153)\ttotal: 44m 6s\tremaining: 11m\n",
      "4100:\tlearn: 0.0919952\ttest: 0.2214975\tbest: 0.2181604 (1153)\ttotal: 45m 12s\tremaining: 9m 54s\n",
      "4200:\tlearn: 0.0901392\ttest: 0.2216647\tbest: 0.2181604 (1153)\ttotal: 46m 19s\tremaining: 8m 48s\n",
      "4300:\tlearn: 0.0883986\ttest: 0.2218237\tbest: 0.2181604 (1153)\ttotal: 47m 25s\tremaining: 7m 42s\n",
      "4400:\tlearn: 0.0866778\ttest: 0.2220021\tbest: 0.2181604 (1153)\ttotal: 48m 33s\tremaining: 6m 36s\n",
      "4500:\tlearn: 0.0851238\ttest: 0.2221836\tbest: 0.2181604 (1153)\ttotal: 49m 39s\tremaining: 5m 30s\n",
      "4600:\tlearn: 0.0835210\ttest: 0.2223366\tbest: 0.2181604 (1153)\ttotal: 50m 47s\tremaining: 4m 24s\n",
      "4700:\tlearn: 0.0820633\ttest: 0.2224563\tbest: 0.2181604 (1153)\ttotal: 51m 53s\tremaining: 3m 18s\n",
      "4800:\tlearn: 0.0805218\ttest: 0.2225848\tbest: 0.2181604 (1153)\ttotal: 53m\tremaining: 2m 11s\n",
      "4900:\tlearn: 0.0791388\ttest: 0.2227731\tbest: 0.2181604 (1153)\ttotal: 54m 6s\tremaining: 1m 5s\n",
      "4999:\tlearn: 0.0776944\ttest: 0.2230348\tbest: 0.2181604 (1153)\ttotal: 55m 13s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.218160442\n",
      "bestIteration = 1153\n",
      "\n",
      "Shrink model to first 1154 iterations.\n",
      "Our fold 4 CV score is 0.7929252897888939\n",
      "Our out of folds CV score is 0.7929305578947454\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# Train & Evaluate\n",
    "# ====================================================\n",
    "# def train_and_evaluate(train, test):\n",
    "    # Label encode categorical features\n",
    "    \n",
    "cat_features = [\n",
    "    \"B_30\",\n",
    "    \"B_38\",\n",
    "    \"D_114\",\n",
    "    \"D_116\",\n",
    "    \"D_117\",\n",
    "    \"D_120\",\n",
    "    \"D_126\",\n",
    "    \"D_63\",\n",
    "    \"D_64\",\n",
    "    \"D_66\",\n",
    "    \"D_68\"\n",
    "]\n",
    "cat_features = [f\"{cf}_last\" for cf in cat_features]\n",
    "for cat_col in cat_features:\n",
    "    encoder = LabelEncoder()\n",
    "    train[cat_col] = encoder.fit_transform(train[cat_col])\n",
    "    test[cat_col] = encoder.transform(test[cat_col])\n",
    "# Round last float features to 2 decimal place\n",
    "num_cols = list(train.dtypes[(train.dtypes == 'float32') | (train.dtypes == 'float64')].index)\n",
    "num_cols = [col for col in num_cols if 'last' in col]\n",
    "for col in num_cols:\n",
    "    train[col + '_round2'] = train[col].round(2)\n",
    "    test[col + '_round2'] = test[col].round(2)\n",
    "# Get the difference between last and mean\n",
    "num_cols = [col for col in train.columns if 'last' in col]\n",
    "num_cols = [col[:-5] for col in num_cols if 'round' not in col]\n",
    "for col in num_cols:\n",
    "    try:\n",
    "        train[f'{col}_last_mean_diff'] = train[f'{col}_last'] - train[f'{col}_mean']\n",
    "        test[f'{col}_last_mean_diff'] = test[f'{col}_last'] - test[f'{col}_mean']\n",
    "    except:\n",
    "        pass\n",
    "# Transform float64 and float32 to float16\n",
    "num_cols = list(train.dtypes[(train.dtypes == 'float32') | (train.dtypes == 'float64')].index)\n",
    "for col in tqdm(num_cols):\n",
    "    train[col] = train[col].astype(np.float16)\n",
    "    test[col] = test[col].astype(np.float16)\n",
    "# Get feature list\n",
    "features = [col for col in train.columns if col not in ['customer_ID', CFG.target]]\n",
    "\n",
    "#     params = {\n",
    "#         'objective': 'binary:logistic', \n",
    "#         'tree_method': 'hist', #gpu_hist #hist\n",
    "#         'max_depth': 7,\n",
    "#         'subsample':0.88,\n",
    "#         'colsample_bytree': 0.5,\n",
    "#         'gamma':1.5,\n",
    "#         'min_child_weight':8,\n",
    "#         'lambda':70,\n",
    "#         'eta':0.03}\n",
    "\n",
    "# Create a numpy array to store test predictions\n",
    "test_predictions = np.zeros(len(test))\n",
    "# Create a numpy array to store out of folds predictions\n",
    "oof_predictions = np.zeros(len(train))\n",
    "\n",
    "# cid = []\n",
    "# cids = []\n",
    "\n",
    "preds = []\n",
    "\n",
    "kfold = StratifiedKFold(n_splits = CFG.n_folds, shuffle = True, random_state = CFG.seed)\n",
    "for fold, (trn_ind, val_ind) in enumerate(kfold.split(train, train[CFG.target])):\n",
    "    print(' ')\n",
    "    print('-'*50)\n",
    "    print(f'Training fold {fold} with {len(features)} features...')\n",
    "    \n",
    "    x_train, x_val = train[features].iloc[trn_ind], train[features].iloc[val_ind]\n",
    "    y_train, y_val = train[CFG.target].iloc[trn_ind], train[CFG.target].iloc[val_ind]\n",
    "    # lgb_train = lgb.Dataset(x_train, y_train, categorical_feature = cat_features)\n",
    "    # lgb_valid = lgb.Dataset(x_val, y_val, categorical_feature = cat_features)\n",
    "\n",
    "    val_pred , model = cat_train(x_train, y_train, x_val, y_val,cat_features)\n",
    "\n",
    "    model.save_model(f\"../output/exp05 Cat lag feature/catboost_fold{fold}.cbm\")\n",
    "    # Save best model\n",
    "    # joblib.dump(model, f'../output/exp04 XGB lag feature/{CFG.model}_{CFG.boosting_type}_fold{fold}_seed{CFG.seed}.pkl')\n",
    "    # Predict validation\n",
    "\n",
    "    # val_pred = model.predict(x_val)\n",
    "\n",
    "    # Add to out of folds array\n",
    "    oof_predictions[val_ind] = val_pred\n",
    "    # Predict the test set\n",
    "\n",
    "\n",
    "#     dtest = xgb.DMatrix(data=test[features])\n",
    "    pred = model.predict_proba(test[features])[:, 1]\n",
    "    preds.append(pred)\n",
    "    \n",
    "#     test_predictions += test_pred / CFG.n_folds\n",
    "\n",
    "    # Compute fold metric\n",
    "    score = amex_metric(y_val, val_pred)\n",
    "    print(f'Our fold {fold} CV score is {score}')\n",
    "    del x_train, x_val, y_train, y_val, pred\n",
    "    gc.collect()\n",
    "# Compute out of folds metric\n",
    "score = amex_metric(train[CFG.target], oof_predictions)\n",
    "print(f'Our out of folds CV score is {score}')\n",
    "\n",
    "test_predictions = np.mean(preds,axis = 0)\n",
    "\n",
    "# Create a dataframe to store out of folds predictions\n",
    "oof_df = pd.DataFrame({'customer_ID': train['customer_ID'], 'target': train[CFG.target], 'prediction': oof_predictions})\n",
    "oof_df.to_csv(f'../output/exp05 Cat lag feature/oof_{CFG.model}_{score}_baseline_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)\n",
    "# Create a dataframe to store test prediction\n",
    "test_df = pd.DataFrame({'customer_ID': test['customer_ID'], 'prediction': test_predictions})\n",
    "test_df.to_csv(f'../output/exp05 Cat lag feature/test_{CFG.model}_{score}_baseline_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6031cf-f767-4551-afb2-6feb6efd9dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220db67f-9a57-436b-9ec6-8732c6c6fe67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f770440-1df8-4a28-80c7-a3499e807a13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f3f7fd-7bd1-4e92-93a9-4a18f035feca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amex",
   "language": "python",
   "name": "amex"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
