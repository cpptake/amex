{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70f58d85-14e4-4371-ad96-458843ea228c",
   "metadata": {},
   "source": [
    "# exp43\n",
    "\n",
    "lag_diffのXGB\n",
    "\n",
    "\n",
    "https://www.kaggle.com/code/ragnar123/amex-lgbm-dart-cv-0-7977"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "325051a6-7ea3-4398-b022-6a81c18b14eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Library\n",
    "# ====================================================\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "from tqdm.auto import tqdm\n",
    "import itertools\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "979ad950-7ef8-4116-97b7-0081786d9e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.0\n"
     ]
    }
   ],
   "source": [
    "print(xgb.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce478709-32b7-4d68-bda7-4928785a13b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/data/train.parquet'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11004\\217815574.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;31m# Read & Preprocess Data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m \u001b[0mread_preprocess_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11004\\217815574.py\u001b[0m in \u001b[0;36mread_preprocess_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;31m# ====================================================\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mread_preprocess_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/data/train.parquet'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m     \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'customer_ID'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'S_2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     cat_features = [\n",
      "\u001b[1;32m~\\anaconda3\\envs\\amex\\lib\\site-packages\\pandas\\io\\parquet.py\u001b[0m in \u001b[0;36mread_parquet\u001b[1;34m(path, engine, columns, storage_options, use_nullable_dtypes, **kwargs)\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    499\u001b[0m         \u001b[0muse_nullable_dtypes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_nullable_dtypes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 500\u001b[1;33m         \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    501\u001b[0m     )\n",
      "\u001b[1;32m~\\anaconda3\\envs\\amex\\lib\\site-packages\\pandas\\io\\parquet.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, path, columns, use_nullable_dtypes, storage_options, **kwargs)\u001b[0m\n\u001b[0;32m    234\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"filesystem\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 236\u001b[1;33m             \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    237\u001b[0m         )\n\u001b[0;32m    238\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\amex\\lib\\site-packages\\pandas\\io\\parquet.py\u001b[0m in \u001b[0;36m_get_path_or_handle\u001b[1;34m(path, fs, storage_options, mode, is_dir)\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[1;31m# this branch is used for example when reading from non-fsspec URLs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         handles = get_handle(\n\u001b[1;32m--> 102\u001b[1;33m             \u001b[0mpath_or_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m         )\n\u001b[0;32m    104\u001b[0m         \u001b[0mfs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\amex\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    709\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m             \u001b[1;31m# Binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 711\u001b[1;33m             \u001b[0mhandle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    712\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    713\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/data/train.parquet'"
     ]
    }
   ],
   "source": [
    "\n",
    "# ====================================================\n",
    "# Get the difference\n",
    "# ====================================================\n",
    "def get_difference(data, num_features):\n",
    "    df1 = []\n",
    "    customer_ids = []\n",
    "    for customer_id, df in tqdm(data.groupby(['customer_ID'])):\n",
    "        # Get the differences\n",
    "        diff_df1 = df[num_features].diff(1).iloc[[-1]].values.astype(np.float32)\n",
    "        # Append to lists\n",
    "        df1.append(diff_df1)\n",
    "        customer_ids.append(customer_id)\n",
    "    # Concatenate\n",
    "    df1 = np.concatenate(df1, axis = 0)\n",
    "    # Transform to dataframe\n",
    "    df1 = pd.DataFrame(df1, columns = [col + '_diff1' for col in df[num_features].columns])\n",
    "    # Add customer id\n",
    "    df1['customer_ID'] = customer_ids\n",
    "    return df1\n",
    "\n",
    "# ====================================================\n",
    "# Read & preprocess data and save it to disk\n",
    "# ====================================================\n",
    "def read_preprocess_data():\n",
    "    train = pd.read_parquet('/content/data/train.parquet')\n",
    "    features = train.drop(['customer_ID', 'S_2'], axis = 1).columns.to_list()\n",
    "    cat_features = [\n",
    "        \"B_30\",\n",
    "        \"B_38\",\n",
    "        \"D_114\",\n",
    "        \"D_116\",\n",
    "        \"D_117\",\n",
    "        \"D_120\",\n",
    "        \"D_126\",\n",
    "        \"D_63\",\n",
    "        \"D_64\",\n",
    "        \"D_66\",\n",
    "        \"D_68\",\n",
    "    ]\n",
    "    num_features = [col for col in features if col not in cat_features]\n",
    "    print('Starting training feature engineer...')\n",
    "    train_num_agg = train.groupby(\"customer_ID\")[num_features].agg(['mean', 'std', 'min', 'max', 'last'])\n",
    "    train_num_agg.columns = ['_'.join(x) for x in train_num_agg.columns]\n",
    "    train_num_agg.reset_index(inplace = True)\n",
    "    train_cat_agg = train.groupby(\"customer_ID\")[cat_features].agg(['count', 'last', 'nunique'])\n",
    "    train_cat_agg.columns = ['_'.join(x) for x in train_cat_agg.columns]\n",
    "    train_cat_agg.reset_index(inplace = True)\n",
    "    train_labels = pd.read_csv('../input/amex-default-prediction/train_labels.csv')\n",
    "    # Transform float64 columns to float32\n",
    "    cols = list(train_num_agg.dtypes[train_num_agg.dtypes == 'float64'].index)\n",
    "    for col in tqdm(cols):\n",
    "        train_num_agg[col] = train_num_agg[col].astype(np.float32)\n",
    "    # Transform int64 columns to int32\n",
    "    cols = list(train_cat_agg.dtypes[train_cat_agg.dtypes == 'int64'].index)\n",
    "    for col in tqdm(cols):\n",
    "        train_cat_agg[col] = train_cat_agg[col].astype(np.int32)\n",
    "    # Get the difference\n",
    "    train_diff = get_difference(train, num_features)\n",
    "    train = train_num_agg.merge(train_cat_agg, how = 'inner', on = 'customer_ID').merge(train_diff, how = 'inner', on = 'customer_ID').merge(train_labels, how = 'inner', on = 'customer_ID')\n",
    "    del train_num_agg, train_cat_agg, train_diff\n",
    "    gc.collect()\n",
    "    test = pd.read_parquet('../input/amex-fe/test_fe.parquet')\n",
    "    print('Starting test feature engineer...')\n",
    "    test_num_agg = test.groupby(\"customer_ID\")[num_features].agg(['mean', 'std', 'min', 'max', 'last'])\n",
    "    test_num_agg.columns = ['_'.join(x) for x in test_num_agg.columns]\n",
    "    test_num_agg.reset_index(inplace = True)\n",
    "    test_cat_agg = test.groupby(\"customer_ID\")[cat_features].agg(['count', 'last', 'nunique'])\n",
    "    test_cat_agg.columns = ['_'.join(x) for x in test_cat_agg.columns]\n",
    "    test_cat_agg.reset_index(inplace = True)\n",
    "    # Transform float64 columns to float32\n",
    "    cols = list(test_num_agg.dtypes[test_num_agg.dtypes == 'float64'].index)\n",
    "    for col in tqdm(cols):\n",
    "        test_num_agg[col] = test_num_agg[col].astype(np.float32)\n",
    "    # Transform int64 columns to int32\n",
    "    cols = list(test_cat_agg.dtypes[test_cat_agg.dtypes == 'int64'].index)\n",
    "    for col in tqdm(cols):\n",
    "        test_cat_agg[col] = test_cat_agg[col].astype(np.int32)\n",
    "    # Get the difference\n",
    "    test_diff = get_difference(test, num_features)\n",
    "    test = test_num_agg.merge(test_cat_agg, how = 'inner', on = 'customer_ID').merge(test_diff, how = 'inner', on = 'customer_ID')\n",
    "    del test_num_agg, test_cat_agg, test_diff\n",
    "    gc.collect()\n",
    "    # Save files to disk\n",
    "    train.to_parquet('../input/amex-fe/train_fe.parquet')\n",
    "    test.to_parquet('../input/amex-fe/test_fe.parquet')\n",
    "\n",
    "# Read & Preprocess Data\n",
    "read_preprocess_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e80847-25f2-4784-97c5-b8012eae1a3e",
   "metadata": {},
   "source": [
    "# Training & Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c68ef141-3c78-4cd6-988b-db0421753882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Library\n",
    "# ====================================================\n",
    "import os\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import random\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import itertools\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import lightgbm as lgb\n",
    "from itertools import combinations\n",
    "\n",
    "import pickle\n",
    "\n",
    "# ====================================================\n",
    "# Configurations\n",
    "# ====================================================\n",
    "class CFG:\n",
    "    \n",
    "    \n",
    "    # input_dir = '../feature/exp35_lagdiff/'\n",
    "    input_dir = '../feature/exp03_amex-fe/'\n",
    "    output_dir = '../output/exp52_614_xgb_lagdiff_c3_statedate/'\n",
    "    seed = 614\n",
    "    n_folds = 5\n",
    "    target = 'target'\n",
    "    boosting_type = 'dart'\n",
    "    metric = 'binary_logloss'\n",
    "    model = \"xgb\"\n",
    "    ver =\"exp52\"\n",
    "\n",
    "# ====================================================\n",
    "# Seed everything\n",
    "# ====================================================\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "# ====================================================\n",
    "# Read data\n",
    "# ====================================================\n",
    "# def read_data():\n",
    "#     train = pd.read_parquet(CFG.input_dir + 'train_diff.parquet')\n",
    "#     test = pd.read_parquet(CFG.input_dir + 'test_diff.parquet')\n",
    "#     return train, test\n",
    "\n",
    "def read_data():\n",
    "    train = pd.read_parquet(CFG.input_dir + 'train_fe_plus_plus.parquet')\n",
    "    test = pd.read_parquet(CFG.input_dir + 'test_fe_plus_plus.parquet')\n",
    "    return train, test\n",
    "\n",
    "# ====================================================\n",
    "# Amex metric\n",
    "# ====================================================\n",
    "def amex_metric(y_true, y_pred):\n",
    "    labels = np.transpose(np.array([y_true, y_pred]))\n",
    "    labels = labels[labels[:, 1].argsort()[::-1]]\n",
    "    weights = np.where(labels[:,0]==0, 20, 1)\n",
    "    cut_vals = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n",
    "    top_four = np.sum(cut_vals[:,0]) / np.sum(labels[:,0])\n",
    "    gini = [0,0]\n",
    "    for i in [1,0]:\n",
    "        labels = np.transpose(np.array([y_true, y_pred]))\n",
    "        labels = labels[labels[:, i].argsort()[::-1]]\n",
    "        weight = np.where(labels[:,0]==0, 20, 1)\n",
    "        weight_random = np.cumsum(weight / np.sum(weight))\n",
    "        total_pos = np.sum(labels[:, 0] *  weight)\n",
    "        cum_pos_found = np.cumsum(labels[:, 0] * weight)\n",
    "        lorentz = cum_pos_found / total_pos\n",
    "        gini[i] = np.sum((lorentz - weight_random) * weight)\n",
    "    return 0.5 * (gini[1]/gini[0] + top_four)\n",
    "\n",
    "# ====================================================\n",
    "# LGBM amex metric\n",
    "# ====================================================\n",
    "def lgb_amex_metric(y_pred, y_true):\n",
    "    y_true = y_true.get_label()\n",
    "    return 'amex_metric', amex_metric(y_true, y_pred), True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5df5be5-8119-4c74-965b-89abb98ff5a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(458913, 2025)\n",
      "(924621, 2024)\n"
     ]
    }
   ],
   "source": [
    "seed_everything(CFG.seed)\n",
    "\n",
    "\n",
    "train = pd.read_pickle('../feature/exp50_lagdiff_c3_statedate/train_lagdiff_c3_statedate.pkl')\n",
    "test = pd.read_pickle('../feature/exp50_lagdiff_c3_statedate/test_lagdiff_c3_statedate.pkl')\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30007ce2-4854-4fd8-8c1b-477936511e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def xgb_amex(y_pred, y_true):\n",
    "    return 'amex', amex_metric_np(y_pred,y_true.get_label())\n",
    "\n",
    "\n",
    "def amex_metric_np(preds: np.ndarray, target: np.ndarray) -> float:\n",
    "    indices = np.argsort(preds)[::-1]\n",
    "    preds, target = preds[indices], target[indices]\n",
    "\n",
    "    weight = 20.0 - target * 19.0\n",
    "    cum_norm_weight = (weight / weight.sum()).cumsum()\n",
    "    four_pct_mask = cum_norm_weight <= 0.04\n",
    "    d = np.sum(target[four_pct_mask]) / np.sum(target)\n",
    "\n",
    "    weighted_target = target * weight\n",
    "    lorentz = (weighted_target / weighted_target.sumaaa()).cumsum()\n",
    "    gini = ((lorentz - cum_norm_weight) * weight).sum()\n",
    "\n",
    "    n_pos = np.sum(target)\n",
    "    n_neg = target.shape[0] - n_pos\n",
    "    gini_max = 10 * n_neg * (n_pos + 20 * n_neg - 19) / (n_pos + 20 * n_neg)\n",
    "\n",
    "    g = gini / gini_max\n",
    "    return 0.5 * (g + d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09d173dd-7490-4e18-83e2-0f40ffdf7ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train.fillna(value=0, inplace=True)\n",
    "test.fillna(value=0, inplace=True)\n",
    "\n",
    "## infを含むデータを外れ値（－１００００）に置換\n",
    "train = train.replace([np.inf, -np.inf],100000000000)\n",
    "test = test.replace([np.inf, -np.inf],100000000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da1aef6c-6e01-413f-b9a0-46be991ca78e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "--------------------------------------------------\n",
      "Training fold 0 with 2023 features...\n",
      "[09:32:29] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\ttrain-logloss:0.68725\ttrain-amex:0.71621\tvalid-logloss:0.68725\tvalid-amex:0.70699\n",
      "[100]\ttrain-logloss:0.37733\ttrain-amex:0.77363\tvalid-logloss:0.38144\tvalid-amex:0.75608\n",
      "[200]\ttrain-logloss:0.27975\ttrain-amex:0.78580\tvalid-logloss:0.28726\tvalid-amex:0.76486\n",
      "[300]\ttrain-logloss:0.24147\ttrain-amex:0.79443\tvalid-logloss:0.25182\tvalid-amex:0.77135\n",
      "[400]\ttrain-logloss:0.22415\ttrain-amex:0.80246\tvalid-logloss:0.23708\tvalid-amex:0.77560\n",
      "[500]\ttrain-logloss:0.21496\ttrain-amex:0.80876\tvalid-logloss:0.23010\tvalid-amex:0.77928\n",
      "[600]\ttrain-logloss:0.20911\ttrain-amex:0.81453\tvalid-logloss:0.22636\tvalid-amex:0.78150\n",
      "[700]\ttrain-logloss:0.20454\ttrain-amex:0.82056\tvalid-logloss:0.22402\tvalid-amex:0.78439\n",
      "[800]\ttrain-logloss:0.20066\ttrain-amex:0.82602\tvalid-logloss:0.22243\tvalid-amex:0.78574\n",
      "[900]\ttrain-logloss:0.19727\ttrain-amex:0.83120\tvalid-logloss:0.22123\tvalid-amex:0.78745\n",
      "[1000]\ttrain-logloss:0.19433\ttrain-amex:0.83600\tvalid-logloss:0.22032\tvalid-amex:0.78892\n",
      "[1100]\ttrain-logloss:0.19151\ttrain-amex:0.84047\tvalid-logloss:0.21957\tvalid-amex:0.78937\n",
      "[1200]\ttrain-logloss:0.18898\ttrain-amex:0.84457\tvalid-logloss:0.21897\tvalid-amex:0.79002\n",
      "[1300]\ttrain-logloss:0.18659\ttrain-amex:0.84888\tvalid-logloss:0.21848\tvalid-amex:0.79073\n",
      "[1400]\ttrain-logloss:0.18439\ttrain-amex:0.85269\tvalid-logloss:0.21810\tvalid-amex:0.79152\n",
      "[1500]\ttrain-logloss:0.18227\ttrain-amex:0.85648\tvalid-logloss:0.21775\tvalid-amex:0.79235\n",
      "[1600]\ttrain-logloss:0.18029\ttrain-amex:0.85960\tvalid-logloss:0.21745\tvalid-amex:0.79322\n",
      "[1700]\ttrain-logloss:0.17832\ttrain-amex:0.86321\tvalid-logloss:0.21718\tvalid-amex:0.79297\n",
      "[1800]\ttrain-logloss:0.17638\ttrain-amex:0.86674\tvalid-logloss:0.21695\tvalid-amex:0.79385\n",
      "[1900]\ttrain-logloss:0.17459\ttrain-amex:0.86986\tvalid-logloss:0.21676\tvalid-amex:0.79383\n",
      "[2000]\ttrain-logloss:0.17283\ttrain-amex:0.87303\tvalid-logloss:0.21660\tvalid-amex:0.79372\n",
      "[2100]\ttrain-logloss:0.17104\ttrain-amex:0.87630\tvalid-logloss:0.21645\tvalid-amex:0.79392\n",
      "[2200]\ttrain-logloss:0.16921\ttrain-amex:0.87956\tvalid-logloss:0.21632\tvalid-amex:0.79407\n",
      "[2300]\ttrain-logloss:0.16760\ttrain-amex:0.88241\tvalid-logloss:0.21619\tvalid-amex:0.79401\n",
      "[2400]\ttrain-logloss:0.16599\ttrain-amex:0.88512\tvalid-logloss:0.21607\tvalid-amex:0.79441\n",
      "[2500]\ttrain-logloss:0.16432\ttrain-amex:0.88810\tvalid-logloss:0.21598\tvalid-amex:0.79528\n",
      "[2600]\ttrain-logloss:0.16265\ttrain-amex:0.89093\tvalid-logloss:0.21589\tvalid-amex:0.79563\n",
      "[2700]\ttrain-logloss:0.16115\ttrain-amex:0.89382\tvalid-logloss:0.21582\tvalid-amex:0.79587\n",
      "[2800]\ttrain-logloss:0.15974\ttrain-amex:0.89622\tvalid-logloss:0.21576\tvalid-amex:0.79561\n",
      "[2900]\ttrain-logloss:0.15812\ttrain-amex:0.89882\tvalid-logloss:0.21569\tvalid-amex:0.79576\n",
      "[3000]\ttrain-logloss:0.15661\ttrain-amex:0.90149\tvalid-logloss:0.21562\tvalid-amex:0.79587\n",
      "[3100]\ttrain-logloss:0.15511\ttrain-amex:0.90401\tvalid-logloss:0.21556\tvalid-amex:0.79583\n",
      "[3200]\ttrain-logloss:0.15369\ttrain-amex:0.90632\tvalid-logloss:0.21549\tvalid-amex:0.79594\n",
      "[3300]\ttrain-logloss:0.15221\ttrain-amex:0.90887\tvalid-logloss:0.21545\tvalid-amex:0.79585\n",
      "[3400]\ttrain-logloss:0.15082\ttrain-amex:0.91117\tvalid-logloss:0.21541\tvalid-amex:0.79549\n",
      "[3500]\ttrain-logloss:0.14942\ttrain-amex:0.91345\tvalid-logloss:0.21537\tvalid-amex:0.79593\n",
      "[3600]\ttrain-logloss:0.14797\ttrain-amex:0.91573\tvalid-logloss:0.21532\tvalid-amex:0.79599\n",
      "[3700]\ttrain-logloss:0.14652\ttrain-amex:0.91819\tvalid-logloss:0.21529\tvalid-amex:0.79623\n",
      "[3800]\ttrain-logloss:0.14520\ttrain-amex:0.92039\tvalid-logloss:0.21524\tvalid-amex:0.79640\n",
      "[3900]\ttrain-logloss:0.14389\ttrain-amex:0.92257\tvalid-logloss:0.21522\tvalid-amex:0.79649\n",
      "[4000]\ttrain-logloss:0.14252\ttrain-amex:0.92492\tvalid-logloss:0.21519\tvalid-amex:0.79656\n",
      "[4100]\ttrain-logloss:0.14124\ttrain-amex:0.92707\tvalid-logloss:0.21516\tvalid-amex:0.79645\n",
      "[4200]\ttrain-logloss:0.13993\ttrain-amex:0.92931\tvalid-logloss:0.21515\tvalid-amex:0.79637\n",
      "[4300]\ttrain-logloss:0.13869\ttrain-amex:0.93133\tvalid-logloss:0.21513\tvalid-amex:0.79644\n",
      "[4400]\ttrain-logloss:0.13743\ttrain-amex:0.93323\tvalid-logloss:0.21513\tvalid-amex:0.79660\n",
      "[4500]\ttrain-logloss:0.13614\ttrain-amex:0.93516\tvalid-logloss:0.21511\tvalid-amex:0.79625\n",
      "[4600]\ttrain-logloss:0.13487\ttrain-amex:0.93720\tvalid-logloss:0.21509\tvalid-amex:0.79647\n",
      "[4700]\ttrain-logloss:0.13373\ttrain-amex:0.93878\tvalid-logloss:0.21507\tvalid-amex:0.79681\n",
      "[4800]\ttrain-logloss:0.13249\ttrain-amex:0.94069\tvalid-logloss:0.21507\tvalid-amex:0.79675\n",
      "[4900]\ttrain-logloss:0.13125\ttrain-amex:0.94249\tvalid-logloss:0.21505\tvalid-amex:0.79655\n",
      "[5000]\ttrain-logloss:0.13009\ttrain-amex:0.94423\tvalid-logloss:0.21503\tvalid-amex:0.79639\n",
      "[5100]\ttrain-logloss:0.12887\ttrain-amex:0.94589\tvalid-logloss:0.21502\tvalid-amex:0.79640\n",
      "[5200]\ttrain-logloss:0.12770\ttrain-amex:0.94763\tvalid-logloss:0.21502\tvalid-amex:0.79613\n",
      "[5300]\ttrain-logloss:0.12660\ttrain-amex:0.94902\tvalid-logloss:0.21501\tvalid-amex:0.79639\n",
      "[5378]\ttrain-logloss:0.12575\ttrain-amex:0.95011\tvalid-logloss:0.21502\tvalid-amex:0.79591\n",
      "Our fold 0 CV score is 0.7956465703067168\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 1 with 2023 features...\n",
      "[12:29:04] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\ttrain-logloss:0.68727\ttrain-amex:0.71854\tvalid-logloss:0.68725\tvalid-amex:0.70701\n",
      "[100]\ttrain-logloss:0.37706\ttrain-amex:0.77490\tvalid-logloss:0.38218\tvalid-amex:0.75316\n",
      "[200]\ttrain-logloss:0.27931\ttrain-amex:0.78684\tvalid-logloss:0.28833\tvalid-amex:0.76212\n",
      "[300]\ttrain-logloss:0.24098\ttrain-amex:0.79503\tvalid-logloss:0.25306\tvalid-amex:0.76808\n",
      "[400]\ttrain-logloss:0.22359\ttrain-amex:0.80308\tvalid-logloss:0.23832\tvalid-amex:0.77316\n",
      "[500]\ttrain-logloss:0.21440\ttrain-amex:0.80932\tvalid-logloss:0.23145\tvalid-amex:0.77753\n",
      "[600]\ttrain-logloss:0.20846\ttrain-amex:0.81561\tvalid-logloss:0.22773\tvalid-amex:0.78071\n",
      "[700]\ttrain-logloss:0.20390\ttrain-amex:0.82169\tvalid-logloss:0.22541\tvalid-amex:0.78304\n",
      "[800]\ttrain-logloss:0.20007\ttrain-amex:0.82689\tvalid-logloss:0.22384\tvalid-amex:0.78461\n",
      "[900]\ttrain-logloss:0.19686\ttrain-amex:0.83142\tvalid-logloss:0.22271\tvalid-amex:0.78589\n",
      "[1000]\ttrain-logloss:0.19395\ttrain-amex:0.83545\tvalid-logloss:0.22185\tvalid-amex:0.78689\n",
      "[1100]\ttrain-logloss:0.19131\ttrain-amex:0.83929\tvalid-logloss:0.22115\tvalid-amex:0.78806\n",
      "[1200]\ttrain-logloss:0.18888\ttrain-amex:0.84344\tvalid-logloss:0.22061\tvalid-amex:0.78869\n",
      "[1300]\ttrain-logloss:0.18660\ttrain-amex:0.84723\tvalid-logloss:0.22015\tvalid-amex:0.78904\n",
      "[1400]\ttrain-logloss:0.18437\ttrain-amex:0.85135\tvalid-logloss:0.21976\tvalid-amex:0.78936\n",
      "[1500]\ttrain-logloss:0.18226\ttrain-amex:0.85479\tvalid-logloss:0.21943\tvalid-amex:0.79095\n",
      "[1600]\ttrain-logloss:0.18026\ttrain-amex:0.85818\tvalid-logloss:0.21915\tvalid-amex:0.79092\n",
      "[1700]\ttrain-logloss:0.17833\ttrain-amex:0.86135\tvalid-logloss:0.21893\tvalid-amex:0.79169\n",
      "[1800]\ttrain-logloss:0.17639\ttrain-amex:0.86506\tvalid-logloss:0.21874\tvalid-amex:0.79119\n",
      "[1900]\ttrain-logloss:0.17466\ttrain-amex:0.86837\tvalid-logloss:0.21856\tvalid-amex:0.79134\n",
      "[2000]\ttrain-logloss:0.17291\ttrain-amex:0.87175\tvalid-logloss:0.21843\tvalid-amex:0.79185\n",
      "[2100]\ttrain-logloss:0.17127\ttrain-amex:0.87443\tvalid-logloss:0.21829\tvalid-amex:0.79230\n",
      "[2200]\ttrain-logloss:0.16955\ttrain-amex:0.87760\tvalid-logloss:0.21813\tvalid-amex:0.79271\n",
      "[2300]\ttrain-logloss:0.16791\ttrain-amex:0.88052\tvalid-logloss:0.21802\tvalid-amex:0.79300\n",
      "[2400]\ttrain-logloss:0.16627\ttrain-amex:0.88353\tvalid-logloss:0.21793\tvalid-amex:0.79318\n",
      "[2500]\ttrain-logloss:0.16478\ttrain-amex:0.88617\tvalid-logloss:0.21787\tvalid-amex:0.79310\n",
      "[2600]\ttrain-logloss:0.16318\ttrain-amex:0.88919\tvalid-logloss:0.21779\tvalid-amex:0.79349\n",
      "[2700]\ttrain-logloss:0.16179\ttrain-amex:0.89183\tvalid-logloss:0.21772\tvalid-amex:0.79305\n",
      "[2800]\ttrain-logloss:0.16023\ttrain-amex:0.89462\tvalid-logloss:0.21764\tvalid-amex:0.79367\n",
      "[2900]\ttrain-logloss:0.15870\ttrain-amex:0.89731\tvalid-logloss:0.21759\tvalid-amex:0.79344\n",
      "[3000]\ttrain-logloss:0.15725\ttrain-amex:0.89988\tvalid-logloss:0.21752\tvalid-amex:0.79359\n",
      "[3100]\ttrain-logloss:0.15583\ttrain-amex:0.90231\tvalid-logloss:0.21748\tvalid-amex:0.79346\n",
      "[3200]\ttrain-logloss:0.15433\ttrain-amex:0.90485\tvalid-logloss:0.21743\tvalid-amex:0.79373\n",
      "[3300]\ttrain-logloss:0.15296\ttrain-amex:0.90717\tvalid-logloss:0.21740\tvalid-amex:0.79334\n",
      "[3400]\ttrain-logloss:0.15151\ttrain-amex:0.90968\tvalid-logloss:0.21737\tvalid-amex:0.79321\n",
      "[3500]\ttrain-logloss:0.15009\ttrain-amex:0.91217\tvalid-logloss:0.21731\tvalid-amex:0.79336\n",
      "[3600]\ttrain-logloss:0.14873\ttrain-amex:0.91437\tvalid-logloss:0.21727\tvalid-amex:0.79371\n",
      "[3700]\ttrain-logloss:0.14744\ttrain-amex:0.91661\tvalid-logloss:0.21726\tvalid-amex:0.79370\n",
      "[3800]\ttrain-logloss:0.14613\ttrain-amex:0.91862\tvalid-logloss:0.21722\tvalid-amex:0.79369\n",
      "[3900]\ttrain-logloss:0.14483\ttrain-amex:0.92077\tvalid-logloss:0.21719\tvalid-amex:0.79373\n",
      "[4000]\ttrain-logloss:0.14349\ttrain-amex:0.92291\tvalid-logloss:0.21715\tvalid-amex:0.79328\n",
      "[4100]\ttrain-logloss:0.14220\ttrain-amex:0.92484\tvalid-logloss:0.21713\tvalid-amex:0.79357\n",
      "[4134]\ttrain-logloss:0.14176\ttrain-amex:0.92549\tvalid-logloss:0.21712\tvalid-amex:0.79342\n",
      "Our fold 1 CV score is 0.7931832242296268\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 2 with 2023 features...\n",
      "[14:43:03] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\ttrain-logloss:0.68725\ttrain-amex:0.71681\tvalid-logloss:0.68730\tvalid-amex:0.70810\n",
      "[100]\ttrain-logloss:0.37720\ttrain-amex:0.77486\tvalid-logloss:0.38180\tvalid-amex:0.75437\n",
      "[200]\ttrain-logloss:0.27948\ttrain-amex:0.78693\tvalid-logloss:0.28782\tvalid-amex:0.76355\n",
      "[300]\ttrain-logloss:0.24106\ttrain-amex:0.79590\tvalid-logloss:0.25254\tvalid-amex:0.76880\n",
      "[400]\ttrain-logloss:0.22370\ttrain-amex:0.80307\tvalid-logloss:0.23795\tvalid-amex:0.77273\n",
      "[500]\ttrain-logloss:0.21448\ttrain-amex:0.80995\tvalid-logloss:0.23124\tvalid-amex:0.77594\n",
      "[600]\ttrain-logloss:0.20863\ttrain-amex:0.81560\tvalid-logloss:0.22765\tvalid-amex:0.77831\n",
      "[700]\ttrain-logloss:0.20413\ttrain-amex:0.82139\tvalid-logloss:0.22550\tvalid-amex:0.78048\n",
      "[800]\ttrain-logloss:0.20021\ttrain-amex:0.82717\tvalid-logloss:0.22398\tvalid-amex:0.78182\n",
      "[900]\ttrain-logloss:0.19695\ttrain-amex:0.83214\tvalid-logloss:0.22289\tvalid-amex:0.78292\n",
      "[1000]\ttrain-logloss:0.19405\ttrain-amex:0.83663\tvalid-logloss:0.22203\tvalid-amex:0.78379\n",
      "[1100]\ttrain-logloss:0.19132\ttrain-amex:0.84090\tvalid-logloss:0.22132\tvalid-amex:0.78515\n",
      "[1200]\ttrain-logloss:0.18880\ttrain-amex:0.84476\tvalid-logloss:0.22076\tvalid-amex:0.78576\n",
      "[1300]\ttrain-logloss:0.18641\ttrain-amex:0.84868\tvalid-logloss:0.22029\tvalid-amex:0.78656\n",
      "[1400]\ttrain-logloss:0.18416\ttrain-amex:0.85214\tvalid-logloss:0.21994\tvalid-amex:0.78740\n",
      "[1500]\ttrain-logloss:0.18206\ttrain-amex:0.85601\tvalid-logloss:0.21961\tvalid-amex:0.78823\n",
      "[1600]\ttrain-logloss:0.17998\ttrain-amex:0.85960\tvalid-logloss:0.21934\tvalid-amex:0.78820\n",
      "[1700]\ttrain-logloss:0.17803\ttrain-amex:0.86290\tvalid-logloss:0.21910\tvalid-amex:0.78814\n",
      "[1800]\ttrain-logloss:0.17617\ttrain-amex:0.86606\tvalid-logloss:0.21890\tvalid-amex:0.78878\n",
      "[1900]\ttrain-logloss:0.17408\ttrain-amex:0.86991\tvalid-logloss:0.21871\tvalid-amex:0.78917\n",
      "[2000]\ttrain-logloss:0.17221\ttrain-amex:0.87334\tvalid-logloss:0.21856\tvalid-amex:0.78941\n",
      "[2100]\ttrain-logloss:0.17038\ttrain-amex:0.87655\tvalid-logloss:0.21841\tvalid-amex:0.78997\n",
      "[2200]\ttrain-logloss:0.16875\ttrain-amex:0.87949\tvalid-logloss:0.21829\tvalid-amex:0.78987\n",
      "[2300]\ttrain-logloss:0.16716\ttrain-amex:0.88245\tvalid-logloss:0.21817\tvalid-amex:0.79006\n",
      "[2400]\ttrain-logloss:0.16547\ttrain-amex:0.88533\tvalid-logloss:0.21807\tvalid-amex:0.78981\n",
      "[2500]\ttrain-logloss:0.16387\ttrain-amex:0.88812\tvalid-logloss:0.21798\tvalid-amex:0.78986\n",
      "[2600]\ttrain-logloss:0.16225\ttrain-amex:0.89112\tvalid-logloss:0.21790\tvalid-amex:0.78989\n",
      "[2700]\ttrain-logloss:0.16063\ttrain-amex:0.89409\tvalid-logloss:0.21782\tvalid-amex:0.79005\n",
      "[2727]\ttrain-logloss:0.16021\ttrain-amex:0.89490\tvalid-logloss:0.21780\tvalid-amex:0.78985\n",
      "Our fold 2 CV score is 0.7896099783669838\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 3 with 2023 features...\n",
      "[16:14:32] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\ttrain-logloss:0.68726\ttrain-amex:0.71483\tvalid-logloss:0.68723\tvalid-amex:0.71084\n",
      "[100]\ttrain-logloss:0.37766\ttrain-amex:0.77420\tvalid-logloss:0.38066\tvalid-amex:0.75870\n",
      "[200]\ttrain-logloss:0.28003\ttrain-amex:0.78553\tvalid-logloss:0.28617\tvalid-amex:0.76638\n",
      "[300]\ttrain-logloss:0.24173\ttrain-amex:0.79380\tvalid-logloss:0.25057\tvalid-amex:0.77210\n",
      "[400]\ttrain-logloss:0.22451\ttrain-amex:0.80172\tvalid-logloss:0.23577\tvalid-amex:0.77690\n",
      "[500]\ttrain-logloss:0.21533\ttrain-amex:0.80837\tvalid-logloss:0.22881\tvalid-amex:0.78057\n",
      "[600]\ttrain-logloss:0.20941\ttrain-amex:0.81413\tvalid-logloss:0.22504\tvalid-amex:0.78395\n",
      "[700]\ttrain-logloss:0.20492\ttrain-amex:0.82008\tvalid-logloss:0.22273\tvalid-amex:0.78601\n",
      "[800]\ttrain-logloss:0.20100\ttrain-amex:0.82557\tvalid-logloss:0.22113\tvalid-amex:0.78788\n",
      "[900]\ttrain-logloss:0.19764\ttrain-amex:0.83029\tvalid-logloss:0.21996\tvalid-amex:0.78995\n",
      "[1000]\ttrain-logloss:0.19462\ttrain-amex:0.83519\tvalid-logloss:0.21907\tvalid-amex:0.79074\n",
      "[1100]\ttrain-logloss:0.19191\ttrain-amex:0.83972\tvalid-logloss:0.21837\tvalid-amex:0.79110\n",
      "[1200]\ttrain-logloss:0.18937\ttrain-amex:0.84379\tvalid-logloss:0.21781\tvalid-amex:0.79209\n",
      "[1300]\ttrain-logloss:0.18706\ttrain-amex:0.84770\tvalid-logloss:0.21732\tvalid-amex:0.79278\n",
      "[1400]\ttrain-logloss:0.18481\ttrain-amex:0.85137\tvalid-logloss:0.21696\tvalid-amex:0.79356\n",
      "[1500]\ttrain-logloss:0.18278\ttrain-amex:0.85488\tvalid-logloss:0.21664\tvalid-amex:0.79375\n",
      "[1600]\ttrain-logloss:0.18073\ttrain-amex:0.85847\tvalid-logloss:0.21638\tvalid-amex:0.79430\n",
      "[1700]\ttrain-logloss:0.17883\ttrain-amex:0.86176\tvalid-logloss:0.21617\tvalid-amex:0.79458\n",
      "[1800]\ttrain-logloss:0.17693\ttrain-amex:0.86510\tvalid-logloss:0.21596\tvalid-amex:0.79453\n",
      "[1900]\ttrain-logloss:0.17507\ttrain-amex:0.86853\tvalid-logloss:0.21579\tvalid-amex:0.79472\n",
      "[2000]\ttrain-logloss:0.17329\ttrain-amex:0.87177\tvalid-logloss:0.21562\tvalid-amex:0.79438\n",
      "[2100]\ttrain-logloss:0.17155\ttrain-amex:0.87490\tvalid-logloss:0.21546\tvalid-amex:0.79490\n",
      "[2200]\ttrain-logloss:0.16977\ttrain-amex:0.87780\tvalid-logloss:0.21533\tvalid-amex:0.79509\n",
      "[2300]\ttrain-logloss:0.16812\ttrain-amex:0.88070\tvalid-logloss:0.21522\tvalid-amex:0.79546\n",
      "[2400]\ttrain-logloss:0.16650\ttrain-amex:0.88350\tvalid-logloss:0.21512\tvalid-amex:0.79527\n",
      "[2500]\ttrain-logloss:0.16479\ttrain-amex:0.88657\tvalid-logloss:0.21501\tvalid-amex:0.79560\n",
      "[2600]\ttrain-logloss:0.16320\ttrain-amex:0.88929\tvalid-logloss:0.21492\tvalid-amex:0.79563\n",
      "[2700]\ttrain-logloss:0.16165\ttrain-amex:0.89188\tvalid-logloss:0.21484\tvalid-amex:0.79621\n",
      "[2800]\ttrain-logloss:0.16014\ttrain-amex:0.89449\tvalid-logloss:0.21477\tvalid-amex:0.79596\n",
      "[2900]\ttrain-logloss:0.15869\ttrain-amex:0.89715\tvalid-logloss:0.21470\tvalid-amex:0.79645\n",
      "[3000]\ttrain-logloss:0.15708\ttrain-amex:0.90007\tvalid-logloss:0.21464\tvalid-amex:0.79647\n",
      "[3100]\ttrain-logloss:0.15564\ttrain-amex:0.90246\tvalid-logloss:0.21459\tvalid-amex:0.79634\n",
      "[3200]\ttrain-logloss:0.15418\ttrain-amex:0.90484\tvalid-logloss:0.21455\tvalid-amex:0.79636\n",
      "[3300]\ttrain-logloss:0.15269\ttrain-amex:0.90725\tvalid-logloss:0.21452\tvalid-amex:0.79616\n",
      "[3400]\ttrain-logloss:0.15133\ttrain-amex:0.90968\tvalid-logloss:0.21448\tvalid-amex:0.79643\n",
      "[3472]\ttrain-logloss:0.15028\ttrain-amex:0.91167\tvalid-logloss:0.21446\tvalid-amex:0.79654\n",
      "Our fold 3 CV score is 0.796289136180045\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 4 with 2023 features...\n",
      "[18:09:11] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\ttrain-logloss:0.68726\ttrain-amex:0.71481\tvalid-logloss:0.68729\tvalid-amex:0.71115\n",
      "[100]\ttrain-logloss:0.37748\ttrain-amex:0.77331\tvalid-logloss:0.38147\tvalid-amex:0.76008\n",
      "[200]\ttrain-logloss:0.27984\ttrain-amex:0.78537\tvalid-logloss:0.28707\tvalid-amex:0.76780\n",
      "[300]\ttrain-logloss:0.24153\ttrain-amex:0.79415\tvalid-logloss:0.25150\tvalid-amex:0.77360\n",
      "[400]\ttrain-logloss:0.22423\ttrain-amex:0.80154\tvalid-logloss:0.23660\tvalid-amex:0.77772\n",
      "[500]\ttrain-logloss:0.21510\ttrain-amex:0.80834\tvalid-logloss:0.22965\tvalid-amex:0.78146\n",
      "[600]\ttrain-logloss:0.20932\ttrain-amex:0.81405\tvalid-logloss:0.22593\tvalid-amex:0.78471\n",
      "[700]\ttrain-logloss:0.20494\ttrain-amex:0.81974\tvalid-logloss:0.22364\tvalid-amex:0.78729\n",
      "[800]\ttrain-logloss:0.20121\ttrain-amex:0.82488\tvalid-logloss:0.22209\tvalid-amex:0.78813\n",
      "[900]\ttrain-logloss:0.19792\ttrain-amex:0.82973\tvalid-logloss:0.22092\tvalid-amex:0.78947\n",
      "[1000]\ttrain-logloss:0.19494\ttrain-amex:0.83440\tvalid-logloss:0.22000\tvalid-amex:0.79052\n",
      "[1100]\ttrain-logloss:0.19221\ttrain-amex:0.83862\tvalid-logloss:0.21928\tvalid-amex:0.79186\n",
      "[1200]\ttrain-logloss:0.18968\ttrain-amex:0.84294\tvalid-logloss:0.21868\tvalid-amex:0.79189\n",
      "[1300]\ttrain-logloss:0.18734\ttrain-amex:0.84673\tvalid-logloss:0.21816\tvalid-amex:0.79282\n",
      "[1400]\ttrain-logloss:0.18502\ttrain-amex:0.85044\tvalid-logloss:0.21776\tvalid-amex:0.79371\n",
      "[1500]\ttrain-logloss:0.18285\ttrain-amex:0.85428\tvalid-logloss:0.21744\tvalid-amex:0.79431\n",
      "[1600]\ttrain-logloss:0.18077\ttrain-amex:0.85783\tvalid-logloss:0.21713\tvalid-amex:0.79460\n",
      "[1700]\ttrain-logloss:0.17885\ttrain-amex:0.86104\tvalid-logloss:0.21690\tvalid-amex:0.79478\n",
      "[1800]\ttrain-logloss:0.17699\ttrain-amex:0.86424\tvalid-logloss:0.21668\tvalid-amex:0.79501\n",
      "[1900]\ttrain-logloss:0.17521\ttrain-amex:0.86759\tvalid-logloss:0.21648\tvalid-amex:0.79549\n",
      "[2000]\ttrain-logloss:0.17345\ttrain-amex:0.87089\tvalid-logloss:0.21630\tvalid-amex:0.79541\n",
      "[2100]\ttrain-logloss:0.17175\ttrain-amex:0.87387\tvalid-logloss:0.21616\tvalid-amex:0.79560\n",
      "[2200]\ttrain-logloss:0.17004\ttrain-amex:0.87699\tvalid-logloss:0.21601\tvalid-amex:0.79523\n",
      "[2300]\ttrain-logloss:0.16838\ttrain-amex:0.87986\tvalid-logloss:0.21590\tvalid-amex:0.79525\n",
      "[2400]\ttrain-logloss:0.16670\ttrain-amex:0.88284\tvalid-logloss:0.21578\tvalid-amex:0.79556\n",
      "[2443]\ttrain-logloss:0.16600\ttrain-amex:0.88406\tvalid-logloss:0.21573\tvalid-amex:0.79560\n",
      "Our fold 4 CV score is 0.7954325529246853\n",
      "Our out of folds CV score is 0.020605391255782844\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cat_features = [\n",
    "    \"B_30\",\n",
    "    \"B_38\",\n",
    "    \"D_114\",\n",
    "    \"D_116\",\n",
    "    \"D_117\",\n",
    "    \"D_120\",\n",
    "    \"D_126\",\n",
    "    \"D_63\",\n",
    "    \"D_64\",\n",
    "    \"D_66\",\n",
    "    \"D_68\"\n",
    "]\n",
    "\n",
    "# kmeans_list = [\"kmeans pred 2\",\"kmeans pred 3\",\"kmeans pred 4\"]\n",
    "\n",
    "cat_features = [f\"{cf}_last\" for cf in cat_features]\n",
    "# cat_features.extend(kmeans_list)\n",
    "\n",
    "# for cat_col in cat_features:\n",
    "# #     print(cat_col)\n",
    "#     encoder = LabelEncoder()\n",
    "#     train[cat_col] = encoder.fit_transform(train[cat_col])\n",
    "#     test[cat_col] = encoder.transform(test[cat_col])\n",
    "\n",
    "\n",
    "features = [col for col in train.columns if col not in ['customer_ID', CFG.target]]\n",
    "\n",
    "xgb_parameters={\n",
    "        'max_depth': 9,#7 # optuna 9\n",
    "        'eta': 0.03,\n",
    "        'subsample': 0.88,\n",
    "        'colsample_bytree': 0.5,\n",
    "        'objective': 'binary:logistic',\n",
    "        'learning_rate' : 0.008971755769136095,#0.026582608139330333\n",
    "        'tree_method': 'hist',#gpu_hist\n",
    "        # 'predictor': 'gpu_predictor',\n",
    "        'random_state': 42,\n",
    "        'gamma': 1.5,\n",
    "        'min_child_weight': 19,#8 # optuna 19\n",
    "        'lambda': 70,\n",
    "    }\n",
    "\n",
    "# Create a numpy array to store test predictions\n",
    "test_predictions = np.zeros(len(test))\n",
    "# Create a numpy array to store out of folds predictions\n",
    "# oof_predictions = np.zeros(len(train))\n",
    "oof_predictions = []\n",
    "\n",
    "cids = []\n",
    "tr_target = []\n",
    "\n",
    "# epoch = [10000,7500,7500,8500,10500]\n",
    "\n",
    "kfold = StratifiedKFold(n_splits = CFG.n_folds, shuffle = True, random_state = CFG.seed)\n",
    "for fold, (trn_ind, val_ind) in enumerate(kfold.split(train, train[CFG.target])):\n",
    "    print(' ')\n",
    "    print('-'*50)\n",
    "    print(f'Training fold {fold} with {len(features)} features...')\n",
    "    x_train, x_val = train[features].iloc[trn_ind], train[features].iloc[val_ind]\n",
    "    y_train, y_val = train[CFG.target].iloc[trn_ind], train[CFG.target].iloc[val_ind]\n",
    "    \n",
    "    dtrain = xgb.DMatrix(data=x_train, label=y_train)\n",
    "    dvalid = xgb.DMatrix(data=x_val, label=y_val)\n",
    "    dtest = xgb.DMatrix(data=test[features])\n",
    "    \n",
    "#     des = DartEarlyStopping(\"valid_1\", CFG.metric, 1000)\n",
    "  \n",
    "    model = xgb.train(\n",
    "            xgb_parameters,\n",
    "            dtrain=dtrain,\n",
    "            num_boost_round=9999,#9999\n",
    "            evals=[(dtrain, \"train\"), (dvalid, \"valid\")],\n",
    "            early_stopping_rounds=500,\n",
    "            feval=xgb_amex,\n",
    "            maximize=True,\n",
    "            verbose_eval=100\n",
    "        )\n",
    "    \n",
    "    \n",
    "    # Save best model\n",
    "    model.save_model(f'{CFG.output_dir}{CFG.model}_{CFG.ver}_{CFG.boosting_type}_fold{fold}_seed{CFG.seed}.xgb')\n",
    "#     joblib.dump(model, f'{CFG.output_dir}lgbm_{CFG.boosting_type}_fold{fold}_seed{CFG.seed}.pkl')\n",
    "    # Predict validation\n",
    "    val_pred = model.predict(dvalid)\n",
    "    # Add to out of folds array\n",
    "    # oof_predictions[val_ind] = val_pred\n",
    "    \n",
    "    oof_predictions.extend(val_pred)\n",
    "    cids.extend(train[\"customer_ID\"].loc[val_ind])\n",
    "    tr_target.extend(train[\"target\"].loc[val_ind])\n",
    "    \n",
    "    # Predict the test set\n",
    "    test_pred = model.predict(dtest)\n",
    "    test_predictions += test_pred / CFG.n_folds\n",
    "    # Compute fold metric\n",
    "    score = amex_metric(y_val, val_pred)\n",
    "    print(f'Our fold {fold} CV score is {score}')\n",
    "    del x_train, x_val, y_train, y_val, dtrain, dtest ,dvalid\n",
    "    gc.collect()\n",
    "    \n",
    "# Compute out of folds metric\n",
    "score = amex_metric(train[CFG.target], oof_predictions)\n",
    "print(f'Our out of folds CV score is {score}')\n",
    "\n",
    "\n",
    "# Create a dataframe to store test prediction\n",
    "test_df = pd.DataFrame({'customer_ID': test['customer_ID'], 'prediction': test_predictions})\n",
    "# test_df.to_csv(f'{CFG.output_dir}test_{CFG.model}_{score}_baseline_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)\n",
    "test_df.to_csv(f'{CFG.output_dir}test_614_{CFG.ver}_{CFG.model}_{score}_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)\n",
    "\n",
    "\n",
    "dic_oof = {\n",
    "    \"customer_ID\":cids,\n",
    "    \"target\":tr_target,\n",
    "    f\"{CFG.ver}_{CFG.model}_oof\":oof_predictions\n",
    "}\n",
    "\n",
    "# Create a dataframe to store out of folds predictions\n",
    "oof_df = pd.DataFrame(dic_oof)\n",
    "# oof_df = pd.DataFrame({'customer_ID': train['customer_ID'], 'target': train[CFG.target], 'prediction': oof_predictions})\n",
    "oof_df.to_csv(f'{CFG.output_dir}oof_614_{CFG.ver}_{CFG.model}_{score}_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)\n",
    "\n",
    "\n",
    "# # Create a dataframe to store out of folds predictions\n",
    "# oof_df = pd.DataFrame({'customer_ID': train['customer_ID'], 'target': train[CFG.target], 'prediction': oof_predictions})\n",
    "# oof_df.to_csv(f'../output/Amex LGBM Dart CV 0.7977/oof_lgbm_{CFG.boosting_type}_baseline_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)\n",
    "\n",
    "\n",
    "# # Create a dataframe to store test prediction\n",
    "# test_df = pd.DataFrame({'customer_ID': test['customer_ID'], 'prediction': test_predictions})\n",
    "# test_df.to_csv(f'../output/Amex LGBM Dart CV 0.7977/test_lgbm_{CFG.boosting_type}_baseline_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbeee38-a459-4cde-a283-173b404db41e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae22760e-26c4-4f79-b6f2-44b108efa8db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7939177264121403"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute out of folds metric\n",
    "amex_metric(oof_df[\"target\"], oof_df[\"exp52_xgb_oof\"])\n",
    "# print(f'Our out of folds CV score is {score}')\n",
    "\n",
    "\n",
    "# # Create a dataframe to store out of folds predictions\n",
    "# oof_df = pd.DataFrame(dic_oof)\n",
    "# # oof_df = pd.DataFrame({'customer_ID': train['customer_ID'], 'target': train[CFG.target], 'prediction': oof_predictions})\n",
    "# oof_df.to_csv(f'{CFG.output_dir}oof_614_{CFG.ver}_{CFG.model}_{score}_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69435314-acf8-423f-8dcc-b9cf6a911da8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>target</th>\n",
       "      <th>exp52_xgb_oof</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001b22f846c82c51f6e3958ccd81970162bae8b007e8...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000098081fde4fd64bc4d503a5d6f86a0aedc425c96f52...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.196015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000f99513770170a1aba690daeeb8a96da4a39f11fc27...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.878774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001337ded4e1c2539d1a78ff44a457bd4a95caa55ba17...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.727824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001812036f1558332e5c0880ecbad70b13a6f28ab04a8...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.778236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         customer_ID  target  exp52_xgb_oof\n",
       "0  00001b22f846c82c51f6e3958ccd81970162bae8b007e8...       0       0.000702\n",
       "1  000098081fde4fd64bc4d503a5d6f86a0aedc425c96f52...       0       0.196015\n",
       "2  0000f99513770170a1aba690daeeb8a96da4a39f11fc27...       1       0.878774\n",
       "3  0001337ded4e1c2539d1a78ff44a457bd4a95caa55ba17...       1       0.727824\n",
       "4  0001812036f1558332e5c0880ecbad70b13a6f28ab04a8...       1       0.778236"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022f92c3-54ae-4d72-a253-1fcf75eab071",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecec902c-14ab-4642-866f-f7cb16649991",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3e9a74-28aa-469b-8713-04720d838bb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bc2720-3052-46c6-80b7-1231506643d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fed9500-72c1-48b4-893d-bc1fa5d7a2d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6762416b-52f6-4464-94ff-e76c6e7da87e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda1dca5-1edb-4513-82d0-b66ee1b4df81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e494e0-50f8-47ad-88c9-637a1b994414",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f770440-1df8-4a28-80c7-a3499e807a13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f3f7fd-7bd1-4e92-93a9-4a18f035feca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amex",
   "language": "python",
   "name": "amex"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
