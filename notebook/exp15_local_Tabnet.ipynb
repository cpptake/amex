{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70f58d85-14e4-4371-ad96-458843ea228c",
   "metadata": {},
   "source": [
    "# exp15\n",
    "\n",
    "exp03 Tabnet entmax\n",
    "\n",
    "https://www.kaggle.com/code/ragnar123/amex-lgbm-dart-cv-0-7977"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "325051a6-7ea3-4398-b022-6a81c18b14eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Library\n",
    "# ====================================================\n",
    "import os\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "from tqdm.auto import tqdm\n",
    "import itertools\n",
    "\n",
    "import joblib\n",
    "import random\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "from itertools import combinations\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import snappy\n",
    "\n",
    "\n",
    "from pytorch_tabnet.pretraining import TabNetPretrainer\n",
    "\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "\n",
    "import torch\n",
    "from pytorch_tabnet.metrics import Metric\n",
    "# from ipywidgets import interact, Select\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e80847-25f2-4784-97c5-b8012eae1a3e",
   "metadata": {},
   "source": [
    "# Training & Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68ef141-3c78-4cd6-988b-db0421753882",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3638c92e-7e65-43e5-8a69-e2aef6660f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ====================================================\n",
    "# Configurations\n",
    "# ====================================================\n",
    "class CFG:\n",
    "    input_dir = '../feature/exp03_amex-fe/'\n",
    "    output_dir = '../output/exp15 Tabnet entmax/'\n",
    "    seed = 46\n",
    "    n_folds = 5\n",
    "    target = 'target'\n",
    "    boosting_type = 'dart'\n",
    "    metric = 'binary_logloss'\n",
    "    model = \"tabnet\"\n",
    "    ver = \"exp15\"\n",
    "\n",
    "# ====================================================\n",
    "# Seed everything\n",
    "# ====================================================\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "# ====================================================\n",
    "# Read data\n",
    "# ====================================================\n",
    "def read_data():\n",
    "    train = pd.read_parquet(CFG.input_dir + 'train_fe_plus_plus.parquet')\n",
    "    test = pd.read_parquet(CFG.input_dir + 'test_fe_plus_plus.parquet')\n",
    "    return train, test\n",
    "\n",
    "# ====================================================\n",
    "# XGB train\n",
    "# ====================================================\n",
    "\n",
    "def cat_train(x, y, xt, yt,cat_features):\n",
    "    print(\"# of features:\", x.shape[1])\n",
    "    assert x.shape[1] == xt.shape[1]\n",
    "    \n",
    "    prams = {\n",
    "        'depth': 8,\n",
    "        'iterations':5000,\n",
    "#         'learning_rate': 0.05,\n",
    "        'random_state':CFG.seed,\n",
    "    }\n",
    "\n",
    "#     watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "    watchlist = [(x, 'train'), (xt, 'eval')]\n",
    "    clf = CatBoostClassifier(**prams)# 5000\n",
    "    clf.fit(x, y, eval_set=[(xt, yt)], cat_features=cat_features,plot=True, verbose_eval = 100)\n",
    "#     print('best ntree_limit:', clf.best_ntree_limit)\n",
    "#     print('best score:', clf.best_score)\n",
    "    # return clf.predict_proba(xt)[:, 1]\n",
    "    return clf.predict_proba(xt)[:, 1], clf\n",
    "\n",
    "def tabnet_train(x, y, xt, yt,cat_features):\n",
    "    print(\"# of features:\", x.shape[1])\n",
    "    assert x.shape[1] == xt.shape[1]\n",
    "    \n",
    "    prams = {\n",
    "        'depth': 8,\n",
    "        'iterations':5000,\n",
    "#         'learning_rate': 0.05,\n",
    "        'random_state':CFG.seed,\n",
    "    }\n",
    "\n",
    "#     watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "    watchlist = [(x, 'train'), (xt, 'eval')]\n",
    "    clf = CatBoostClassifier(**prams)# 5000\n",
    "    clf.fit(x, y, eval_set=[(xt, yt)], cat_features=cat_features,plot=True, verbose_eval = 100)\n",
    "#     print('best ntree_limit:', clf.best_ntree_limit)\n",
    "#     print('best score:', clf.best_score)\n",
    "    # return clf.predict_proba(xt)[:, 1]\n",
    "    return clf.predict_proba(xt)[:, 1], clf\n",
    "\n",
    "\n",
    "\n",
    "# using amex metric to evaluate tabnet\n",
    "class Amex_tabnet(Metric):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self._name = 'amex_tabnet'\n",
    "        self._maximize = True\n",
    "\n",
    "    def __call__(self, y_true, y_pred):\n",
    "        amex = amex_metric_numpy(y_true, y_pred[:, 1])\n",
    "        return max(amex, 0.)\n",
    "\n",
    "# ====================================================\n",
    "# Amex metric\n",
    "# ====================================================\n",
    "def amex_metric(y_true, y_pred):\n",
    "    labels = np.transpose(np.array([y_true, y_pred]))\n",
    "    labels = labels[labels[:, 1].argsort()[::-1]]\n",
    "    weights = np.where(labels[:,0]==0, 20, 1)\n",
    "    cut_vals = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n",
    "    top_four = np.sum(cut_vals[:,0]) / np.sum(labels[:,0])\n",
    "    gini = [0,0]\n",
    "    for i in [1,0]:\n",
    "        labels = np.transpose(np.array([y_true, y_pred]))\n",
    "        labels = labels[labels[:, i].argsort()[::-1]]\n",
    "        weight = np.where(labels[:,0]==0, 20, 1)\n",
    "        weight_random = np.cumsum(weight / np.sum(weight))\n",
    "        total_pos = np.sum(labels[:, 0] *  weight)\n",
    "        cum_pos_found = np.cumsum(labels[:, 0] * weight)\n",
    "        lorentz = cum_pos_found / total_pos\n",
    "        gini[i] = np.sum((lorentz - weight_random) * weight)\n",
    "    return 0.5 * (gini[1]/gini[0] + top_four)\n",
    "\n",
    "\n",
    "def xgb_amex(y_pred, y_true):\n",
    "    return 'amex', amex_metric_np(y_pred,y_true.get_label())\n",
    "\n",
    "\n",
    "# Created by https://www.kaggle.com/yunchonggan\n",
    "# https://www.kaggle.com/competitions/amex-default-prediction/discussion/328020\n",
    "def amex_metric_np(preds: np.ndarray, target: np.ndarray) -> float:\n",
    "    indices = np.argsort(preds)[::-1]\n",
    "    preds, target = preds[indices], target[indices]\n",
    "\n",
    "    weight = 20.0 - target * 19.0\n",
    "    cum_norm_weight = (weight / weight.sum()).cumsum()\n",
    "    four_pct_mask = cum_norm_weight <= 0.04\n",
    "    d = np.sum(target[four_pct_mask]) / np.sum(target)\n",
    "\n",
    "    weighted_target = target * weight\n",
    "    lorentz = (weighted_target / weighted_target.sum()).cumsum()\n",
    "    gini = ((lorentz - cum_norm_weight) * weight).sum()\n",
    "\n",
    "    n_pos = np.sum(target)\n",
    "    n_neg = target.shape[0] - n_pos\n",
    "    gini_max = 10 * n_neg * (n_pos + 20 * n_neg - 19) / (n_pos + 20 * n_neg)\n",
    "\n",
    "    g = gini / gini_max\n",
    "    return 0.5 * (g + d)\n",
    "\n",
    "def amex_metric_numpy(y_true: np.array, y_pred: np.array) -> float:\n",
    "\n",
    "    # count of positives and negatives\n",
    "    n_pos = y_true.sum()\n",
    "    n_neg = y_true.shape[0] - n_pos\n",
    "\n",
    "    # sorting by descring prediction values\n",
    "    indices = np.argsort(y_pred)[::-1]\n",
    "    preds, target = y_pred[indices], y_true[indices]\n",
    "\n",
    "    # filter the top 4% by cumulative row weights\n",
    "    weight = 20.0 - target * 19.0\n",
    "    cum_norm_weight = (weight / weight.sum()).cumsum()\n",
    "    four_pct_filter = cum_norm_weight <= 0.04\n",
    "\n",
    "    # default rate captured at 4%\n",
    "    d = target[four_pct_filter].sum() / n_pos\n",
    "\n",
    "    # weighted gini coefficient\n",
    "    lorentz = (target / n_pos).cumsum()\n",
    "    gini = ((lorentz - cum_norm_weight) * weight).sum()\n",
    "\n",
    "    # max weighted gini coefficient\n",
    "    gini_max = 10 * n_neg * (1 - 19 / (n_pos + 20 * n_neg))\n",
    "\n",
    "    # normalized weighted gini coefficient\n",
    "    g = gini / gini_max\n",
    "\n",
    "    return 0.5 * (g + d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30007ce2-4854-4fd8-8c1b-477936511e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(CFG.seed)\n",
    "train, test = read_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "220db67f-9a57-436b-9ec6-8732c6c6fe67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "--------------------------------------------------\n",
      "Training fold 0 with 1460 features...\n",
      "pass training fold\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 1 with 1460 features...\n",
      "pass training fold\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 2 with 1460 features...\n",
      "pass training fold\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 3 with 1460 features...\n",
      "start Training fold 3\n",
      "epoch 0  | loss: 0.53533 | val_0_auc: 0.91519 | val_0_accuracy: 0.84288 | val_0_amex_tabnet: 0.61936 |  0:04:49s\n",
      "epoch 1  | loss: 0.36586 | val_0_auc: 0.92877 | val_0_accuracy: 0.86212 | val_0_amex_tabnet: 0.66351 |  0:09:39s\n",
      "epoch 2  | loss: 0.32232 | val_0_auc: 0.93464 | val_0_accuracy: 0.86606 | val_0_amex_tabnet: 0.6854  |  0:14:29s\n",
      "epoch 3  | loss: 0.30048 | val_0_auc: 0.93859 | val_0_accuracy: 0.87247 | val_0_amex_tabnet: 0.70112 |  0:19:17s\n",
      "epoch 4  | loss: 0.28998 | val_0_auc: 0.94057 | val_0_accuracy: 0.87384 | val_0_amex_tabnet: 0.70878 |  0:24:06s\n",
      "epoch 5  | loss: 0.27745 | val_0_auc: 0.94563 | val_0_accuracy: 0.88402 | val_0_amex_tabnet: 0.72958 |  0:28:56s\n",
      "epoch 6  | loss: 0.26295 | val_0_auc: 0.94933 | val_0_accuracy: 0.88572 | val_0_amex_tabnet: 0.74268 |  0:33:43s\n",
      "epoch 7  | loss: 0.25488 | val_0_auc: 0.9516  | val_0_accuracy: 0.89076 | val_0_amex_tabnet: 0.75366 |  0:38:26s\n",
      "epoch 8  | loss: 0.24932 | val_0_auc: 0.95219 | val_0_accuracy: 0.89169 | val_0_amex_tabnet: 0.75414 |  0:43:05s\n",
      "epoch 9  | loss: 0.24571 | val_0_auc: 0.95316 | val_0_accuracy: 0.89308 | val_0_amex_tabnet: 0.76019 |  0:47:40s\n",
      "epoch 10 | loss: 0.2445  | val_0_auc: 0.95321 | val_0_accuracy: 0.89108 | val_0_amex_tabnet: 0.76338 |  0:52:03s\n",
      "epoch 11 | loss: 0.23896 | val_0_auc: 0.95643 | val_0_accuracy: 0.89806 | val_0_amex_tabnet: 0.77219 |  0:56:44s\n",
      "epoch 12 | loss: 0.23446 | val_0_auc: 0.95783 | val_0_accuracy: 0.89905 | val_0_amex_tabnet: 0.77624 |  1:01:32s\n",
      "epoch 13 | loss: 0.23085 | val_0_auc: 0.95851 | val_0_accuracy: 0.89932 | val_0_amex_tabnet: 0.78168 |  1:06:21s\n",
      "epoch 14 | loss: 0.22667 | val_0_auc: 0.95929 | val_0_accuracy: 0.9014  | val_0_amex_tabnet: 0.78218 |  1:11:10s\n",
      "epoch 15 | loss: 0.23204 | val_0_auc: 0.9586  | val_0_accuracy: 0.89958 | val_0_amex_tabnet: 0.78071 |  1:15:59s\n",
      "epoch 16 | loss: 0.2306  | val_0_auc: 0.95943 | val_0_accuracy: 0.90123 | val_0_amex_tabnet: 0.78272 |  1:20:47s\n",
      "epoch 17 | loss: 0.2282  | val_0_auc: 0.95978 | val_0_accuracy: 0.90253 | val_0_amex_tabnet: 0.78504 |  1:25:35s\n",
      "epoch 18 | loss: 0.22641 | val_0_auc: 0.96004 | val_0_accuracy: 0.9022  | val_0_amex_tabnet: 0.78657 |  1:30:22s\n",
      "epoch 19 | loss: 0.2239  | val_0_auc: 0.95999 | val_0_accuracy: 0.90303 | val_0_amex_tabnet: 0.78709 |  1:35:08s\n",
      "epoch 20 | loss: 0.2285  | val_0_auc: 0.95907 | val_0_accuracy: 0.90062 | val_0_amex_tabnet: 0.78221 |  1:39:54s\n",
      "epoch 21 | loss: 0.22724 | val_0_auc: 0.95999 | val_0_accuracy: 0.90195 | val_0_amex_tabnet: 0.78713 |  1:44:40s\n",
      "epoch 22 | loss: 0.22583 | val_0_auc: 0.96    | val_0_accuracy: 0.90292 | val_0_amex_tabnet: 0.78584 |  1:49:22s\n",
      "epoch 23 | loss: 0.22433 | val_0_auc: 0.96038 | val_0_accuracy: 0.90263 | val_0_amex_tabnet: 0.78784 |  1:53:59s\n",
      "epoch 24 | loss: 0.22176 | val_0_auc: 0.96044 | val_0_accuracy: 0.90245 | val_0_amex_tabnet: 0.78882 |  1:58:27s\n",
      "epoch 25 | loss: 0.22682 | val_0_auc: 0.95984 | val_0_accuracy: 0.90274 | val_0_amex_tabnet: 0.78632 |  2:03:10s\n",
      "epoch 26 | loss: 0.22581 | val_0_auc: 0.96008 | val_0_accuracy: 0.90112 | val_0_amex_tabnet: 0.7867  |  2:07:54s\n",
      "epoch 27 | loss: 0.22459 | val_0_auc: 0.95999 | val_0_accuracy: 0.90161 | val_0_amex_tabnet: 0.78663 |  2:12:27s\n",
      "epoch 28 | loss: 0.223   | val_0_auc: 0.96039 | val_0_accuracy: 0.90281 | val_0_amex_tabnet: 0.7888  |  2:16:49s\n",
      "epoch 29 | loss: 0.22061 | val_0_auc: 0.96032 | val_0_accuracy: 0.90301 | val_0_amex_tabnet: 0.78788 |  2:21:02s\n",
      "epoch 30 | loss: 0.22574 | val_0_auc: 0.96005 | val_0_accuracy: 0.90231 | val_0_amex_tabnet: 0.78605 |  2:25:48s\n",
      "epoch 31 | loss: 0.22458 | val_0_auc: 0.9599  | val_0_accuracy: 0.90165 | val_0_amex_tabnet: 0.78597 |  2:30:31s\n",
      "epoch 32 | loss: 0.22392 | val_0_auc: 0.95988 | val_0_accuracy: 0.90127 | val_0_amex_tabnet: 0.78527 |  2:35:07s\n",
      "epoch 33 | loss: 0.22182 | val_0_auc: 0.96011 | val_0_accuracy: 0.9017  | val_0_amex_tabnet: 0.78666 |  2:39:35s\n",
      "epoch 34 | loss: 0.21962 | val_0_auc: 0.96034 | val_0_accuracy: 0.90222 | val_0_amex_tabnet: 0.78855 |  2:43:47s\n",
      "epoch 35 | loss: 0.22527 | val_0_auc: 0.9599  | val_0_accuracy: 0.9003  | val_0_amex_tabnet: 0.78449 |  2:48:32s\n",
      "epoch 36 | loss: 0.22422 | val_0_auc: 0.96001 | val_0_accuracy: 0.90189 | val_0_amex_tabnet: 0.78521 |  2:53:15s\n",
      "epoch 37 | loss: 0.22305 | val_0_auc: 0.96013 | val_0_accuracy: 0.90283 | val_0_amex_tabnet: 0.78756 |  2:57:54s\n",
      "epoch 38 | loss: 0.22119 | val_0_auc: 0.96027 | val_0_accuracy: 0.90215 | val_0_amex_tabnet: 0.7873  |  3:02:21s\n",
      "epoch 39 | loss: 0.21901 | val_0_auc: 0.96025 | val_0_accuracy: 0.90194 | val_0_amex_tabnet: 0.78804 |  3:06:32s\n",
      "epoch 40 | loss: 0.22459 | val_0_auc: 0.96008 | val_0_accuracy: 0.9019  | val_0_amex_tabnet: 0.78592 |  3:11:17s\n",
      "epoch 41 | loss: 0.22385 | val_0_auc: 0.96017 | val_0_accuracy: 0.90218 | val_0_amex_tabnet: 0.78572 |  3:16:00s\n",
      "epoch 42 | loss: 0.22263 | val_0_auc: 0.95975 | val_0_accuracy: 0.90155 | val_0_amex_tabnet: 0.78485 |  3:20:40s\n",
      "epoch 43 | loss: 0.22057 | val_0_auc: 0.96026 | val_0_accuracy: 0.90104 | val_0_amex_tabnet: 0.78753 |  3:25:09s\n",
      "epoch 44 | loss: 0.21851 | val_0_auc: 0.9602  | val_0_accuracy: 0.90241 | val_0_amex_tabnet: 0.78698 |  3:29:24s\n",
      "epoch 45 | loss: 0.22467 | val_0_auc: 0.95956 | val_0_accuracy: 0.90031 | val_0_amex_tabnet: 0.78258 |  3:34:09s\n",
      "epoch 46 | loss: 0.22344 | val_0_auc: 0.95985 | val_0_accuracy: 0.90167 | val_0_amex_tabnet: 0.78605 |  3:38:55s\n",
      "epoch 47 | loss: 0.22233 | val_0_auc: 0.95988 | val_0_accuracy: 0.90144 | val_0_amex_tabnet: 0.78565 |  3:43:34s\n",
      "epoch 48 | loss: 0.22067 | val_0_auc: 0.95993 | val_0_accuracy: 0.90238 | val_0_amex_tabnet: 0.78654 |  3:48:02s\n",
      "epoch 49 | loss: 0.21797 | val_0_auc: 0.96017 | val_0_accuracy: 0.90232 | val_0_amex_tabnet: 0.78822 |  3:52:15s\n",
      "Stop training because you reached max_epochs = 50 with best_epoch = 24 and best_val_0_amex_tabnet = 0.78882\n",
      "Successfully saved model at ../output/exp15 Tabnet entmax/tabnet_fold3.zip\n",
      "3 score is :  0.7888245459171852\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 4 with 1460 features...\n",
      "start Training fold 4\n",
      "epoch 0  | loss: 0.54289 | val_0_auc: 0.91242 | val_0_accuracy: 0.83935 | val_0_amex_tabnet: 0.60657 |  0:04:47s\n",
      "epoch 1  | loss: 0.37072 | val_0_auc: 0.92614 | val_0_accuracy: 0.85919 | val_0_amex_tabnet: 0.65545 |  0:09:33s\n",
      "epoch 2  | loss: 0.33521 | val_0_auc: 0.93068 | val_0_accuracy: 0.86397 | val_0_amex_tabnet: 0.67254 |  0:14:20s\n",
      "epoch 3  | loss: 0.31777 | val_0_auc: 0.93503 | val_0_accuracy: 0.86845 | val_0_amex_tabnet: 0.68851 |  0:19:08s\n",
      "epoch 4  | loss: 0.30755 | val_0_auc: 0.93616 | val_0_accuracy: 0.87039 | val_0_amex_tabnet: 0.69334 |  0:23:54s\n",
      "epoch 5  | loss: 0.28961 | val_0_auc: 0.94145 | val_0_accuracy: 0.87648 | val_0_amex_tabnet: 0.71757 |  0:28:41s\n",
      "epoch 6  | loss: 0.27092 | val_0_auc: 0.94626 | val_0_accuracy: 0.88314 | val_0_amex_tabnet: 0.73456 |  0:33:27s\n",
      "epoch 7  | loss: 0.25907 | val_0_auc: 0.94969 | val_0_accuracy: 0.88644 | val_0_amex_tabnet: 0.74658 |  0:38:08s\n",
      "epoch 8  | loss: 0.25248 | val_0_auc: 0.95077 | val_0_accuracy: 0.88954 | val_0_amex_tabnet: 0.75205 |  0:42:46s\n",
      "epoch 9  | loss: 0.24844 | val_0_auc: 0.95173 | val_0_accuracy: 0.89123 | val_0_amex_tabnet: 0.75385 |  0:47:21s\n",
      "epoch 10 | loss: 0.24871 | val_0_auc: 0.95363 | val_0_accuracy: 0.89363 | val_0_amex_tabnet: 0.75997 |  0:51:45s\n",
      "epoch 11 | loss: 0.24433 | val_0_auc: 0.95445 | val_0_accuracy: 0.89446 | val_0_amex_tabnet: 0.7618  |  0:55:58s\n",
      "epoch 12 | loss: 0.23925 | val_0_auc: 0.95688 | val_0_accuracy: 0.89796 | val_0_amex_tabnet: 0.77489 |  1:00:05s\n",
      "epoch 13 | loss: 0.23366 | val_0_auc: 0.95787 | val_0_accuracy: 0.89941 | val_0_amex_tabnet: 0.777   |  1:04:17s\n",
      "epoch 14 | loss: 0.22886 | val_0_auc: 0.95898 | val_0_accuracy: 0.90053 | val_0_amex_tabnet: 0.7824  |  1:08:42s\n",
      "epoch 15 | loss: 0.23398 | val_0_auc: 0.95831 | val_0_accuracy: 0.8984  | val_0_amex_tabnet: 0.77895 |  1:13:27s\n",
      "epoch 16 | loss: 0.23257 | val_0_auc: 0.95892 | val_0_accuracy: 0.89962 | val_0_amex_tabnet: 0.78217 |  1:18:12s\n",
      "epoch 17 | loss: 0.2302  | val_0_auc: 0.95896 | val_0_accuracy: 0.89982 | val_0_amex_tabnet: 0.78136 |  1:22:58s\n",
      "epoch 18 | loss: 0.22777 | val_0_auc: 0.95972 | val_0_accuracy: 0.90183 | val_0_amex_tabnet: 0.78385 |  1:27:41s\n",
      "epoch 19 | loss: 0.22523 | val_0_auc: 0.95983 | val_0_accuracy: 0.90143 | val_0_amex_tabnet: 0.78382 |  1:32:23s\n",
      "epoch 20 | loss: 0.22985 | val_0_auc: 0.95906 | val_0_accuracy: 0.90061 | val_0_amex_tabnet: 0.78033 |  1:37:07s\n",
      "epoch 21 | loss: 0.22852 | val_0_auc: 0.95934 | val_0_accuracy: 0.90082 | val_0_amex_tabnet: 0.78326 |  1:41:49s\n",
      "epoch 22 | loss: 0.22728 | val_0_auc: 0.95977 | val_0_accuracy: 0.90152 | val_0_amex_tabnet: 0.7847  |  1:46:29s\n",
      "epoch 23 | loss: 0.22578 | val_0_auc: 0.95986 | val_0_accuracy: 0.90172 | val_0_amex_tabnet: 0.78277 |  1:51:06s\n",
      "epoch 24 | loss: 0.22379 | val_0_auc: 0.95996 | val_0_accuracy: 0.90147 | val_0_amex_tabnet: 0.7842  |  1:55:37s\n",
      "epoch 25 | loss: 0.22805 | val_0_auc: 0.9594  | val_0_accuracy: 0.90111 | val_0_amex_tabnet: 0.78109 |  2:00:19s\n",
      "epoch 26 | loss: 0.22724 | val_0_auc: 0.95997 | val_0_accuracy: 0.90173 | val_0_amex_tabnet: 0.78604 |  2:04:59s\n",
      "epoch 27 | loss: 0.22606 | val_0_auc: 0.95976 | val_0_accuracy: 0.90083 | val_0_amex_tabnet: 0.78427 |  2:09:35s\n",
      "epoch 28 | loss: 0.22433 | val_0_auc: 0.96012 | val_0_accuracy: 0.90185 | val_0_amex_tabnet: 0.78406 |  2:14:02s\n",
      "epoch 29 | loss: 0.22265 | val_0_auc: 0.96015 | val_0_accuracy: 0.90218 | val_0_amex_tabnet: 0.78611 |  2:18:16s\n",
      "epoch 30 | loss: 0.22699 | val_0_auc: 0.95936 | val_0_accuracy: 0.9011  | val_0_amex_tabnet: 0.78269 |  2:22:56s\n",
      "epoch 31 | loss: 0.22613 | val_0_auc: 0.95973 | val_0_accuracy: 0.90117 | val_0_amex_tabnet: 0.78256 |  2:27:34s\n",
      "epoch 32 | loss: 0.22475 | val_0_auc: 0.95986 | val_0_accuracy: 0.90224 | val_0_amex_tabnet: 0.78439 |  2:32:05s\n",
      "epoch 33 | loss: 0.22277 | val_0_auc: 0.96016 | val_0_accuracy: 0.90249 | val_0_amex_tabnet: 0.78418 |  2:36:24s\n",
      "epoch 34 | loss: 0.22109 | val_0_auc: 0.96028 | val_0_accuracy: 0.90193 | val_0_amex_tabnet: 0.78612 |  2:40:31s\n",
      "epoch 35 | loss: 0.22643 | val_0_auc: 0.95932 | val_0_accuracy: 0.90122 | val_0_amex_tabnet: 0.7836  |  2:45:12s\n",
      "epoch 36 | loss: 0.22529 | val_0_auc: 0.95957 | val_0_accuracy: 0.9008  | val_0_amex_tabnet: 0.78304 |  2:49:52s\n",
      "epoch 37 | loss: 0.22386 | val_0_auc: 0.96023 | val_0_accuracy: 0.9021  | val_0_amex_tabnet: 0.78661 |  2:54:24s\n",
      "epoch 38 | loss: 0.22215 | val_0_auc: 0.96024 | val_0_accuracy: 0.90252 | val_0_amex_tabnet: 0.78542 |  2:58:44s\n",
      "epoch 39 | loss: 0.2199  | val_0_auc: 0.96026 | val_0_accuracy: 0.90165 | val_0_amex_tabnet: 0.78557 |  3:02:52s\n",
      "epoch 40 | loss: 0.2253  | val_0_auc: 0.96002 | val_0_accuracy: 0.90215 | val_0_amex_tabnet: 0.785   |  3:07:35s\n",
      "epoch 41 | loss: 0.22451 | val_0_auc: 0.95999 | val_0_accuracy: 0.901   | val_0_amex_tabnet: 0.78618 |  3:12:16s\n",
      "epoch 42 | loss: 0.22348 | val_0_auc: 0.96002 | val_0_accuracy: 0.90177 | val_0_amex_tabnet: 0.78537 |  3:16:49s\n",
      "epoch 43 | loss: 0.22165 | val_0_auc: 0.96029 | val_0_accuracy: 0.9026  | val_0_amex_tabnet: 0.78764 |  3:21:10s\n",
      "epoch 44 | loss: 0.2197  | val_0_auc: 0.96035 | val_0_accuracy: 0.90257 | val_0_amex_tabnet: 0.78736 |  3:25:19s\n",
      "epoch 45 | loss: 0.22504 | val_0_auc: 0.9601  | val_0_accuracy: 0.90218 | val_0_amex_tabnet: 0.78629 |  3:30:02s\n",
      "epoch 46 | loss: 0.22401 | val_0_auc: 0.96005 | val_0_accuracy: 0.90204 | val_0_amex_tabnet: 0.78547 |  3:34:43s\n",
      "epoch 47 | loss: 0.22309 | val_0_auc: 0.96021 | val_0_accuracy: 0.90109 | val_0_amex_tabnet: 0.78525 |  3:39:14s\n",
      "epoch 48 | loss: 0.22115 | val_0_auc: 0.96038 | val_0_accuracy: 0.90295 | val_0_amex_tabnet: 0.78634 |  3:43:36s\n",
      "epoch 49 | loss: 0.21895 | val_0_auc: 0.96029 | val_0_accuracy: 0.90253 | val_0_amex_tabnet: 0.78648 |  3:47:44s\n",
      "Stop training because you reached max_epochs = 50 with best_epoch = 43 and best_val_0_amex_tabnet = 0.78764\n",
      "Successfully saved model at ../output/exp15 Tabnet entmax/tabnet_fold4.zip\n",
      "4 score is :  0.7876384784395436\n"
     ]
    }
   ],
   "source": [
    "# Get feature list\n",
    "features = [col for col in train.columns if col not in ['customer_ID', CFG.target]]\n",
    "# all_data = features.extend(\"customer_ID\")\n",
    "\n",
    "\n",
    "train.fillna(value=0, inplace=True)\n",
    "test.fillna(value=0, inplace=True)\n",
    "\n",
    "## infを含むデータを外れ値（－１００００）に置換\n",
    "train = train.replace([np.inf, -np.inf],1000000000)\n",
    "test = test.replace([np.inf, -np.inf],1000000000)\n",
    "\n",
    "# Create a numpy array to store test predictions\n",
    "test_predictions = np.zeros(len(test))\n",
    "# Create a numpy array to store out of folds predictions\n",
    "oof_predictions = np.zeros(len(train))\n",
    "\n",
    "\n",
    "preds = []\n",
    "cids = []\n",
    "tr_target = []\n",
    "test_preds = []\n",
    "\n",
    "kfold = StratifiedKFold(n_splits = CFG.n_folds, shuffle = True, random_state = CFG.seed)\n",
    "for fold, (trn_ind, val_ind) in enumerate(kfold.split(train, train[CFG.target])):\n",
    "    print(' ')\n",
    "    print('-'*50)\n",
    "    print(f'Training fold {fold} with {len(features)} features...')\n",
    "    \n",
    "    if fold == 0 or fold == 1,:\n",
    "        print(\"pass training fold\")\n",
    "        continue\n",
    "    \n",
    "    x_train, x_val = train[features].iloc[trn_ind], train[features].iloc[val_ind]\n",
    "    y_train, y_val = train[CFG.target].iloc[trn_ind], train[CFG.target].iloc[val_ind]\n",
    "    \n",
    "#     cid = train[\"customer_ID\"].loc[val_ind]\n",
    "    cid = train[\"customer_ID\"].loc[val_ind]\n",
    "    cids.extend(cid)\n",
    "    # lgb_train = lgb.Dataset(x_train, y_train, categorical_feature = cat_features)\n",
    "    # lgb_valid = lgb.Dataset(x_val, y_val, categorical_feature = cat_features)\n",
    "\n",
    "    \n",
    "    model = TabNetClassifier(n_d = 32,\n",
    "                         n_a = 32,\n",
    "                         n_steps = 3,\n",
    "                         gamma = 1.3,\n",
    "                         n_independent = 2,\n",
    "                         n_shared = 2,\n",
    "                         momentum = 0.02,\n",
    "                         clip_value = None,\n",
    "                         lambda_sparse = 1e-3,\n",
    "                         optimizer_fn = torch.optim.Adam,\n",
    "                         optimizer_params = dict(lr = 1e-3, weight_decay=1e-3),\n",
    "                         scheduler_fn = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts,\n",
    "                         scheduler_params = {'T_0':5,\n",
    "                                             'eta_min':1e-4,\n",
    "                                             'T_mult':1,\n",
    "                                             'last_epoch':-1},\n",
    "                         mask_type = 'entmax',\n",
    "                         seed = CFG.seed)\n",
    "\n",
    "    print(f'start Training fold {fold}')\n",
    "    model.fit(np.array(x_train),\n",
    "                    np.array(y_train.values.ravel()),\n",
    "                    eval_set = [(np.array(x_val), np.array(y_val.values.ravel()))],\n",
    "                    max_epochs = 50,#50\n",
    "                    patience = 50,#50\n",
    "                    batch_size = 512,\n",
    "                    eval_metric = ['auc', 'accuracy', Amex_tabnet]) # Last metric is used for early stoppin\n",
    "    \n",
    "    \n",
    "    file_path = f\"{CFG.output_dir}{CFG.model}_fold{fold}\"\n",
    "    saved_filepath = model.save_model(file_path)\n",
    "    \n",
    "#     oof_predictions[valid_idx] = model.predict_proba(x_val.values)[:, 1]\n",
    "    pred = model.predict_proba(np.array(x_val))[:, 1]\n",
    "    preds.extend(pred)\n",
    "    tr_target.extend(y_val)\n",
    "    \n",
    "    fold_score = amex_metric(y_val, pred)\n",
    "    print(f\"{fold} score is : \",fold_score)\n",
    "    \n",
    "    # OOF用のcustomer_IDをExtend\n",
    "    cids.extend(train[\"customer_ID\"].loc[val_ind])\n",
    "    test_preds.append(model.predict_proba(np.array(test[features]))[:, 1])\n",
    "    # test predct\n",
    "#     print(f'OOF score across folds: {amex_metric_numpy(target, oof_predictions.flatten())}')\n",
    "\n",
    "#     # Compute fold metric\n",
    "    del x_train, x_val, y_train, y_val\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f770440-1df8-4a28-80c7-a3499e807a13",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12936\\3915580609.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# Compute out of folds metric\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mtest_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_preds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mamex_metric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mCFG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Our out of folds CV score is {score}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12936\\461571139.py\u001b[0m in \u001b[0;36mamex_metric\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mamex_metric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m     \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m     \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[0mcut_vals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.04\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
     ]
    }
   ],
   "source": [
    "\n",
    "############## ここにFold1の予測結果を読み込む処理を書く\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Compute out of folds metric\n",
    "test_predictions = np.mean(test_preds,axis = 0)\n",
    "score = amex_metric(train[CFG.target], preds)\n",
    "print(f'Our out of folds CV score is {score}')\n",
    "\n",
    "# Create a dataframe to store test prediction\n",
    "test_df = pd.DataFrame({'customer_ID': test['customer_ID'], 'prediction': test_predictions})\n",
    "# test_df.to_csv(f'{CFG.output_dir}test_{CFG.model}_{score}_baseline_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)\n",
    "test_df.to_csv(f'{CFG.output_dir}test_{CFG.model}_{score}_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)\n",
    "\n",
    "\n",
    "dic_oof = {\n",
    "    \"customer_ID\":cids,\n",
    "    \"target\":tr_target,\n",
    "    \"tabnet_oot\":oof_predictions\n",
    "}\n",
    "\n",
    "# Create a dataframe to store out of folds predictions\n",
    "oof_df = pd.DataFrame(dic_oof)\n",
    "# oof_df = pd.DataFrame({'customer_ID': train['customer_ID'], 'target': train[CFG.target], 'prediction': oof_predictions})\n",
    "oof_df.to_csv(f'{CFG.output_dir}oof_{CFG.ver}_{CFG.model}_{score}_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c776e3a-e9b0-4505-aa4a-ae71d5738596",
   "metadata": {},
   "source": [
    "# Infer\n",
    "\n",
    "学習しない場合こちら"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9f3f7fd-7bd1-4e92-93a9-4a18f035feca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold : 0\n",
      "load model\n",
      "0 score is :  0.7920919714728045\n",
      "fold : 1\n",
      "load model\n",
      "1 score is :  0.7876776860325015\n",
      "fold : 2\n",
      "load model\n",
      "2 score is :  0.7890420759417227\n",
      "fold : 3\n",
      "load model\n",
      "3 score is :  0.7888245459171852\n",
      "fold : 4\n",
      "load model\n",
      "4 score is :  0.7876384784395436\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get feature list\n",
    "features = [col for col in train.columns if col not in ['customer_ID', CFG.target]]\n",
    "# all_data = features.extend(\"customer_ID\")\n",
    "\n",
    "\n",
    "train.fillna(value=0, inplace=True)\n",
    "test.fillna(value=0, inplace=True)\n",
    "\n",
    "## infを含むデータを外れ値（－１００００）に置換\n",
    "train = train.replace([np.inf, -np.inf],1000000000)\n",
    "test = test.replace([np.inf, -np.inf],1000000000)\n",
    "\n",
    "# Create a numpy array to store test predictions\n",
    "test_predictions = np.zeros(len(test))\n",
    "# Create a numpy array to store out of folds predictions\n",
    "oof_predictions = np.zeros(len(train))\n",
    "\n",
    "\n",
    "preds = []\n",
    "cids = []\n",
    "tr_target = []\n",
    "test_preds = []\n",
    "\n",
    "\n",
    "kfold = StratifiedKFold(n_splits = CFG.n_folds, shuffle = True, random_state = CFG.seed)\n",
    "for fold, (trn_ind, val_ind) in enumerate(kfold.split(train, train[CFG.target])):\n",
    "\n",
    "    print(f\"fold : {fold}\")\n",
    "    \n",
    "    x_train, x_val = train[features].iloc[trn_ind], train[features].iloc[val_ind]\n",
    "    y_train, y_val = train[CFG.target].iloc[trn_ind], train[CFG.target].iloc[val_ind]\n",
    "    \n",
    "    model = TabNetClassifier(n_d = 32,\n",
    "                         n_a = 32,\n",
    "                         n_steps = 3,\n",
    "                         gamma = 1.3,\n",
    "                         n_independent = 2,\n",
    "                         n_shared = 2,\n",
    "                         momentum = 0.02,\n",
    "                         clip_value = None,\n",
    "                         lambda_sparse = 1e-3,\n",
    "                         optimizer_fn = torch.optim.Adam,\n",
    "                         optimizer_params = dict(lr = 1e-3, weight_decay=1e-3),\n",
    "                         scheduler_fn = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts,\n",
    "                         scheduler_params = {'T_0':5,\n",
    "                                             'eta_min':1e-4,\n",
    "                                             'T_mult':1,\n",
    "                                             'last_epoch':-1},\n",
    "                         mask_type = 'entmax',\n",
    "                         seed = CFG.seed)\n",
    "    \n",
    "    print(\"load model\")\n",
    "    model_path = f\"../output/exp15 Tabnet entmax/tabnet_fold{fold}.zip\"\n",
    "    model.load_model(model_path)\n",
    "    \n",
    "    cid = train[\"customer_ID\"].loc[val_ind]\n",
    "    cids.extend(cid)\n",
    "    \n",
    "    pred = model.predict_proba(np.array(x_val))[:, 1]\n",
    "    preds.extend(pred)\n",
    "    \n",
    "    fold_score = amex_metric(y_val, pred)\n",
    "    print(f\"{fold} score is : \",fold_score)\n",
    "    \n",
    "    test_pred= model.predict_proba(np.array(test[features]))[:, 1]\n",
    "    test_preds.append(test_pred)\n",
    "    \n",
    "    tr_target.extend(y_val)\n",
    "#     pred = model.predict_proba(test[all_features].values)[:, 1]\n",
    "\n",
    "    del pred,cid\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46c81617-43aa-43de-b05e-9efb459ee4ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.01365403, 0.00291401, 0.03214177, ..., 0.5378061 , 0.33354393,\n",
       "        0.09402709], dtype=float32),\n",
       " array([0.01883214, 0.00218072, 0.04229571, ..., 0.44275218, 0.22777435,\n",
       "        0.08200692], dtype=float32),\n",
       " array([0.01187868, 0.00250312, 0.03653168, ..., 0.66964495, 0.3351964 ,\n",
       "        0.11270957], dtype=float32),\n",
       " array([0.02224178, 0.00230813, 0.02615114, ..., 0.67060965, 0.29399443,\n",
       "        0.07807986], dtype=float32),\n",
       " array([0.03113907, 0.00377897, 0.04021817, ..., 0.55600375, 0.3859081 ,\n",
       "        0.08209409], dtype=float32)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ded7967c-d02c-44bb-b066-2ff90e85526b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our out of folds CV score is 0.788206478467055\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Compute out of folds metric\n",
    "test_predictions = np.mean(test_preds,axis = 0)\n",
    "# score = amex_metric(train[CFG.target], preds)\n",
    "score = amex_metric(tr_target, preds)\n",
    "\n",
    "print(f'Our out of folds CV score is {score}')\n",
    "\n",
    "# Create a dataframe to store test prediction\n",
    "test_predictions = np.mean(test_preds,axis = 0)\n",
    "\n",
    "test_df = pd.DataFrame({'customer_ID': test['customer_ID'], 'prediction': test_predictions})\n",
    "# test_df.to_csv(f'{CFG.output_dir}test_{CFG.model}_{score}_baseline_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)\n",
    "test_df.to_csv(f'{CFG.output_dir}test_{CFG.model}_{score}_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)\n",
    "\n",
    "\n",
    "dic_oof = {\n",
    "    \"customer_ID\":cids,\n",
    "#     \"target\":tr_target,\n",
    "    \"tabnet_oof\":preds\n",
    "}\n",
    "\n",
    "# Create a dataframe to store out of folds predictions\n",
    "oof_df = pd.DataFrame(dic_oof)\n",
    "# oof_df = pd.DataFrame({'customer_ID': train['customer_ID'], 'target': train[CFG.target], 'prediction': oof_predictions})\n",
    "oof_df.to_csv(f'{CFG.output_dir}oof_{CFG.ver}_{CFG.model}_{score}_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# sub = np.array(preds).mean(axis = 0)\n",
    "# df_sub = pd.read_csv('../input/amex-default-prediction/sample_submission.csv')\n",
    "# df_sub['prediction'] = sub\n",
    "\n",
    "# df_sub.to_csv('tabnet_pred.csv',index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b442ccf0-11c9-486b-a930-8c71868e46eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000469ba478561f23a92a868bd366de6f6527a684c9a...</td>\n",
       "      <td>0.019549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00001bf2e77ff879fab36aa4fac689b9ba411dae63ae39...</td>\n",
       "      <td>0.002737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000210045da4f81e5f122c6bde5c2a617d03eef67f82c...</td>\n",
       "      <td>0.035468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00003b41e58ede33b8daf61ab56d9952f17c9ad1c3976c...</td>\n",
       "      <td>0.262243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00004b22eaeeeb0ec976890c1d9bfc14fd9427e98c4ee9...</td>\n",
       "      <td>0.708322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         customer_ID  prediction\n",
       "0  00000469ba478561f23a92a868bd366de6f6527a684c9a...    0.019549\n",
       "1  00001bf2e77ff879fab36aa4fac689b9ba411dae63ae39...    0.002737\n",
       "2  0000210045da4f81e5f122c6bde5c2a617d03eef67f82c...    0.035468\n",
       "3  00003b41e58ede33b8daf61ab56d9952f17c9ad1c3976c...    0.262243\n",
       "4  00004b22eaeeeb0ec976890c1d9bfc14fd9427e98c4ee9...    0.708322"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f9304445-f6c3-4212-903c-f12274420afe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>tabnet_oof</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00007889e4fcd2614b6cbe7f8f3d2e5c728eca32d9eb8a...</td>\n",
       "      <td>0.002710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00031e8be98bc3411f6037cbd4d3eeaf24b3ae221682b7...</td>\n",
       "      <td>0.017477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003e58375faf90552b2861c1ccea4ee5757827cbb6ecd...</td>\n",
       "      <td>0.009180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0004837f0c785928a29a6f83f70f4a1c54caec483a773f...</td>\n",
       "      <td>0.228023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0005e52a3fa31b7eed49ceb576f011433ee2578833cd3f...</td>\n",
       "      <td>0.779503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         customer_ID  tabnet_oof\n",
       "0  00007889e4fcd2614b6cbe7f8f3d2e5c728eca32d9eb8a...    0.002710\n",
       "1  00031e8be98bc3411f6037cbd4d3eeaf24b3ae221682b7...    0.017477\n",
       "2  0003e58375faf90552b2861c1ccea4ee5757827cbb6ecd...    0.009180\n",
       "3  0004837f0c785928a29a6f83f70f4a1c54caec483a773f...    0.228023\n",
       "4  0005e52a3fa31b7eed49ceb576f011433ee2578833cd3f...    0.779503"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a864c4e6-4f3e-49bd-88fb-482cdca14728",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amex",
   "language": "python",
   "name": "amex"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
