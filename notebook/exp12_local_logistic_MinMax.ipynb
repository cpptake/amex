{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70f58d85-14e4-4371-ad96-458843ea228c",
   "metadata": {},
   "source": [
    "# exp10\n",
    "\n",
    "exp10 ロジスティック回帰 のL1正則化\n",
    "\n",
    "https://www.kaggle.com/code/ragnar123/amex-lgbm-dart-cv-0-7977"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "325051a6-7ea3-4398-b022-6a81c18b14eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Library\n",
    "# ====================================================\n",
    "import os\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "from tqdm.auto import tqdm\n",
    "import itertools\n",
    "\n",
    "import joblib\n",
    "import random\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "from itertools import combinations\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import snappy\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "\n",
    "\n",
    "from pytorch_tabnet.pretraining import TabNetPretrainer\n",
    "\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "\n",
    "import torch\n",
    "from pytorch_tabnet.metrics import Metric\n",
    "# from ipywidgets import interact, Select\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e80847-25f2-4784-97c5-b8012eae1a3e",
   "metadata": {},
   "source": [
    "# Training & Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68ef141-3c78-4cd6-988b-db0421753882",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3638c92e-7e65-43e5-8a69-e2aef6660f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ====================================================\n",
    "# Configurations\n",
    "# ====================================================\n",
    "class CFG:\n",
    "    input_dir = '../feature/exp03_amex-fe/'\n",
    "    output_dir = '../output/exp12_logistic_MinMaxScaler/'\n",
    "    seed = 46\n",
    "    n_folds = 5\n",
    "    target = 'target'\n",
    "    boosting_type = 'dart'\n",
    "    metric = 'binary_logloss'\n",
    "    model = \"logistic\"\n",
    "    ver = \"exp12\"\n",
    "\n",
    "# ====================================================\n",
    "# Seed everything\n",
    "# ====================================================\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "# ====================================================\n",
    "# Read data\n",
    "# ====================================================\n",
    "def read_data():\n",
    "    train = pd.read_parquet(CFG.input_dir + 'train_fe_plus_plus.parquet')\n",
    "    test = pd.read_parquet(CFG.input_dir + 'test_fe_plus_plus.parquet')\n",
    "    return train, test\n",
    "\n",
    "# ====================================================\n",
    "# XGB train\n",
    "# ====================================================\n",
    "\n",
    "def cat_train(x, y, xt, yt,cat_features):\n",
    "    print(\"# of features:\", x.shape[1])\n",
    "    assert x.shape[1] == xt.shape[1]\n",
    "    \n",
    "    prams = {\n",
    "        'depth': 8,\n",
    "        'iterations':5000,\n",
    "#         'learning_rate': 0.05,\n",
    "        'random_state':CFG.seed,\n",
    "    }\n",
    "\n",
    "#     watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "    watchlist = [(x, 'train'), (xt, 'eval')]\n",
    "    clf = CatBoostClassifier(**prams)# 5000\n",
    "    clf.fit(x, y, eval_set=[(xt, yt)], cat_features=cat_features,plot=True, verbose_eval = 100)\n",
    "#     print('best ntree_limit:', clf.best_ntree_limit)\n",
    "#     print('best score:', clf.best_score)\n",
    "    # return clf.predict_proba(xt)[:, 1]\n",
    "    return clf.predict_proba(xt)[:, 1], clf\n",
    "\n",
    "def tabnet_train(x, y, xt, yt,cat_features):\n",
    "    print(\"# of features:\", x.shape[1])\n",
    "    assert x.shape[1] == xt.shape[1]\n",
    "    \n",
    "    prams = {\n",
    "        'depth': 8,\n",
    "        'iterations':5000,\n",
    "#         'learning_rate': 0.05,\n",
    "        'random_state':CFG.seed,\n",
    "    }\n",
    "\n",
    "#     watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "    watchlist = [(x, 'train'), (xt, 'eval')]\n",
    "    clf = CatBoostClassifier(**prams)# 5000\n",
    "    clf.fit(x, y, eval_set=[(xt, yt)], cat_features=cat_features,plot=True, verbose_eval = 100)\n",
    "#     print('best ntree_limit:', clf.best_ntree_limit)\n",
    "#     print('best score:', clf.best_score)\n",
    "    # return clf.predict_proba(xt)[:, 1]\n",
    "    return clf.predict_proba(xt)[:, 1], clf\n",
    "\n",
    "\n",
    "\n",
    "# using amex metric to evaluate tabnet\n",
    "class Amex_tabnet(Metric):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self._name = 'amex_tabnet'\n",
    "        self._maximize = True\n",
    "\n",
    "    def __call__(self, y_true, y_pred):\n",
    "        amex = amex_metric_numpy(y_true, y_pred[:, 1])\n",
    "        return max(amex, 0.)\n",
    "\n",
    "# ====================================================\n",
    "# Amex metric\n",
    "# ====================================================\n",
    "def amex_metric(y_true, y_pred):\n",
    "    labels = np.transpose(np.array([y_true, y_pred]))\n",
    "    labels = labels[labels[:, 1].argsort()[::-1]]\n",
    "    weights = np.where(labels[:,0]==0, 20, 1)\n",
    "    cut_vals = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n",
    "    top_four = np.sum(cut_vals[:,0]) / np.sum(labels[:,0])\n",
    "    gini = [0,0]\n",
    "    for i in [1,0]:\n",
    "        labels = np.transpose(np.array([y_true, y_pred]))\n",
    "        labels = labels[labels[:, i].argsort()[::-1]]\n",
    "        weight = np.where(labels[:,0]==0, 20, 1)\n",
    "        weight_random = np.cumsum(weight / np.sum(weight))\n",
    "        total_pos = np.sum(labels[:, 0] *  weight)\n",
    "        cum_pos_found = np.cumsum(labels[:, 0] * weight)\n",
    "        lorentz = cum_pos_found / total_pos\n",
    "        gini[i] = np.sum((lorentz - weight_random) * weight)\n",
    "    return 0.5 * (gini[1]/gini[0] + top_four)\n",
    "\n",
    "\n",
    "def xgb_amex(y_pred, y_true):\n",
    "    return 'amex', amex_metric_np(y_pred,y_true.get_label())\n",
    "\n",
    "\n",
    "# Created by https://www.kaggle.com/yunchonggan\n",
    "# https://www.kaggle.com/competitions/amex-default-prediction/discussion/328020\n",
    "def amex_metric_np(preds: np.ndarray, target: np.ndarray) -> float:\n",
    "    indices = np.argsort(preds)[::-1]\n",
    "    preds, target = preds[indices], target[indices]\n",
    "\n",
    "    weight = 20.0 - target * 19.0\n",
    "    cum_norm_weight = (weight / weight.sum()).cumsum()\n",
    "    four_pct_mask = cum_norm_weight <= 0.04\n",
    "    d = np.sum(target[four_pct_mask]) / np.sum(target)\n",
    "\n",
    "    weighted_target = target * weight\n",
    "    lorentz = (weighted_target / weighted_target.sum()).cumsum()\n",
    "    gini = ((lorentz - cum_norm_weight) * weight).sum()\n",
    "\n",
    "    n_pos = np.sum(target)\n",
    "    n_neg = target.shape[0] - n_pos\n",
    "    gini_max = 10 * n_neg * (n_pos + 20 * n_neg - 19) / (n_pos + 20 * n_neg)\n",
    "\n",
    "    g = gini / gini_max\n",
    "    return 0.5 * (g + d)\n",
    "\n",
    "def amex_metric_numpy(y_true: np.array, y_pred: np.array) -> float:\n",
    "\n",
    "    # count of positives and negatives\n",
    "    n_pos = y_true.sum()\n",
    "    n_neg = y_true.shape[0] - n_pos\n",
    "\n",
    "    # sorting by descring prediction values\n",
    "    indices = np.argsort(y_pred)[::-1]\n",
    "    preds, target = y_pred[indices], y_true[indices]\n",
    "\n",
    "    # filter the top 4% by cumulative row weights\n",
    "    weight = 20.0 - target * 19.0\n",
    "    cum_norm_weight = (weight / weight.sum()).cumsum()\n",
    "    four_pct_filter = cum_norm_weight <= 0.04\n",
    "\n",
    "    # default rate captured at 4%\n",
    "    d = target[four_pct_filter].sum() / n_pos\n",
    "\n",
    "    # weighted gini coefficient\n",
    "    lorentz = (target / n_pos).cumsum()\n",
    "    gini = ((lorentz - cum_norm_weight) * weight).sum()\n",
    "\n",
    "    # max weighted gini coefficient\n",
    "    gini_max = 10 * n_neg * (1 - 19 / (n_pos + 20 * n_neg))\n",
    "\n",
    "    # normalized weighted gini coefficient\n",
    "    g = gini / gini_max\n",
    "\n",
    "    return 0.5 * (g + d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30007ce2-4854-4fd8-8c1b-477936511e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(CFG.seed)\n",
    "train, test = read_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b719cd4-45c3-4dba-8955-cb37b93b1f31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# # ====================================================\n",
    "# # Train & Evaluate\n",
    "# # ====================================================\n",
    "\n",
    "\n",
    "# cat_features = [\n",
    "#     \"B_30\",\n",
    "#     \"B_38\",\n",
    "#     \"D_114\",\n",
    "#     \"D_116\",\n",
    "#     \"D_117\",\n",
    "#     \"D_120\",\n",
    "#     \"D_126\",\n",
    "#     \"D_63\",\n",
    "#     \"D_64\",\n",
    "#     \"D_66\",\n",
    "#     \"D_68\"\n",
    "# ]\n",
    "# cat_features = [f\"{cf}_last\" for cf in cat_features]\n",
    "# for cat_col in cat_features:\n",
    "#     encoder = LabelEncoder()\n",
    "#     train[cat_col] = encoder.fit_transform(train[cat_col])\n",
    "#     test[cat_col] = encoder.transform(test[cat_col])\n",
    "# # Round last float features to 2 decimal place\n",
    "# num_cols = list(train.dtypes[(train.dtypes == 'float32') | (train.dtypes == 'float64')].index)\n",
    "# num_cols = [col for col in num_cols if 'last' in col]\n",
    "# for col in num_cols:\n",
    "#     train[col + '_round2'] = train[col].round(2)\n",
    "#     test[col + '_round2'] = test[col].round(2)\n",
    "# # Get the difference between last and mean\n",
    "# num_cols = [col for col in train.columns if 'last' in col]\n",
    "# num_cols = [col[:-5] for col in num_cols if 'round' not in col]\n",
    "# for col in num_cols:\n",
    "#     try:\n",
    "#         train[f'{col}_last_mean_diff'] = train[f'{col}_last'] - train[f'{col}_mean']\n",
    "#         test[f'{col}_last_mean_diff'] = test[f'{col}_last'] - test[f'{col}_mean']\n",
    "#     except:\n",
    "#         pass\n",
    "# # Transform float64 and float32 to float16\n",
    "# num_cols = list(train.dtypes[(train.dtypes == 'float32') | (train.dtypes == 'float64')].index)\n",
    "# for col in tqdm(num_cols):\n",
    "#     train[col] = train[col].astype(np.float16)\n",
    "#     test[col] = test[col].astype(np.float16)\n",
    "\n",
    "\n",
    "# #     params = {\n",
    "# #         'objective': 'binary:logistic', \n",
    "# #         'tree_method': 'hist', #gpu_hist #hist\n",
    "# #         'max_depth': 7,\n",
    "# #         'subsample':0.88,\n",
    "# #         'colsample_bytree': 0.5,\n",
    "# #         'gamma':1.5,\n",
    "# #         'min_child_weight':8,\n",
    "# #         'lambda':70,\n",
    "# #         'eta':0.03}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "220db67f-9a57-436b-9ec6-8732c6c6fe67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "--------------------------------------------------\n",
      "Training fold 0 with 1460 features...\n",
      "start Training fold 0\n",
      "save fold0 model\n",
      "oof_preds :  91783\n",
      "0 score is :  0.7755095986006146\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 1 with 1460 features...\n",
      "start Training fold 1\n",
      "save fold1 model\n",
      "oof_preds :  183566\n",
      "1 score is :  0.7715307239449436\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 2 with 1460 features...\n",
      "start Training fold 2\n",
      "save fold2 model\n",
      "oof_preds :  275349\n",
      "2 score is :  0.7736153032463103\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 3 with 1460 features...\n",
      "start Training fold 3\n",
      "save fold3 model\n",
      "oof_preds :  367131\n",
      "3 score is :  0.7761920250792835\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 4 with 1460 features...\n",
      "start Training fold 4\n",
      "save fold4 model\n",
      "oof_preds :  458913\n",
      "4 score is :  0.7752375453769422\n",
      "Our out of folds CV score is 0.7744170392496189\n"
     ]
    }
   ],
   "source": [
    "# Get feature list\n",
    "features = [col for col in train.columns if col not in ['customer_ID', CFG.target]]\n",
    "# all_data = features.extend(\"customer_ID\")\n",
    "\n",
    "train.fillna(value=0, inplace=True)\n",
    "test.fillna(value=0, inplace=True)\n",
    "\n",
    "## infを含むデータを外れ値（1000000000）に置換\n",
    "train = train.replace([np.inf, -np.inf],1000000000)\n",
    "test = test.replace([np.inf, -np.inf],1000000000)\n",
    "\n",
    "# Create a numpy array to store test predictions\n",
    "test_predictions = np.zeros(len(test))\n",
    "# Create a numpy array to store out of folds predictions\n",
    "oof_predictions = np.zeros(len(train))\n",
    "\n",
    "trainid = train[\"customer_ID\"]\n",
    "testid = test[\"customer_ID\"]\n",
    "\n",
    "\n",
    "\n",
    "# cid = []\n",
    "# cids = []\n",
    "\n",
    "pred = []\n",
    "oof_preds = []\n",
    "test_preds = []\n",
    "cids = []\n",
    "CVscore = []\n",
    "\n",
    "# 標準化\n",
    "mn = MinMaxScaler()\n",
    "\n",
    "kfold = StratifiedKFold(n_splits = CFG.n_folds, shuffle = True, random_state = CFG.seed)\n",
    "for fold, (trn_ind, val_ind) in enumerate(kfold.split(train, train[CFG.target])):\n",
    "    print(' ')\n",
    "    print('-'*50)\n",
    "    print(f'Training fold {fold} with {len(features)} features...')\n",
    "    \n",
    "    x_train, x_val = train[features].iloc[trn_ind], train[features].iloc[val_ind]\n",
    "    y_train, y_val = train[CFG.target].iloc[trn_ind], train[CFG.target].iloc[val_ind]\n",
    "    \n",
    "    ## 標準化\n",
    "    x_train = mn.fit_transform(x_train[features])\n",
    "    x_val = mn.fit_transform(x_val[features])\n",
    "    \n",
    "    \n",
    "#     cid = train[\"customer_ID\"].loc[val_ind]\n",
    "    model = LogisticRegression(penalty = 'none')\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    print(f'start Training fold {fold}')\n",
    "#     model.fit(np.array(x_train),]\n",
    "#                     np.array(y_train.values.ravel()),\n",
    "#                     eval_set = [(np.array(x_val), np.array(y_val.values.ravel()))],\n",
    "#                     max_epochs = 1,#50\n",
    "#                     patience = 1,#50\n",
    "#                     batch_size = 512,\n",
    "#                     eval_metric = ['auc', 'accuracy', Amex_tabnet]) # Last metric is used for early stoppin\n",
    "    \n",
    "    print(f'save fold{fold} model')\n",
    "    file_path = f\"{CFG.output_dir}{CFG.model}_fold{fold}\"\n",
    "    pickle.dump(model, open(file_path, 'wb'))\n",
    "#     saved_filepath = model.save_model(file_path)\n",
    "    \n",
    "#     oof_predictions[valid_idx] = model.predict_proba(x_val.values)[:, 1]\n",
    "    pred = model.predict_proba(np.array(x_val))[:, 1]\n",
    "    oof_preds.extend(pred)\n",
    "    \n",
    "#     preds.extend(oof_predictions)\n",
    "    print(\"oof_preds : \",len(oof_preds))\n",
    "    \n",
    "    fold_score = amex_metric(y_val, pred)\n",
    "    print(f\"{fold} score is : \",fold_score)\n",
    "    CVscore.append(fold_score)\n",
    "\n",
    "    # Add to out of folds array\n",
    "#     oof_predictions[val_ind] = val_pred\n",
    "    \n",
    "    # OOF用のcustomer_IDをExtend\n",
    "    cids.extend(train[\"customer_ID\"].loc[val_ind])\n",
    "    # test predct\n",
    "    test_preds.append(model.predict_proba(mn.fit_transform(test[features]))[:, 1])\n",
    "#     print(f'OOF score across folds: {amex_metric_numpy(target, oof_predictions.flatten())}')\n",
    "\n",
    "#     # Compute fold metric\n",
    "    del x_train, x_val, y_train, y_val\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "# Compute out of folds metric\n",
    "# test_predictions = np.mean(test_preds,axis = 0)\n",
    "\n",
    "\n",
    "score = np.mean(CVscore)\n",
    "# score = amex_metric(train[CFG.target], oof_preds)\n",
    "print(f'Our out of folds CV score is {score}')\n",
    "\n",
    "\n",
    "# Create a dataframe to store test prediction\n",
    "test_df = pd.DataFrame({'customer_ID': test['customer_ID'], 'prediction': test_predictions})\n",
    "# test_df.to_csv(f'{CFG.output_dir}test_{CFG.model}_{score}_baseline_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)\n",
    "test_df.to_csv(f'{CFG.output_dir}test_{CFG.model}_{score}_{CFG.ver}_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)\n",
    "\n",
    "\n",
    "dic_oof = {\n",
    "    \"customer_ID\":cids,\n",
    "    \"target\":train[CFG.target],\n",
    "    \"tabnet_oot\":oof_predictions\n",
    "}\n",
    "\n",
    "# Create a dataframe to store out of folds predictions\n",
    "oof_df = pd.DataFrame(dic_oof)\n",
    "# oof_df = pd.DataFrame({'customer_ID': train['customer_ID'], 'target': train[CFG.target], 'prediction': oof_predictions})\n",
    "oof_df.to_csv(f'{CFG.output_dir}oof_{CFG.ver}_{CFG.model}_{score}_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)\n",
    "\n",
    "    \n",
    "    \n",
    "# # Compute out of folds metric\n",
    "# score = amex_metric(train[CFG.target], preds)\n",
    "# print(f'Our out of folds CV score is {score}')\n",
    "# test_predictions = np.mean(preds,axis = 0)\n",
    "\n",
    "# dic_oof = {\n",
    "#     \"customer_ID\":cids,\n",
    "#     \"target\":train[CFG.target],\n",
    "#     \"tabnet_oot\":oof_predictions\n",
    "# }\n",
    "\n",
    "# # Create a dataframe to store out of folds predictions\n",
    "# oof_df = pd.DataFrame(dic_oof)\n",
    "# # oof_df = pd.DataFrame({'customer_ID': train['customer_ID'], 'target': train[CFG.target], 'prediction': oof_predictions})\n",
    "# oof_df.to_csv(f'{CFG.output_dir}oof_{CFG.ver}_{CFG.model}_{score}_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)\n",
    "\n",
    "\n",
    "# # Create a dataframe to store test predictionS\n",
    "# test_df = pd.DataFrame({'customer_ID': test['customer_ID'], 'prediction': test_predictions})\n",
    "# test_df.to_csv(f'{CFG.output_dir}test_{CFG.model}_{score}_baseline_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "359938fa-d8f8-40bd-8d85-47944e0b6273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Density'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.distplot(oof_preds)\n",
    "# model.predict_proba(sc.fit_transform(test[features]))[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebc4845-f09d-458c-9f7e-f397d4a9f4d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amex",
   "language": "python",
   "name": "amex"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
