{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70f58d85-14e4-4371-ad96-458843ea228c",
   "metadata": {},
   "source": [
    "# exp41\n",
    "\n",
    "lag_diff„ÅÆcatboost\n",
    "\n",
    "\n",
    "https://www.kaggle.com/code/ragnar123/amex-lgbm-dart-cv-0-7977"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "325051a6-7ea3-4398-b022-6a81c18b14eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Library\n",
    "# ====================================================\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "from tqdm.auto import tqdm\n",
    "import itertools\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce478709-32b7-4d68-bda7-4928785a13b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/data/train.parquet'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3440\\217815574.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;31m# Read & Preprocess Data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m \u001b[0mread_preprocess_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3440\\217815574.py\u001b[0m in \u001b[0;36mread_preprocess_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;31m# ====================================================\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mread_preprocess_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/data/train.parquet'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m     \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'customer_ID'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'S_2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     cat_features = [\n",
      "\u001b[1;32m~\\anaconda3\\envs\\amex\\lib\\site-packages\\pandas\\io\\parquet.py\u001b[0m in \u001b[0;36mread_parquet\u001b[1;34m(path, engine, columns, storage_options, use_nullable_dtypes, **kwargs)\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    499\u001b[0m         \u001b[0muse_nullable_dtypes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_nullable_dtypes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 500\u001b[1;33m         \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    501\u001b[0m     )\n",
      "\u001b[1;32m~\\anaconda3\\envs\\amex\\lib\\site-packages\\pandas\\io\\parquet.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, path, columns, use_nullable_dtypes, storage_options, **kwargs)\u001b[0m\n\u001b[0;32m    234\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"filesystem\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 236\u001b[1;33m             \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    237\u001b[0m         )\n\u001b[0;32m    238\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\amex\\lib\\site-packages\\pandas\\io\\parquet.py\u001b[0m in \u001b[0;36m_get_path_or_handle\u001b[1;34m(path, fs, storage_options, mode, is_dir)\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[1;31m# this branch is used for example when reading from non-fsspec URLs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         handles = get_handle(\n\u001b[1;32m--> 102\u001b[1;33m             \u001b[0mpath_or_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m         )\n\u001b[0;32m    104\u001b[0m         \u001b[0mfs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\amex\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    709\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m             \u001b[1;31m# Binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 711\u001b[1;33m             \u001b[0mhandle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    712\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    713\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/data/train.parquet'"
     ]
    }
   ],
   "source": [
    "\n",
    "# ====================================================\n",
    "# Get the difference\n",
    "# ====================================================\n",
    "def get_difference(data, num_features):\n",
    "    df1 = []\n",
    "    customer_ids = []\n",
    "    for customer_id, df in tqdm(data.groupby(['customer_ID'])):\n",
    "        # Get the differences\n",
    "        diff_df1 = df[num_features].diff(1).iloc[[-1]].values.astype(np.float32)\n",
    "        # Append to lists\n",
    "        df1.append(diff_df1)\n",
    "        customer_ids.append(customer_id)\n",
    "    # Concatenate\n",
    "    df1 = np.concatenate(df1, axis = 0)\n",
    "    # Transform to dataframe\n",
    "    df1 = pd.DataFrame(df1, columns = [col + '_diff1' for col in df[num_features].columns])\n",
    "    # Add customer id\n",
    "    df1['customer_ID'] = customer_ids\n",
    "    return df1\n",
    "\n",
    "# ====================================================\n",
    "# Read & preprocess data and save it to disk\n",
    "# ====================================================\n",
    "def read_preprocess_data():\n",
    "    train = pd.read_parquet('/content/data/train.parquet')\n",
    "    features = train.drop(['customer_ID', 'S_2'], axis = 1).columns.to_list()\n",
    "    cat_features = [\n",
    "        \"B_30\",\n",
    "        \"B_38\",\n",
    "        \"D_114\",\n",
    "        \"D_116\",\n",
    "        \"D_117\",\n",
    "        \"D_120\",\n",
    "        \"D_126\",\n",
    "        \"D_63\",\n",
    "        \"D_64\",\n",
    "        \"D_66\",\n",
    "        \"D_68\",\n",
    "    ]\n",
    "    num_features = [col for col in features if col not in cat_features]\n",
    "    print('Starting training feature engineer...')\n",
    "    train_num_agg = train.groupby(\"customer_ID\")[num_features].agg(['mean', 'std', 'min', 'max', 'last'])\n",
    "    train_num_agg.columns = ['_'.join(x) for x in train_num_agg.columns]\n",
    "    train_num_agg.reset_index(inplace = True)\n",
    "    train_cat_agg = train.groupby(\"customer_ID\")[cat_features].agg(['count', 'last', 'nunique'])\n",
    "    train_cat_agg.columns = ['_'.join(x) for x in train_cat_agg.columns]\n",
    "    train_cat_agg.reset_index(inplace = True)\n",
    "    train_labels = pd.read_csv('../input/amex-default-prediction/train_labels.csv')\n",
    "    # Transform float64 columns to float32\n",
    "    cols = list(train_num_agg.dtypes[train_num_agg.dtypes == 'float64'].index)\n",
    "    for col in tqdm(cols):\n",
    "        train_num_agg[col] = train_num_agg[col].astype(np.float32)\n",
    "    # Transform int64 columns to int32\n",
    "    cols = list(train_cat_agg.dtypes[train_cat_agg.dtypes == 'int64'].index)\n",
    "    for col in tqdm(cols):\n",
    "        train_cat_agg[col] = train_cat_agg[col].astype(np.int32)\n",
    "    # Get the difference\n",
    "    train_diff = get_difference(train, num_features)\n",
    "    train = train_num_agg.merge(train_cat_agg, how = 'inner', on = 'customer_ID').merge(train_diff, how = 'inner', on = 'customer_ID').merge(train_labels, how = 'inner', on = 'customer_ID')\n",
    "    del train_num_agg, train_cat_agg, train_diff\n",
    "    gc.collect()\n",
    "    test = pd.read_parquet('../input/amex-fe/test_fe.parquet')\n",
    "    print('Starting test feature engineer...')\n",
    "    test_num_agg = test.groupby(\"customer_ID\")[num_features].agg(['mean', 'std', 'min', 'max', 'last'])\n",
    "    test_num_agg.columns = ['_'.join(x) for x in test_num_agg.columns]\n",
    "    test_num_agg.reset_index(inplace = True)\n",
    "    test_cat_agg = test.groupby(\"customer_ID\")[cat_features].agg(['count', 'last', 'nunique'])\n",
    "    test_cat_agg.columns = ['_'.join(x) for x in test_cat_agg.columns]\n",
    "    test_cat_agg.reset_index(inplace = True)\n",
    "    # Transform float64 columns to float32\n",
    "    cols = list(test_num_agg.dtypes[test_num_agg.dtypes == 'float64'].index)\n",
    "    for col in tqdm(cols):\n",
    "        test_num_agg[col] = test_num_agg[col].astype(np.float32)\n",
    "    # Transform int64 columns to int32\n",
    "    cols = list(test_cat_agg.dtypes[test_cat_agg.dtypes == 'int64'].index)\n",
    "    for col in tqdm(cols):\n",
    "        test_cat_agg[col] = test_cat_agg[col].astype(np.int32)\n",
    "    # Get the difference\n",
    "    test_diff = get_difference(test, num_features)\n",
    "    test = test_num_agg.merge(test_cat_agg, how = 'inner', on = 'customer_ID').merge(test_diff, how = 'inner', on = 'customer_ID')\n",
    "    del test_num_agg, test_cat_agg, test_diff\n",
    "    gc.collect()\n",
    "    # Save files to disk\n",
    "    train.to_parquet('../input/amex-fe/train_fe.parquet')\n",
    "    test.to_parquet('../input/amex-fe/test_fe.parquet')\n",
    "\n",
    "# Read & Preprocess Data\n",
    "read_preprocess_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e80847-25f2-4784-97c5-b8012eae1a3e",
   "metadata": {},
   "source": [
    "# Training & Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c68ef141-3c78-4cd6-988b-db0421753882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Library\n",
    "# ====================================================\n",
    "import os\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import random\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import itertools\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import lightgbm as lgb\n",
    "from itertools import combinations\n",
    "\n",
    "import pickle\n",
    "\n",
    "# ====================================================\n",
    "# Configurations\n",
    "# ====================================================\n",
    "class CFG:\n",
    "    \n",
    "    \n",
    "    # input_dir = '../feature/exp35_lagdiff/'\n",
    "    input_dir = '../feature/exp03_amex-fe/'\n",
    "    output_dir = '../output/exp41_cat_lagdiff_c3/'\n",
    "    seed = 42\n",
    "    n_folds = 5\n",
    "    target = 'target'\n",
    "    boosting_type = 'dart'\n",
    "    metric = 'binary_logloss'\n",
    "    model = \"cat\"\n",
    "    ver = \"exp41\"\n",
    "\n",
    "# ====================================================\n",
    "# Seed everything\n",
    "# ====================================================\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "# ====================================================\n",
    "# Read data\n",
    "# ====================================================\n",
    "# def read_data():\n",
    "#     train = pd.read_parquet(CFG.input_dir + 'train_diff.parquet')\n",
    "#     test = pd.read_parquet(CFG.input_dir + 'test_diff.parquet')\n",
    "#     return train, test\n",
    "\n",
    "def read_data():\n",
    "    train = pd.read_parquet(CFG.input_dir + 'train_fe_plus_plus.parquet')\n",
    "    test = pd.read_parquet(CFG.input_dir + 'test_fe_plus_plus.parquet')\n",
    "    return train, test\n",
    "\n",
    "# ====================================================\n",
    "# Amex metric\n",
    "# ====================================================\n",
    "def amex_metric(y_true, y_pred):\n",
    "    labels = np.transpose(np.array([y_true, y_pred]))\n",
    "    labels = labels[labels[:, 1].argsort()[::-1]]\n",
    "    weights = np.where(labels[:,0]==0, 20, 1)\n",
    "    cut_vals = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n",
    "    top_four = np.sum(cut_vals[:,0]) / np.sum(labels[:,0])\n",
    "    gini = [0,0]\n",
    "    for i in [1,0]:\n",
    "        labels = np.transpose(np.array([y_true, y_pred]))\n",
    "        labels = labels[labels[:, i].argsort()[::-1]]\n",
    "        weight = np.where(labels[:,0]==0, 20, 1)\n",
    "        weight_random = np.cumsum(weight / np.sum(weight))\n",
    "        total_pos = np.sum(labels[:, 0] *  weight)\n",
    "        cum_pos_found = np.cumsum(labels[:, 0] * weight)\n",
    "        lorentz = cum_pos_found / total_pos\n",
    "        gini[i] = np.sum((lorentz - weight_random) * weight)\n",
    "    return 0.5 * (gini[1]/gini[0] + top_four)\n",
    "\n",
    "# ====================================================\n",
    "# LGBM amex metric\n",
    "# ====================================================\n",
    "def lgb_amex_metric(y_pred, y_true):\n",
    "    y_true = y_true.get_label()\n",
    "    return 'amex_metric', amex_metric(y_true, y_pred), True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5df5be5-8119-4c74-965b-89abb98ff5a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(458913, 2013)\n",
      "(924621, 2012)\n"
     ]
    }
   ],
   "source": [
    "seed_everything(CFG.seed)\n",
    "\n",
    "train = pd.read_parquet('../feature/exp35_lagdiff/train_lagdiff.parquet')\n",
    "test = pd.read_parquet('../feature/exp35_lagdiff/test_lagdiff.parquet')\n",
    "\n",
    "# train, test = read_data()\n",
    "\n",
    "train_c3 = pd.read_pickle('../feature/exp18_4_tsfresh/train_c3.pkl')\n",
    "test_c3 = pd.read_pickle('../feature/exp18_4_tsfresh/test_c3.pkl')\n",
    "\n",
    "train = train.merge(train_c3,on = \"customer_ID\",how = \"left\")\n",
    "test = test.merge(test_c3,on = \"customer_ID\",how = \"left\")\n",
    "\n",
    "del train_c3,test_c3\n",
    "gc.collect\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30007ce2-4854-4fd8-8c1b-477936511e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def xgb_amex(y_pred, y_true):\n",
    "    return 'amex', amex_metric_np(y_pred,y_true.get_label())\n",
    "\n",
    "\n",
    "def amex_metric_np(preds: np.ndarray, target: np.ndarray) -> float:\n",
    "    indices = np.argsort(preds)[::-1]\n",
    "    preds, target = preds[indices], target[indices]\n",
    "\n",
    "    weight = 20.0 - target * 19.0\n",
    "    cum_norm_weight = (weight / weight.sum()).cumsum()\n",
    "    four_pct_mask = cum_norm_weight <= 0.04\n",
    "    d = np.sum(target[four_pct_mask]) / np.sum(target)\n",
    "\n",
    "    weighted_target = target * weight\n",
    "    lorentz = (weighted_target / weighted_target.sum()).cumsum()\n",
    "    gini = ((lorentz - cum_norm_weight) * weight).sum()\n",
    "\n",
    "    n_pos = np.sum(target)\n",
    "    n_neg = target.shape[0] - n_pos\n",
    "    gini_max = 10 * n_neg * (n_pos + 20 * n_neg - 19) / (n_pos + 20 * n_neg)\n",
    "\n",
    "    g = gini / gini_max\n",
    "    return 0.5 * (g + d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5f272d-2129-4b46-a8de-80d78b84a600",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f980b292-35c6-4c96-a0c1-bc05c4f311c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da1aef6c-6e01-413f-b9a0-46be991ca78e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "--------------------------------------------------\n",
      "Training fold 0 with 2011 features...\n",
      "0:\tlearn: 0.6671410\ttest: 0.6670561\tbest: 0.6670561 (0)\ttotal: 676ms\tremaining: 1h 30m 5s\n",
      "100:\tlearn: 0.2438105\ttest: 0.2433128\tbest: 0.2433128 (100)\ttotal: 1m 7s\tremaining: 1h 28m 7s\n",
      "200:\tlearn: 0.2290271\ttest: 0.2295302\tbest: 0.2295302 (200)\ttotal: 2m 12s\tremaining: 1h 25m 55s\n",
      "300:\tlearn: 0.2234682\ttest: 0.2251648\tbest: 0.2251648 (300)\ttotal: 3m 18s\tremaining: 1h 24m 36s\n",
      "400:\tlearn: 0.2197603\ttest: 0.2227460\tbest: 0.2227460 (400)\ttotal: 4m 24s\tremaining: 1h 23m 26s\n",
      "500:\tlearn: 0.2168978\ttest: 0.2211216\tbest: 0.2211216 (500)\ttotal: 5m 29s\tremaining: 1h 22m 14s\n",
      "600:\tlearn: 0.2144838\ttest: 0.2200045\tbest: 0.2200045 (600)\ttotal: 6m 33s\tremaining: 1h 20m 45s\n",
      "700:\tlearn: 0.2120917\ttest: 0.2190235\tbest: 0.2190235 (700)\ttotal: 7m 38s\tremaining: 1h 19m 35s\n",
      "800:\tlearn: 0.2097026\ttest: 0.2183041\tbest: 0.2183041 (800)\ttotal: 8m 42s\tremaining: 1h 18m 13s\n",
      "900:\tlearn: 0.2075532\ttest: 0.2178139\tbest: 0.2178139 (900)\ttotal: 9m 45s\tremaining: 1h 16m 49s\n",
      "1000:\tlearn: 0.2055559\ttest: 0.2174255\tbest: 0.2174255 (1000)\ttotal: 10m 46s\tremaining: 1h 15m 18s\n",
      "1100:\tlearn: 0.2036117\ttest: 0.2170975\tbest: 0.2170975 (1100)\ttotal: 11m 48s\tremaining: 1h 13m 59s\n",
      "1200:\tlearn: 0.2018246\ttest: 0.2167789\tbest: 0.2167789 (1200)\ttotal: 12m 49s\tremaining: 1h 12m 37s\n",
      "1300:\tlearn: 0.2000364\ttest: 0.2165174\tbest: 0.2165174 (1300)\ttotal: 13m 51s\tremaining: 1h 11m 21s\n",
      "1400:\tlearn: 0.1984222\ttest: 0.2163163\tbest: 0.2163163 (1400)\ttotal: 14m 51s\tremaining: 1h 9m 57s\n",
      "1500:\tlearn: 0.1968148\ttest: 0.2161483\tbest: 0.2161483 (1500)\ttotal: 15m 51s\tremaining: 1h 8m 41s\n",
      "1600:\tlearn: 0.1952453\ttest: 0.2159761\tbest: 0.2159761 (1600)\ttotal: 16m 52s\tremaining: 1h 7m 25s\n",
      "1700:\tlearn: 0.1936603\ttest: 0.2158169\tbest: 0.2158169 (1700)\ttotal: 17m 53s\tremaining: 1h 6m 14s\n",
      "1800:\tlearn: 0.1921406\ttest: 0.2157127\tbest: 0.2157127 (1800)\ttotal: 18m 53s\tremaining: 1h 5m\n",
      "1900:\tlearn: 0.1906327\ttest: 0.2155653\tbest: 0.2155653 (1900)\ttotal: 19m 53s\tremaining: 1h 3m 50s\n",
      "2000:\tlearn: 0.1891852\ttest: 0.2154637\tbest: 0.2154637 (2000)\ttotal: 20m 54s\tremaining: 1h 2m 40s\n",
      "2100:\tlearn: 0.1877949\ttest: 0.2153349\tbest: 0.2153349 (2100)\ttotal: 21m 54s\tremaining: 1h 1m 31s\n",
      "2200:\tlearn: 0.1863608\ttest: 0.2152242\tbest: 0.2152242 (2200)\ttotal: 22m 54s\tremaining: 1h 22s\n",
      "2300:\tlearn: 0.1850055\ttest: 0.2151595\tbest: 0.2151595 (2300)\ttotal: 23m 55s\tremaining: 59m 15s\n",
      "2400:\tlearn: 0.1836153\ttest: 0.2150851\tbest: 0.2150851 (2400)\ttotal: 24m 55s\tremaining: 58m 6s\n",
      "2500:\tlearn: 0.1822815\ttest: 0.2149989\tbest: 0.2149989 (2500)\ttotal: 25m 56s\tremaining: 57m 1s\n",
      "2600:\tlearn: 0.1809121\ttest: 0.2149293\tbest: 0.2149293 (2600)\ttotal: 26m 55s\tremaining: 55m 54s\n",
      "2700:\tlearn: 0.1795108\ttest: 0.2148801\tbest: 0.2148801 (2700)\ttotal: 27m 57s\tremaining: 54m 51s\n",
      "2800:\tlearn: 0.1781807\ttest: 0.2148166\tbest: 0.2148166 (2800)\ttotal: 28m 57s\tremaining: 53m 45s\n",
      "2900:\tlearn: 0.1768489\ttest: 0.2147244\tbest: 0.2147244 (2900)\ttotal: 29m 58s\tremaining: 52m 41s\n",
      "3000:\tlearn: 0.1755728\ttest: 0.2146277\tbest: 0.2146277 (3000)\ttotal: 30m 58s\tremaining: 51m 36s\n",
      "3100:\tlearn: 0.1742905\ttest: 0.2145878\tbest: 0.2145878 (3100)\ttotal: 32m\tremaining: 50m 33s\n",
      "3200:\tlearn: 0.1730642\ttest: 0.2145429\tbest: 0.2145429 (3200)\ttotal: 33m\tremaining: 49m 29s\n",
      "3300:\tlearn: 0.1718864\ttest: 0.2145088\tbest: 0.2145088 (3300)\ttotal: 34m 1s\tremaining: 48m 25s\n",
      "3400:\tlearn: 0.1706715\ttest: 0.2144655\tbest: 0.2144655 (3400)\ttotal: 35m\tremaining: 47m 20s\n",
      "3500:\tlearn: 0.1694924\ttest: 0.2144338\tbest: 0.2144338 (3500)\ttotal: 36m 1s\tremaining: 46m 17s\n",
      "3600:\tlearn: 0.1682995\ttest: 0.2143753\tbest: 0.2143753 (3600)\ttotal: 37m 1s\tremaining: 45m 13s\n",
      "3700:\tlearn: 0.1670974\ttest: 0.2143240\tbest: 0.2143240 (3700)\ttotal: 38m 2s\tremaining: 44m 11s\n",
      "3800:\tlearn: 0.1659455\ttest: 0.2142963\tbest: 0.2142963 (3800)\ttotal: 39m 3s\tremaining: 43m 8s\n",
      "3900:\tlearn: 0.1647608\ttest: 0.2142492\tbest: 0.2142492 (3900)\ttotal: 40m 5s\tremaining: 42m 7s\n",
      "4000:\tlearn: 0.1635925\ttest: 0.2142476\tbest: 0.2142476 (4000)\ttotal: 41m 5s\tremaining: 41m 4s\n",
      "4100:\tlearn: 0.1624632\ttest: 0.2142163\tbest: 0.2142163 (4100)\ttotal: 42m 6s\tremaining: 40m 1s\n",
      "4200:\tlearn: 0.1613242\ttest: 0.2141972\tbest: 0.2141972 (4200)\ttotal: 43m 7s\tremaining: 38m 59s\n",
      "4300:\tlearn: 0.1602113\ttest: 0.2141953\tbest: 0.2141953 (4300)\ttotal: 44m 8s\tremaining: 37m 57s\n",
      "4400:\tlearn: 0.1591146\ttest: 0.2141493\tbest: 0.2141493 (4400)\ttotal: 45m 8s\tremaining: 36m 55s\n",
      "4500:\tlearn: 0.1580125\ttest: 0.2141492\tbest: 0.2141492 (4500)\ttotal: 46m 9s\tremaining: 35m 52s\n",
      "4600:\tlearn: 0.1569188\ttest: 0.2141357\tbest: 0.2141357 (4600)\ttotal: 47m 9s\tremaining: 34m 50s\n",
      "4700:\tlearn: 0.1558474\ttest: 0.2141250\tbest: 0.2141250 (4700)\ttotal: 48m 11s\tremaining: 33m 48s\n",
      "4800:\tlearn: 0.1548026\ttest: 0.2141148\tbest: 0.2141148 (4800)\ttotal: 49m 11s\tremaining: 32m 46s\n",
      "4900:\tlearn: 0.1537317\ttest: 0.2141075\tbest: 0.2141075 (4900)\ttotal: 50m 12s\tremaining: 31m 44s\n",
      "5000:\tlearn: 0.1526814\ttest: 0.2140872\tbest: 0.2140872 (5000)\ttotal: 51m 12s\tremaining: 30m 42s\n",
      "5100:\tlearn: 0.1516400\ttest: 0.2140729\tbest: 0.2140729 (5100)\ttotal: 52m 13s\tremaining: 29m 40s\n",
      "5200:\tlearn: 0.1506079\ttest: 0.2140415\tbest: 0.2140415 (5200)\ttotal: 53m 15s\tremaining: 28m 39s\n",
      "5300:\tlearn: 0.1496037\ttest: 0.2140289\tbest: 0.2140289 (5300)\ttotal: 54m 16s\tremaining: 27m 37s\n",
      "5400:\tlearn: 0.1485894\ttest: 0.2140321\tbest: 0.2140289 (5300)\ttotal: 55m 16s\tremaining: 26m 36s\n",
      "5500:\tlearn: 0.1475296\ttest: 0.2140175\tbest: 0.2140175 (5500)\ttotal: 56m 17s\tremaining: 25m 34s\n",
      "5600:\tlearn: 0.1465248\ttest: 0.2140048\tbest: 0.2140048 (5600)\ttotal: 57m 18s\tremaining: 24m 32s\n",
      "5700:\tlearn: 0.1454794\ttest: 0.2139838\tbest: 0.2139838 (5700)\ttotal: 58m 20s\tremaining: 23m 31s\n",
      "5800:\tlearn: 0.1444936\ttest: 0.2139867\tbest: 0.2139838 (5700)\ttotal: 59m 21s\tremaining: 22m 29s\n",
      "5900:\tlearn: 0.1434831\ttest: 0.2139777\tbest: 0.2139777 (5900)\ttotal: 1h 22s\tremaining: 21m 28s\n",
      "6000:\tlearn: 0.1424863\ttest: 0.2139860\tbest: 0.2139777 (5900)\ttotal: 1h 1m 23s\tremaining: 20m 26s\n",
      "6100:\tlearn: 0.1415812\ttest: 0.2139631\tbest: 0.2139631 (6100)\ttotal: 1h 2m 23s\tremaining: 19m 25s\n",
      "6200:\tlearn: 0.1406085\ttest: 0.2139618\tbest: 0.2139618 (6200)\ttotal: 1h 3m 24s\tremaining: 18m 23s\n",
      "6300:\tlearn: 0.1396328\ttest: 0.2139621\tbest: 0.2139618 (6200)\ttotal: 1h 4m 25s\tremaining: 17m 22s\n",
      "6400:\tlearn: 0.1386711\ttest: 0.2139549\tbest: 0.2139549 (6400)\ttotal: 1h 5m 26s\tremaining: 16m 20s\n",
      "6500:\tlearn: 0.1377445\ttest: 0.2139349\tbest: 0.2139349 (6500)\ttotal: 1h 6m 27s\tremaining: 15m 19s\n",
      "6600:\tlearn: 0.1368459\ttest: 0.2139130\tbest: 0.2139130 (6600)\ttotal: 1h 7m 28s\tremaining: 14m 17s\n",
      "6700:\tlearn: 0.1359544\ttest: 0.2139304\tbest: 0.2139130 (6600)\ttotal: 1h 8m 28s\tremaining: 13m 16s\n",
      "6800:\tlearn: 0.1351104\ttest: 0.2139355\tbest: 0.2139130 (6600)\ttotal: 1h 9m 28s\tremaining: 12m 14s\n",
      "6900:\tlearn: 0.1342203\ttest: 0.2139138\tbest: 0.2139130 (6600)\ttotal: 1h 10m 28s\tremaining: 11m 13s\n",
      "7000:\tlearn: 0.1333346\ttest: 0.2139123\tbest: 0.2139123 (7000)\ttotal: 1h 11m 30s\tremaining: 10m 12s\n",
      "7100:\tlearn: 0.1325100\ttest: 0.2139371\tbest: 0.2139123 (7000)\ttotal: 1h 12m 31s\tremaining: 9m 10s\n",
      "7200:\tlearn: 0.1316899\ttest: 0.2139624\tbest: 0.2139123 (7000)\ttotal: 1h 13m 31s\tremaining: 8m 9s\n",
      "7300:\tlearn: 0.1308868\ttest: 0.2139540\tbest: 0.2139123 (7000)\ttotal: 1h 14m 31s\tremaining: 7m 8s\n",
      "7400:\tlearn: 0.1300423\ttest: 0.2139590\tbest: 0.2139123 (7000)\ttotal: 1h 15m 32s\tremaining: 6m 6s\n",
      "7500:\tlearn: 0.1291992\ttest: 0.2139341\tbest: 0.2139123 (7000)\ttotal: 1h 16m 32s\tremaining: 5m 5s\n",
      "7600:\tlearn: 0.1284066\ttest: 0.2139441\tbest: 0.2139123 (7000)\ttotal: 1h 17m 32s\tremaining: 4m 4s\n",
      "7700:\tlearn: 0.1276148\ttest: 0.2139568\tbest: 0.2139123 (7000)\ttotal: 1h 18m 33s\tremaining: 3m 2s\n",
      "7800:\tlearn: 0.1267692\ttest: 0.2139492\tbest: 0.2139123 (7000)\ttotal: 1h 19m 34s\tremaining: 2m 1s\n",
      "7900:\tlearn: 0.1259520\ttest: 0.2139488\tbest: 0.2139123 (7000)\ttotal: 1h 20m 35s\tremaining: 1m\n",
      "7999:\tlearn: 0.1251429\ttest: 0.2139646\tbest: 0.2139123 (7000)\ttotal: 1h 21m 35s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2139123204\n",
      "bestIteration = 7000\n",
      "\n",
      "Shrink model to first 7001 iterations.\n",
      "Our fold 0 CV score is 0.5925236179657332\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 1 with 2011 features...\n",
      "0:\tlearn: 0.6670383\ttest: 0.6669980\tbest: 0.6669980 (0)\ttotal: 701ms\tremaining: 1h 33m 27s\n",
      "100:\tlearn: 0.2433332\ttest: 0.2450192\tbest: 0.2450192 (100)\ttotal: 1m 8s\tremaining: 1h 29m 14s\n",
      "200:\tlearn: 0.2283569\ttest: 0.2319330\tbest: 0.2319330 (200)\ttotal: 2m 14s\tremaining: 1h 26m 44s\n",
      "300:\tlearn: 0.2226553\ttest: 0.2276621\tbest: 0.2276621 (300)\ttotal: 3m 19s\tremaining: 1h 25m 5s\n",
      "400:\tlearn: 0.2189665\ttest: 0.2253524\tbest: 0.2253524 (400)\ttotal: 4m 25s\tremaining: 1h 23m 53s\n",
      "500:\tlearn: 0.2161044\ttest: 0.2238922\tbest: 0.2238922 (500)\ttotal: 5m 30s\tremaining: 1h 22m 27s\n",
      "600:\tlearn: 0.2136317\ttest: 0.2228889\tbest: 0.2228889 (600)\ttotal: 6m 35s\tremaining: 1h 21m 12s\n",
      "700:\tlearn: 0.2112244\ttest: 0.2220402\tbest: 0.2220402 (700)\ttotal: 7m 40s\tremaining: 1h 19m 53s\n",
      "800:\tlearn: 0.2087526\ttest: 0.2213731\tbest: 0.2213731 (800)\ttotal: 8m 44s\tremaining: 1h 18m 31s\n",
      "900:\tlearn: 0.2065204\ttest: 0.2208923\tbest: 0.2208923 (900)\ttotal: 9m 48s\tremaining: 1h 17m 13s\n",
      "1000:\tlearn: 0.2043784\ttest: 0.2204884\tbest: 0.2204884 (1000)\ttotal: 10m 51s\tremaining: 1h 15m 53s\n",
      "1100:\tlearn: 0.2024364\ttest: 0.2201758\tbest: 0.2201758 (1100)\ttotal: 11m 53s\tremaining: 1h 14m 33s\n",
      "1200:\tlearn: 0.2006318\ttest: 0.2199418\tbest: 0.2199418 (1200)\ttotal: 12m 55s\tremaining: 1h 13m 13s\n",
      "1300:\tlearn: 0.1989080\ttest: 0.2197242\tbest: 0.2197242 (1300)\ttotal: 13m 57s\tremaining: 1h 11m 54s\n",
      "1400:\tlearn: 0.1972482\ttest: 0.2195539\tbest: 0.2195539 (1400)\ttotal: 14m 59s\tremaining: 1h 10m 34s\n",
      "1500:\tlearn: 0.1955750\ttest: 0.2193894\tbest: 0.2193894 (1500)\ttotal: 16m 1s\tremaining: 1h 9m 21s\n",
      "1600:\tlearn: 0.1939439\ttest: 0.2192871\tbest: 0.2192871 (1600)\ttotal: 17m 2s\tremaining: 1h 8m 6s\n",
      "1700:\tlearn: 0.1924228\ttest: 0.2191843\tbest: 0.2191843 (1700)\ttotal: 18m 3s\tremaining: 1h 6m 52s\n",
      "1800:\tlearn: 0.1909573\ttest: 0.2190892\tbest: 0.2190892 (1800)\ttotal: 19m 3s\tremaining: 1h 5m 35s\n",
      "1900:\tlearn: 0.1895097\ttest: 0.2189934\tbest: 0.2189934 (1900)\ttotal: 20m 4s\tremaining: 1h 4m 22s\n",
      "2000:\tlearn: 0.1881056\ttest: 0.2189303\tbest: 0.2189303 (2000)\ttotal: 21m 3s\tremaining: 1h 3m 8s\n",
      "2100:\tlearn: 0.1866675\ttest: 0.2188408\tbest: 0.2188408 (2100)\ttotal: 22m 6s\tremaining: 1h 2m 3s\n",
      "2200:\tlearn: 0.1852136\ttest: 0.2187646\tbest: 0.2187646 (2200)\ttotal: 23m 7s\tremaining: 1h 55s\n",
      "2300:\tlearn: 0.1838240\ttest: 0.2186896\tbest: 0.2186896 (2300)\ttotal: 24m 8s\tremaining: 59m 47s\n",
      "2400:\tlearn: 0.1823838\ttest: 0.2186220\tbest: 0.2186220 (2400)\ttotal: 25m 9s\tremaining: 58m 41s\n",
      "2500:\tlearn: 0.1810206\ttest: 0.2185724\tbest: 0.2185724 (2500)\ttotal: 26m 11s\tremaining: 57m 35s\n",
      "2600:\tlearn: 0.1796375\ttest: 0.2184954\tbest: 0.2184954 (2600)\ttotal: 27m 12s\tremaining: 56m 28s\n",
      "2700:\tlearn: 0.1783214\ttest: 0.2184597\tbest: 0.2184597 (2700)\ttotal: 28m 13s\tremaining: 55m 23s\n",
      "2800:\tlearn: 0.1770763\ttest: 0.2184528\tbest: 0.2184528 (2800)\ttotal: 29m 13s\tremaining: 54m 14s\n",
      "2900:\tlearn: 0.1757921\ttest: 0.2184215\tbest: 0.2184215 (2900)\ttotal: 30m 14s\tremaining: 53m 9s\n",
      "3000:\tlearn: 0.1745422\ttest: 0.2183688\tbest: 0.2183688 (3000)\ttotal: 31m 14s\tremaining: 52m 2s\n",
      "3100:\tlearn: 0.1733233\ttest: 0.2183250\tbest: 0.2183250 (3100)\ttotal: 32m 15s\tremaining: 50m 57s\n",
      "3200:\tlearn: 0.1720513\ttest: 0.2182987\tbest: 0.2182987 (3200)\ttotal: 33m 15s\tremaining: 49m 52s\n",
      "3300:\tlearn: 0.1708376\ttest: 0.2182694\tbest: 0.2182694 (3300)\ttotal: 34m 16s\tremaining: 48m 48s\n",
      "3400:\tlearn: 0.1696547\ttest: 0.2182596\tbest: 0.2182596 (3400)\ttotal: 35m 16s\tremaining: 47m 42s\n",
      "3500:\tlearn: 0.1684785\ttest: 0.2182348\tbest: 0.2182348 (3500)\ttotal: 36m 17s\tremaining: 46m 38s\n",
      "3600:\tlearn: 0.1672842\ttest: 0.2182033\tbest: 0.2182033 (3600)\ttotal: 37m 17s\tremaining: 45m 33s\n",
      "3700:\tlearn: 0.1661106\ttest: 0.2181627\tbest: 0.2181627 (3700)\ttotal: 38m 19s\tremaining: 44m 30s\n",
      "3800:\tlearn: 0.1649211\ttest: 0.2181850\tbest: 0.2181627 (3700)\ttotal: 39m 19s\tremaining: 43m 26s\n",
      "3900:\tlearn: 0.1637877\ttest: 0.2181434\tbest: 0.2181434 (3900)\ttotal: 40m 20s\tremaining: 42m 22s\n",
      "4000:\tlearn: 0.1626542\ttest: 0.2181080\tbest: 0.2181080 (4000)\ttotal: 41m 20s\tremaining: 41m 18s\n",
      "4100:\tlearn: 0.1615478\ttest: 0.2181020\tbest: 0.2181020 (4100)\ttotal: 42m 21s\tremaining: 40m 16s\n",
      "4200:\tlearn: 0.1604039\ttest: 0.2181068\tbest: 0.2181020 (4100)\ttotal: 43m 22s\tremaining: 39m 13s\n",
      "4300:\tlearn: 0.1592888\ttest: 0.2180832\tbest: 0.2180832 (4300)\ttotal: 44m 22s\tremaining: 38m 9s\n",
      "4400:\tlearn: 0.1581339\ttest: 0.2180986\tbest: 0.2180832 (4300)\ttotal: 45m 23s\tremaining: 37m 7s\n",
      "4500:\tlearn: 0.1570733\ttest: 0.2180998\tbest: 0.2180832 (4300)\ttotal: 46m 25s\tremaining: 36m 5s\n",
      "4600:\tlearn: 0.1559832\ttest: 0.2180690\tbest: 0.2180690 (4600)\ttotal: 47m 26s\tremaining: 35m 2s\n",
      "4700:\tlearn: 0.1549395\ttest: 0.2180622\tbest: 0.2180622 (4700)\ttotal: 48m 26s\tremaining: 33m 59s\n",
      "4800:\tlearn: 0.1538809\ttest: 0.2180510\tbest: 0.2180510 (4800)\ttotal: 49m 27s\tremaining: 32m 57s\n",
      "4900:\tlearn: 0.1528567\ttest: 0.2180252\tbest: 0.2180252 (4900)\ttotal: 50m 28s\tremaining: 31m 54s\n",
      "5000:\tlearn: 0.1517857\ttest: 0.2179848\tbest: 0.2179848 (5000)\ttotal: 51m 29s\tremaining: 30m 52s\n",
      "5100:\tlearn: 0.1507435\ttest: 0.2179734\tbest: 0.2179734 (5100)\ttotal: 52m 30s\tremaining: 29m 50s\n",
      "5200:\tlearn: 0.1497032\ttest: 0.2179589\tbest: 0.2179589 (5200)\ttotal: 53m 32s\tremaining: 28m 48s\n",
      "5300:\tlearn: 0.1487251\ttest: 0.2179700\tbest: 0.2179589 (5200)\ttotal: 54m 35s\tremaining: 27m 47s\n",
      "5400:\tlearn: 0.1476944\ttest: 0.2179762\tbest: 0.2179589 (5200)\ttotal: 55m 37s\tremaining: 26m 45s\n",
      "5500:\tlearn: 0.1466951\ttest: 0.2179905\tbest: 0.2179589 (5200)\ttotal: 56m 40s\tremaining: 25m 44s\n",
      "5600:\tlearn: 0.1457125\ttest: 0.2179957\tbest: 0.2179589 (5200)\ttotal: 57m 42s\tremaining: 24m 43s\n",
      "5700:\tlearn: 0.1447094\ttest: 0.2179740\tbest: 0.2179589 (5200)\ttotal: 58m 44s\tremaining: 23m 41s\n",
      "5800:\tlearn: 0.1437460\ttest: 0.2179790\tbest: 0.2179589 (5200)\ttotal: 59m 48s\tremaining: 22m 40s\n",
      "5900:\tlearn: 0.1427252\ttest: 0.2179654\tbest: 0.2179589 (5200)\ttotal: 1h 52s\tremaining: 21m 39s\n",
      "6000:\tlearn: 0.1418192\ttest: 0.2179826\tbest: 0.2179589 (5200)\ttotal: 1h 1m 53s\tremaining: 20m 36s\n",
      "6100:\tlearn: 0.1408385\ttest: 0.2179865\tbest: 0.2179589 (5200)\ttotal: 1h 2m 54s\tremaining: 19m 34s\n",
      "6200:\tlearn: 0.1399215\ttest: 0.2180202\tbest: 0.2179589 (5200)\ttotal: 1h 3m 56s\tremaining: 18m 33s\n",
      "6300:\tlearn: 0.1390223\ttest: 0.2180224\tbest: 0.2179589 (5200)\ttotal: 1h 4m 57s\tremaining: 17m 30s\n",
      "6400:\tlearn: 0.1380438\ttest: 0.2180261\tbest: 0.2179589 (5200)\ttotal: 1h 6m 3s\tremaining: 16m 29s\n",
      "6500:\tlearn: 0.1371016\ttest: 0.2180114\tbest: 0.2179589 (5200)\ttotal: 1h 7m 4s\tremaining: 15m 28s\n",
      "6600:\tlearn: 0.1362124\ttest: 0.2180152\tbest: 0.2179589 (5200)\ttotal: 1h 8m 7s\tremaining: 14m 26s\n",
      "6700:\tlearn: 0.1352968\ttest: 0.2180306\tbest: 0.2179589 (5200)\ttotal: 1h 9m 11s\tremaining: 13m 24s\n",
      "6800:\tlearn: 0.1344777\ttest: 0.2180662\tbest: 0.2179589 (5200)\ttotal: 1h 10m 12s\tremaining: 12m 22s\n",
      "6900:\tlearn: 0.1336305\ttest: 0.2180902\tbest: 0.2179589 (5200)\ttotal: 1h 11m 15s\tremaining: 11m 20s\n",
      "7000:\tlearn: 0.1327413\ttest: 0.2181276\tbest: 0.2179589 (5200)\ttotal: 1h 12m 17s\tremaining: 10m 18s\n",
      "7100:\tlearn: 0.1318746\ttest: 0.2181212\tbest: 0.2179589 (5200)\ttotal: 1h 13m 18s\tremaining: 9m 16s\n",
      "7200:\tlearn: 0.1310234\ttest: 0.2181552\tbest: 0.2179589 (5200)\ttotal: 1h 14m 22s\tremaining: 8m 15s\n",
      "7300:\tlearn: 0.1301724\ttest: 0.2181921\tbest: 0.2179589 (5200)\ttotal: 1h 15m 23s\tremaining: 7m 13s\n",
      "7400:\tlearn: 0.1293605\ttest: 0.2182224\tbest: 0.2179589 (5200)\ttotal: 1h 16m 25s\tremaining: 6m 11s\n",
      "7500:\tlearn: 0.1285379\ttest: 0.2182561\tbest: 0.2179589 (5200)\ttotal: 1h 17m 27s\tremaining: 5m 9s\n",
      "7600:\tlearn: 0.1277042\ttest: 0.2182892\tbest: 0.2179589 (5200)\ttotal: 1h 18m 29s\tremaining: 4m 7s\n",
      "7700:\tlearn: 0.1268908\ttest: 0.2183268\tbest: 0.2179589 (5200)\ttotal: 1h 19m 32s\tremaining: 3m 5s\n",
      "7800:\tlearn: 0.1260629\ttest: 0.2183236\tbest: 0.2179589 (5200)\ttotal: 1h 20m 34s\tremaining: 2m 3s\n",
      "7900:\tlearn: 0.1252733\ttest: 0.2183349\tbest: 0.2179589 (5200)\ttotal: 1h 21m 37s\tremaining: 1m 1s\n",
      "7999:\tlearn: 0.1244807\ttest: 0.2183520\tbest: 0.2179589 (5200)\ttotal: 1h 22m 38s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.217958943\n",
      "bestIteration = 5200\n",
      "\n",
      "Shrink model to first 5201 iterations.\n",
      "Our fold 1 CV score is 0.589818274071325\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 2 with 2011 features...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3440\\2962338409.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'-'\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Training fold {fold} with {len(features)} features...'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrn_ind\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval_ind\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m     \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mCFG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrn_ind\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mCFG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval_ind\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;31m#     lgb_train = lgb.Dataset(x_train, y_train, categorical_feature = cat_features)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "cat_features = [\n",
    "    \"B_30\",\n",
    "    \"B_38\",\n",
    "    \"D_114\",\n",
    "    \"D_116\",\n",
    "    \"D_117\",\n",
    "    \"D_120\",\n",
    "    \"D_126\",\n",
    "    \"D_63\",\n",
    "    \"D_64\",\n",
    "    \"D_66\",\n",
    "    \"D_68\"\n",
    "]\n",
    "\n",
    "# kmeans_list = [\"kmeans pred 2\",\"kmeans pred 3\",\"kmeans pred 4\"]\n",
    "\n",
    "cat_features = [f\"{cf}_last\" for cf in cat_features]\n",
    "# cat_features.extend(kmeans_list)\n",
    "\n",
    "for cat_col in cat_features:\n",
    "#     print(cat_col)\n",
    "    encoder = LabelEncoder()\n",
    "    train[cat_col] = encoder.fit_transform(train[cat_col])\n",
    "    test[cat_col] = encoder.transform(test[cat_col])\n",
    "\n",
    "\n",
    "features = [col for col in train.columns if col not in ['customer_ID', CFG.target]]\n",
    "\n",
    "prams = {\n",
    "    'depth': 8,\n",
    "    'iterations':10,#8000\n",
    "    'learning_rate': 0.02,\n",
    "    'random_state':CFG.seed,\n",
    "    'task_type':\"CPU\",\n",
    "    'early_stopping_rounds': 300,\n",
    "}\n",
    "\n",
    "# Create a numpy array to store test predictions\n",
    "test_predictions = np.zeros(len(test))\n",
    "# Create a numpy array to store out of folds predictions\n",
    "oof_predictions = np.zeros(len(train))\n",
    "\n",
    "cids = []\n",
    "tr_target = []\n",
    "\n",
    "epoch = [10000,7500,7500,8500,10500]\n",
    "\n",
    "kfold = StratifiedKFold(n_splits = CFG.n_folds, shuffle = True, random_state = CFG.seed)\n",
    "for fold, (trn_ind, val_ind) in enumerate(kfold.split(train, train[CFG.target])):\n",
    "    print(' ')\n",
    "    print('-'*50)\n",
    "    print(f'Training fold {fold} with {len(features)} features...')\n",
    "    x_train, x_val = train[features].iloc[trn_ind], train[features].iloc[val_ind]\n",
    "    y_train, y_val = train[CFG.target].iloc[trn_ind], train[CFG.target].iloc[val_ind]\n",
    "#     lgb_train = lgb.Dataset(x_train, y_train, categorical_feature = cat_features)\n",
    "#     lgb_valid = lgb.Dataset(x_val, y_val, categorical_feature = cat_features)\n",
    "    \n",
    "#     des = DartEarlyStopping(\"valid_1\", CFG.metric, 1000)\n",
    "    \n",
    "    model = CatBoostClassifier(**prams)\n",
    "    \n",
    "    model.fit(x_train, y_train,\n",
    "                  eval_set = [(x_val, y_val)], \n",
    "                  metric_period=100\n",
    "                 )\n",
    "    \n",
    "#     model = lgb.train(\n",
    "#         params = params,\n",
    "#         train_set = lgb_train,\n",
    "#         num_boost_round = epoch[fold],#10500\n",
    "#         valid_sets = [lgb_train, lgb_valid],\n",
    "#         early_stopping_rounds = 1500,\n",
    "# #         eval_metric=[lgb_amex_metric],\n",
    "#         verbose_eval = 500,\n",
    "#         feval = lgb_amex_metric\n",
    "#         )\n",
    "    \n",
    "    # Save best model\n",
    "    model.save_model(f\"{CFG.output_dir}{CFG.model}_fold{fold}_seed{CFG.seed}.cbm\")\n",
    "    joblib.dump(model, f'{CFG.output_dir}lgbm_{CFG.boosting_type}_fold{fold}_seed{CFG.seed}.pkl')\n",
    "    # Predict validation\n",
    "    val_pred = model.predict(x_val)\n",
    "    # Add to out of folds array\n",
    "    # oof_predictions[val_ind] = val_pred\n",
    "    \n",
    "    oof_preds = model.predict_proba(x_val)[:,1]\n",
    "    \n",
    "    cids.extend(train[\"customer_ID\"].loc[val_ind])\n",
    "    tr_target.extend(train[\"target\"].loc[val_ind])\n",
    "    \n",
    "    # Predict the test set\n",
    "    test_pred = model.predict_proba(test[features])[:,1]\n",
    "    # test_pred = model.predict(test[features])\n",
    "    test_predictions += test_pred / CFG.n_folds\n",
    "    # Compute fold metric\n",
    "    score = amex_metric(y_val, val_pred)\n",
    "    print(f'Our fold {fold} CV score is {score}')\n",
    "    del x_train, x_val, y_train, y_val\n",
    "    gc.collect()\n",
    "    \n",
    "# Compute out of folds metric\n",
    "score = amex_metric(train[CFG.target], oof_predictions)\n",
    "print(f'Our out of folds CV score is {score}')\n",
    "\n",
    "\n",
    "# Create a dataframe to store test prediction\n",
    "test_df = pd.DataFrame({'customer_ID': test['customer_ID'], 'prediction': test_predictions})\n",
    "# test_df.to_csv(f'{CFG.output_dir}test_{CFG.model}_{score}_baseline_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)\n",
    "test_df.to_csv(f'{CFG.output_dir}test_{CFG.ver}_{CFG.model}_{score}_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)\n",
    "\n",
    "\n",
    "dic_oof = {\n",
    "    \"customer_ID\":cids,\n",
    "    \"target\":tr_target,\n",
    "    \"tabnet_oot\":oof_predictions\n",
    "}\n",
    "\n",
    "# Create a dataframe to store out of folds predictions\n",
    "oof_df = pd.DataFrame(dic_oof)\n",
    "# oof_df = pd.DataFrame({'customer_ID': train['customer_ID'], 'target': train[CFG.target], 'prediction': oof_predictions})\n",
    "oof_df.to_csv(f'{CFG.output_dir}oof_{CFG.ver}_{CFG.model}_{score}_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)\n",
    "\n",
    "\n",
    "# # Create a dataframe to store out of folds predictions\n",
    "# oof_df = pd.DataFrame({'customer_ID': train['customer_ID'], 'target': train[CFG.target], 'prediction': oof_predictions})\n",
    "# oof_df.to_csv(f'../output/Amex LGBM Dart CV 0.7977/oof_lgbm_{CFG.boosting_type}_baseline_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)\n",
    "\n",
    "\n",
    "# # Create a dataframe to store test prediction\n",
    "# test_df = pd.DataFrame({'customer_ID': test['customer_ID'], 'prediction': test_predictions})\n",
    "# test_df.to_csv(f'../output/Amex LGBM Dart CV 0.7977/test_lgbm_{CFG.boosting_type}_baseline_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dc8ec7-b353-4056-976f-581865e0b83b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f08ac4-d86f-4dcd-b281-4788f52bcce1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634fb39d-280e-43dd-82af-6e7d23f4e910",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca73b844-d691-4829-aeca-841426a24943",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec43c9c-9829-4275-911c-758a2bb8f8c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aeefba0-9b46-4227-b634-0a45793eb9e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f92108-afb7-45f5-b3e1-706857cb9d93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fed9500-72c1-48b4-893d-bc1fa5d7a2d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6762416b-52f6-4464-94ff-e76c6e7da87e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda1dca5-1edb-4513-82d0-b66ee1b4df81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e494e0-50f8-47ad-88c9-637a1b994414",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f770440-1df8-4a28-80c7-a3499e807a13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f3f7fd-7bd1-4e92-93a9-4a18f035feca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amex",
   "language": "python",
   "name": "amex"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
